# data


```python
%load_ext autoreload
%autoreload 2
import importlib
from importlib import reload  
  
import monotonic
import utils
from train import execute_model_evaluation
from train_config import FlatACLConfig
import train_config
import data_manager
from data_manager import DatasetManager
import metrics
from dataclasses import replace

reload(utils)
reload(monotonic)
reload(train_config)


%load_ext autoreload
%autoreload 2 
data_mgr = DatasetManager(device='cuda')
 
data_mgr.load_csv('ettm2', './ettm2.csv')
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    
    ==================================================
    Dataset: ettm2 (csv)
    ==================================================
    Shape: torch.Size([69680, 7])
    Channels: 7
    Length: 69680
    Source: ./ettm2.csv
    
    Sample data (first 2 rows):
    tensor([[41.1300, 12.4810, 36.5360,  9.3550,  4.4240,  1.3110, 38.6620],
            [39.6220, 11.3090, 35.5440,  8.5510,  3.2090,  1.2580, 38.2230]])
    ==================================================
    




    <data_manager.DatasetManager at 0x2192d9b6990>



# seq=196 Normal

### EigenACL

#### pred=96

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 34.3054, mae: 2.8383, huber: 2.4230, swd: 24.6734, ept: 81.5841
    Epoch [1/50], Val Losses: mse: 14.1841, mae: 2.3363, huber: 1.9326, swd: 7.1921, ept: 83.6130
    Epoch [1/50], Test Losses: mse: 10.7787, mae: 2.0900, huber: 1.6729, swd: 5.2718, ept: 85.9827
      Epoch 1 composite train-obj: 2.422956
            Val objective improved inf → 1.9326, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.9388, mae: 1.9913, huber: 1.5866, swd: 6.4561, ept: 89.1831
    Epoch [2/50], Val Losses: mse: 13.2810, mae: 2.2523, huber: 1.8519, swd: 6.9388, ept: 84.4499
    Epoch [2/50], Test Losses: mse: 9.7993, mae: 1.9924, huber: 1.5781, swd: 4.7983, ept: 86.8275
      Epoch 2 composite train-obj: 1.586570
            Val objective improved 1.9326 → 1.8519, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.2400, mae: 1.9261, huber: 1.5245, swd: 6.0269, ept: 89.5857
    Epoch [3/50], Val Losses: mse: 15.2520, mae: 2.4440, huber: 2.0382, swd: 8.6525, ept: 81.0286
    Epoch [3/50], Test Losses: mse: 12.2993, mae: 2.2516, huber: 1.8302, swd: 6.9789, ept: 83.3097
      Epoch 3 composite train-obj: 1.524512
            No improvement (2.0382), counter 1/5
    Epoch [4/50], Train Losses: mse: 10.8125, mae: 1.8804, huber: 1.4813, swd: 5.7298, ept: 89.8506
    Epoch [4/50], Val Losses: mse: 13.2145, mae: 2.2216, huber: 1.8237, swd: 7.1519, ept: 83.7373
    Epoch [4/50], Test Losses: mse: 10.5337, mae: 2.0211, huber: 1.6085, swd: 5.5616, ept: 85.7158
      Epoch 4 composite train-obj: 1.481301
            Val objective improved 1.8519 → 1.8237, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 10.4876, mae: 1.8474, huber: 1.4497, swd: 5.5173, ept: 90.0632
    Epoch [5/50], Val Losses: mse: 12.7304, mae: 2.1638, huber: 1.7696, swd: 6.9215, ept: 84.4727
    Epoch [5/50], Test Losses: mse: 9.4988, mae: 1.9378, huber: 1.5263, swd: 4.8006, ept: 87.3597
      Epoch 5 composite train-obj: 1.449720
            Val objective improved 1.8237 → 1.7696, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 10.1779, mae: 1.8114, huber: 1.4155, swd: 5.3037, ept: 90.2542
    Epoch [6/50], Val Losses: mse: 12.6374, mae: 2.1641, huber: 1.7727, swd: 6.8186, ept: 84.2424
    Epoch [6/50], Test Losses: mse: 9.4876, mae: 1.9130, huber: 1.5064, swd: 4.7631, ept: 86.7650
      Epoch 6 composite train-obj: 1.415530
            No improvement (1.7727), counter 1/5
    Epoch [7/50], Train Losses: mse: 9.8576, mae: 1.7944, huber: 1.3993, swd: 5.0625, ept: 90.3654
    Epoch [7/50], Val Losses: mse: 12.5543, mae: 2.1613, huber: 1.7703, swd: 6.6591, ept: 84.5001
    Epoch [7/50], Test Losses: mse: 9.5594, mae: 1.9288, huber: 1.5203, swd: 4.8476, ept: 86.9656
      Epoch 7 composite train-obj: 1.399286
            No improvement (1.7703), counter 2/5
    Epoch [8/50], Train Losses: mse: 9.5728, mae: 1.7652, huber: 1.3716, swd: 4.8588, ept: 90.5085
    Epoch [8/50], Val Losses: mse: 13.2378, mae: 2.2104, huber: 1.8210, swd: 7.2022, ept: 83.8832
    Epoch [8/50], Test Losses: mse: 9.9763, mae: 1.9421, huber: 1.5363, swd: 5.0947, ept: 85.9446
      Epoch 8 composite train-obj: 1.371650
            No improvement (1.8210), counter 3/5
    Epoch [9/50], Train Losses: mse: 9.4678, mae: 1.7590, huber: 1.3660, swd: 4.8067, ept: 90.5364
    Epoch [9/50], Val Losses: mse: 13.1640, mae: 2.1903, huber: 1.8026, swd: 7.2058, ept: 83.8130
    Epoch [9/50], Test Losses: mse: 9.7696, mae: 1.9457, huber: 1.5377, swd: 5.0026, ept: 86.4963
      Epoch 9 composite train-obj: 1.365955
            No improvement (1.8026), counter 4/5
    Epoch [10/50], Train Losses: mse: 9.3517, mae: 1.7388, huber: 1.3469, swd: 4.7303, ept: 90.6777
    Epoch [10/50], Val Losses: mse: 13.2331, mae: 2.2032, huber: 1.8157, swd: 7.0485, ept: 83.4425
    Epoch [10/50], Test Losses: mse: 10.1093, mae: 1.9476, huber: 1.5425, swd: 5.2202, ept: 85.8743
      Epoch 10 composite train-obj: 1.346858
    Epoch [10/50], Test Losses: mse: 9.4988, mae: 1.9378, huber: 1.5263, swd: 4.8006, ept: 87.3590
    Best round's Test MSE: 9.4988, MAE: 1.9378, SWD: 4.8006
    Best round's Validation MSE: 12.7304, MAE: 2.1638, SWD: 6.9215
    Best round's Test verification MSE : 9.4988, MAE: 1.9378, SWD: 4.8006
    Time taken: 104.20 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 35.0831, mae: 2.8735, huber: 2.4583, swd: 24.3582, ept: 81.4717
    Epoch [1/50], Val Losses: mse: 14.2592, mae: 2.3437, huber: 1.9420, swd: 7.0371, ept: 84.1531
    Epoch [1/50], Test Losses: mse: 10.6692, mae: 2.0977, huber: 1.6796, swd: 4.9487, ept: 87.1573
      Epoch 1 composite train-obj: 2.458268
            Val objective improved inf → 1.9420, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.9013, mae: 1.9834, huber: 1.5794, swd: 6.2660, ept: 89.2404
    Epoch [2/50], Val Losses: mse: 13.2903, mae: 2.2498, huber: 1.8513, swd: 6.8003, ept: 84.7124
    Epoch [2/50], Test Losses: mse: 9.7484, mae: 1.9996, huber: 1.5835, swd: 4.6206, ept: 87.4729
      Epoch 2 composite train-obj: 1.579387
            Val objective improved 1.9420 → 1.8513, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.2272, mae: 1.9170, huber: 1.5161, swd: 5.7983, ept: 89.6504
    Epoch [3/50], Val Losses: mse: 13.2612, mae: 2.2273, huber: 1.8292, swd: 6.7755, ept: 83.7392
    Epoch [3/50], Test Losses: mse: 10.0443, mae: 1.9873, huber: 1.5738, swd: 4.8587, ept: 86.4523
      Epoch 3 composite train-obj: 1.516054
            Val objective improved 1.8513 → 1.8292, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.7832, mae: 1.8741, huber: 1.4752, swd: 5.5006, ept: 89.8639
    Epoch [4/50], Val Losses: mse: 13.3742, mae: 2.2318, huber: 1.8369, swd: 6.8939, ept: 83.0728
    Epoch [4/50], Test Losses: mse: 10.1394, mae: 1.9828, huber: 1.5720, swd: 4.9756, ept: 85.7239
      Epoch 4 composite train-obj: 1.475164
            No improvement (1.8369), counter 1/5
    Epoch [5/50], Train Losses: mse: 10.4108, mae: 1.8343, huber: 1.4371, swd: 5.2614, ept: 90.0812
    Epoch [5/50], Val Losses: mse: 13.0341, mae: 2.1959, huber: 1.8006, swd: 6.9216, ept: 84.1099
    Epoch [5/50], Test Losses: mse: 9.4813, mae: 1.9325, huber: 1.5227, swd: 4.5797, ept: 87.0706
      Epoch 5 composite train-obj: 1.437112
            Val objective improved 1.8292 → 1.8006, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 10.2463, mae: 1.8237, huber: 1.4271, swd: 5.1751, ept: 90.1313
    Epoch [6/50], Val Losses: mse: 13.2503, mae: 2.2038, huber: 1.8122, swd: 6.9730, ept: 83.5342
    Epoch [6/50], Test Losses: mse: 9.8891, mae: 1.9547, huber: 1.5460, swd: 4.9093, ept: 86.0486
      Epoch 6 composite train-obj: 1.427096
            No improvement (1.8122), counter 1/5
    Epoch [7/50], Train Losses: mse: 9.9143, mae: 1.7936, huber: 1.3986, swd: 4.9357, ept: 90.2801
    Epoch [7/50], Val Losses: mse: 13.1180, mae: 2.1966, huber: 1.8061, swd: 6.7445, ept: 83.7403
    Epoch [7/50], Test Losses: mse: 9.6390, mae: 1.9269, huber: 1.5201, swd: 4.6256, ept: 86.5757
      Epoch 7 composite train-obj: 1.398579
            No improvement (1.8061), counter 2/5
    Epoch [8/50], Train Losses: mse: 9.7062, mae: 1.7814, huber: 1.3867, swd: 4.7859, ept: 90.3745
    Epoch [8/50], Val Losses: mse: 14.1471, mae: 2.2908, huber: 1.8966, swd: 7.5405, ept: 82.6683
    Epoch [8/50], Test Losses: mse: 10.6736, mae: 2.0287, huber: 1.6193, swd: 5.4738, ept: 85.2149
      Epoch 8 composite train-obj: 1.386737
            No improvement (1.8966), counter 3/5
    Epoch [9/50], Train Losses: mse: 9.4052, mae: 1.7485, huber: 1.3557, swd: 4.5681, ept: 90.5714
    Epoch [9/50], Val Losses: mse: 13.9587, mae: 2.2543, huber: 1.8640, swd: 7.5097, ept: 83.2540
    Epoch [9/50], Test Losses: mse: 9.8369, mae: 1.9389, huber: 1.5326, swd: 4.8072, ept: 86.0648
      Epoch 9 composite train-obj: 1.355657
            No improvement (1.8640), counter 4/5
    Epoch [10/50], Train Losses: mse: 9.3092, mae: 1.7357, huber: 1.3434, swd: 4.5129, ept: 90.6476
    Epoch [10/50], Val Losses: mse: 13.4490, mae: 2.2169, huber: 1.8281, swd: 7.1183, ept: 83.7543
    Epoch [10/50], Test Losses: mse: 9.9760, mae: 1.9446, huber: 1.5388, swd: 4.9405, ept: 86.0102
      Epoch 10 composite train-obj: 1.343388
    Epoch [10/50], Test Losses: mse: 9.4810, mae: 1.9325, huber: 1.5227, swd: 4.5793, ept: 87.0717
    Best round's Test MSE: 9.4813, MAE: 1.9325, SWD: 4.5797
    Best round's Validation MSE: 13.0341, MAE: 2.1959, SWD: 6.9216
    Best round's Test verification MSE : 9.4810, MAE: 1.9325, SWD: 4.5793
    Time taken: 120.39 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 35.1497, mae: 2.8661, huber: 2.4509, swd: 23.0202, ept: 82.0802
    Epoch [1/50], Val Losses: mse: 13.7953, mae: 2.2939, huber: 1.8919, swd: 6.3542, ept: 84.5692
    Epoch [1/50], Test Losses: mse: 9.9855, mae: 2.0088, huber: 1.5936, swd: 4.2566, ept: 87.1314
      Epoch 1 composite train-obj: 2.450865
            Val objective improved inf → 1.8919, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.9827, mae: 1.9950, huber: 1.5909, swd: 5.9058, ept: 89.2453
    Epoch [2/50], Val Losses: mse: 15.7720, mae: 2.4515, huber: 2.0481, swd: 8.0004, ept: 81.5779
    Epoch [2/50], Test Losses: mse: 12.2726, mae: 2.2346, huber: 1.8150, swd: 6.1448, ept: 84.9522
      Epoch 2 composite train-obj: 1.590905
            No improvement (2.0481), counter 1/5
    Epoch [3/50], Train Losses: mse: 11.2589, mae: 1.9195, huber: 1.5188, swd: 5.4711, ept: 89.6541
    Epoch [3/50], Val Losses: mse: 13.2767, mae: 2.2199, huber: 1.8225, swd: 6.2431, ept: 83.9277
    Epoch [3/50], Test Losses: mse: 9.9891, mae: 1.9651, huber: 1.5548, swd: 4.4105, ept: 86.7999
      Epoch 3 composite train-obj: 1.518764
            Val objective improved 1.8919 → 1.8225, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.9499, mae: 1.8892, huber: 1.4900, swd: 5.3119, ept: 89.8228
    Epoch [4/50], Val Losses: mse: 12.5733, mae: 2.1702, huber: 1.7728, swd: 5.9035, ept: 84.5084
    Epoch [4/50], Test Losses: mse: 9.4088, mae: 1.9124, huber: 1.5032, swd: 4.1718, ept: 87.0929
      Epoch 4 composite train-obj: 1.490042
            Val objective improved 1.8225 → 1.7728, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 10.5551, mae: 1.8470, huber: 1.4495, swd: 5.0382, ept: 90.0668
    Epoch [5/50], Val Losses: mse: 13.1241, mae: 2.2051, huber: 1.8103, swd: 6.2302, ept: 83.7312
    Epoch [5/50], Test Losses: mse: 10.2892, mae: 1.9872, huber: 1.5791, swd: 4.8284, ept: 86.1963
      Epoch 5 composite train-obj: 1.449487
            No improvement (1.8103), counter 1/5
    Epoch [6/50], Train Losses: mse: 10.3015, mae: 1.8189, huber: 1.4228, swd: 4.8783, ept: 90.2165
    Epoch [6/50], Val Losses: mse: 13.1863, mae: 2.2033, huber: 1.8094, swd: 6.3660, ept: 83.7711
    Epoch [6/50], Test Losses: mse: 10.1391, mae: 1.9627, huber: 1.5563, swd: 4.6824, ept: 86.0160
      Epoch 6 composite train-obj: 1.422790
            No improvement (1.8094), counter 2/5
    Epoch [7/50], Train Losses: mse: 10.1046, mae: 1.8075, huber: 1.4119, swd: 4.7664, ept: 90.3246
    Epoch [7/50], Val Losses: mse: 13.1388, mae: 2.2104, huber: 1.8155, swd: 6.2381, ept: 83.7072
    Epoch [7/50], Test Losses: mse: 10.0173, mae: 1.9515, huber: 1.5441, swd: 4.6493, ept: 86.4100
      Epoch 7 composite train-obj: 1.411889
            No improvement (1.8155), counter 3/5
    Epoch [8/50], Train Losses: mse: 9.8946, mae: 1.7882, huber: 1.3937, swd: 4.6345, ept: 90.4216
    Epoch [8/50], Val Losses: mse: 12.8328, mae: 2.1834, huber: 1.7904, swd: 6.1218, ept: 84.3765
    Epoch [8/50], Test Losses: mse: 9.6677, mae: 1.9164, huber: 1.5096, swd: 4.4954, ept: 86.9709
      Epoch 8 composite train-obj: 1.393696
            No improvement (1.7904), counter 4/5
    Epoch [9/50], Train Losses: mse: 9.6448, mae: 1.7645, huber: 1.3712, swd: 4.4694, ept: 90.5266
    Epoch [9/50], Val Losses: mse: 13.3364, mae: 2.2467, huber: 1.8516, swd: 6.5421, ept: 84.2021
    Epoch [9/50], Test Losses: mse: 9.8802, mae: 1.9811, huber: 1.5710, swd: 4.5962, ept: 87.3108
      Epoch 9 composite train-obj: 1.371190
    Epoch [9/50], Test Losses: mse: 9.4089, mae: 1.9124, huber: 1.5032, swd: 4.1719, ept: 87.0929
    Best round's Test MSE: 9.4088, MAE: 1.9124, SWD: 4.1718
    Best round's Validation MSE: 12.5733, MAE: 2.1702, SWD: 5.9035
    Best round's Test verification MSE : 9.4089, MAE: 1.9124, SWD: 4.1719
    Time taken: 115.43 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred96_20250512_1809)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.4630 ± 0.0390
      mae: 1.9276 ± 0.0109
      huber: 1.5174 ± 0.0102
      swd: 4.5174 ± 0.2605
      ept: 87.1744 ± 0.1313
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 12.7792 ± 0.1913
      mae: 2.1766 ± 0.0139
      huber: 1.7810 ± 0.0139
      swd: 6.5822 ± 0.4799
      ept: 84.3637 ± 0.1800
      count: 53.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 341.64 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred96_20250512_1809
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1820, mae: 0.2629, huber: 0.0765, swd: 0.0887, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1584, mae: 0.2622, huber: 0.0762, swd: 0.0685, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1170, mae: 0.2324, huber: 0.0571, swd: 0.0503, target_std: 0.7443
      Epoch 1 composite train-obj: 0.076452
            Val objective improved inf → 0.0762, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1306, mae: 0.2247, huber: 0.0569, swd: 0.0535, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1579, mae: 0.2609, huber: 0.0759, swd: 0.0695, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1170, mae: 0.2312, huber: 0.0570, swd: 0.0503, target_std: 0.7443
      Epoch 2 composite train-obj: 0.056949
            Val objective improved 0.0762 → 0.0759, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1182, mae: 0.2162, huber: 0.0527, swd: 0.0468, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1576, mae: 0.2581, huber: 0.0755, swd: 0.0684, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1195, mae: 0.2310, huber: 0.0580, swd: 0.0518, target_std: 0.7443
      Epoch 3 composite train-obj: 0.052669
            Val objective improved 0.0759 → 0.0755, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1124, mae: 0.2115, huber: 0.0503, swd: 0.0437, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1610, mae: 0.2595, huber: 0.0765, swd: 0.0680, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1236, mae: 0.2330, huber: 0.0597, swd: 0.0549, target_std: 0.7443
      Epoch 4 composite train-obj: 0.050338
            No improvement (0.0765), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.1080, mae: 0.2075, huber: 0.0485, swd: 0.0415, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1685, mae: 0.2664, huber: 0.0802, swd: 0.0739, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1300, mae: 0.2398, huber: 0.0627, swd: 0.0606, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048485
            No improvement (0.0802), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.1046, mae: 0.2047, huber: 0.0470, swd: 0.0399, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1766, mae: 0.2738, huber: 0.0835, swd: 0.0793, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1356, mae: 0.2465, huber: 0.0653, swd: 0.0645, target_std: 0.7443
      Epoch 6 composite train-obj: 0.047026
            No improvement (0.0835), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.1008, mae: 0.2015, huber: 0.0455, swd: 0.0382, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1907, mae: 0.2850, huber: 0.0895, swd: 0.0868, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1477, mae: 0.2553, huber: 0.0705, swd: 0.0717, target_std: 0.7443
      Epoch 7 composite train-obj: 0.045466
            No improvement (0.0895), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.0981, mae: 0.1997, huber: 0.0444, swd: 0.0370, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1780, mae: 0.2764, huber: 0.0844, swd: 0.0837, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1370, mae: 0.2446, huber: 0.0658, swd: 0.0655, target_std: 0.7443
      Epoch 8 composite train-obj: 0.044362
    Epoch [8/50], Test Losses: mse: 0.1195, mae: 0.2310, huber: 0.0580, swd: 0.0518, target_std: 0.7443
    Best round's Test MSE: 0.1195, MAE: 0.2310, SWD: 0.0518
    Best round's Validation MSE: 0.1576, MAE: 0.2581
    Best round's Test verification MSE : 0.1195, MAE: 0.2310, SWD: 0.0518
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1797, mae: 0.2614, huber: 0.0758, swd: 0.0866, target_std: 0.7858
    Epoch [1/50], Val Losses: mse: 0.1605, mae: 0.2685, huber: 0.0774, swd: 0.0722, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1192, mae: 0.2355, huber: 0.0581, swd: 0.0517, target_std: 0.7443
      Epoch 1 composite train-obj: 0.075769
            Val objective improved inf → 0.0774, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1314, mae: 0.2256, huber: 0.0573, swd: 0.0532, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1660, mae: 0.2766, huber: 0.0798, swd: 0.0790, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1230, mae: 0.2385, huber: 0.0599, swd: 0.0583, target_std: 0.7443
      Epoch 2 composite train-obj: 0.057259
            No improvement (0.0798), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1188, mae: 0.2171, huber: 0.0530, swd: 0.0465, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1615, mae: 0.2673, huber: 0.0778, swd: 0.0728, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1225, mae: 0.2348, huber: 0.0594, swd: 0.0566, target_std: 0.7443
      Epoch 3 composite train-obj: 0.053016
            No improvement (0.0778), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1125, mae: 0.2123, huber: 0.0505, swd: 0.0430, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1646, mae: 0.2660, huber: 0.0790, swd: 0.0727, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1264, mae: 0.2363, huber: 0.0610, swd: 0.0573, target_std: 0.7443
      Epoch 4 composite train-obj: 0.050499
            No improvement (0.0790), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1080, mae: 0.2080, huber: 0.0486, swd: 0.0408, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1784, mae: 0.2764, huber: 0.0846, swd: 0.0793, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1340, mae: 0.2424, huber: 0.0642, swd: 0.0603, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048556
            No improvement (0.0846), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1045, mae: 0.2052, huber: 0.0471, swd: 0.0392, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1732, mae: 0.2715, huber: 0.0820, swd: 0.0724, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1378, mae: 0.2424, huber: 0.0659, swd: 0.0591, target_std: 0.7443
      Epoch 6 composite train-obj: 0.047073
    Epoch [6/50], Test Losses: mse: 0.1192, mae: 0.2355, huber: 0.0581, swd: 0.0517, target_std: 0.7443
    Best round's Test MSE: 0.1192, MAE: 0.2355, SWD: 0.0517
    Best round's Validation MSE: 0.1605, MAE: 0.2685
    Best round's Test verification MSE : 0.1192, MAE: 0.2355, SWD: 0.0517
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1831, mae: 0.2659, huber: 0.0773, swd: 0.0807, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1643, mae: 0.2742, huber: 0.0793, swd: 0.0676, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1208, mae: 0.2385, huber: 0.0588, swd: 0.0491, target_std: 0.7443
      Epoch 1 composite train-obj: 0.077317
            Val objective improved inf → 0.0793, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1322, mae: 0.2255, huber: 0.0574, swd: 0.0502, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1563, mae: 0.2601, huber: 0.0753, swd: 0.0625, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1187, mae: 0.2320, huber: 0.0578, swd: 0.0481, target_std: 0.7443
      Epoch 2 composite train-obj: 0.057386
            Val objective improved 0.0793 → 0.0753, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1213, mae: 0.2187, huber: 0.0538, swd: 0.0452, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1597, mae: 0.2619, huber: 0.0766, swd: 0.0605, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1185, mae: 0.2311, huber: 0.0577, swd: 0.0459, target_std: 0.7443
      Epoch 3 composite train-obj: 0.053806
            No improvement (0.0766), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1140, mae: 0.2130, huber: 0.0510, swd: 0.0411, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1631, mae: 0.2625, huber: 0.0778, swd: 0.0644, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1230, mae: 0.2331, huber: 0.0595, swd: 0.0514, target_std: 0.7443
      Epoch 4 composite train-obj: 0.051031
            No improvement (0.0778), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1089, mae: 0.2082, huber: 0.0488, swd: 0.0386, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1706, mae: 0.2717, huber: 0.0813, swd: 0.0722, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1268, mae: 0.2387, huber: 0.0613, swd: 0.0543, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048846
            No improvement (0.0813), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1053, mae: 0.2054, huber: 0.0473, swd: 0.0371, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1659, mae: 0.2612, huber: 0.0788, swd: 0.0653, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1296, mae: 0.2373, huber: 0.0624, swd: 0.0550, target_std: 0.7443
      Epoch 6 composite train-obj: 0.047291
            No improvement (0.0788), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1018, mae: 0.2022, huber: 0.0458, swd: 0.0357, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1859, mae: 0.2740, huber: 0.0869, swd: 0.0737, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1412, mae: 0.2442, huber: 0.0672, swd: 0.0586, target_std: 0.7443
      Epoch 7 composite train-obj: 0.045817
    Epoch [7/50], Test Losses: mse: 0.1187, mae: 0.2320, huber: 0.0578, swd: 0.0481, target_std: 0.7443
    Best round's Test MSE: 0.1187, MAE: 0.2320, SWD: 0.0481
    Best round's Validation MSE: 0.1563, MAE: 0.2601
    Best round's Test verification MSE : 0.1187, MAE: 0.2320, SWD: 0.0481
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred96_20250430_2328)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1191 ± 0.0003
      mae: 0.2328 ± 0.0019
      huber: 0.0579 ± 0.0001
      swd: 0.0505 ± 0.0017
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1581 ± 0.0018
      mae: 0.2622 ± 0.0045
      huber: 0.0761 ± 0.0009
      swd: 0.0677 ± 0.0040
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq196_pred96_20250430_2328
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=True,
    householder_reflects_latent = 4,
    householder_reflects_data = 8,
    mixing_strategy='delay_only',
    # single_magnitude_for_shift=True,

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1817, mae: 0.2626, huber: 0.0765, swd: 0.0868, target_std: 0.7858
    Epoch [1/50], Val Losses: mse: 0.1570, mae: 0.2628, huber: 0.0757, swd: 0.0663, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1162, mae: 0.2327, huber: 0.0568, swd: 0.0487, target_std: 0.7443
      Epoch 1 composite train-obj: 0.076501
            Val objective improved inf → 0.0757, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1305, mae: 0.2239, huber: 0.0566, swd: 0.0537, target_std: 0.7858
    Epoch [2/50], Val Losses: mse: 0.1590, mae: 0.2633, huber: 0.0764, swd: 0.0721, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1245, mae: 0.2373, huber: 0.0602, swd: 0.0590, target_std: 0.7443
      Epoch 2 composite train-obj: 0.056646
            No improvement (0.0764), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1189, mae: 0.2163, huber: 0.0526, swd: 0.0478, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1671, mae: 0.2702, huber: 0.0796, swd: 0.0757, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1365, mae: 0.2472, huber: 0.0655, swd: 0.0647, target_std: 0.7443
      Epoch 3 composite train-obj: 0.052638
            No improvement (0.0796), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1115, mae: 0.2113, huber: 0.0499, swd: 0.0435, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1642, mae: 0.2700, huber: 0.0789, swd: 0.0800, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1288, mae: 0.2427, huber: 0.0624, swd: 0.0637, target_std: 0.7443
      Epoch 4 composite train-obj: 0.049920
            No improvement (0.0789), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1066, mae: 0.2071, huber: 0.0479, swd: 0.0410, target_std: 0.7858
    Epoch [5/50], Val Losses: mse: 0.1668, mae: 0.2662, huber: 0.0795, swd: 0.0730, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1339, mae: 0.2431, huber: 0.0641, swd: 0.0612, target_std: 0.7443
      Epoch 5 composite train-obj: 0.047916
            No improvement (0.0795), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1023, mae: 0.2038, huber: 0.0461, swd: 0.0389, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1674, mae: 0.2682, huber: 0.0800, swd: 0.0765, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1299, mae: 0.2425, huber: 0.0628, swd: 0.0605, target_std: 0.7443
      Epoch 6 composite train-obj: 0.046141
    Epoch [6/50], Test Losses: mse: 0.1162, mae: 0.2327, huber: 0.0568, swd: 0.0487, target_std: 0.7443
    Best round's Test MSE: 0.1162, MAE: 0.2327, SWD: 0.0487
    Best round's Validation MSE: 0.1570, MAE: 0.2628
    Best round's Test verification MSE : 0.1162, MAE: 0.2327, SWD: 0.0487
    Time taken: 90.17 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1847, mae: 0.2677, huber: 0.0783, swd: 0.0869, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1591, mae: 0.2666, huber: 0.0767, swd: 0.0682, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1188, mae: 0.2352, huber: 0.0579, swd: 0.0509, target_std: 0.7443
      Epoch 1 composite train-obj: 0.078261
            Val objective improved inf → 0.0767, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1321, mae: 0.2266, huber: 0.0576, swd: 0.0537, target_std: 0.7858
    Epoch [2/50], Val Losses: mse: 0.1588, mae: 0.2629, huber: 0.0765, swd: 0.0659, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1188, mae: 0.2332, huber: 0.0579, swd: 0.0487, target_std: 0.7443
      Epoch 2 composite train-obj: 0.057550
            Val objective improved 0.0767 → 0.0765, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1194, mae: 0.2182, huber: 0.0531, swd: 0.0471, target_std: 0.7858
    Epoch [3/50], Val Losses: mse: 0.1647, mae: 0.2675, huber: 0.0791, swd: 0.0725, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1254, mae: 0.2381, huber: 0.0607, swd: 0.0564, target_std: 0.7443
      Epoch 3 composite train-obj: 0.053142
            No improvement (0.0791), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1115, mae: 0.2120, huber: 0.0500, swd: 0.0429, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1710, mae: 0.2707, huber: 0.0814, swd: 0.0727, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1306, mae: 0.2405, huber: 0.0627, swd: 0.0569, target_std: 0.7443
      Epoch 4 composite train-obj: 0.050018
            No improvement (0.0814), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1066, mae: 0.2084, huber: 0.0480, swd: 0.0405, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1770, mae: 0.2718, huber: 0.0838, swd: 0.0796, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1353, mae: 0.2427, huber: 0.0649, swd: 0.0615, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048038
            No improvement (0.0838), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1018, mae: 0.2043, huber: 0.0461, swd: 0.0380, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1767, mae: 0.2735, huber: 0.0837, swd: 0.0778, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1337, mae: 0.2426, huber: 0.0642, swd: 0.0610, target_std: 0.7443
      Epoch 6 composite train-obj: 0.046066
            No improvement (0.0837), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.0982, mae: 0.2013, huber: 0.0446, swd: 0.0358, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1798, mae: 0.2753, huber: 0.0846, swd: 0.0767, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1460, mae: 0.2508, huber: 0.0696, swd: 0.0647, target_std: 0.7443
      Epoch 7 composite train-obj: 0.044557
    Epoch [7/50], Test Losses: mse: 0.1188, mae: 0.2332, huber: 0.0579, swd: 0.0487, target_std: 0.7443
    Best round's Test MSE: 0.1188, MAE: 0.2332, SWD: 0.0487
    Best round's Validation MSE: 0.1588, MAE: 0.2629
    Best round's Test verification MSE : 0.1188, MAE: 0.2332, SWD: 0.0487
    Time taken: 101.72 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1778, mae: 0.2614, huber: 0.0754, swd: 0.0763, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1713, mae: 0.2863, huber: 0.0826, swd: 0.0795, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1241, mae: 0.2436, huber: 0.0604, swd: 0.0568, target_std: 0.7443
      Epoch 1 composite train-obj: 0.075365
            Val objective improved inf → 0.0826, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1292, mae: 0.2240, huber: 0.0565, swd: 0.0485, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1609, mae: 0.2701, huber: 0.0775, swd: 0.0690, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1244, mae: 0.2411, huber: 0.0605, swd: 0.0561, target_std: 0.7443
      Epoch 2 composite train-obj: 0.056471
            Val objective improved 0.0826 → 0.0775, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1182, mae: 0.2163, huber: 0.0525, swd: 0.0436, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1652, mae: 0.2633, huber: 0.0783, swd: 0.0631, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1267, mae: 0.2367, huber: 0.0609, swd: 0.0500, target_std: 0.7443
      Epoch 3 composite train-obj: 0.052531
            No improvement (0.0783), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1110, mae: 0.2106, huber: 0.0497, swd: 0.0401, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1689, mae: 0.2655, huber: 0.0797, swd: 0.0665, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1378, mae: 0.2429, huber: 0.0654, swd: 0.0562, target_std: 0.7443
      Epoch 4 composite train-obj: 0.049729
            No improvement (0.0797), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1050, mae: 0.2057, huber: 0.0473, swd: 0.0372, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1727, mae: 0.2675, huber: 0.0812, swd: 0.0656, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1394, mae: 0.2438, huber: 0.0664, swd: 0.0553, target_std: 0.7443
      Epoch 5 composite train-obj: 0.047296
            No improvement (0.0812), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1010, mae: 0.2029, huber: 0.0457, swd: 0.0353, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1704, mae: 0.2667, huber: 0.0809, swd: 0.0698, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1377, mae: 0.2454, huber: 0.0661, swd: 0.0592, target_std: 0.7443
      Epoch 6 composite train-obj: 0.045723
            No improvement (0.0809), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.0968, mae: 0.1998, huber: 0.0440, swd: 0.0329, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1757, mae: 0.2745, huber: 0.0835, swd: 0.0711, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1375, mae: 0.2466, huber: 0.0660, swd: 0.0586, target_std: 0.7443
      Epoch 7 composite train-obj: 0.044036
    Epoch [7/50], Test Losses: mse: 0.1244, mae: 0.2411, huber: 0.0605, swd: 0.0561, target_std: 0.7443
    Best round's Test MSE: 0.1244, MAE: 0.2411, SWD: 0.0561
    Best round's Validation MSE: 0.1609, MAE: 0.2701
    Best round's Test verification MSE : 0.1244, MAE: 0.2411, SWD: 0.0561
    Time taken: 100.00 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred96_20250503_1601)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1198 ± 0.0034
      mae: 0.2357 ± 0.0039
      huber: 0.0584 ± 0.0016
      swd: 0.0512 ± 0.0035
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1589 ± 0.0016
      mae: 0.2652 ± 0.0034
      huber: 0.0766 ± 0.0007
      swd: 0.0671 ± 0.0014
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 291.99 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred96_20250503_1601
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### ab: (8, 4) rotations


```python
importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=True,
    householder_reflects_latent = 2,
    householder_reflects_data = 6,
    mixing_strategy='delay_only',
    # single_magnitude_for_shift=True,

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1846, mae: 0.2646, huber: 0.0775, swd: 0.0886, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1605, mae: 0.2685, huber: 0.0774, swd: 0.0718, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1181, mae: 0.2355, huber: 0.0576, swd: 0.0522, target_std: 0.7443
      Epoch 1 composite train-obj: 0.077478
            Val objective improved inf → 0.0774, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1324, mae: 0.2256, huber: 0.0574, swd: 0.0544, target_std: 0.7858
    Epoch [2/50], Val Losses: mse: 0.1587, mae: 0.2615, huber: 0.0763, swd: 0.0679, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1194, mae: 0.2323, huber: 0.0581, swd: 0.0526, target_std: 0.7443
      Epoch 2 composite train-obj: 0.057427
            Val objective improved 0.0774 → 0.0763, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1223, mae: 0.2191, huber: 0.0540, swd: 0.0495, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1658, mae: 0.2727, huber: 0.0796, swd: 0.0803, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1273, mae: 0.2418, huber: 0.0618, swd: 0.0650, target_std: 0.7443
      Epoch 3 composite train-obj: 0.054032
            No improvement (0.0796), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1142, mae: 0.2133, huber: 0.0511, swd: 0.0448, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1721, mae: 0.2736, huber: 0.0818, swd: 0.0806, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1352, mae: 0.2444, huber: 0.0651, swd: 0.0679, target_std: 0.7443
      Epoch 4 composite train-obj: 0.051057
            No improvement (0.0818), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1091, mae: 0.2093, huber: 0.0490, swd: 0.0420, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1695, mae: 0.2704, huber: 0.0811, swd: 0.0794, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1323, mae: 0.2410, huber: 0.0639, swd: 0.0636, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048960
            No improvement (0.0811), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1052, mae: 0.2064, huber: 0.0474, swd: 0.0402, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1648, mae: 0.2646, huber: 0.0788, swd: 0.0743, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1275, mae: 0.2374, huber: 0.0617, swd: 0.0595, target_std: 0.7443
      Epoch 6 composite train-obj: 0.047395
            No improvement (0.0788), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1012, mae: 0.2027, huber: 0.0457, swd: 0.0381, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1744, mae: 0.2716, huber: 0.0830, swd: 0.0771, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1369, mae: 0.2437, huber: 0.0655, swd: 0.0608, target_std: 0.7443
      Epoch 7 composite train-obj: 0.045734
    Epoch [7/50], Test Losses: mse: 0.1194, mae: 0.2323, huber: 0.0581, swd: 0.0526, target_std: 0.7443
    Best round's Test MSE: 0.1194, MAE: 0.2323, SWD: 0.0526
    Best round's Validation MSE: 0.1587, MAE: 0.2615
    Best round's Test verification MSE : 0.1194, MAE: 0.2323, SWD: 0.0526
    Time taken: 90.75 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1849, mae: 0.2668, huber: 0.0780, swd: 0.0870, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1603, mae: 0.2697, huber: 0.0774, swd: 0.0696, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1199, mae: 0.2371, huber: 0.0585, swd: 0.0511, target_std: 0.7443
      Epoch 1 composite train-obj: 0.078031
            Val objective improved inf → 0.0774, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1341, mae: 0.2280, huber: 0.0583, swd: 0.0540, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1563, mae: 0.2592, huber: 0.0752, swd: 0.0637, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1176, mae: 0.2327, huber: 0.0574, swd: 0.0490, target_std: 0.7443
      Epoch 2 composite train-obj: 0.058310
            Val objective improved 0.0774 → 0.0752, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1225, mae: 0.2197, huber: 0.0543, swd: 0.0482, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1612, mae: 0.2674, huber: 0.0774, swd: 0.0743, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1237, mae: 0.2392, huber: 0.0602, swd: 0.0599, target_std: 0.7443
      Epoch 3 composite train-obj: 0.054276
            No improvement (0.0774), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1162, mae: 0.2148, huber: 0.0518, swd: 0.0452, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1643, mae: 0.2645, huber: 0.0784, swd: 0.0698, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1272, mae: 0.2395, huber: 0.0615, swd: 0.0570, target_std: 0.7443
      Epoch 4 composite train-obj: 0.051835
            No improvement (0.0784), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1110, mae: 0.2106, huber: 0.0497, swd: 0.0426, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1724, mae: 0.2729, huber: 0.0820, swd: 0.0757, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1325, mae: 0.2440, huber: 0.0639, swd: 0.0615, target_std: 0.7443
      Epoch 5 composite train-obj: 0.049743
            No improvement (0.0820), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1066, mae: 0.2071, huber: 0.0479, swd: 0.0405, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1642, mae: 0.2645, huber: 0.0785, swd: 0.0709, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1305, mae: 0.2377, huber: 0.0625, swd: 0.0578, target_std: 0.7443
      Epoch 6 composite train-obj: 0.047927
            No improvement (0.0785), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1035, mae: 0.2048, huber: 0.0467, swd: 0.0392, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1657, mae: 0.2643, huber: 0.0790, swd: 0.0704, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1287, mae: 0.2387, huber: 0.0622, swd: 0.0575, target_std: 0.7443
      Epoch 7 composite train-obj: 0.046722
    Epoch [7/50], Test Losses: mse: 0.1176, mae: 0.2327, huber: 0.0574, swd: 0.0490, target_std: 0.7443
    Best round's Test MSE: 0.1176, MAE: 0.2327, SWD: 0.0490
    Best round's Validation MSE: 0.1563, MAE: 0.2592
    Best round's Test verification MSE : 0.1176, MAE: 0.2327, SWD: 0.0490
    Time taken: 93.24 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1797, mae: 0.2621, huber: 0.0760, swd: 0.0778, target_std: 0.7858
    Epoch [1/50], Val Losses: mse: 0.1597, mae: 0.2647, huber: 0.0769, swd: 0.0609, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1186, mae: 0.2340, huber: 0.0578, swd: 0.0450, target_std: 0.7443
      Epoch 1 composite train-obj: 0.076012
            Val objective improved inf → 0.0769, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1307, mae: 0.2243, huber: 0.0568, swd: 0.0492, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1554, mae: 0.2575, huber: 0.0748, swd: 0.0606, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1154, mae: 0.2291, huber: 0.0562, swd: 0.0450, target_std: 0.7443
      Epoch 2 composite train-obj: 0.056809
            Val objective improved 0.0769 → 0.0748, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1193, mae: 0.2163, huber: 0.0529, swd: 0.0440, target_std: 0.7858
    Epoch [3/50], Val Losses: mse: 0.1538, mae: 0.2570, huber: 0.0740, swd: 0.0594, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1197, mae: 0.2310, huber: 0.0582, swd: 0.0481, target_std: 0.7443
      Epoch 3 composite train-obj: 0.052870
            Val objective improved 0.0748 → 0.0740, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1125, mae: 0.2113, huber: 0.0503, swd: 0.0404, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1523, mae: 0.2550, huber: 0.0735, swd: 0.0590, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1183, mae: 0.2300, huber: 0.0576, swd: 0.0471, target_std: 0.7443
      Epoch 4 composite train-obj: 0.050316
            Val objective improved 0.0740 → 0.0735, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.1080, mae: 0.2075, huber: 0.0484, swd: 0.0383, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1617, mae: 0.2620, huber: 0.0774, swd: 0.0656, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1311, mae: 0.2400, huber: 0.0631, swd: 0.0558, target_std: 0.7443
      Epoch 5 composite train-obj: 0.048435
            No improvement (0.0774), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.1039, mae: 0.2043, huber: 0.0468, swd: 0.0365, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1663, mae: 0.2655, huber: 0.0796, swd: 0.0657, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1257, mae: 0.2374, huber: 0.0609, swd: 0.0490, target_std: 0.7443
      Epoch 6 composite train-obj: 0.046787
            No improvement (0.0796), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.1001, mae: 0.2015, huber: 0.0453, swd: 0.0348, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1772, mae: 0.2746, huber: 0.0842, swd: 0.0761, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1408, mae: 0.2465, huber: 0.0671, swd: 0.0601, target_std: 0.7443
      Epoch 7 composite train-obj: 0.045261
            No improvement (0.0842), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.0968, mae: 0.1992, huber: 0.0440, swd: 0.0332, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1865, mae: 0.2835, huber: 0.0880, swd: 0.0848, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1529, mae: 0.2606, huber: 0.0726, swd: 0.0695, target_std: 0.7443
      Epoch 8 composite train-obj: 0.043964
            No improvement (0.0880), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.0934, mae: 0.1968, huber: 0.0426, swd: 0.0311, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1803, mae: 0.2734, huber: 0.0853, swd: 0.0804, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1471, mae: 0.2532, huber: 0.0701, swd: 0.0663, target_std: 0.7443
      Epoch 9 composite train-obj: 0.042645
    Epoch [9/50], Test Losses: mse: 0.1183, mae: 0.2300, huber: 0.0576, swd: 0.0471, target_std: 0.7443
    Best round's Test MSE: 0.1183, MAE: 0.2300, SWD: 0.0471
    Best round's Validation MSE: 0.1523, MAE: 0.2550
    Best round's Test verification MSE : 0.1183, MAE: 0.2300, SWD: 0.0471
    Time taken: 120.97 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred96_20250503_1642)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1184 ± 0.0007
      mae: 0.2317 ± 0.0012
      huber: 0.0577 ± 0.0003
      swd: 0.0496 ± 0.0023
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1557 ± 0.0026
      mae: 0.2586 ± 0.0027
      huber: 0.0750 ± 0.0012
      swd: 0.0635 ± 0.0036
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 305.07 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred96_20250503_1642
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.0610, mae: 3.1310, huber: 2.7112, swd: 26.7754, ept: 152.3816
    Epoch [1/50], Val Losses: mse: 22.6566, mae: 2.9412, huber: 2.5278, swd: 11.8180, ept: 141.7295
    Epoch [1/50], Test Losses: mse: 16.9495, mae: 2.6430, huber: 2.2165, swd: 8.9233, ept: 150.9429
      Epoch 1 composite train-obj: 2.711245
            Val objective improved inf → 2.5278, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 16.6228, mae: 2.3018, huber: 1.8912, swd: 8.8570, ept: 168.7431
    Epoch [2/50], Val Losses: mse: 19.6907, mae: 2.7715, huber: 2.3573, swd: 9.1876, ept: 147.9466
    Epoch [2/50], Test Losses: mse: 14.7718, mae: 2.5190, huber: 2.0883, swd: 6.2356, ept: 155.1369
      Epoch 2 composite train-obj: 1.891217
            Val objective improved 2.5278 → 2.3573, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 15.8519, mae: 2.2376, huber: 1.8296, swd: 8.3222, ept: 170.4339
    Epoch [3/50], Val Losses: mse: 19.5080, mae: 2.7517, huber: 2.3399, swd: 9.9606, ept: 150.5973
    Epoch [3/50], Test Losses: mse: 14.1847, mae: 2.4332, huber: 2.0088, swd: 6.3766, ept: 160.5485
      Epoch 3 composite train-obj: 1.829597
            Val objective improved 2.3573 → 2.3399, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 15.4002, mae: 2.1933, huber: 1.7869, swd: 8.1099, ept: 171.4189
    Epoch [4/50], Val Losses: mse: 20.4311, mae: 2.8454, huber: 2.4348, swd: 12.2882, ept: 152.1170
    Epoch [4/50], Test Losses: mse: 13.6095, mae: 2.4079, huber: 1.9837, swd: 7.2296, ept: 162.7942
      Epoch 4 composite train-obj: 1.786948
            No improvement (2.4348), counter 1/5
    Epoch [5/50], Train Losses: mse: 14.9185, mae: 2.1590, huber: 1.7537, swd: 7.7257, ept: 172.0673
    Epoch [5/50], Val Losses: mse: 19.1926, mae: 2.7220, huber: 2.3143, swd: 10.2485, ept: 153.0936
    Epoch [5/50], Test Losses: mse: 12.8123, mae: 2.3042, huber: 1.8832, swd: 5.7809, ept: 163.0199
      Epoch 5 composite train-obj: 1.753715
            Val objective improved 2.3399 → 2.3143, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 14.7145, mae: 2.1413, huber: 1.7369, swd: 7.5650, ept: 172.3953
    Epoch [6/50], Val Losses: mse: 17.5796, mae: 2.6037, huber: 2.1979, swd: 9.0029, ept: 153.9069
    Epoch [6/50], Test Losses: mse: 12.7302, mae: 2.2658, huber: 1.8445, swd: 6.2132, ept: 162.2688
      Epoch 6 composite train-obj: 1.736940
            Val objective improved 2.3143 → 2.1979, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 14.2307, mae: 2.1058, huber: 1.7020, swd: 7.1620, ept: 172.8990
    Epoch [7/50], Val Losses: mse: 23.0398, mae: 3.0693, huber: 2.6617, swd: 14.7101, ept: 145.1756
    Epoch [7/50], Test Losses: mse: 15.8238, mae: 2.5917, huber: 2.1686, swd: 9.2136, ept: 160.1056
      Epoch 7 composite train-obj: 1.702039
            No improvement (2.6617), counter 1/5
    Epoch [8/50], Train Losses: mse: 13.9978, mae: 2.0918, huber: 1.6888, swd: 6.9703, ept: 173.1288
    Epoch [8/50], Val Losses: mse: 18.8202, mae: 2.6925, huber: 2.2892, swd: 9.9329, ept: 152.4620
    Epoch [8/50], Test Losses: mse: 13.3397, mae: 2.3106, huber: 1.8922, swd: 6.2687, ept: 159.4814
      Epoch 8 composite train-obj: 1.688758
            No improvement (2.2892), counter 2/5
    Epoch [9/50], Train Losses: mse: 13.6916, mae: 2.0717, huber: 1.6695, swd: 6.8055, ept: 173.4961
    Epoch [9/50], Val Losses: mse: 26.9901, mae: 3.2195, huber: 2.8118, swd: 17.4355, ept: 140.2813
    Epoch [9/50], Test Losses: mse: 23.3888, mae: 3.1017, huber: 2.6699, swd: 15.8213, ept: 143.3477
      Epoch 9 composite train-obj: 1.669507
            No improvement (2.8118), counter 3/5
    Epoch [10/50], Train Losses: mse: 13.5144, mae: 2.0587, huber: 1.6572, swd: 6.6784, ept: 173.6449
    Epoch [10/50], Val Losses: mse: 18.4996, mae: 2.6183, huber: 2.2181, swd: 9.9037, ept: 153.1794
    Epoch [10/50], Test Losses: mse: 13.7000, mae: 2.2905, huber: 1.8714, swd: 7.0069, ept: 160.6335
      Epoch 10 composite train-obj: 1.657237
            No improvement (2.2181), counter 4/5
    Epoch [11/50], Train Losses: mse: 13.1005, mae: 2.0213, huber: 1.6211, swd: 6.3874, ept: 174.3801
    Epoch [11/50], Val Losses: mse: 21.5626, mae: 2.8547, huber: 2.4547, swd: 12.1312, ept: 145.7153
    Epoch [11/50], Test Losses: mse: 16.8147, mae: 2.5708, huber: 2.1495, swd: 9.2204, ept: 148.7351
      Epoch 11 composite train-obj: 1.621121
    Epoch [11/50], Test Losses: mse: 12.7306, mae: 2.2658, huber: 1.8445, swd: 6.2135, ept: 162.2696
    Best round's Test MSE: 12.7302, MAE: 2.2658, SWD: 6.2132
    Best round's Validation MSE: 17.5796, MAE: 2.6037, SWD: 9.0029
    Best round's Test verification MSE : 12.7306, MAE: 2.2658, SWD: 6.2135
    Time taken: 148.58 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 40.2680, mae: 3.2101, huber: 2.7895, swd: 29.3471, ept: 150.9027
    Epoch [1/50], Val Losses: mse: 135.1547, mae: 7.2344, huber: 6.8062, swd: 123.1729, ept: 108.3820
    Epoch [1/50], Test Losses: mse: 116.3153, mae: 7.4437, huber: 6.9900, swd: 107.7815, ept: 79.3198
      Epoch 1 composite train-obj: 2.789530
            Val objective improved inf → 6.8062, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 18.8205, mae: 2.4487, huber: 2.0361, swd: 11.1600, ept: 165.2644
    Epoch [2/50], Val Losses: mse: 18.4111, mae: 2.6569, huber: 2.2426, swd: 9.9609, ept: 155.7820
    Epoch [2/50], Test Losses: mse: 12.9216, mae: 2.3603, huber: 1.9277, swd: 6.6628, ept: 165.0201
      Epoch 2 composite train-obj: 2.036111
            Val objective improved 6.8062 → 2.2426, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 16.2568, mae: 2.2575, huber: 1.8493, swd: 9.0036, ept: 170.2669
    Epoch [3/50], Val Losses: mse: 27.2017, mae: 3.3313, huber: 2.9165, swd: 20.2128, ept: 140.0701
    Epoch [3/50], Test Losses: mse: 18.8597, mae: 2.9273, huber: 2.4956, swd: 13.4357, ept: 157.9370
      Epoch 3 composite train-obj: 1.849258
            No improvement (2.9165), counter 1/5
    Epoch [4/50], Train Losses: mse: 16.4917, mae: 2.2684, huber: 1.8607, swd: 9.3076, ept: 169.9571
    Epoch [4/50], Val Losses: mse: 30.4140, mae: 3.4108, huber: 2.9968, swd: 19.2974, ept: 133.2276
    Epoch [4/50], Test Losses: mse: 25.5250, mae: 3.2463, huber: 2.8140, swd: 16.6986, ept: 136.3946
      Epoch 4 composite train-obj: 1.860715
            No improvement (2.9968), counter 2/5
    Epoch [5/50], Train Losses: mse: 15.6754, mae: 2.2172, huber: 1.8109, swd: 8.5715, ept: 170.7008
    Epoch [5/50], Val Losses: mse: 18.8152, mae: 2.7420, huber: 2.3326, swd: 10.5550, ept: 152.5849
    Epoch [5/50], Test Losses: mse: 12.6217, mae: 2.3162, huber: 1.8912, swd: 6.3856, ept: 165.0654
      Epoch 5 composite train-obj: 1.810877
            No improvement (2.3326), counter 3/5
    Epoch [6/50], Train Losses: mse: 15.0138, mae: 2.1620, huber: 1.7571, swd: 8.0709, ept: 172.0481
    Epoch [6/50], Val Losses: mse: 20.8720, mae: 2.8226, huber: 2.4155, swd: 10.9023, ept: 146.0247
    Epoch [6/50], Test Losses: mse: 14.8431, mae: 2.4231, huber: 2.0027, swd: 7.2010, ept: 157.6056
      Epoch 6 composite train-obj: 1.757067
            No improvement (2.4155), counter 4/5
    Epoch [7/50], Train Losses: mse: 14.8164, mae: 2.1465, huber: 1.7420, swd: 7.9278, ept: 172.1092
    Epoch [7/50], Val Losses: mse: 32.3578, mae: 3.6579, huber: 3.2391, swd: 22.3795, ept: 131.4720
    Epoch [7/50], Test Losses: mse: 25.9626, mae: 3.3558, huber: 2.9123, swd: 18.5988, ept: 138.9358
      Epoch 7 composite train-obj: 1.742007
    Epoch [7/50], Test Losses: mse: 12.9216, mae: 2.3603, huber: 1.9277, swd: 6.6628, ept: 165.0201
    Best round's Test MSE: 12.9216, MAE: 2.3603, SWD: 6.6628
    Best round's Validation MSE: 18.4111, MAE: 2.6569, SWD: 9.9609
    Best round's Test verification MSE : 12.9216, MAE: 2.3603, SWD: 6.6628
    Time taken: 90.62 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.2833, mae: 3.1292, huber: 2.7093, swd: 23.5283, ept: 152.5689
    Epoch [1/50], Val Losses: mse: 21.8784, mae: 2.9329, huber: 2.5173, swd: 10.0018, ept: 143.7773
    Epoch [1/50], Test Losses: mse: 15.2165, mae: 2.5654, huber: 2.1335, swd: 6.2614, ept: 155.0404
      Epoch 1 composite train-obj: 2.709337
            Val objective improved inf → 2.5173, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 17.3934, mae: 2.3339, huber: 1.9226, swd: 7.9993, ept: 168.2615
    Epoch [2/50], Val Losses: mse: 20.7696, mae: 2.9666, huber: 2.5445, swd: 10.6826, ept: 149.7029
    Epoch [2/50], Test Losses: mse: 15.0761, mae: 2.7173, huber: 2.2730, swd: 7.5472, ept: 149.1099
      Epoch 2 composite train-obj: 1.922642
            No improvement (2.5445), counter 1/5
    Epoch [3/50], Train Losses: mse: 16.1499, mae: 2.2532, huber: 1.8444, swd: 7.5580, ept: 170.2582
    Epoch [3/50], Val Losses: mse: 19.4671, mae: 2.7471, huber: 2.3363, swd: 8.7018, ept: 151.5799
    Epoch [3/50], Test Losses: mse: 13.6894, mae: 2.4244, huber: 1.9935, swd: 5.3812, ept: 161.4522
      Epoch 3 composite train-obj: 1.844353
            Val objective improved 2.5173 → 2.3363, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 15.5416, mae: 2.2076, huber: 1.8005, swd: 7.1202, ept: 171.3663
    Epoch [4/50], Val Losses: mse: 28.5739, mae: 3.3745, huber: 2.9593, swd: 15.9438, ept: 133.4731
    Epoch [4/50], Test Losses: mse: 22.9012, mae: 3.1495, huber: 2.7131, swd: 13.1873, ept: 137.0606
      Epoch 4 composite train-obj: 1.800459
            No improvement (2.9593), counter 1/5
    Epoch [5/50], Train Losses: mse: 15.0491, mae: 2.1652, huber: 1.7596, swd: 6.8292, ept: 171.8642
    Epoch [5/50], Val Losses: mse: 18.0818, mae: 2.6276, huber: 2.2212, swd: 8.0229, ept: 151.8177
    Epoch [5/50], Test Losses: mse: 13.1463, mae: 2.2761, huber: 1.8571, swd: 5.5942, ept: 158.7494
      Epoch 5 composite train-obj: 1.759586
            Val objective improved 2.3363 → 2.2212, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 14.4472, mae: 2.1191, huber: 1.7147, swd: 6.4509, ept: 172.8844
    Epoch [6/50], Val Losses: mse: 52.6221, mae: 4.6115, huber: 4.1952, swd: 34.6820, ept: 119.5843
    Epoch [6/50], Test Losses: mse: 47.3090, mae: 4.6635, huber: 4.2211, swd: 32.3865, ept: 108.0713
      Epoch 6 composite train-obj: 1.714692
            No improvement (4.1952), counter 1/5
    Epoch [7/50], Train Losses: mse: 14.8570, mae: 2.1682, huber: 1.7626, swd: 6.7192, ept: 171.3310
    Epoch [7/50], Val Losses: mse: 20.6273, mae: 2.8458, huber: 2.4384, swd: 9.7860, ept: 144.3655
    Epoch [7/50], Test Losses: mse: 16.7954, mae: 2.6042, huber: 2.1791, swd: 8.4797, ept: 149.8879
      Epoch 7 composite train-obj: 1.762588
            No improvement (2.4384), counter 2/5
    Epoch [8/50], Train Losses: mse: 13.9676, mae: 2.0916, huber: 1.6882, swd: 6.1383, ept: 173.1724
    Epoch [8/50], Val Losses: mse: 23.5332, mae: 2.9865, huber: 2.5798, swd: 11.6184, ept: 142.0738
    Epoch [8/50], Test Losses: mse: 18.3933, mae: 2.6892, huber: 2.2666, swd: 9.0586, ept: 148.7291
      Epoch 8 composite train-obj: 1.688168
            No improvement (2.5798), counter 3/5
    Epoch [9/50], Train Losses: mse: 13.5902, mae: 2.0714, huber: 1.6688, swd: 5.8778, ept: 173.2934
    Epoch [9/50], Val Losses: mse: 41.4537, mae: 4.0761, huber: 3.6635, swd: 29.1158, ept: 122.8722
    Epoch [9/50], Test Losses: mse: 28.0894, mae: 3.5522, huber: 3.1150, swd: 18.7768, ept: 133.5334
      Epoch 9 composite train-obj: 1.668779
            No improvement (3.6635), counter 4/5
    Epoch [10/50], Train Losses: mse: 16.0946, mae: 2.2559, huber: 1.8491, swd: 7.5158, ept: 168.9411
    Epoch [10/50], Val Losses: mse: 18.3003, mae: 2.6791, huber: 2.2706, swd: 8.8361, ept: 155.2641
    Epoch [10/50], Test Losses: mse: 12.7898, mae: 2.3636, huber: 1.9326, swd: 5.6659, ept: 165.5926
      Epoch 10 composite train-obj: 1.849087
    Epoch [10/50], Test Losses: mse: 13.1461, mae: 2.2761, huber: 1.8571, swd: 5.5941, ept: 158.7467
    Best round's Test MSE: 13.1463, MAE: 2.2761, SWD: 5.5942
    Best round's Validation MSE: 18.0818, MAE: 2.6276, SWD: 8.0229
    Best round's Test verification MSE : 13.1461, MAE: 2.2761, SWD: 5.5941
    Time taken: 132.35 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred196_20250512_1815)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.9327 ± 0.1701
      mae: 2.3007 ± 0.0423
      huber: 1.8765 ± 0.0366
      swd: 6.1567 ± 0.4381
      ept: 162.0128 ± 2.5664
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 18.0242 ± 0.3419
      mae: 2.6294 ± 0.0218
      huber: 2.2206 ± 0.0183
      swd: 8.9956 ± 0.7912
      ept: 153.8355 ± 1.6192
      count: 52.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 371.64 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred196_20250512_1815
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    



#### pred=336

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 43.6815, mae: 3.4360, huber: 3.0119, swd: 29.1977, ept: 233.7038
    Epoch [1/50], Val Losses: mse: 23.5138, mae: 3.0880, huber: 2.6683, swd: 9.7999, ept: 224.8455
    Epoch [1/50], Test Losses: mse: 16.6039, mae: 2.6041, huber: 2.1762, swd: 7.3056, ept: 244.8584
      Epoch 1 composite train-obj: 3.011873
            Val objective improved inf → 2.6683, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 22.3204, mae: 2.6633, huber: 2.2457, swd: 11.4267, ept: 259.6686
    Epoch [2/50], Val Losses: mse: 20.9879, mae: 2.9357, huber: 2.5172, swd: 8.5762, ept: 233.3030
    Epoch [2/50], Test Losses: mse: 15.6038, mae: 2.5073, huber: 2.0809, swd: 7.1268, ept: 249.6417
      Epoch 2 composite train-obj: 2.245722
            Val objective improved 2.6683 → 2.5172, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 20.5922, mae: 2.5222, huber: 2.1086, swd: 10.3405, ept: 268.4141
    Epoch [3/50], Val Losses: mse: 20.9306, mae: 2.9200, huber: 2.5022, swd: 8.9539, ept: 234.6206
    Epoch [3/50], Test Losses: mse: 15.1941, mae: 2.4779, huber: 2.0502, swd: 7.0049, ept: 252.4773
      Epoch 3 composite train-obj: 2.108600
            Val objective improved 2.5172 → 2.5022, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 19.7215, mae: 2.4743, huber: 2.0615, swd: 9.7198, ept: 269.8717
    Epoch [4/50], Val Losses: mse: 20.9736, mae: 2.8947, huber: 2.4769, swd: 9.0212, ept: 234.5075
    Epoch [4/50], Test Losses: mse: 16.3555, mae: 2.5339, huber: 2.1092, swd: 8.0283, ept: 245.7591
      Epoch 4 composite train-obj: 2.061454
            Val objective improved 2.5022 → 2.4769, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 18.8398, mae: 2.4232, huber: 2.0112, swd: 9.0838, ept: 271.7480
    Epoch [5/50], Val Losses: mse: 22.4995, mae: 2.9873, huber: 2.5716, swd: 10.2737, ept: 230.1421
    Epoch [5/50], Test Losses: mse: 18.2393, mae: 2.6967, huber: 2.2692, swd: 9.6954, ept: 241.3234
      Epoch 5 composite train-obj: 2.011250
            No improvement (2.5716), counter 1/5
    Epoch [6/50], Train Losses: mse: 18.1838, mae: 2.3882, huber: 1.9771, swd: 8.5639, ept: 272.8369
    Epoch [6/50], Val Losses: mse: 22.6239, mae: 2.9819, huber: 2.5698, swd: 10.3763, ept: 233.2942
    Epoch [6/50], Test Losses: mse: 17.8280, mae: 2.6546, huber: 2.2278, swd: 9.2215, ept: 242.0166
      Epoch 6 composite train-obj: 1.977129
            No improvement (2.5698), counter 2/5
    Epoch [7/50], Train Losses: mse: 18.0855, mae: 2.3856, huber: 1.9746, swd: 8.5966, ept: 272.7673
    Epoch [7/50], Val Losses: mse: 22.7113, mae: 2.9755, huber: 2.5658, swd: 10.6936, ept: 236.6590
    Epoch [7/50], Test Losses: mse: 16.9207, mae: 2.5660, huber: 2.1422, swd: 8.5560, ept: 248.1326
      Epoch 7 composite train-obj: 1.974589
            No improvement (2.5658), counter 3/5
    Epoch [8/50], Train Losses: mse: 17.4961, mae: 2.3391, huber: 1.9293, swd: 8.1812, ept: 274.2552
    Epoch [8/50], Val Losses: mse: 23.2378, mae: 2.9672, huber: 2.5590, swd: 11.1302, ept: 234.3876
    Epoch [8/50], Test Losses: mse: 17.6476, mae: 2.6020, huber: 2.1785, swd: 9.1115, ept: 243.7322
      Epoch 8 composite train-obj: 1.929337
            No improvement (2.5590), counter 4/5
    Epoch [9/50], Train Losses: mse: 17.1878, mae: 2.3105, huber: 1.9014, swd: 8.0100, ept: 275.0861
    Epoch [9/50], Val Losses: mse: 23.6594, mae: 3.0330, huber: 2.6219, swd: 11.6076, ept: 234.5163
    Epoch [9/50], Test Losses: mse: 17.3398, mae: 2.6180, huber: 2.1911, swd: 8.9475, ept: 247.2603
      Epoch 9 composite train-obj: 1.901366
    Epoch [9/50], Test Losses: mse: 16.3554, mae: 2.5340, huber: 2.1092, swd: 8.0282, ept: 245.7875
    Best round's Test MSE: 16.3555, MAE: 2.5339, SWD: 8.0283
    Best round's Validation MSE: 20.9736, MAE: 2.8947, SWD: 9.0212
    Best round's Test verification MSE : 16.3554, MAE: 2.5340, SWD: 8.0282
    Time taken: 121.02 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 44.4829, mae: 3.4291, huber: 3.0045, swd: 31.7187, ept: 234.9129
    Epoch [1/50], Val Losses: mse: 23.4463, mae: 3.0991, huber: 2.6780, swd: 10.8063, ept: 227.9705
    Epoch [1/50], Test Losses: mse: 16.1868, mae: 2.5947, huber: 2.1651, swd: 7.7195, ept: 248.5492
      Epoch 1 composite train-obj: 3.004518
            Val objective improved inf → 2.6780, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.6906, mae: 2.6232, huber: 2.2060, swd: 11.5748, ept: 263.2579
    Epoch [2/50], Val Losses: mse: 21.3139, mae: 2.8889, huber: 2.4721, swd: 9.4239, ept: 235.5727
    Epoch [2/50], Test Losses: mse: 16.2898, mae: 2.5400, huber: 2.1127, swd: 8.3428, ept: 248.8615
      Epoch 2 composite train-obj: 2.205963
            Val objective improved 2.6780 → 2.4721, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 20.4537, mae: 2.5303, huber: 2.1162, swd: 10.7189, ept: 268.1871
    Epoch [3/50], Val Losses: mse: 21.4977, mae: 2.9072, huber: 2.4919, swd: 9.7365, ept: 233.5543
    Epoch [3/50], Test Losses: mse: 17.2214, mae: 2.5964, huber: 2.1700, swd: 9.2336, ept: 243.8950
      Epoch 3 composite train-obj: 2.116202
            No improvement (2.4919), counter 1/5
    Epoch [4/50], Train Losses: mse: 19.6842, mae: 2.4841, huber: 2.0711, swd: 10.1775, ept: 269.5328
    Epoch [4/50], Val Losses: mse: 19.6504, mae: 2.8269, huber: 2.4114, swd: 8.2149, ept: 236.9003
    Epoch [4/50], Test Losses: mse: 16.0793, mae: 2.5204, huber: 2.0937, swd: 8.1322, ept: 249.9507
      Epoch 4 composite train-obj: 2.071104
            Val objective improved 2.4721 → 2.4114, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 18.9353, mae: 2.4296, huber: 2.0184, swd: 9.5849, ept: 271.5052
    Epoch [5/50], Val Losses: mse: 24.0352, mae: 3.1174, huber: 2.7059, swd: 11.9798, ept: 230.3146
    Epoch [5/50], Test Losses: mse: 16.2177, mae: 2.5101, huber: 2.0885, swd: 8.2524, ept: 249.5459
      Epoch 5 composite train-obj: 2.018384
            No improvement (2.7059), counter 1/5
    Epoch [6/50], Train Losses: mse: 18.5310, mae: 2.4093, huber: 1.9989, swd: 9.3165, ept: 271.9157
    Epoch [6/50], Val Losses: mse: 20.9951, mae: 2.8557, huber: 2.4531, swd: 9.4966, ept: 236.8465
    Epoch [6/50], Test Losses: mse: 17.1181, mae: 2.5756, huber: 2.1538, swd: 9.0013, ept: 243.6642
      Epoch 6 composite train-obj: 1.998895
            No improvement (2.4531), counter 2/5
    Epoch [7/50], Train Losses: mse: 18.0665, mae: 2.3796, huber: 1.9699, swd: 9.0024, ept: 273.0560
    Epoch [7/50], Val Losses: mse: 23.9520, mae: 3.0149, huber: 2.6100, swd: 11.7060, ept: 233.2318
    Epoch [7/50], Test Losses: mse: 17.9222, mae: 2.6278, huber: 2.2054, swd: 9.8262, ept: 241.9361
      Epoch 7 composite train-obj: 1.969871
            No improvement (2.6100), counter 3/5
    Epoch [8/50], Train Losses: mse: 17.6796, mae: 2.3510, huber: 1.9424, swd: 8.7773, ept: 273.9398
    Epoch [8/50], Val Losses: mse: 25.0363, mae: 3.0751, huber: 2.6707, swd: 12.6132, ept: 228.7409
    Epoch [8/50], Test Losses: mse: 20.1849, mae: 2.7811, huber: 2.3579, swd: 11.8891, ept: 234.0705
      Epoch 8 composite train-obj: 1.942361
            No improvement (2.6707), counter 4/5
    Epoch [9/50], Train Losses: mse: 17.4855, mae: 2.3506, huber: 1.9419, swd: 8.7187, ept: 273.6605
    Epoch [9/50], Val Losses: mse: 26.1547, mae: 3.1185, huber: 2.7120, swd: 13.9059, ept: 229.0454
    Epoch [9/50], Test Losses: mse: 19.9021, mae: 2.7772, huber: 2.3473, swd: 11.6861, ept: 237.0415
      Epoch 9 composite train-obj: 1.941927
    Epoch [9/50], Test Losses: mse: 16.0793, mae: 2.5204, huber: 2.0937, swd: 8.1322, ept: 249.9489
    Best round's Test MSE: 16.0793, MAE: 2.5204, SWD: 8.1322
    Best round's Validation MSE: 19.6504, MAE: 2.8269, SWD: 8.2149
    Best round's Test verification MSE : 16.0793, MAE: 2.5204, SWD: 8.1322
    Time taken: 117.35 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 43.5170, mae: 3.4186, huber: 2.9947, swd: 28.0687, ept: 234.7153
    Epoch [1/50], Val Losses: mse: 22.6108, mae: 3.0121, huber: 2.5925, swd: 9.1737, ept: 228.5451
    Epoch [1/50], Test Losses: mse: 16.1031, mae: 2.5870, huber: 2.1552, swd: 7.0480, ept: 248.4322
      Epoch 1 composite train-obj: 2.994715
            Val objective improved inf → 2.5925, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.4060, mae: 2.6012, huber: 2.1851, swd: 10.4906, ept: 264.3523
    Epoch [2/50], Val Losses: mse: 20.8033, mae: 2.8873, huber: 2.4683, swd: 8.3706, ept: 236.8141
    Epoch [2/50], Test Losses: mse: 15.3379, mae: 2.5099, huber: 2.0779, swd: 6.9345, ept: 254.2996
      Epoch 2 composite train-obj: 2.185112
            Val objective improved 2.5925 → 2.4683, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 20.1216, mae: 2.5047, huber: 2.0914, swd: 9.6609, ept: 269.4943
    Epoch [3/50], Val Losses: mse: 21.1628, mae: 2.9353, huber: 2.5186, swd: 9.3469, ept: 238.8227
    Epoch [3/50], Test Losses: mse: 14.7370, mae: 2.4464, huber: 2.0208, swd: 6.5656, ept: 256.1279
      Epoch 3 composite train-obj: 2.091373
            No improvement (2.5186), counter 1/5
    Epoch [4/50], Train Losses: mse: 19.3599, mae: 2.4561, huber: 2.0432, swd: 9.1832, ept: 271.0572
    Epoch [4/50], Val Losses: mse: 21.7404, mae: 2.9622, huber: 2.5443, swd: 9.0357, ept: 232.0682
    Epoch [4/50], Test Losses: mse: 17.4458, mae: 2.6401, huber: 2.2118, swd: 8.5280, ept: 241.7223
      Epoch 4 composite train-obj: 2.043231
            No improvement (2.5443), counter 2/5
    Epoch [5/50], Train Losses: mse: 18.7210, mae: 2.4223, huber: 2.0104, swd: 8.7365, ept: 271.8756
    Epoch [5/50], Val Losses: mse: 20.9521, mae: 2.9034, huber: 2.4882, swd: 8.6087, ept: 235.1975
    Epoch [5/50], Test Losses: mse: 16.2965, mae: 2.5346, huber: 2.1080, swd: 7.6552, ept: 246.5982
      Epoch 5 composite train-obj: 2.010368
            No improvement (2.4882), counter 3/5
    Epoch [6/50], Train Losses: mse: 17.9696, mae: 2.3803, huber: 1.9695, swd: 8.1541, ept: 273.2843
    Epoch [6/50], Val Losses: mse: 21.7372, mae: 2.9758, huber: 2.5629, swd: 9.1135, ept: 234.3757
    Epoch [6/50], Test Losses: mse: 16.8850, mae: 2.5344, huber: 2.1120, swd: 8.0700, ept: 246.9053
      Epoch 6 composite train-obj: 1.969474
            No improvement (2.5629), counter 4/5
    Epoch [7/50], Train Losses: mse: 17.6252, mae: 2.3592, huber: 1.9488, swd: 7.9671, ept: 273.9823
    Epoch [7/50], Val Losses: mse: 20.9960, mae: 2.9187, huber: 2.5074, swd: 9.0109, ept: 236.2299
    Epoch [7/50], Test Losses: mse: 16.5099, mae: 2.5635, huber: 2.1372, swd: 7.9158, ept: 248.8103
      Epoch 7 composite train-obj: 1.948832
    Epoch [7/50], Test Losses: mse: 15.3381, mae: 2.5099, huber: 2.0779, swd: 6.9346, ept: 254.2967
    Best round's Test MSE: 15.3379, MAE: 2.5099, SWD: 6.9345
    Best round's Validation MSE: 20.8033, MAE: 2.8873, SWD: 8.3706
    Best round's Test verification MSE : 15.3381, MAE: 2.5099, SWD: 6.9346
    Time taken: 91.14 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred336_20250512_1821)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 15.9243 ± 0.4297
      mae: 2.5214 ± 0.0098
      huber: 2.0936 ± 0.0128
      swd: 7.6984 ± 0.5418
      ept: 250.0031 ± 3.4869
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 20.4758 ± 0.5878
      mae: 2.8697 ± 0.0304
      huber: 2.4522 ± 0.0291
      swd: 8.5355 ± 0.3492
      ept: 236.0740 ± 1.1082
      count: 51.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 329.63 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred336_20250512_1821
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### ab: (8, 4) rotations


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2897, mae: 0.3282, huber: 0.1153, swd: 0.1344, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2825, mae: 0.3722, huber: 0.1323, swd: 0.1534, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.2044, mae: 0.3187, huber: 0.0970, swd: 0.1071, target_std: 0.7399
      Epoch 1 composite train-obj: 0.115322
            Val objective improved inf → 0.1323, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2249, mae: 0.2890, huber: 0.0924, swd: 0.0892, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2577, mae: 0.3422, huber: 0.1214, swd: 0.1196, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1828, mae: 0.2920, huber: 0.0870, swd: 0.0821, target_std: 0.7399
      Epoch 2 composite train-obj: 0.092363
            Val objective improved 0.1323 → 0.1214, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2083, mae: 0.2806, huber: 0.0872, swd: 0.0820, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2625, mae: 0.3464, huber: 0.1235, swd: 0.1156, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1861, mae: 0.2895, huber: 0.0883, swd: 0.0843, target_std: 0.7399
      Epoch 3 composite train-obj: 0.087190
            No improvement (0.1235), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.1974, mae: 0.2749, huber: 0.0834, swd: 0.0768, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2809, mae: 0.3574, huber: 0.1307, swd: 0.1333, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.2124, mae: 0.3164, huber: 0.1003, swd: 0.1033, target_std: 0.7399
      Epoch 4 composite train-obj: 0.083357
            No improvement (0.1307), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1885, mae: 0.2691, huber: 0.0799, swd: 0.0725, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2769, mae: 0.3597, huber: 0.1293, swd: 0.1317, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.2280, mae: 0.3315, huber: 0.1073, swd: 0.1144, target_std: 0.7399
      Epoch 5 composite train-obj: 0.079861
            No improvement (0.1293), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1809, mae: 0.2643, huber: 0.0768, swd: 0.0685, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2997, mae: 0.3635, huber: 0.1371, swd: 0.1278, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.2201, mae: 0.3167, huber: 0.1027, swd: 0.0973, target_std: 0.7399
      Epoch 6 composite train-obj: 0.076816
            No improvement (0.1371), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1734, mae: 0.2588, huber: 0.0737, swd: 0.0646, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2817, mae: 0.3555, huber: 0.1309, swd: 0.1191, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.2242, mae: 0.3217, huber: 0.1052, swd: 0.0996, target_std: 0.7399
      Epoch 7 composite train-obj: 0.073656
    Epoch [7/50], Test Losses: mse: 0.1828, mae: 0.2920, huber: 0.0870, swd: 0.0821, target_std: 0.7399
    Best round's Test MSE: 0.1828, MAE: 0.2920, SWD: 0.0821
    Best round's Validation MSE: 0.2577, MAE: 0.3422
    Best round's Test verification MSE : 0.1828, MAE: 0.2920, SWD: 0.0821
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2946, mae: 0.3325, huber: 0.1174, swd: 0.1434, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2619, mae: 0.3508, huber: 0.1232, swd: 0.1290, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1781, mae: 0.2896, huber: 0.0848, swd: 0.0791, target_std: 0.7399
      Epoch 1 composite train-obj: 0.117446
            Val objective improved inf → 0.1232, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2262, mae: 0.2896, huber: 0.0928, swd: 0.0923, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2628, mae: 0.3458, huber: 0.1235, swd: 0.1277, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1859, mae: 0.2933, huber: 0.0883, swd: 0.0887, target_std: 0.7399
      Epoch 2 composite train-obj: 0.092809
            No improvement (0.1235), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2082, mae: 0.2810, huber: 0.0873, swd: 0.0844, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2771, mae: 0.3581, huber: 0.1295, swd: 0.1392, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.2008, mae: 0.3059, huber: 0.0950, swd: 0.1001, target_std: 0.7399
      Epoch 3 composite train-obj: 0.087280
            No improvement (0.1295), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1969, mae: 0.2748, huber: 0.0832, swd: 0.0788, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2757, mae: 0.3533, huber: 0.1283, swd: 0.1306, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.2077, mae: 0.3073, huber: 0.0980, swd: 0.1034, target_std: 0.7399
      Epoch 4 composite train-obj: 0.083236
            No improvement (0.1283), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1879, mae: 0.2688, huber: 0.0797, swd: 0.0740, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2826, mae: 0.3520, huber: 0.1299, swd: 0.1291, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.2174, mae: 0.3121, huber: 0.1015, swd: 0.1009, target_std: 0.7399
      Epoch 5 composite train-obj: 0.079664
            No improvement (0.1299), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1802, mae: 0.2635, huber: 0.0765, swd: 0.0699, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2867, mae: 0.3610, huber: 0.1326, swd: 0.1368, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.2265, mae: 0.3200, huber: 0.1057, swd: 0.1067, target_std: 0.7399
      Epoch 6 composite train-obj: 0.076474
    Epoch [6/50], Test Losses: mse: 0.1781, mae: 0.2896, huber: 0.0848, swd: 0.0791, target_std: 0.7399
    Best round's Test MSE: 0.1781, MAE: 0.2896, SWD: 0.0791
    Best round's Validation MSE: 0.2619, MAE: 0.3508
    Best round's Test verification MSE : 0.1781, MAE: 0.2896, SWD: 0.0791
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2899, mae: 0.3292, huber: 0.1157, swd: 0.1346, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2796, mae: 0.3709, huber: 0.1312, swd: 0.1528, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1998, mae: 0.3133, huber: 0.0948, swd: 0.1021, target_std: 0.7399
      Epoch 1 composite train-obj: 0.115670
            Val objective improved inf → 0.1312, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2244, mae: 0.2888, huber: 0.0924, swd: 0.0897, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2773, mae: 0.3614, huber: 0.1296, swd: 0.1451, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.2009, mae: 0.3104, huber: 0.0951, swd: 0.1007, target_std: 0.7399
      Epoch 2 composite train-obj: 0.092396
            Val objective improved 0.1312 → 0.1296, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2071, mae: 0.2804, huber: 0.0869, swd: 0.0817, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2590, mae: 0.3431, huber: 0.1219, swd: 0.1170, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1904, mae: 0.2954, huber: 0.0902, swd: 0.0855, target_std: 0.7399
      Epoch 3 composite train-obj: 0.086947
            Val objective improved 0.1296 → 0.1219, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1972, mae: 0.2743, huber: 0.0832, swd: 0.0771, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2632, mae: 0.3420, huber: 0.1231, swd: 0.1129, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1985, mae: 0.3003, huber: 0.0938, swd: 0.0882, target_std: 0.7399
      Epoch 4 composite train-obj: 0.083187
            No improvement (0.1231), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.1883, mae: 0.2685, huber: 0.0797, swd: 0.0724, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2689, mae: 0.3456, huber: 0.1252, swd: 0.1140, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.2091, mae: 0.3075, huber: 0.0985, swd: 0.0968, target_std: 0.7399
      Epoch 5 composite train-obj: 0.079684
            No improvement (0.1252), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.1811, mae: 0.2638, huber: 0.0767, swd: 0.0685, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2735, mae: 0.3510, huber: 0.1270, swd: 0.1123, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.2122, mae: 0.3059, huber: 0.0995, swd: 0.0880, target_std: 0.7399
      Epoch 6 composite train-obj: 0.076722
            No improvement (0.1270), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.1746, mae: 0.2591, huber: 0.0741, swd: 0.0655, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2760, mae: 0.3512, huber: 0.1284, swd: 0.1182, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.2229, mae: 0.3169, huber: 0.1046, swd: 0.0994, target_std: 0.7399
      Epoch 7 composite train-obj: 0.074068
            No improvement (0.1284), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.1695, mae: 0.2557, huber: 0.0720, swd: 0.0632, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2778, mae: 0.3546, huber: 0.1293, swd: 0.1195, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.2187, mae: 0.3178, huber: 0.1031, swd: 0.0990, target_std: 0.7399
      Epoch 8 composite train-obj: 0.071979
    Epoch [8/50], Test Losses: mse: 0.1904, mae: 0.2953, huber: 0.0902, swd: 0.0855, target_std: 0.7399
    Best round's Test MSE: 0.1904, MAE: 0.2954, SWD: 0.0855
    Best round's Validation MSE: 0.2590, MAE: 0.3431
    Best round's Test verification MSE : 0.1904, MAE: 0.2953, SWD: 0.0855
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred336_20250501_0000)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1837 ± 0.0051
      mae: 0.2923 ± 0.0024
      huber: 0.0873 ± 0.0022
      swd: 0.0823 ± 0.0026
      target_std: 0.7399 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2595 ± 0.0017
      mae: 0.3454 ± 0.0039
      huber: 0.1222 ± 0.0008
      swd: 0.1219 ± 0.0051
      target_std: 0.9653 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq196_pred336_20250501_0000
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 50.4746, mae: 3.7675, huber: 3.3380, swd: 32.0352, ept: 410.6589
    Epoch [1/50], Val Losses: mse: 27.1227, mae: 3.4177, huber: 2.9883, swd: 9.5913, ept: 369.2180
    Epoch [1/50], Test Losses: mse: 20.5489, mae: 2.9243, huber: 2.4890, swd: 9.0645, ept: 414.1176
      Epoch 1 composite train-obj: 3.337982
            Val objective improved inf → 2.9883, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 28.8590, mae: 2.9986, huber: 2.5746, swd: 13.8597, ept: 467.0143
    Epoch [2/50], Val Losses: mse: 25.8401, mae: 3.3094, huber: 2.8838, swd: 9.3572, ept: 389.1085
    Epoch [2/50], Test Losses: mse: 20.9977, mae: 2.9223, huber: 2.4870, swd: 10.3172, ept: 417.5851
      Epoch 2 composite train-obj: 2.574575
            Val objective improved 2.9883 → 2.8838, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 27.5805, mae: 2.9150, huber: 2.4928, swd: 13.0349, ept: 478.7933
    Epoch [3/50], Val Losses: mse: 28.9603, mae: 3.4914, huber: 3.0630, swd: 11.7429, ept: 378.4586
    Epoch [3/50], Test Losses: mse: 26.0761, mae: 3.3010, huber: 2.8621, swd: 14.7572, ept: 389.6430
      Epoch 3 composite train-obj: 2.492779
            No improvement (3.0630), counter 1/5
    Epoch [4/50], Train Losses: mse: 26.7074, mae: 2.8527, huber: 2.4316, swd: 12.4560, ept: 483.8789
    Epoch [4/50], Val Losses: mse: 26.2767, mae: 3.3462, huber: 2.9190, swd: 9.6634, ept: 390.5694
    Epoch [4/50], Test Losses: mse: 21.7180, mae: 3.0345, huber: 2.5931, swd: 10.8216, ept: 415.8778
      Epoch 4 composite train-obj: 2.431557
            No improvement (2.9190), counter 2/5
    Epoch [5/50], Train Losses: mse: 26.3641, mae: 2.8289, huber: 2.4085, swd: 12.2501, ept: 485.0959
    Epoch [5/50], Val Losses: mse: 25.3013, mae: 3.3013, huber: 2.8785, swd: 9.1741, ept: 396.1125
    Epoch [5/50], Test Losses: mse: 19.8357, mae: 2.8851, huber: 2.4491, swd: 9.3934, ept: 423.7884
      Epoch 5 composite train-obj: 2.408525
            Val objective improved 2.8838 → 2.8785, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 25.8073, mae: 2.7844, huber: 2.3649, swd: 11.7840, ept: 488.5692
    Epoch [6/50], Val Losses: mse: 24.9424, mae: 3.2603, huber: 2.8370, swd: 9.0585, ept: 393.7897
    Epoch [6/50], Test Losses: mse: 20.4237, mae: 2.9043, huber: 2.4702, swd: 10.0266, ept: 422.0838
      Epoch 6 composite train-obj: 2.364858
            Val objective improved 2.8785 → 2.8370, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 25.4822, mae: 2.7615, huber: 2.3426, swd: 11.5766, ept: 490.3371
    Epoch [7/50], Val Losses: mse: 25.3833, mae: 3.2821, huber: 2.8624, swd: 9.7192, ept: 395.7099
    Epoch [7/50], Test Losses: mse: 20.0520, mae: 2.8589, huber: 2.4280, swd: 9.7149, ept: 427.1754
      Epoch 7 composite train-obj: 2.342593
            No improvement (2.8624), counter 1/5
    Epoch [8/50], Train Losses: mse: 25.2396, mae: 2.7474, huber: 2.3289, swd: 11.4424, ept: 491.1155
    Epoch [8/50], Val Losses: mse: 26.3882, mae: 3.3277, huber: 2.9052, swd: 10.3528, ept: 388.6195
    Epoch [8/50], Test Losses: mse: 21.2042, mae: 2.9221, huber: 2.4920, swd: 10.6180, ept: 418.3717
      Epoch 8 composite train-obj: 2.328863
            No improvement (2.9052), counter 2/5
    Epoch [9/50], Train Losses: mse: 24.8131, mae: 2.7110, huber: 2.2934, swd: 11.1501, ept: 494.1187
    Epoch [9/50], Val Losses: mse: 24.6981, mae: 3.2135, huber: 2.7931, swd: 9.3489, ept: 400.8392
    Epoch [9/50], Test Losses: mse: 20.0021, mae: 2.8741, huber: 2.4418, swd: 9.7471, ept: 426.5690
      Epoch 9 composite train-obj: 2.293403
            Val objective improved 2.8370 → 2.7931, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 24.5894, mae: 2.6933, huber: 2.2762, swd: 11.0185, ept: 495.7727
    Epoch [10/50], Val Losses: mse: 25.4219, mae: 3.2794, huber: 2.8591, swd: 9.9836, ept: 400.4364
    Epoch [10/50], Test Losses: mse: 20.3266, mae: 2.9011, huber: 2.4687, swd: 9.9775, ept: 426.8286
      Epoch 10 composite train-obj: 2.276200
            No improvement (2.8591), counter 1/5
    Epoch [11/50], Train Losses: mse: 24.2915, mae: 2.6669, huber: 2.2505, swd: 10.8340, ept: 497.4546
    Epoch [11/50], Val Losses: mse: 24.8856, mae: 3.2287, huber: 2.8086, swd: 9.6478, ept: 403.0004
    Epoch [11/50], Test Losses: mse: 20.4504, mae: 2.9324, huber: 2.4971, swd: 10.1563, ept: 427.3318
      Epoch 11 composite train-obj: 2.250549
            No improvement (2.8086), counter 2/5
    Epoch [12/50], Train Losses: mse: 24.1532, mae: 2.6588, huber: 2.2426, swd: 10.7629, ept: 497.7798
    Epoch [12/50], Val Losses: mse: 25.5910, mae: 3.3010, huber: 2.8805, swd: 10.1860, ept: 406.3556
    Epoch [12/50], Test Losses: mse: 20.4395, mae: 2.9679, huber: 2.5316, swd: 10.2156, ept: 424.0223
      Epoch 12 composite train-obj: 2.242637
            No improvement (2.8805), counter 3/5
    Epoch [13/50], Train Losses: mse: 23.8358, mae: 2.6367, huber: 2.2210, swd: 10.5432, ept: 499.7073
    Epoch [13/50], Val Losses: mse: 26.1452, mae: 3.2901, huber: 2.8714, swd: 10.4668, ept: 396.6317
    Epoch [13/50], Test Losses: mse: 20.5771, mae: 2.9231, huber: 2.4906, swd: 10.0705, ept: 423.3901
      Epoch 13 composite train-obj: 2.221016
            No improvement (2.8714), counter 4/5
    Epoch [14/50], Train Losses: mse: 23.6484, mae: 2.6262, huber: 2.2108, swd: 10.4576, ept: 500.3077
    Epoch [14/50], Val Losses: mse: 27.1717, mae: 3.3299, huber: 2.9120, swd: 11.2653, ept: 397.6449
    Epoch [14/50], Test Losses: mse: 21.8260, mae: 3.0127, huber: 2.5804, swd: 11.1524, ept: 421.0761
      Epoch 14 composite train-obj: 2.210778
    Epoch [14/50], Test Losses: mse: 20.0045, mae: 2.8743, huber: 2.4419, swd: 9.7476, ept: 426.6699
    Best round's Test MSE: 20.0021, MAE: 2.8741, SWD: 9.7471
    Best round's Validation MSE: 24.6981, MAE: 3.2135, SWD: 9.3489
    Best round's Test verification MSE : 20.0045, MAE: 2.8743, SWD: 9.7476
    Time taken: 178.70 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 48.9214, mae: 3.7161, huber: 3.2869, swd: 28.3028, ept: 416.1286
    Epoch [1/50], Val Losses: mse: 27.0349, mae: 3.4122, huber: 2.9828, swd: 8.8669, ept: 372.8608
    Epoch [1/50], Test Losses: mse: 20.3059, mae: 2.9197, huber: 2.4837, swd: 8.3173, ept: 410.9033
      Epoch 1 composite train-obj: 3.286941
            Val objective improved inf → 2.9828, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 28.7188, mae: 2.9943, huber: 2.5702, swd: 12.7070, ept: 466.4619
    Epoch [2/50], Val Losses: mse: 25.5760, mae: 3.3123, huber: 2.8860, swd: 8.5013, ept: 390.9953
    Epoch [2/50], Test Losses: mse: 19.2875, mae: 2.8049, huber: 2.3721, swd: 8.1046, ept: 426.7577
      Epoch 2 composite train-obj: 2.570187
            Val objective improved 2.9828 → 2.8860, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 27.2569, mae: 2.8942, huber: 2.4728, swd: 11.8288, ept: 481.0483
    Epoch [3/50], Val Losses: mse: 28.6048, mae: 3.4680, huber: 3.0420, swd: 10.6527, ept: 382.1129
    Epoch [3/50], Test Losses: mse: 23.2985, mae: 3.0944, huber: 2.6571, swd: 11.3776, ept: 407.5816
      Epoch 3 composite train-obj: 2.472750
            No improvement (3.0420), counter 1/5
    Epoch [4/50], Train Losses: mse: 26.5531, mae: 2.8520, huber: 2.4313, swd: 11.4544, ept: 484.5374
    Epoch [4/50], Val Losses: mse: 24.6594, mae: 3.2741, huber: 2.8463, swd: 8.6799, ept: 406.2555
    Epoch [4/50], Test Losses: mse: 18.3213, mae: 2.7623, huber: 2.3276, swd: 7.7776, ept: 439.2127
      Epoch 4 composite train-obj: 2.431343
            Val objective improved 2.8860 → 2.8463, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 25.6531, mae: 2.7776, huber: 2.3586, swd: 10.8343, ept: 490.6895
    Epoch [5/50], Val Losses: mse: 25.7913, mae: 3.3131, huber: 2.8913, swd: 8.8010, ept: 391.6322
    Epoch [5/50], Test Losses: mse: 19.8050, mae: 2.8759, huber: 2.4403, swd: 8.6349, ept: 420.1512
      Epoch 5 composite train-obj: 2.358637
            No improvement (2.8913), counter 1/5
    Epoch [6/50], Train Losses: mse: 25.3520, mae: 2.7577, huber: 2.3394, swd: 10.7035, ept: 491.5665
    Epoch [6/50], Val Losses: mse: 24.7931, mae: 3.2770, huber: 2.8574, swd: 8.7866, ept: 406.6557
    Epoch [6/50], Test Losses: mse: 19.2233, mae: 2.8366, huber: 2.4032, swd: 8.4210, ept: 433.7051
      Epoch 6 composite train-obj: 2.339425
            No improvement (2.8574), counter 2/5
    Epoch [7/50], Train Losses: mse: 24.9937, mae: 2.7274, huber: 2.3098, swd: 10.4958, ept: 493.7100
    Epoch [7/50], Val Losses: mse: 25.0311, mae: 3.2739, huber: 2.8522, swd: 8.7817, ept: 398.7584
    Epoch [7/50], Test Losses: mse: 19.9279, mae: 2.9173, huber: 2.4787, swd: 8.8923, ept: 427.0420
      Epoch 7 composite train-obj: 2.309803
            No improvement (2.8522), counter 3/5
    Epoch [8/50], Train Losses: mse: 24.5000, mae: 2.6879, huber: 2.2710, swd: 10.1737, ept: 495.6869
    Epoch [8/50], Val Losses: mse: 26.5605, mae: 3.3366, huber: 2.9154, swd: 9.6517, ept: 392.8825
    Epoch [8/50], Test Losses: mse: 21.5223, mae: 3.0060, huber: 2.5703, swd: 10.1099, ept: 415.3543
      Epoch 8 composite train-obj: 2.271005
            No improvement (2.9154), counter 4/5
    Epoch [9/50], Train Losses: mse: 24.2472, mae: 2.6764, huber: 2.2593, swd: 10.0296, ept: 496.1336
    Epoch [9/50], Val Losses: mse: 25.7407, mae: 3.3567, huber: 2.9327, swd: 9.6715, ept: 402.7629
    Epoch [9/50], Test Losses: mse: 19.3123, mae: 2.8256, huber: 2.3944, swd: 8.7146, ept: 430.8379
      Epoch 9 composite train-obj: 2.259304
    Epoch [9/50], Test Losses: mse: 18.3217, mae: 2.7623, huber: 2.3276, swd: 7.7779, ept: 439.2213
    Best round's Test MSE: 18.3213, MAE: 2.7623, SWD: 7.7776
    Best round's Validation MSE: 24.6594, MAE: 3.2741, SWD: 8.6799
    Best round's Test verification MSE : 18.3217, MAE: 2.7623, SWD: 7.7779
    Time taken: 114.66 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 49.0363, mae: 3.7143, huber: 3.2853, swd: 31.2642, ept: 415.8406
    Epoch [1/50], Val Losses: mse: 29.2386, mae: 3.5264, huber: 3.0967, swd: 11.3563, ept: 356.0822
    Epoch [1/50], Test Losses: mse: 23.3971, mae: 3.1392, huber: 2.7001, swd: 11.9018, ept: 390.9311
      Epoch 1 composite train-obj: 3.285328
            Val objective improved inf → 3.0967, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 28.6163, mae: 2.9919, huber: 2.5680, swd: 14.3655, ept: 467.9904
    Epoch [2/50], Val Losses: mse: 24.1407, mae: 3.2271, huber: 2.8011, swd: 8.8577, ept: 399.6975
    Epoch [2/50], Test Losses: mse: 18.6247, mae: 2.7640, huber: 2.3298, swd: 8.8147, ept: 441.5139
      Epoch 2 composite train-obj: 2.568002
            Val objective improved 3.0967 → 2.8011, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 27.1894, mae: 2.8944, huber: 2.4729, swd: 13.4353, ept: 481.4807
    Epoch [3/50], Val Losses: mse: 24.0550, mae: 3.2444, huber: 2.8178, swd: 8.7874, ept: 404.9919
    Epoch [3/50], Test Losses: mse: 18.9541, mae: 2.7983, huber: 2.3637, swd: 9.0771, ept: 429.4554
      Epoch 3 composite train-obj: 2.472851
            No improvement (2.8178), counter 1/5
    Epoch [4/50], Train Losses: mse: 26.1595, mae: 2.8129, huber: 2.3933, swd: 12.6396, ept: 487.2845
    Epoch [4/50], Val Losses: mse: 25.2470, mae: 3.2718, huber: 2.8470, swd: 9.2180, ept: 392.8978
    Epoch [4/50], Test Losses: mse: 20.9269, mae: 2.9217, huber: 2.4874, swd: 10.7900, ept: 418.3414
      Epoch 4 composite train-obj: 2.393268
            No improvement (2.8470), counter 2/5
    Epoch [5/50], Train Losses: mse: 25.6621, mae: 2.7758, huber: 2.3571, swd: 12.3009, ept: 489.8621
    Epoch [5/50], Val Losses: mse: 26.1214, mae: 3.3199, huber: 2.8982, swd: 10.0466, ept: 387.4986
    Epoch [5/50], Test Losses: mse: 20.6451, mae: 2.9335, huber: 2.4976, swd: 10.4973, ept: 420.2057
      Epoch 5 composite train-obj: 2.357058
            No improvement (2.8982), counter 3/5
    Epoch [6/50], Train Losses: mse: 25.3448, mae: 2.7517, huber: 2.3333, swd: 12.0775, ept: 491.9575
    Epoch [6/50], Val Losses: mse: 24.4023, mae: 3.2728, huber: 2.8497, swd: 9.3237, ept: 405.0272
    Epoch [6/50], Test Losses: mse: 19.1465, mae: 2.8235, huber: 2.3909, swd: 9.4564, ept: 432.4578
      Epoch 6 composite train-obj: 2.333261
            No improvement (2.8497), counter 4/5
    Epoch [7/50], Train Losses: mse: 25.0056, mae: 2.7287, huber: 2.3105, swd: 11.8505, ept: 492.9609
    Epoch [7/50], Val Losses: mse: 25.2720, mae: 3.2541, huber: 2.8325, swd: 9.5584, ept: 390.7270
    Epoch [7/50], Test Losses: mse: 21.0653, mae: 2.9260, huber: 2.4938, swd: 11.0340, ept: 421.7374
      Epoch 7 composite train-obj: 2.310485
    Epoch [7/50], Test Losses: mse: 18.6244, mae: 2.7640, huber: 2.3298, swd: 8.8145, ept: 441.4931
    Best round's Test MSE: 18.6247, MAE: 2.7640, SWD: 8.8147
    Best round's Validation MSE: 24.1407, MAE: 3.2271, SWD: 8.8577
    Best round's Test verification MSE : 18.6244, MAE: 2.7640, SWD: 8.8145
    Time taken: 93.10 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred720_20250512_1826)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 18.9827 ± 0.7314
      mae: 2.8002 ± 0.0523
      huber: 2.3664 ± 0.0533
      swd: 8.7798 ± 0.8044
      ept: 435.7652 ± 6.5702
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 24.4994 ± 0.2541
      mae: 3.2382 ± 0.0260
      huber: 2.8135 ± 0.0234
      swd: 8.9622 ± 0.2829
      ept: 402.2641 ± 2.8606
      count: 48.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 386.59 seconds
    
    Experiment complete: ACL_ettm2_seq196_pred720_20250512_1826
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

##### ab: (8, 4) rotations


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3773, mae: 0.3762, huber: 0.1454, swd: 0.1804, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3392, mae: 0.4029, huber: 0.1569, swd: 0.1719, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2388, mae: 0.3452, huber: 0.1131, swd: 0.1206, target_std: 0.7348
      Epoch 1 composite train-obj: 0.145430
            Val objective improved inf → 0.1569, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3152, mae: 0.3348, huber: 0.1213, swd: 0.1315, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3472, mae: 0.4071, huber: 0.1595, swd: 0.1794, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2398, mae: 0.3455, huber: 0.1138, swd: 0.1242, target_std: 0.7348
      Epoch 2 composite train-obj: 0.121268
            No improvement (0.1595), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2966, mae: 0.3263, huber: 0.1155, swd: 0.1216, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3366, mae: 0.3946, huber: 0.1551, swd: 0.1560, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2516, mae: 0.3527, huber: 0.1188, swd: 0.1282, target_std: 0.7348
      Epoch 3 composite train-obj: 0.115480
            Val objective improved 0.1569 → 0.1551, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2824, mae: 0.3199, huber: 0.1109, swd: 0.1138, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3680, mae: 0.4190, huber: 0.1666, swd: 0.1816, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2780, mae: 0.3737, huber: 0.1304, swd: 0.1446, target_std: 0.7348
      Epoch 4 composite train-obj: 0.110863
            No improvement (0.1666), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2710, mae: 0.3144, huber: 0.1068, swd: 0.1080, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3422, mae: 0.3994, huber: 0.1575, swd: 0.1389, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2549, mae: 0.3457, huber: 0.1194, swd: 0.1118, target_std: 0.7348
      Epoch 5 composite train-obj: 0.106801
            No improvement (0.1575), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.2612, mae: 0.3088, huber: 0.1030, swd: 0.1030, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3609, mae: 0.4058, huber: 0.1639, swd: 0.1489, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2661, mae: 0.3546, huber: 0.1245, swd: 0.1215, target_std: 0.7348
      Epoch 6 composite train-obj: 0.103045
            No improvement (0.1639), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.2531, mae: 0.3038, huber: 0.0999, swd: 0.0987, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3497, mae: 0.4017, huber: 0.1586, swd: 0.1472, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2763, mae: 0.3697, huber: 0.1297, swd: 0.1336, target_std: 0.7348
      Epoch 7 composite train-obj: 0.099866
            No improvement (0.1586), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.2452, mae: 0.2986, huber: 0.0967, swd: 0.0939, target_std: 0.7879
    Epoch [8/50], Val Losses: mse: 0.3582, mae: 0.4066, huber: 0.1627, swd: 0.1385, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2571, mae: 0.3470, huber: 0.1206, swd: 0.1045, target_std: 0.7348
      Epoch 8 composite train-obj: 0.096706
    Epoch [8/50], Test Losses: mse: 0.2516, mae: 0.3527, huber: 0.1188, swd: 0.1282, target_std: 0.7348
    Best round's Test MSE: 0.2516, MAE: 0.3527, SWD: 0.1282
    Best round's Validation MSE: 0.3366, MAE: 0.3946
    Best round's Test verification MSE : 0.2516, MAE: 0.3527, SWD: 0.1282
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3802, mae: 0.3781, huber: 0.1463, swd: 0.1766, target_std: 0.7879
    Epoch [1/50], Val Losses: mse: 0.3489, mae: 0.4078, huber: 0.1605, swd: 0.1632, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2314, mae: 0.3313, huber: 0.1091, swd: 0.1014, target_std: 0.7348
      Epoch 1 composite train-obj: 0.146330
            Val objective improved inf → 0.1605, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3149, mae: 0.3347, huber: 0.1212, swd: 0.1268, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3454, mae: 0.4008, huber: 0.1585, swd: 0.1555, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2489, mae: 0.3491, huber: 0.1175, swd: 0.1122, target_std: 0.7348
      Epoch 2 composite train-obj: 0.121157
            Val objective improved 0.1605 → 0.1585, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2972, mae: 0.3273, huber: 0.1157, swd: 0.1180, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3448, mae: 0.4001, huber: 0.1586, swd: 0.1413, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2473, mae: 0.3453, huber: 0.1166, swd: 0.1088, target_std: 0.7348
      Epoch 3 composite train-obj: 0.115739
            No improvement (0.1586), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2834, mae: 0.3204, huber: 0.1111, swd: 0.1109, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3386, mae: 0.3937, huber: 0.1550, swd: 0.1417, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2576, mae: 0.3519, huber: 0.1210, swd: 0.1156, target_std: 0.7348
      Epoch 4 composite train-obj: 0.111149
            Val objective improved 0.1585 → 0.1550, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2720, mae: 0.3147, huber: 0.1071, swd: 0.1052, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3554, mae: 0.4048, huber: 0.1623, swd: 0.1442, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2618, mae: 0.3519, huber: 0.1226, swd: 0.1165, target_std: 0.7348
      Epoch 5 composite train-obj: 0.107123
            No improvement (0.1623), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2616, mae: 0.3090, huber: 0.1033, swd: 0.0993, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3482, mae: 0.4022, huber: 0.1595, swd: 0.1258, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2635, mae: 0.3506, huber: 0.1232, swd: 0.1078, target_std: 0.7348
      Epoch 6 composite train-obj: 0.103283
            No improvement (0.1595), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.2522, mae: 0.3036, huber: 0.0997, swd: 0.0942, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3967, mae: 0.4278, huber: 0.1769, swd: 0.1586, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.3026, mae: 0.3833, huber: 0.1393, swd: 0.1249, target_std: 0.7348
      Epoch 7 composite train-obj: 0.099723
            No improvement (0.1769), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.2440, mae: 0.2989, huber: 0.0966, swd: 0.0889, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3699, mae: 0.4124, huber: 0.1679, swd: 0.1382, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2866, mae: 0.3674, huber: 0.1330, swd: 0.1117, target_std: 0.7348
      Epoch 8 composite train-obj: 0.096554
            No improvement (0.1679), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.2345, mae: 0.2937, huber: 0.0932, swd: 0.0830, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3663, mae: 0.4126, huber: 0.1666, swd: 0.1398, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2832, mae: 0.3673, huber: 0.1317, swd: 0.1140, target_std: 0.7348
      Epoch 9 composite train-obj: 0.093216
    Epoch [9/50], Test Losses: mse: 0.2576, mae: 0.3519, huber: 0.1210, swd: 0.1156, target_std: 0.7348
    Best round's Test MSE: 0.2576, MAE: 0.3519, SWD: 0.1156
    Best round's Validation MSE: 0.3386, MAE: 0.3937
    Best round's Test verification MSE : 0.2576, MAE: 0.3519, SWD: 0.1156
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3774, mae: 0.3765, huber: 0.1454, swd: 0.1870, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3322, mae: 0.3970, huber: 0.1540, swd: 0.1557, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2209, mae: 0.3242, huber: 0.1045, swd: 0.0986, target_std: 0.7348
      Epoch 1 composite train-obj: 0.145370
            Val objective improved inf → 0.1540, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3162, mae: 0.3354, huber: 0.1216, swd: 0.1376, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3358, mae: 0.3954, huber: 0.1551, swd: 0.1547, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2217, mae: 0.3222, huber: 0.1048, swd: 0.1002, target_std: 0.7348
      Epoch 2 composite train-obj: 0.121640
            No improvement (0.1551), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2982, mae: 0.3274, huber: 0.1160, swd: 0.1286, target_std: 0.7879
    Epoch [3/50], Val Losses: mse: 0.3402, mae: 0.3992, huber: 0.1563, swd: 0.1632, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2460, mae: 0.3488, huber: 0.1164, swd: 0.1281, target_std: 0.7348
      Epoch 3 composite train-obj: 0.115970
            No improvement (0.1563), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2849, mae: 0.3212, huber: 0.1116, swd: 0.1218, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3541, mae: 0.3997, huber: 0.1604, swd: 0.1618, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2749, mae: 0.3667, huber: 0.1287, swd: 0.1458, target_std: 0.7348
      Epoch 4 composite train-obj: 0.111607
            No improvement (0.1604), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2749, mae: 0.3162, huber: 0.1081, swd: 0.1160, target_std: 0.7879
    Epoch [5/50], Val Losses: mse: 0.3412, mae: 0.3961, huber: 0.1561, swd: 0.1555, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2664, mae: 0.3629, huber: 0.1253, swd: 0.1349, target_std: 0.7348
      Epoch 5 composite train-obj: 0.108129
            No improvement (0.1561), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.2639, mae: 0.3102, huber: 0.1041, swd: 0.1097, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3477, mae: 0.4014, huber: 0.1592, swd: 0.1534, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2675, mae: 0.3583, huber: 0.1255, swd: 0.1288, target_std: 0.7348
      Epoch 6 composite train-obj: 0.104055
    Epoch [6/50], Test Losses: mse: 0.2209, mae: 0.3242, huber: 0.1045, swd: 0.0986, target_std: 0.7348
    Best round's Test MSE: 0.2209, MAE: 0.3242, SWD: 0.0986
    Best round's Validation MSE: 0.3322, MAE: 0.3970
    Best round's Test verification MSE : 0.2209, MAE: 0.3242, SWD: 0.0986
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred720_20250501_1931)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2434 ± 0.0160
      mae: 0.3429 ± 0.0133
      huber: 0.1148 ± 0.0073
      swd: 0.1141 ± 0.0122
      target_std: 0.7348 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3358 ± 0.0027
      mae: 0.3951 ± 0.0014
      huber: 0.1547 ± 0.0005
      swd: 0.1511 ± 0.0067
      target_std: 0.9639 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq196_pred720_20250501_1931
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent=4,
    householder_reflects_data=8,
)
cfg.x_to_z_delay.enable_magnitudes = [False, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, False]  
cfg.x_to_z_delay.spectral_flags_scale_shift = [False, False]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]

cfg.x_to_z_deri.enable_magnitudes = [False, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, False]
cfg.x_to_z_deri.spectral_flags_scale_shift = [False, False]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]

cfg.z_to_x_main.enable_magnitudes = [False, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, False]
cfg.z_to_x_main.spectral_flags_scale_shift = [False, False]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]

cfg.z_to_y_main.enable_magnitudes = [False, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, False]
cfg.z_to_y_main.spectral_flags_scale_shift = [False, False]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]

exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3868, mae: 0.3824, huber: 0.1488, swd: 0.1800, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3375, mae: 0.4068, huber: 0.1558, swd: 0.1703, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2380, mae: 0.3453, huber: 0.1127, swd: 0.1177, target_std: 0.7348
      Epoch 1 composite train-obj: 0.148830
            Val objective improved inf → 0.1558, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3257, mae: 0.3406, huber: 0.1245, swd: 0.1366, target_std: 0.7879
    Epoch [2/50], Val Losses: mse: 0.3336, mae: 0.4041, huber: 0.1549, swd: 0.1578, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2429, mae: 0.3489, huber: 0.1153, swd: 0.1212, target_std: 0.7348
      Epoch 2 composite train-obj: 0.124468
            Val objective improved 0.1558 → 0.1549, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3077, mae: 0.3317, huber: 0.1186, swd: 0.1283, target_std: 0.7879
    Epoch [3/50], Val Losses: mse: 0.3967, mae: 0.4392, huber: 0.1792, swd: 0.2212, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2807, mae: 0.3793, huber: 0.1321, swd: 0.1670, target_std: 0.7348
      Epoch 3 composite train-obj: 0.118562
            No improvement (0.1792), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2948, mae: 0.3258, huber: 0.1145, swd: 0.1216, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3432, mae: 0.3991, huber: 0.1578, swd: 0.1428, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2427, mae: 0.3375, huber: 0.1143, swd: 0.1112, target_std: 0.7348
      Epoch 4 composite train-obj: 0.114473
            No improvement (0.1578), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2806, mae: 0.3199, huber: 0.1101, swd: 0.1135, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3464, mae: 0.4017, huber: 0.1591, swd: 0.1487, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2583, mae: 0.3549, huber: 0.1213, swd: 0.1292, target_std: 0.7348
      Epoch 5 composite train-obj: 0.110144
            No improvement (0.1591), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2686, mae: 0.3137, huber: 0.1060, swd: 0.1066, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3813, mae: 0.4143, huber: 0.1712, swd: 0.1653, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2706, mae: 0.3557, huber: 0.1255, swd: 0.1323, target_std: 0.7348
      Epoch 6 composite train-obj: 0.106016
            No improvement (0.1712), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2582, mae: 0.3083, huber: 0.1024, swd: 0.1012, target_std: 0.7879
    Epoch [7/50], Val Losses: mse: 0.3729, mae: 0.4125, huber: 0.1683, swd: 0.1518, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2796, mae: 0.3610, huber: 0.1293, swd: 0.1308, target_std: 0.7348
      Epoch 7 composite train-obj: 0.102364
    Epoch [7/50], Test Losses: mse: 0.2429, mae: 0.3489, huber: 0.1153, swd: 0.1212, target_std: 0.7348
    Best round's Test MSE: 0.2429, MAE: 0.3489, SWD: 0.1212
    Best round's Validation MSE: 0.3336, MAE: 0.4041
    Best round's Test verification MSE : 0.2429, MAE: 0.3489, SWD: 0.1212
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3877, mae: 0.3808, huber: 0.1486, swd: 0.1746, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3661, mae: 0.4281, huber: 0.1681, swd: 0.1910, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2459, mae: 0.3534, huber: 0.1165, swd: 0.1225, target_std: 0.7348
      Epoch 1 composite train-obj: 0.148586
            Val objective improved inf → 0.1681, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3266, mae: 0.3404, huber: 0.1245, swd: 0.1321, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3402, mae: 0.3996, huber: 0.1566, swd: 0.1459, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2381, mae: 0.3356, huber: 0.1121, swd: 0.0983, target_std: 0.7348
      Epoch 2 composite train-obj: 0.124493
            Val objective improved 0.1681 → 0.1566, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3113, mae: 0.3336, huber: 0.1196, swd: 0.1255, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3521, mae: 0.4121, huber: 0.1615, swd: 0.1741, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2523, mae: 0.3542, huber: 0.1190, swd: 0.1272, target_std: 0.7348
      Epoch 3 composite train-obj: 0.119572
            No improvement (0.1615), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2979, mae: 0.3268, huber: 0.1154, swd: 0.1185, target_std: 0.7879
    Epoch [4/50], Val Losses: mse: 0.3507, mae: 0.4012, huber: 0.1597, swd: 0.1543, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2476, mae: 0.3438, huber: 0.1166, swd: 0.1079, target_std: 0.7348
      Epoch 4 composite train-obj: 0.115361
            No improvement (0.1597), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2845, mae: 0.3209, huber: 0.1112, swd: 0.1110, target_std: 0.7879
    Epoch [5/50], Val Losses: mse: 0.3356, mae: 0.3919, huber: 0.1540, swd: 0.1359, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2456, mae: 0.3390, huber: 0.1154, swd: 0.1043, target_std: 0.7348
      Epoch 5 composite train-obj: 0.111225
            Val objective improved 0.1566 → 0.1540, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2729, mae: 0.3161, huber: 0.1074, swd: 0.1051, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3438, mae: 0.3964, huber: 0.1573, swd: 0.1422, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2625, mae: 0.3509, huber: 0.1227, swd: 0.1216, target_std: 0.7348
      Epoch 6 composite train-obj: 0.107406
            No improvement (0.1573), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.2627, mae: 0.3105, huber: 0.1038, swd: 0.0996, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3528, mae: 0.4023, huber: 0.1606, swd: 0.1337, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2637, mae: 0.3515, huber: 0.1232, swd: 0.1079, target_std: 0.7348
      Epoch 7 composite train-obj: 0.103753
            No improvement (0.1606), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.2514, mae: 0.3052, huber: 0.1002, swd: 0.0925, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3795, mae: 0.4210, huber: 0.1703, swd: 0.1587, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2863, mae: 0.3758, huber: 0.1336, swd: 0.1292, target_std: 0.7348
      Epoch 8 composite train-obj: 0.100176
            No improvement (0.1703), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.2399, mae: 0.2998, huber: 0.0965, swd: 0.0844, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3641, mae: 0.4057, huber: 0.1644, swd: 0.1363, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2745, mae: 0.3570, huber: 0.1276, swd: 0.1123, target_std: 0.7348
      Epoch 9 composite train-obj: 0.096497
            No improvement (0.1644), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.2294, mae: 0.2930, huber: 0.0924, swd: 0.0789, target_std: 0.7878
    Epoch [10/50], Val Losses: mse: 0.3611, mae: 0.4064, huber: 0.1636, swd: 0.1379, target_std: 0.9639
    Epoch [10/50], Test Losses: mse: 0.2831, mae: 0.3727, huber: 0.1323, swd: 0.1191, target_std: 0.7348
      Epoch 10 composite train-obj: 0.092400
    Epoch [10/50], Test Losses: mse: 0.2456, mae: 0.3390, huber: 0.1154, swd: 0.1043, target_std: 0.7348
    Best round's Test MSE: 0.2456, MAE: 0.3390, SWD: 0.1043
    Best round's Validation MSE: 0.3356, MAE: 0.3919
    Best round's Test verification MSE : 0.2456, MAE: 0.3390, SWD: 0.1043
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3884, mae: 0.3824, huber: 0.1492, swd: 0.1880, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3361, mae: 0.4026, huber: 0.1554, swd: 0.1741, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2282, mae: 0.3343, huber: 0.1081, swd: 0.1116, target_std: 0.7348
      Epoch 1 composite train-obj: 0.149153
            Val objective improved inf → 0.1554, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3246, mae: 0.3406, huber: 0.1241, swd: 0.1429, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3303, mae: 0.3947, huber: 0.1531, swd: 0.1594, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2374, mae: 0.3394, huber: 0.1123, swd: 0.1211, target_std: 0.7348
      Epoch 2 composite train-obj: 0.124135
            Val objective improved 0.1554 → 0.1531, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3082, mae: 0.3317, huber: 0.1185, swd: 0.1341, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3373, mae: 0.3970, huber: 0.1549, swd: 0.1615, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2363, mae: 0.3364, huber: 0.1118, swd: 0.1195, target_std: 0.7348
      Epoch 3 composite train-obj: 0.118531
            No improvement (0.1549), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2952, mae: 0.3260, huber: 0.1145, swd: 0.1267, target_std: 0.7879
    Epoch [4/50], Val Losses: mse: 0.3424, mae: 0.3983, huber: 0.1573, swd: 0.1536, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2476, mae: 0.3428, huber: 0.1165, swd: 0.1227, target_std: 0.7348
      Epoch 4 composite train-obj: 0.114539
            No improvement (0.1573), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2807, mae: 0.3202, huber: 0.1101, swd: 0.1178, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3576, mae: 0.4068, huber: 0.1628, swd: 0.1639, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2621, mae: 0.3621, huber: 0.1237, swd: 0.1376, target_std: 0.7348
      Epoch 5 composite train-obj: 0.110112
            No improvement (0.1628), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2694, mae: 0.3147, huber: 0.1062, swd: 0.1110, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3763, mae: 0.4181, huber: 0.1698, swd: 0.1577, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2758, mae: 0.3623, huber: 0.1287, swd: 0.1277, target_std: 0.7348
      Epoch 6 composite train-obj: 0.106179
            No improvement (0.1698), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2586, mae: 0.3092, huber: 0.1023, swd: 0.1043, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3842, mae: 0.4178, huber: 0.1722, swd: 0.1641, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2755, mae: 0.3611, huber: 0.1285, swd: 0.1319, target_std: 0.7348
      Epoch 7 composite train-obj: 0.102332
    Epoch [7/50], Test Losses: mse: 0.2374, mae: 0.3394, huber: 0.1123, swd: 0.1211, target_std: 0.7348
    Best round's Test MSE: 0.2374, MAE: 0.3394, SWD: 0.1211
    Best round's Validation MSE: 0.3303, MAE: 0.3947
    Best round's Test verification MSE : 0.2374, MAE: 0.3394, SWD: 0.1211
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq196_pred720_20250501_2042)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2420 ± 0.0034
      mae: 0.3425 ± 0.0046
      huber: 0.1143 ± 0.0014
      swd: 0.1155 ± 0.0079
      target_std: 0.7348 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3332 ± 0.0022
      mae: 0.3969 ± 0.0052
      huber: 0.1540 ± 0.0008
      swd: 0.1510 ± 0.0107
      target_std: 0.9639 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq196_pred720_20250501_2042
    Model: ACL
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### Timemixer

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1568, mae: 0.2307, huber: 0.0643, swd: 0.0621, target_std: 0.7858
    Epoch [1/50], Val Losses: mse: 0.1555, mae: 0.2539, huber: 0.0745, swd: 0.0670, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1150, mae: 0.2244, huber: 0.0556, swd: 0.0490, target_std: 0.7443
      Epoch 1 composite train-obj: 0.064308
            Val objective improved inf → 0.0745, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1426, mae: 0.2183, huber: 0.0585, swd: 0.0573, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1545, mae: 0.2526, huber: 0.0740, swd: 0.0656, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1157, mae: 0.2247, huber: 0.0557, swd: 0.0489, target_std: 0.7443
      Epoch 2 composite train-obj: 0.058493
            Val objective improved 0.0745 → 0.0740, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1374, mae: 0.2143, huber: 0.0564, swd: 0.0551, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1535, mae: 0.2514, huber: 0.0735, swd: 0.0656, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1134, mae: 0.2234, huber: 0.0547, swd: 0.0471, target_std: 0.7443
      Epoch 3 composite train-obj: 0.056380
            Val objective improved 0.0740 → 0.0735, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1330, mae: 0.2114, huber: 0.0548, swd: 0.0532, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1560, mae: 0.2549, huber: 0.0748, swd: 0.0692, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1133, mae: 0.2239, huber: 0.0548, swd: 0.0486, target_std: 0.7443
      Epoch 4 composite train-obj: 0.054761
            No improvement (0.0748), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.1287, mae: 0.2089, huber: 0.0531, swd: 0.0515, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1541, mae: 0.2533, huber: 0.0740, swd: 0.0679, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1147, mae: 0.2249, huber: 0.0553, swd: 0.0483, target_std: 0.7443
      Epoch 5 composite train-obj: 0.053140
            No improvement (0.0740), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.1246, mae: 0.2067, huber: 0.0517, swd: 0.0497, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1609, mae: 0.2604, huber: 0.0771, swd: 0.0702, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1204, mae: 0.2281, huber: 0.0578, swd: 0.0515, target_std: 0.7443
      Epoch 6 composite train-obj: 0.051728
            No improvement (0.0771), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.1196, mae: 0.2044, huber: 0.0501, swd: 0.0477, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1597, mae: 0.2571, huber: 0.0763, swd: 0.0697, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1168, mae: 0.2265, huber: 0.0564, swd: 0.0487, target_std: 0.7443
      Epoch 7 composite train-obj: 0.050088
            No improvement (0.0763), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.1138, mae: 0.2015, huber: 0.0482, swd: 0.0451, target_std: 0.7858
    Epoch [8/50], Val Losses: mse: 0.1606, mae: 0.2595, huber: 0.0769, swd: 0.0714, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1219, mae: 0.2308, huber: 0.0587, swd: 0.0522, target_std: 0.7443
      Epoch 8 composite train-obj: 0.048216
    Epoch [8/50], Test Losses: mse: 0.1134, mae: 0.2234, huber: 0.0547, swd: 0.0471, target_std: 0.7443
    Best round's Test MSE: 0.1134, MAE: 0.2234, SWD: 0.0471
    Best round's Validation MSE: 0.1535, MAE: 0.2514
    Best round's Test verification MSE : 0.1134, MAE: 0.2234, SWD: 0.0471
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1579, mae: 0.2311, huber: 0.0647, swd: 0.0616, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1512, mae: 0.2496, huber: 0.0725, swd: 0.0645, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1131, mae: 0.2251, huber: 0.0549, swd: 0.0457, target_std: 0.7443
      Epoch 1 composite train-obj: 0.064682
            Val objective improved inf → 0.0725, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1429, mae: 0.2187, huber: 0.0586, swd: 0.0564, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1552, mae: 0.2528, huber: 0.0743, swd: 0.0658, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1119, mae: 0.2234, huber: 0.0543, swd: 0.0451, target_std: 0.7443
      Epoch 2 composite train-obj: 0.058649
            No improvement (0.0743), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1376, mae: 0.2147, huber: 0.0566, swd: 0.0544, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1541, mae: 0.2519, huber: 0.0738, swd: 0.0650, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1157, mae: 0.2259, huber: 0.0559, swd: 0.0479, target_std: 0.7443
      Epoch 3 composite train-obj: 0.056564
            No improvement (0.0738), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1328, mae: 0.2116, huber: 0.0548, swd: 0.0525, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1578, mae: 0.2533, huber: 0.0753, swd: 0.0679, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1133, mae: 0.2233, huber: 0.0548, swd: 0.0472, target_std: 0.7443
      Epoch 4 composite train-obj: 0.054770
            No improvement (0.0753), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1277, mae: 0.2085, huber: 0.0529, swd: 0.0505, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1567, mae: 0.2544, huber: 0.0750, swd: 0.0660, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1175, mae: 0.2266, huber: 0.0565, swd: 0.0486, target_std: 0.7443
      Epoch 5 composite train-obj: 0.052903
            No improvement (0.0750), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1219, mae: 0.2056, huber: 0.0510, swd: 0.0480, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1626, mae: 0.2582, huber: 0.0774, swd: 0.0692, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1202, mae: 0.2293, huber: 0.0576, swd: 0.0496, target_std: 0.7443
      Epoch 6 composite train-obj: 0.050978
    Epoch [6/50], Test Losses: mse: 0.1131, mae: 0.2251, huber: 0.0549, swd: 0.0457, target_std: 0.7443
    Best round's Test MSE: 0.1131, MAE: 0.2251, SWD: 0.0457
    Best round's Validation MSE: 0.1512, MAE: 0.2496
    Best round's Test verification MSE : 0.1131, MAE: 0.2251, SWD: 0.0457
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1593, mae: 0.2330, huber: 0.0653, swd: 0.0576, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1530, mae: 0.2513, huber: 0.0734, swd: 0.0605, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1138, mae: 0.2262, huber: 0.0552, swd: 0.0434, target_std: 0.7443
      Epoch 1 composite train-obj: 0.065330
            Val objective improved inf → 0.0734, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1429, mae: 0.2191, huber: 0.0587, swd: 0.0524, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1557, mae: 0.2530, huber: 0.0745, swd: 0.0619, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1123, mae: 0.2227, huber: 0.0544, swd: 0.0433, target_std: 0.7443
      Epoch 2 composite train-obj: 0.058745
            No improvement (0.0745), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1377, mae: 0.2152, huber: 0.0568, swd: 0.0505, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1557, mae: 0.2534, huber: 0.0746, swd: 0.0626, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1138, mae: 0.2220, huber: 0.0549, swd: 0.0447, target_std: 0.7443
      Epoch 3 composite train-obj: 0.056783
            No improvement (0.0746), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1336, mae: 0.2121, huber: 0.0551, swd: 0.0488, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1550, mae: 0.2526, huber: 0.0742, swd: 0.0622, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1156, mae: 0.2235, huber: 0.0557, swd: 0.0457, target_std: 0.7443
      Epoch 4 composite train-obj: 0.055128
            No improvement (0.0742), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1293, mae: 0.2095, huber: 0.0536, swd: 0.0473, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1585, mae: 0.2548, huber: 0.0758, swd: 0.0650, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1122, mae: 0.2220, huber: 0.0544, swd: 0.0428, target_std: 0.7443
      Epoch 5 composite train-obj: 0.053580
            No improvement (0.0758), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1247, mae: 0.2070, huber: 0.0520, swd: 0.0455, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1585, mae: 0.2564, huber: 0.0759, swd: 0.0627, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1169, mae: 0.2278, huber: 0.0565, swd: 0.0440, target_std: 0.7443
      Epoch 6 composite train-obj: 0.052015
    Epoch [6/50], Test Losses: mse: 0.1138, mae: 0.2262, huber: 0.0552, swd: 0.0434, target_std: 0.7443
    Best round's Test MSE: 0.1138, MAE: 0.2262, SWD: 0.0434
    Best round's Validation MSE: 0.1530, MAE: 0.2513
    Best round's Test verification MSE : 0.1138, MAE: 0.2262, SWD: 0.0434
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq196_pred96_20250430_2347)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1134 ± 0.0003
      mae: 0.2249 ± 0.0012
      huber: 0.0549 ± 0.0002
      swd: 0.0454 ± 0.0015
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1526 ± 0.0010
      mae: 0.2508 ± 0.0008
      huber: 0.0732 ± 0.0004
      swd: 0.0635 ± 0.0022
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq196_pred96_20250430_2347
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2889, mae: 0.3045, huber: 0.1085, swd: 0.1072, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2603, mae: 0.3348, huber: 0.1219, swd: 0.1181, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1714, mae: 0.2779, huber: 0.0813, swd: 0.0640, target_std: 0.7399
      Epoch 1 composite train-obj: 0.108537
            Val objective improved inf → 0.1219, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2698, mae: 0.2937, huber: 0.1023, swd: 0.1019, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2572, mae: 0.3332, huber: 0.1206, swd: 0.1144, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1739, mae: 0.2784, huber: 0.0822, swd: 0.0647, target_std: 0.7399
      Epoch 2 composite train-obj: 0.102269
            Val objective improved 0.1219 → 0.1206, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2603, mae: 0.2895, huber: 0.0996, swd: 0.0984, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2668, mae: 0.3379, huber: 0.1242, swd: 0.1197, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1761, mae: 0.2806, huber: 0.0832, swd: 0.0674, target_std: 0.7399
      Epoch 3 composite train-obj: 0.099553
            No improvement (0.1242), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2483, mae: 0.2855, huber: 0.0964, swd: 0.0930, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2642, mae: 0.3382, huber: 0.1234, swd: 0.1155, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1767, mae: 0.2833, huber: 0.0837, swd: 0.0658, target_std: 0.7399
      Epoch 4 composite train-obj: 0.096381
            No improvement (0.1234), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2358, mae: 0.2807, huber: 0.0925, swd: 0.0876, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2669, mae: 0.3404, huber: 0.1244, swd: 0.1175, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1800, mae: 0.2853, huber: 0.0851, swd: 0.0674, target_std: 0.7399
      Epoch 5 composite train-obj: 0.092519
            No improvement (0.1244), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2225, mae: 0.2751, huber: 0.0883, swd: 0.0831, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2660, mae: 0.3401, huber: 0.1238, swd: 0.1185, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1843, mae: 0.2888, huber: 0.0868, swd: 0.0676, target_std: 0.7399
      Epoch 6 composite train-obj: 0.088257
            No improvement (0.1238), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2091, mae: 0.2696, huber: 0.0842, swd: 0.0785, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2768, mae: 0.3482, huber: 0.1285, swd: 0.1205, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1898, mae: 0.2939, huber: 0.0895, swd: 0.0694, target_std: 0.7399
      Epoch 7 composite train-obj: 0.084169
    Epoch [7/50], Test Losses: mse: 0.1739, mae: 0.2784, huber: 0.0822, swd: 0.0647, target_std: 0.7399
    Best round's Test MSE: 0.1739, MAE: 0.2784, SWD: 0.0647
    Best round's Validation MSE: 0.2572, MAE: 0.3332
    Best round's Test verification MSE : 0.1739, MAE: 0.2784, SWD: 0.0647
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2905, mae: 0.3059, huber: 0.1092, swd: 0.1126, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2579, mae: 0.3342, huber: 0.1210, swd: 0.1203, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1739, mae: 0.2803, huber: 0.0824, swd: 0.0692, target_std: 0.7399
      Epoch 1 composite train-obj: 0.109205
            Val objective improved inf → 0.1210, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2717, mae: 0.2947, huber: 0.1028, swd: 0.1072, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2651, mae: 0.3377, huber: 0.1239, swd: 0.1213, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1765, mae: 0.2828, huber: 0.0837, swd: 0.0689, target_std: 0.7399
      Epoch 2 composite train-obj: 0.102776
            No improvement (0.1239), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2630, mae: 0.2904, huber: 0.1002, swd: 0.1036, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2630, mae: 0.3361, huber: 0.1228, swd: 0.1226, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1748, mae: 0.2801, huber: 0.0827, swd: 0.0691, target_std: 0.7399
      Epoch 3 composite train-obj: 0.100206
            No improvement (0.1228), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2531, mae: 0.2868, huber: 0.0976, swd: 0.0994, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2581, mae: 0.3352, huber: 0.1210, swd: 0.1180, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1782, mae: 0.2834, huber: 0.0842, swd: 0.0692, target_std: 0.7399
      Epoch 4 composite train-obj: 0.097568
            No improvement (0.1210), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2408, mae: 0.2826, huber: 0.0941, swd: 0.0935, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2642, mae: 0.3385, huber: 0.1234, swd: 0.1208, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1872, mae: 0.2890, huber: 0.0878, swd: 0.0727, target_std: 0.7399
      Epoch 5 composite train-obj: 0.094112
            No improvement (0.1234), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.2290, mae: 0.2780, huber: 0.0905, swd: 0.0883, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2704, mae: 0.3436, huber: 0.1261, swd: 0.1249, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1860, mae: 0.2903, huber: 0.0878, swd: 0.0729, target_std: 0.7399
      Epoch 6 composite train-obj: 0.090509
    Epoch [6/50], Test Losses: mse: 0.1739, mae: 0.2803, huber: 0.0824, swd: 0.0692, target_std: 0.7399
    Best round's Test MSE: 0.1739, MAE: 0.2803, SWD: 0.0692
    Best round's Validation MSE: 0.2579, MAE: 0.3342
    Best round's Test verification MSE : 0.1739, MAE: 0.2803, SWD: 0.0692
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3006, mae: 0.3126, huber: 0.1130, swd: 0.1084, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2645, mae: 0.3370, huber: 0.1235, swd: 0.1168, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1734, mae: 0.2798, huber: 0.0823, swd: 0.0628, target_std: 0.7399
      Epoch 1 composite train-obj: 0.112960
            Val objective improved inf → 0.1235, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2709, mae: 0.2953, huber: 0.1029, swd: 0.1023, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2591, mae: 0.3355, huber: 0.1215, swd: 0.1125, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1733, mae: 0.2809, huber: 0.0824, swd: 0.0624, target_std: 0.7399
      Epoch 2 composite train-obj: 0.102913
            Val objective improved 0.1235 → 0.1215, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2623, mae: 0.2912, huber: 0.1003, swd: 0.0989, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2725, mae: 0.3420, huber: 0.1268, swd: 0.1167, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1770, mae: 0.2835, huber: 0.0840, swd: 0.0636, target_std: 0.7399
      Epoch 3 composite train-obj: 0.100283
            No improvement (0.1268), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2530, mae: 0.2878, huber: 0.0977, swd: 0.0949, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2546, mae: 0.3336, huber: 0.1193, swd: 0.1126, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1805, mae: 0.2849, huber: 0.0849, swd: 0.0659, target_std: 0.7399
      Epoch 4 composite train-obj: 0.097671
            Val objective improved 0.1215 → 0.1193, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2396, mae: 0.2830, huber: 0.0938, swd: 0.0891, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2679, mae: 0.3417, huber: 0.1248, swd: 0.1155, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1818, mae: 0.2876, huber: 0.0860, swd: 0.0648, target_std: 0.7399
      Epoch 5 composite train-obj: 0.093838
            No improvement (0.1248), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2278, mae: 0.2778, huber: 0.0901, swd: 0.0846, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2821, mae: 0.3508, huber: 0.1306, swd: 0.1227, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1883, mae: 0.2930, huber: 0.0888, swd: 0.0687, target_std: 0.7399
      Epoch 6 composite train-obj: 0.090062
            No improvement (0.1306), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.2162, mae: 0.2729, huber: 0.0865, swd: 0.0812, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2757, mae: 0.3463, huber: 0.1279, swd: 0.1225, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1934, mae: 0.2951, huber: 0.0905, swd: 0.0701, target_std: 0.7399
      Epoch 7 composite train-obj: 0.086519
            No improvement (0.1279), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.2080, mae: 0.2692, huber: 0.0839, swd: 0.0786, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2808, mae: 0.3496, huber: 0.1300, swd: 0.1220, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.1952, mae: 0.2967, huber: 0.0913, swd: 0.0698, target_std: 0.7399
      Epoch 8 composite train-obj: 0.083893
            No improvement (0.1300), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.1985, mae: 0.2651, huber: 0.0810, swd: 0.0749, target_std: 0.7864
    Epoch [9/50], Val Losses: mse: 0.2950, mae: 0.3579, huber: 0.1353, swd: 0.1246, target_std: 0.9653
    Epoch [9/50], Test Losses: mse: 0.2011, mae: 0.3020, huber: 0.0942, swd: 0.0715, target_std: 0.7399
      Epoch 9 composite train-obj: 0.080977
    Epoch [9/50], Test Losses: mse: 0.1805, mae: 0.2849, huber: 0.0849, swd: 0.0659, target_std: 0.7399
    Best round's Test MSE: 0.1805, MAE: 0.2849, SWD: 0.0659
    Best round's Validation MSE: 0.2546, MAE: 0.3336
    Best round's Test verification MSE : 0.1805, MAE: 0.2849, SWD: 0.0659
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq196_pred336_20250501_0005)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1761 ± 0.0031
      mae: 0.2812 ± 0.0027
      huber: 0.0832 ± 0.0012
      swd: 0.0666 ± 0.0019
      target_std: 0.7399 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2566 ± 0.0014
      mae: 0.3337 ± 0.0004
      huber: 0.1203 ± 0.0007
      swd: 0.1158 ± 0.0033
      target_std: 0.9653 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq196_pred336_20250501_0005
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3916, mae: 0.3556, huber: 0.1416, swd: 0.1459, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3300, mae: 0.3889, huber: 0.1528, swd: 0.1378, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2138, mae: 0.3173, huber: 0.1016, swd: 0.0799, target_std: 0.7348
      Epoch 1 composite train-obj: 0.141600
            Val objective improved inf → 0.1528, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3715, mae: 0.3450, huber: 0.1346, swd: 0.1424, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3286, mae: 0.3864, huber: 0.1517, swd: 0.1372, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2124, mae: 0.3138, huber: 0.1006, swd: 0.0791, target_std: 0.7348
      Epoch 2 composite train-obj: 0.134641
            Val objective improved 0.1528 → 0.1517, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3600, mae: 0.3403, huber: 0.1311, swd: 0.1378, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3406, mae: 0.3949, huber: 0.1567, swd: 0.1431, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2185, mae: 0.3185, huber: 0.1031, swd: 0.0818, target_std: 0.7348
      Epoch 3 composite train-obj: 0.131131
            No improvement (0.1567), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.3431, mae: 0.3345, huber: 0.1265, swd: 0.1295, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3537, mae: 0.4035, huber: 0.1621, swd: 0.1484, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2285, mae: 0.3260, huber: 0.1075, swd: 0.0835, target_std: 0.7348
      Epoch 4 composite train-obj: 0.126462
            No improvement (0.1621), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.3240, mae: 0.3266, huber: 0.1206, swd: 0.1214, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3581, mae: 0.4047, huber: 0.1631, swd: 0.1461, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2308, mae: 0.3289, huber: 0.1085, swd: 0.0818, target_std: 0.7348
      Epoch 5 composite train-obj: 0.120603
            No improvement (0.1631), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.3054, mae: 0.3189, huber: 0.1149, swd: 0.1153, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3674, mae: 0.4084, huber: 0.1662, swd: 0.1553, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2301, mae: 0.3278, huber: 0.1083, swd: 0.0828, target_std: 0.7348
      Epoch 6 composite train-obj: 0.114940
            No improvement (0.1662), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2920, mae: 0.3131, huber: 0.1107, swd: 0.1115, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3761, mae: 0.4138, huber: 0.1694, swd: 0.1574, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2399, mae: 0.3348, huber: 0.1123, swd: 0.0860, target_std: 0.7348
      Epoch 7 composite train-obj: 0.110660
    Epoch [7/50], Test Losses: mse: 0.2124, mae: 0.3138, huber: 0.1006, swd: 0.0791, target_std: 0.7348
    Best round's Test MSE: 0.2124, MAE: 0.3138, SWD: 0.0791
    Best round's Validation MSE: 0.3286, MAE: 0.3864
    Best round's Test verification MSE : 0.2124, MAE: 0.3138, SWD: 0.0791
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3900, mae: 0.3550, huber: 0.1412, swd: 0.1387, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3276, mae: 0.3859, huber: 0.1516, swd: 0.1308, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2137, mae: 0.3135, huber: 0.1011, swd: 0.0732, target_std: 0.7348
      Epoch 1 composite train-obj: 0.141207
            Val objective improved inf → 0.1516, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3711, mae: 0.3450, huber: 0.1347, swd: 0.1339, target_std: 0.7879
    Epoch [2/50], Val Losses: mse: 0.3272, mae: 0.3857, huber: 0.1513, swd: 0.1267, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2120, mae: 0.3142, huber: 0.1005, swd: 0.0719, target_std: 0.7348
      Epoch 2 composite train-obj: 0.134742
            Val objective improved 0.1516 → 0.1513, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3612, mae: 0.3403, huber: 0.1315, swd: 0.1305, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3278, mae: 0.3869, huber: 0.1514, swd: 0.1293, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2133, mae: 0.3160, huber: 0.1010, swd: 0.0733, target_std: 0.7348
      Epoch 3 composite train-obj: 0.131509
            No improvement (0.1514), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.3491, mae: 0.3362, huber: 0.1282, swd: 0.1256, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3361, mae: 0.3933, huber: 0.1550, swd: 0.1308, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2168, mae: 0.3192, huber: 0.1027, swd: 0.0750, target_std: 0.7348
      Epoch 4 composite train-obj: 0.128199
            No improvement (0.1550), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.3329, mae: 0.3306, huber: 0.1236, swd: 0.1192, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3365, mae: 0.3937, huber: 0.1549, swd: 0.1339, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2189, mae: 0.3195, huber: 0.1033, swd: 0.0743, target_std: 0.7348
      Epoch 5 composite train-obj: 0.123559
            No improvement (0.1549), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.3166, mae: 0.3243, huber: 0.1187, swd: 0.1139, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3443, mae: 0.3977, huber: 0.1581, swd: 0.1346, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2269, mae: 0.3256, huber: 0.1069, swd: 0.0761, target_std: 0.7348
      Epoch 6 composite train-obj: 0.118692
            No improvement (0.1581), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.3028, mae: 0.3185, huber: 0.1143, swd: 0.1096, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3557, mae: 0.4049, huber: 0.1625, swd: 0.1436, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2294, mae: 0.3276, huber: 0.1080, swd: 0.0772, target_std: 0.7348
      Epoch 7 composite train-obj: 0.114267
    Epoch [7/50], Test Losses: mse: 0.2120, mae: 0.3142, huber: 0.1005, swd: 0.0719, target_std: 0.7348
    Best round's Test MSE: 0.2120, MAE: 0.3142, SWD: 0.0719
    Best round's Validation MSE: 0.3272, MAE: 0.3857
    Best round's Test verification MSE : 0.2120, MAE: 0.3142, SWD: 0.0719
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3963, mae: 0.3590, huber: 0.1435, swd: 0.1553, target_std: 0.7879
    Epoch [1/50], Val Losses: mse: 0.3399, mae: 0.3927, huber: 0.1566, swd: 0.1503, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2170, mae: 0.3146, huber: 0.1024, swd: 0.0841, target_std: 0.7348
      Epoch 1 composite train-obj: 0.143515
            Val objective improved inf → 0.1566, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3738, mae: 0.3465, huber: 0.1355, swd: 0.1493, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3262, mae: 0.3872, huber: 0.1514, swd: 0.1385, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2149, mae: 0.3182, huber: 0.1019, swd: 0.0830, target_std: 0.7348
      Epoch 2 composite train-obj: 0.135492
            Val objective improved 0.1566 → 0.1514, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3643, mae: 0.3424, huber: 0.1325, swd: 0.1455, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3251, mae: 0.3881, huber: 0.1509, swd: 0.1370, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2165, mae: 0.3196, huber: 0.1026, swd: 0.0830, target_std: 0.7348
      Epoch 3 composite train-obj: 0.132523
            Val objective improved 0.1514 → 0.1509, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3542, mae: 0.3389, huber: 0.1297, swd: 0.1411, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3304, mae: 0.3912, huber: 0.1530, swd: 0.1359, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2187, mae: 0.3209, huber: 0.1036, swd: 0.0818, target_std: 0.7348
      Epoch 4 composite train-obj: 0.129717
            No improvement (0.1530), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.3410, mae: 0.3343, huber: 0.1260, swd: 0.1351, target_std: 0.7879
    Epoch [5/50], Val Losses: mse: 0.3427, mae: 0.3992, huber: 0.1583, swd: 0.1422, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2260, mae: 0.3257, huber: 0.1068, swd: 0.0866, target_std: 0.7348
      Epoch 5 composite train-obj: 0.126019
            No improvement (0.1583), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.3258, mae: 0.3290, huber: 0.1217, swd: 0.1285, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3440, mae: 0.4004, huber: 0.1588, swd: 0.1436, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2279, mae: 0.3293, huber: 0.1079, swd: 0.0857, target_std: 0.7348
      Epoch 6 composite train-obj: 0.121719
            No improvement (0.1588), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.3118, mae: 0.3235, huber: 0.1174, swd: 0.1237, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3526, mae: 0.4032, huber: 0.1614, swd: 0.1497, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2310, mae: 0.3278, huber: 0.1084, swd: 0.0871, target_std: 0.7348
      Epoch 7 composite train-obj: 0.117446
            No improvement (0.1614), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.3000, mae: 0.3180, huber: 0.1135, swd: 0.1195, target_std: 0.7879
    Epoch [8/50], Val Losses: mse: 0.3648, mae: 0.4112, huber: 0.1664, swd: 0.1570, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2360, mae: 0.3320, huber: 0.1106, swd: 0.0903, target_std: 0.7348
      Epoch 8 composite train-obj: 0.113506
    Epoch [8/50], Test Losses: mse: 0.2165, mae: 0.3196, huber: 0.1026, swd: 0.0830, target_std: 0.7348
    Best round's Test MSE: 0.2165, MAE: 0.3196, SWD: 0.0830
    Best round's Validation MSE: 0.3251, MAE: 0.3881
    Best round's Test verification MSE : 0.2165, MAE: 0.3196, SWD: 0.0830
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq196_pred720_20250501_1924)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2136 ± 0.0020
      mae: 0.3159 ± 0.0027
      huber: 0.1012 ± 0.0010
      swd: 0.0780 ± 0.0046
      target_std: 0.7348 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3270 ± 0.0015
      mae: 0.3867 ± 0.0010
      huber: 0.1513 ± 0.0003
      swd: 0.1336 ± 0.0049
      target_std: 0.9639 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq196_pred720_20250501_1924
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### PatchTST

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1685, mae: 0.2421, huber: 0.0693, swd: 0.0608, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1567, mae: 0.2570, huber: 0.0752, swd: 0.0721, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1108, mae: 0.2250, huber: 0.0540, swd: 0.0464, target_std: 0.7443
      Epoch 1 composite train-obj: 0.069257
            Val objective improved inf → 0.0752, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1555, mae: 0.2308, huber: 0.0638, swd: 0.0577, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1562, mae: 0.2575, huber: 0.0751, swd: 0.0706, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1133, mae: 0.2279, huber: 0.0551, swd: 0.0468, target_std: 0.7443
      Epoch 2 composite train-obj: 0.063842
            Val objective improved 0.0752 → 0.0751, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1512, mae: 0.2277, huber: 0.0622, swd: 0.0564, target_std: 0.7858
    Epoch [3/50], Val Losses: mse: 0.1538, mae: 0.2532, huber: 0.0738, swd: 0.0679, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1125, mae: 0.2247, huber: 0.0545, swd: 0.0472, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062183
            Val objective improved 0.0751 → 0.0738, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1484, mae: 0.2257, huber: 0.0611, swd: 0.0553, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1537, mae: 0.2548, huber: 0.0739, swd: 0.0706, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1100, mae: 0.2232, huber: 0.0535, swd: 0.0460, target_std: 0.7443
      Epoch 4 composite train-obj: 0.061121
            No improvement (0.0739), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.1452, mae: 0.2240, huber: 0.0601, swd: 0.0541, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1552, mae: 0.2557, huber: 0.0744, swd: 0.0695, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1117, mae: 0.2233, huber: 0.0541, swd: 0.0467, target_std: 0.7443
      Epoch 5 composite train-obj: 0.060068
            No improvement (0.0744), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.1426, mae: 0.2223, huber: 0.0591, swd: 0.0528, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1530, mae: 0.2535, huber: 0.0735, swd: 0.0668, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1133, mae: 0.2247, huber: 0.0548, swd: 0.0472, target_std: 0.7443
      Epoch 6 composite train-obj: 0.059058
            Val objective improved 0.0738 → 0.0735, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.1401, mae: 0.2209, huber: 0.0582, swd: 0.0517, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1550, mae: 0.2551, huber: 0.0745, swd: 0.0706, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1103, mae: 0.2234, huber: 0.0536, swd: 0.0465, target_std: 0.7443
      Epoch 7 composite train-obj: 0.058193
            No improvement (0.0745), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.1386, mae: 0.2203, huber: 0.0577, swd: 0.0512, target_std: 0.7858
    Epoch [8/50], Val Losses: mse: 0.1576, mae: 0.2571, huber: 0.0757, swd: 0.0709, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1133, mae: 0.2254, huber: 0.0549, swd: 0.0473, target_std: 0.7443
      Epoch 8 composite train-obj: 0.057725
            No improvement (0.0757), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.1356, mae: 0.2188, huber: 0.0568, swd: 0.0499, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1560, mae: 0.2571, huber: 0.0750, swd: 0.0689, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1174, mae: 0.2293, huber: 0.0568, swd: 0.0501, target_std: 0.7443
      Epoch 9 composite train-obj: 0.056779
            No improvement (0.0750), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.1337, mae: 0.2176, huber: 0.0561, swd: 0.0490, target_std: 0.7857
    Epoch [10/50], Val Losses: mse: 0.1594, mae: 0.2590, huber: 0.0764, swd: 0.0729, target_std: 0.9665
    Epoch [10/50], Test Losses: mse: 0.1130, mae: 0.2247, huber: 0.0548, swd: 0.0485, target_std: 0.7443
      Epoch 10 composite train-obj: 0.056085
            No improvement (0.0764), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.1310, mae: 0.2164, huber: 0.0553, swd: 0.0477, target_std: 0.7857
    Epoch [11/50], Val Losses: mse: 0.1616, mae: 0.2605, huber: 0.0775, swd: 0.0715, target_std: 0.9665
    Epoch [11/50], Test Losses: mse: 0.1173, mae: 0.2287, huber: 0.0566, swd: 0.0499, target_std: 0.7443
      Epoch 11 composite train-obj: 0.055268
    Epoch [11/50], Test Losses: mse: 0.1133, mae: 0.2247, huber: 0.0548, swd: 0.0472, target_std: 0.7443
    Best round's Test MSE: 0.1133, MAE: 0.2247, SWD: 0.0472
    Best round's Validation MSE: 0.1530, MAE: 0.2535
    Best round's Test verification MSE : 0.1133, MAE: 0.2247, SWD: 0.0472
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1677, mae: 0.2407, huber: 0.0688, swd: 0.0593, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1545, mae: 0.2563, huber: 0.0742, swd: 0.0673, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1144, mae: 0.2265, huber: 0.0554, swd: 0.0467, target_std: 0.7443
      Epoch 1 composite train-obj: 0.068811
            Val objective improved inf → 0.0742, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1555, mae: 0.2304, huber: 0.0638, swd: 0.0570, target_std: 0.7858
    Epoch [2/50], Val Losses: mse: 0.1548, mae: 0.2546, huber: 0.0742, swd: 0.0665, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1122, mae: 0.2247, huber: 0.0543, swd: 0.0447, target_std: 0.7443
      Epoch 2 composite train-obj: 0.063772
            Val objective improved 0.0742 → 0.0742, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1514, mae: 0.2274, huber: 0.0622, swd: 0.0558, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1547, mae: 0.2546, huber: 0.0741, swd: 0.0666, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1134, mae: 0.2247, huber: 0.0547, swd: 0.0464, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062168
            Val objective improved 0.0742 → 0.0741, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1487, mae: 0.2256, huber: 0.0611, swd: 0.0546, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1534, mae: 0.2535, huber: 0.0737, swd: 0.0663, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1119, mae: 0.2250, huber: 0.0543, swd: 0.0452, target_std: 0.7443
      Epoch 4 composite train-obj: 0.061106
            Val objective improved 0.0741 → 0.0737, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.1459, mae: 0.2236, huber: 0.0600, swd: 0.0534, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1522, mae: 0.2526, huber: 0.0731, swd: 0.0666, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1138, mae: 0.2255, huber: 0.0549, swd: 0.0462, target_std: 0.7443
      Epoch 5 composite train-obj: 0.060046
            Val objective improved 0.0737 → 0.0731, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.1431, mae: 0.2221, huber: 0.0591, swd: 0.0522, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1540, mae: 0.2559, huber: 0.0741, swd: 0.0686, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1139, mae: 0.2270, huber: 0.0550, swd: 0.0461, target_std: 0.7443
      Epoch 6 composite train-obj: 0.059060
            No improvement (0.0741), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.1407, mae: 0.2208, huber: 0.0582, swd: 0.0513, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1557, mae: 0.2559, huber: 0.0748, swd: 0.0663, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1150, mae: 0.2278, huber: 0.0555, swd: 0.0453, target_std: 0.7443
      Epoch 7 composite train-obj: 0.058245
            No improvement (0.0748), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.1381, mae: 0.2195, huber: 0.0574, swd: 0.0504, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1568, mae: 0.2567, huber: 0.0751, swd: 0.0671, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1156, mae: 0.2266, huber: 0.0557, swd: 0.0470, target_std: 0.7443
      Epoch 8 composite train-obj: 0.057394
            No improvement (0.0751), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.1362, mae: 0.2188, huber: 0.0568, swd: 0.0496, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1542, mae: 0.2556, huber: 0.0742, swd: 0.0677, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1147, mae: 0.2268, huber: 0.0553, swd: 0.0456, target_std: 0.7443
      Epoch 9 composite train-obj: 0.056811
            No improvement (0.0742), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.1336, mae: 0.2174, huber: 0.0560, swd: 0.0484, target_std: 0.7857
    Epoch [10/50], Val Losses: mse: 0.1569, mae: 0.2579, huber: 0.0755, swd: 0.0681, target_std: 0.9665
    Epoch [10/50], Test Losses: mse: 0.1161, mae: 0.2299, huber: 0.0562, swd: 0.0467, target_std: 0.7443
      Epoch 10 composite train-obj: 0.055964
    Epoch [10/50], Test Losses: mse: 0.1138, mae: 0.2255, huber: 0.0549, swd: 0.0462, target_std: 0.7443
    Best round's Test MSE: 0.1138, MAE: 0.2255, SWD: 0.0462
    Best round's Validation MSE: 0.1522, MAE: 0.2526
    Best round's Test verification MSE : 0.1138, MAE: 0.2255, SWD: 0.0462
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1693, mae: 0.2427, huber: 0.0696, swd: 0.0552, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1599, mae: 0.2621, huber: 0.0767, swd: 0.0667, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1161, mae: 0.2273, huber: 0.0562, swd: 0.0453, target_std: 0.7443
      Epoch 1 composite train-obj: 0.069611
            Val objective improved inf → 0.0767, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1556, mae: 0.2313, huber: 0.0640, swd: 0.0524, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1625, mae: 0.2646, huber: 0.0779, swd: 0.0651, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1226, mae: 0.2322, huber: 0.0589, swd: 0.0472, target_std: 0.7443
      Epoch 2 composite train-obj: 0.063959
            No improvement (0.0779), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1511, mae: 0.2279, huber: 0.0622, swd: 0.0510, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1547, mae: 0.2539, huber: 0.0741, swd: 0.0621, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1135, mae: 0.2251, huber: 0.0549, swd: 0.0430, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062198
            Val objective improved 0.0767 → 0.0741, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1478, mae: 0.2256, huber: 0.0610, swd: 0.0501, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1538, mae: 0.2543, huber: 0.0739, swd: 0.0637, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1128, mae: 0.2252, huber: 0.0547, swd: 0.0438, target_std: 0.7443
      Epoch 4 composite train-obj: 0.061012
            Val objective improved 0.0741 → 0.0739, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.1453, mae: 0.2242, huber: 0.0601, swd: 0.0491, target_std: 0.7858
    Epoch [5/50], Val Losses: mse: 0.1517, mae: 0.2526, huber: 0.0730, swd: 0.0612, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1133, mae: 0.2262, huber: 0.0550, swd: 0.0424, target_std: 0.7443
      Epoch 5 composite train-obj: 0.060122
            Val objective improved 0.0739 → 0.0730, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.1428, mae: 0.2224, huber: 0.0592, swd: 0.0481, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1524, mae: 0.2534, huber: 0.0732, swd: 0.0616, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1133, mae: 0.2265, huber: 0.0549, swd: 0.0427, target_std: 0.7443
      Epoch 6 composite train-obj: 0.059161
            No improvement (0.0732), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.1404, mae: 0.2213, huber: 0.0585, swd: 0.0472, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1566, mae: 0.2573, huber: 0.0752, swd: 0.0646, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1134, mae: 0.2270, huber: 0.0550, swd: 0.0433, target_std: 0.7443
      Epoch 7 composite train-obj: 0.058457
            No improvement (0.0752), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.1376, mae: 0.2197, huber: 0.0575, swd: 0.0461, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1553, mae: 0.2554, huber: 0.0746, swd: 0.0632, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1157, mae: 0.2279, huber: 0.0559, swd: 0.0435, target_std: 0.7443
      Epoch 8 composite train-obj: 0.057459
            No improvement (0.0746), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.1353, mae: 0.2185, huber: 0.0567, swd: 0.0450, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1519, mae: 0.2539, huber: 0.0731, swd: 0.0609, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1161, mae: 0.2278, huber: 0.0560, swd: 0.0435, target_std: 0.7443
      Epoch 9 composite train-obj: 0.056704
            No improvement (0.0731), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.1325, mae: 0.2176, huber: 0.0560, swd: 0.0440, target_std: 0.7857
    Epoch [10/50], Val Losses: mse: 0.1525, mae: 0.2530, huber: 0.0733, swd: 0.0614, target_std: 0.9665
    Epoch [10/50], Test Losses: mse: 0.1159, mae: 0.2295, huber: 0.0562, swd: 0.0437, target_std: 0.7443
      Epoch 10 composite train-obj: 0.055969
    Epoch [10/50], Test Losses: mse: 0.1133, mae: 0.2262, huber: 0.0550, swd: 0.0424, target_std: 0.7443
    Best round's Test MSE: 0.1133, MAE: 0.2262, SWD: 0.0424
    Best round's Validation MSE: 0.1517, MAE: 0.2526
    Best round's Test verification MSE : 0.1133, MAE: 0.2262, SWD: 0.0424
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq196_pred96_20250430_2351)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1135 ± 0.0002
      mae: 0.2255 ± 0.0006
      huber: 0.0549 ± 0.0001
      swd: 0.0453 ± 0.0020
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1523 ± 0.0005
      mae: 0.2529 ± 0.0005
      huber: 0.0732 ± 0.0002
      swd: 0.0649 ± 0.0026
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq196_pred96_20250430_2351
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2974, mae: 0.3123, huber: 0.1121, swd: 0.1029, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2739, mae: 0.3466, huber: 0.1277, swd: 0.1261, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1749, mae: 0.2811, huber: 0.0829, swd: 0.0662, target_std: 0.7399
      Epoch 1 composite train-obj: 0.112144
            Val objective improved inf → 0.1277, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2730, mae: 0.3009, huber: 0.1049, swd: 0.0973, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2641, mae: 0.3390, huber: 0.1233, swd: 0.1203, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1773, mae: 0.2824, huber: 0.0837, swd: 0.0667, target_std: 0.7399
      Epoch 2 composite train-obj: 0.104870
            Val objective improved 0.1277 → 0.1233, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2624, mae: 0.2967, huber: 0.1019, swd: 0.0943, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2599, mae: 0.3381, huber: 0.1217, swd: 0.1210, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1811, mae: 0.2870, huber: 0.0853, swd: 0.0680, target_std: 0.7399
      Epoch 3 composite train-obj: 0.101904
            Val objective improved 0.1233 → 0.1217, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2546, mae: 0.2937, huber: 0.0997, swd: 0.0919, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2643, mae: 0.3392, huber: 0.1232, swd: 0.1211, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1780, mae: 0.2830, huber: 0.0838, swd: 0.0658, target_std: 0.7399
      Epoch 4 composite train-obj: 0.099700
            No improvement (0.1232), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2490, mae: 0.2916, huber: 0.0981, swd: 0.0903, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2631, mae: 0.3416, huber: 0.1235, swd: 0.1220, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1762, mae: 0.2844, huber: 0.0835, swd: 0.0661, target_std: 0.7399
      Epoch 5 composite train-obj: 0.098114
            No improvement (0.1235), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.2435, mae: 0.2895, huber: 0.0966, swd: 0.0879, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2685, mae: 0.3433, huber: 0.1254, swd: 0.1239, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1804, mae: 0.2867, huber: 0.0852, swd: 0.0689, target_std: 0.7399
      Epoch 6 composite train-obj: 0.096605
            No improvement (0.1254), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.2393, mae: 0.2875, huber: 0.0952, swd: 0.0864, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2648, mae: 0.3408, huber: 0.1238, swd: 0.1197, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1822, mae: 0.2879, huber: 0.0859, swd: 0.0672, target_std: 0.7399
      Epoch 7 composite train-obj: 0.095235
            No improvement (0.1238), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.2362, mae: 0.2862, huber: 0.0943, swd: 0.0853, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2688, mae: 0.3430, huber: 0.1254, swd: 0.1234, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.1795, mae: 0.2859, huber: 0.0849, swd: 0.0682, target_std: 0.7399
      Epoch 8 composite train-obj: 0.094266
    Epoch [8/50], Test Losses: mse: 0.1811, mae: 0.2870, huber: 0.0853, swd: 0.0680, target_std: 0.7399
    Best round's Test MSE: 0.1811, MAE: 0.2870, SWD: 0.0680
    Best round's Validation MSE: 0.2599, MAE: 0.3381
    Best round's Test verification MSE : 0.1811, MAE: 0.2870, SWD: 0.0680
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2970, mae: 0.3115, huber: 0.1118, swd: 0.1069, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2589, mae: 0.3380, huber: 0.1218, swd: 0.1233, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1749, mae: 0.2836, huber: 0.0831, swd: 0.0683, target_std: 0.7399
      Epoch 1 composite train-obj: 0.111811
            Val objective improved inf → 0.1218, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2748, mae: 0.3012, huber: 0.1053, swd: 0.1029, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2646, mae: 0.3396, huber: 0.1235, swd: 0.1296, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1763, mae: 0.2807, huber: 0.0832, swd: 0.0710, target_std: 0.7399
      Epoch 2 composite train-obj: 0.105292
            No improvement (0.1235), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2628, mae: 0.2970, huber: 0.1023, swd: 0.0990, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2703, mae: 0.3426, huber: 0.1260, swd: 0.1307, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1775, mae: 0.2810, huber: 0.0836, swd: 0.0714, target_std: 0.7399
      Epoch 3 composite train-obj: 0.102284
            No improvement (0.1260), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2532, mae: 0.2936, huber: 0.0997, swd: 0.0957, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2650, mae: 0.3407, huber: 0.1239, swd: 0.1252, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1752, mae: 0.2827, huber: 0.0829, swd: 0.0684, target_std: 0.7399
      Epoch 4 composite train-obj: 0.099690
            No improvement (0.1239), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2472, mae: 0.2917, huber: 0.0981, swd: 0.0936, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2691, mae: 0.3431, huber: 0.1255, swd: 0.1284, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1814, mae: 0.2850, huber: 0.0854, swd: 0.0713, target_std: 0.7399
      Epoch 5 composite train-obj: 0.098122
            No improvement (0.1255), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.2409, mae: 0.2893, huber: 0.0963, swd: 0.0905, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2711, mae: 0.3453, huber: 0.1265, swd: 0.1273, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1814, mae: 0.2868, huber: 0.0856, swd: 0.0700, target_std: 0.7399
      Epoch 6 composite train-obj: 0.096340
    Epoch [6/50], Test Losses: mse: 0.1749, mae: 0.2836, huber: 0.0831, swd: 0.0683, target_std: 0.7399
    Best round's Test MSE: 0.1749, MAE: 0.2836, SWD: 0.0683
    Best round's Validation MSE: 0.2589, MAE: 0.3380
    Best round's Test verification MSE : 0.1749, MAE: 0.2836, SWD: 0.0683
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2963, mae: 0.3112, huber: 0.1116, swd: 0.1032, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2735, mae: 0.3460, huber: 0.1274, swd: 0.1258, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1773, mae: 0.2827, huber: 0.0839, swd: 0.0688, target_std: 0.7399
      Epoch 1 composite train-obj: 0.111589
            Val objective improved inf → 0.1274, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2753, mae: 0.3013, huber: 0.1053, swd: 0.0993, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2634, mae: 0.3397, huber: 0.1234, swd: 0.1203, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1700, mae: 0.2789, huber: 0.0809, swd: 0.0623, target_std: 0.7399
      Epoch 2 composite train-obj: 0.105309
            Val objective improved 0.1274 → 0.1234, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2641, mae: 0.2975, huber: 0.1025, swd: 0.0961, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2643, mae: 0.3403, huber: 0.1235, swd: 0.1214, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1749, mae: 0.2813, huber: 0.0826, swd: 0.0635, target_std: 0.7399
      Epoch 3 composite train-obj: 0.102484
            No improvement (0.1235), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2567, mae: 0.2946, huber: 0.1004, swd: 0.0937, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2718, mae: 0.3450, huber: 0.1265, swd: 0.1249, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1749, mae: 0.2831, huber: 0.0830, swd: 0.0655, target_std: 0.7399
      Epoch 4 composite train-obj: 0.100392
            No improvement (0.1265), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2508, mae: 0.2926, huber: 0.0989, swd: 0.0916, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2673, mae: 0.3448, huber: 0.1250, swd: 0.1223, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1802, mae: 0.2852, huber: 0.0849, swd: 0.0655, target_std: 0.7399
      Epoch 5 composite train-obj: 0.098871
            No improvement (0.1250), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2447, mae: 0.2902, huber: 0.0971, swd: 0.0889, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2682, mae: 0.3431, huber: 0.1252, swd: 0.1215, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1772, mae: 0.2830, huber: 0.0837, swd: 0.0650, target_std: 0.7399
      Epoch 6 composite train-obj: 0.097083
            No improvement (0.1252), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2407, mae: 0.2886, huber: 0.0959, swd: 0.0875, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2656, mae: 0.3423, huber: 0.1241, swd: 0.1215, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1754, mae: 0.2821, huber: 0.0831, swd: 0.0657, target_std: 0.7399
      Epoch 7 composite train-obj: 0.095921
    Epoch [7/50], Test Losses: mse: 0.1700, mae: 0.2789, huber: 0.0809, swd: 0.0623, target_std: 0.7399
    Best round's Test MSE: 0.1700, MAE: 0.2789, SWD: 0.0623
    Best round's Validation MSE: 0.2634, MAE: 0.3397
    Best round's Test verification MSE : 0.1700, MAE: 0.2789, SWD: 0.0623
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq196_pred336_20250501_0013)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1754 ± 0.0045
      mae: 0.2831 ± 0.0033
      huber: 0.0831 ± 0.0018
      swd: 0.0662 ± 0.0028
      target_std: 0.7399 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2608 ± 0.0019
      mae: 0.3386 ± 0.0008
      huber: 0.1223 ± 0.0008
      swd: 0.1215 ± 0.0013
      target_std: 0.9653 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq196_pred336_20250501_0013
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3965, mae: 0.3614, huber: 0.1443, swd: 0.1416, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3413, mae: 0.3961, huber: 0.1574, swd: 0.1496, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2181, mae: 0.3171, huber: 0.1030, swd: 0.0836, target_std: 0.7348
      Epoch 1 composite train-obj: 0.144297
            Val objective improved inf → 0.1574, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3770, mae: 0.3516, huber: 0.1377, swd: 0.1372, target_std: 0.7879
    Epoch [2/50], Val Losses: mse: 0.3391, mae: 0.3942, huber: 0.1560, swd: 0.1491, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2177, mae: 0.3163, huber: 0.1026, swd: 0.0834, target_std: 0.7348
      Epoch 2 composite train-obj: 0.137745
            Val objective improved 0.1574 → 0.1560, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3680, mae: 0.3480, huber: 0.1351, swd: 0.1345, target_std: 0.7879
    Epoch [3/50], Val Losses: mse: 0.3265, mae: 0.3883, huber: 0.1508, swd: 0.1447, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2159, mae: 0.3167, huber: 0.1019, swd: 0.0815, target_std: 0.7348
      Epoch 3 composite train-obj: 0.135064
            Val objective improved 0.1560 → 0.1508, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3585, mae: 0.3446, huber: 0.1324, swd: 0.1311, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3371, mae: 0.3940, huber: 0.1552, swd: 0.1508, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2174, mae: 0.3180, huber: 0.1027, swd: 0.0837, target_std: 0.7348
      Epoch 4 composite train-obj: 0.132425
            No improvement (0.1552), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.3505, mae: 0.3419, huber: 0.1303, swd: 0.1284, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3299, mae: 0.3908, huber: 0.1527, swd: 0.1442, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2198, mae: 0.3222, huber: 0.1039, swd: 0.0825, target_std: 0.7348
      Epoch 5 composite train-obj: 0.130319
            No improvement (0.1527), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.3440, mae: 0.3397, huber: 0.1285, swd: 0.1259, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3277, mae: 0.3906, huber: 0.1520, swd: 0.1428, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2216, mae: 0.3243, huber: 0.1049, swd: 0.0834, target_std: 0.7348
      Epoch 6 composite train-obj: 0.128458
            No improvement (0.1520), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.3390, mae: 0.3378, huber: 0.1271, swd: 0.1243, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3340, mae: 0.3930, huber: 0.1541, swd: 0.1487, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2211, mae: 0.3220, huber: 0.1043, swd: 0.0832, target_std: 0.7348
      Epoch 7 composite train-obj: 0.127065
            No improvement (0.1541), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.3341, mae: 0.3358, huber: 0.1255, swd: 0.1221, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3450, mae: 0.3992, huber: 0.1582, swd: 0.1524, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2241, mae: 0.3251, huber: 0.1056, swd: 0.0830, target_std: 0.7348
      Epoch 8 composite train-obj: 0.125518
    Epoch [8/50], Test Losses: mse: 0.2159, mae: 0.3167, huber: 0.1019, swd: 0.0815, target_std: 0.7348
    Best round's Test MSE: 0.2159, MAE: 0.3167, SWD: 0.0815
    Best round's Validation MSE: 0.3265, MAE: 0.3883
    Best round's Test verification MSE : 0.2159, MAE: 0.3167, SWD: 0.0815
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3975, mae: 0.3617, huber: 0.1446, swd: 0.1336, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3337, mae: 0.3906, huber: 0.1540, swd: 0.1392, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2151, mae: 0.3151, huber: 0.1016, swd: 0.0762, target_std: 0.7348
      Epoch 1 composite train-obj: 0.144620
            Val objective improved inf → 0.1540, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3738, mae: 0.3509, huber: 0.1372, swd: 0.1292, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3342, mae: 0.3909, huber: 0.1540, swd: 0.1348, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2162, mae: 0.3157, huber: 0.1020, swd: 0.0732, target_std: 0.7348
      Epoch 2 composite train-obj: 0.137190
            Val objective improved 0.1540 → 0.1540, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3610, mae: 0.3463, huber: 0.1337, swd: 0.1256, target_std: 0.7879
    Epoch [3/50], Val Losses: mse: 0.3300, mae: 0.3879, huber: 0.1524, swd: 0.1379, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2154, mae: 0.3159, huber: 0.1018, swd: 0.0749, target_std: 0.7348
      Epoch 3 composite train-obj: 0.133659
            Val objective improved 0.1540 → 0.1524, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3521, mae: 0.3431, huber: 0.1312, swd: 0.1225, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3249, mae: 0.3888, huber: 0.1509, swd: 0.1285, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2200, mae: 0.3245, huber: 0.1044, swd: 0.0738, target_std: 0.7348
      Epoch 4 composite train-obj: 0.131158
            Val objective improved 0.1524 → 0.1509, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3456, mae: 0.3405, huber: 0.1292, swd: 0.1203, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3306, mae: 0.3902, huber: 0.1528, swd: 0.1360, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2163, mae: 0.3185, huber: 0.1023, swd: 0.0743, target_std: 0.7348
      Epoch 5 composite train-obj: 0.129196
            No improvement (0.1528), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3404, mae: 0.3384, huber: 0.1276, swd: 0.1188, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3325, mae: 0.3899, huber: 0.1537, swd: 0.1353, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2193, mae: 0.3198, huber: 0.1036, swd: 0.0751, target_std: 0.7348
      Epoch 6 composite train-obj: 0.127596
            No improvement (0.1537), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.3351, mae: 0.3366, huber: 0.1261, swd: 0.1169, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3351, mae: 0.3927, huber: 0.1545, swd: 0.1389, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2192, mae: 0.3208, huber: 0.1035, swd: 0.0734, target_std: 0.7348
      Epoch 7 composite train-obj: 0.126126
            No improvement (0.1545), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.3313, mae: 0.3347, huber: 0.1248, swd: 0.1154, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3430, mae: 0.3972, huber: 0.1577, swd: 0.1416, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2240, mae: 0.3246, huber: 0.1055, swd: 0.0757, target_std: 0.7348
      Epoch 8 composite train-obj: 0.124832
            No improvement (0.1577), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.3276, mae: 0.3331, huber: 0.1236, swd: 0.1138, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3485, mae: 0.4010, huber: 0.1599, swd: 0.1412, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2247, mae: 0.3250, huber: 0.1057, swd: 0.0745, target_std: 0.7348
      Epoch 9 composite train-obj: 0.123583
    Epoch [9/50], Test Losses: mse: 0.2200, mae: 0.3245, huber: 0.1044, swd: 0.0738, target_std: 0.7348
    Best round's Test MSE: 0.2200, MAE: 0.3245, SWD: 0.0738
    Best round's Validation MSE: 0.3249, MAE: 0.3888
    Best round's Test verification MSE : 0.2200, MAE: 0.3245, SWD: 0.0738
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3985, mae: 0.3622, huber: 0.1448, swd: 0.1484, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3373, mae: 0.3953, huber: 0.1560, swd: 0.1447, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2183, mae: 0.3214, huber: 0.1033, swd: 0.0826, target_std: 0.7348
      Epoch 1 composite train-obj: 0.144802
            Val objective improved inf → 0.1560, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3787, mae: 0.3520, huber: 0.1381, swd: 0.1436, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3259, mae: 0.3882, huber: 0.1511, swd: 0.1437, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2153, mae: 0.3188, huber: 0.1020, swd: 0.0820, target_std: 0.7348
      Epoch 2 composite train-obj: 0.138055
            Val objective improved 0.1560 → 0.1511, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3684, mae: 0.3480, huber: 0.1351, swd: 0.1403, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3331, mae: 0.3912, huber: 0.1537, swd: 0.1495, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2163, mae: 0.3182, huber: 0.1022, swd: 0.0841, target_std: 0.7348
      Epoch 3 composite train-obj: 0.135125
            No improvement (0.1537), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.3589, mae: 0.3450, huber: 0.1326, swd: 0.1369, target_std: 0.7879
    Epoch [4/50], Val Losses: mse: 0.3205, mae: 0.3862, huber: 0.1490, swd: 0.1385, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2187, mae: 0.3228, huber: 0.1037, swd: 0.0814, target_std: 0.7348
      Epoch 4 composite train-obj: 0.132625
            Val objective improved 0.1511 → 0.1490, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3524, mae: 0.3426, huber: 0.1308, swd: 0.1343, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3319, mae: 0.3920, huber: 0.1535, swd: 0.1475, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2184, mae: 0.3212, huber: 0.1033, swd: 0.0828, target_std: 0.7348
      Epoch 5 composite train-obj: 0.130761
            No improvement (0.1535), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3465, mae: 0.3402, huber: 0.1290, swd: 0.1322, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3314, mae: 0.3925, huber: 0.1535, swd: 0.1465, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2202, mae: 0.3235, huber: 0.1043, swd: 0.0847, target_std: 0.7348
      Epoch 6 composite train-obj: 0.128981
            No improvement (0.1535), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.3407, mae: 0.3382, huber: 0.1274, swd: 0.1296, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3300, mae: 0.3905, huber: 0.1527, swd: 0.1500, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2194, mae: 0.3208, huber: 0.1036, swd: 0.0855, target_std: 0.7348
      Epoch 7 composite train-obj: 0.127420
            No improvement (0.1527), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.3353, mae: 0.3360, huber: 0.1257, swd: 0.1272, target_std: 0.7879
    Epoch [8/50], Val Losses: mse: 0.3337, mae: 0.3945, huber: 0.1541, swd: 0.1493, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2242, mae: 0.3274, huber: 0.1061, swd: 0.0864, target_std: 0.7348
      Epoch 8 composite train-obj: 0.125745
            No improvement (0.1541), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.3314, mae: 0.3344, huber: 0.1246, swd: 0.1257, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3280, mae: 0.3929, huber: 0.1526, swd: 0.1428, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2289, mae: 0.3327, huber: 0.1084, swd: 0.0862, target_std: 0.7348
      Epoch 9 composite train-obj: 0.124592
    Epoch [9/50], Test Losses: mse: 0.2187, mae: 0.3228, huber: 0.1037, swd: 0.0814, target_std: 0.7348
    Best round's Test MSE: 0.2187, MAE: 0.3228, SWD: 0.0814
    Best round's Validation MSE: 0.3205, MAE: 0.3862
    Best round's Test verification MSE : 0.2187, MAE: 0.3228, SWD: 0.0814
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq196_pred720_20250501_1919)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2182 ± 0.0017
      mae: 0.3213 ± 0.0033
      huber: 0.1033 ± 0.0010
      swd: 0.0789 ± 0.0036
      target_std: 0.7348 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3240 ± 0.0025
      mae: 0.3878 ± 0.0011
      huber: 0.1502 ± 0.0009
      swd: 0.1372 ± 0.0067
      target_std: 0.9639 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq196_pred720_20250501_1919
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### pred=96


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1813, mae: 0.2507, huber: 0.0738, swd: 0.0725, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1537, mae: 0.2588, huber: 0.0739, swd: 0.0692, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1149, mae: 0.2273, huber: 0.0558, swd: 0.0506, target_std: 0.7443
      Epoch 1 composite train-obj: 0.073820
            Val objective improved inf → 0.0739, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1509, mae: 0.2276, huber: 0.0623, swd: 0.0630, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1539, mae: 0.2537, huber: 0.0738, swd: 0.0672, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1134, mae: 0.2266, huber: 0.0552, swd: 0.0478, target_std: 0.7443
      Epoch 2 composite train-obj: 0.062295
            Val objective improved 0.0739 → 0.0738, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.1506, mae: 0.2272, huber: 0.0621, swd: 0.0629, target_std: 0.7858
    Epoch [3/50], Val Losses: mse: 0.1531, mae: 0.2564, huber: 0.0736, swd: 0.0684, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1156, mae: 0.2293, huber: 0.0562, swd: 0.0507, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062130
            Val objective improved 0.0738 → 0.0736, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1502, mae: 0.2270, huber: 0.0620, swd: 0.0626, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1525, mae: 0.2582, huber: 0.0734, swd: 0.0697, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1174, mae: 0.2306, huber: 0.0571, swd: 0.0537, target_std: 0.7443
      Epoch 4 composite train-obj: 0.062029
            Val objective improved 0.0736 → 0.0734, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.1501, mae: 0.2272, huber: 0.0620, swd: 0.0627, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1567, mae: 0.2652, huber: 0.0754, swd: 0.0728, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1162, mae: 0.2283, huber: 0.0564, swd: 0.0526, target_std: 0.7443
      Epoch 5 composite train-obj: 0.062023
            No improvement (0.0754), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.1501, mae: 0.2273, huber: 0.0620, swd: 0.0627, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1523, mae: 0.2564, huber: 0.0732, swd: 0.0683, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1132, mae: 0.2267, huber: 0.0550, swd: 0.0492, target_std: 0.7443
      Epoch 6 composite train-obj: 0.062016
            Val objective improved 0.0734 → 0.0732, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.1497, mae: 0.2269, huber: 0.0619, swd: 0.0624, target_std: 0.7857
    Epoch [7/50], Val Losses: mse: 0.1531, mae: 0.2524, huber: 0.0735, swd: 0.0666, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1127, mae: 0.2255, huber: 0.0549, swd: 0.0474, target_std: 0.7443
      Epoch 7 composite train-obj: 0.061871
            No improvement (0.0735), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.1502, mae: 0.2273, huber: 0.0621, swd: 0.0628, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1538, mae: 0.2600, huber: 0.0741, swd: 0.0713, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1177, mae: 0.2316, huber: 0.0573, swd: 0.0551, target_std: 0.7443
      Epoch 8 composite train-obj: 0.062068
            No improvement (0.0741), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.1503, mae: 0.2275, huber: 0.0621, swd: 0.0627, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1679, mae: 0.2775, huber: 0.0807, swd: 0.0855, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1175, mae: 0.2292, huber: 0.0570, swd: 0.0560, target_std: 0.7443
      Epoch 9 composite train-obj: 0.062073
            No improvement (0.0807), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.1502, mae: 0.2272, huber: 0.0620, swd: 0.0627, target_std: 0.7857
    Epoch [10/50], Val Losses: mse: 0.1553, mae: 0.2615, huber: 0.0747, swd: 0.0709, target_std: 0.9665
    Epoch [10/50], Test Losses: mse: 0.1144, mae: 0.2273, huber: 0.0556, swd: 0.0512, target_std: 0.7443
      Epoch 10 composite train-obj: 0.061990
            No improvement (0.0747), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.1501, mae: 0.2272, huber: 0.0620, swd: 0.0626, target_std: 0.7857
    Epoch [11/50], Val Losses: mse: 0.1527, mae: 0.2519, huber: 0.0733, swd: 0.0661, target_std: 0.9665
    Epoch [11/50], Test Losses: mse: 0.1136, mae: 0.2259, huber: 0.0553, swd: 0.0479, target_std: 0.7443
      Epoch 11 composite train-obj: 0.061986
    Epoch [11/50], Test Losses: mse: 0.1132, mae: 0.2267, huber: 0.0550, swd: 0.0492, target_std: 0.7443
    Best round's Test MSE: 0.1132, MAE: 0.2267, SWD: 0.0492
    Best round's Validation MSE: 0.1523, MAE: 0.2564
    Best round's Test verification MSE : 0.1132, MAE: 0.2267, SWD: 0.0492
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1812, mae: 0.2509, huber: 0.0738, swd: 0.0709, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1544, mae: 0.2550, huber: 0.0741, swd: 0.0656, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1137, mae: 0.2265, huber: 0.0553, swd: 0.0460, target_std: 0.7443
      Epoch 1 composite train-obj: 0.073840
            Val objective improved inf → 0.0741, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1512, mae: 0.2277, huber: 0.0624, swd: 0.0618, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1616, mae: 0.2692, huber: 0.0777, swd: 0.0749, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1148, mae: 0.2275, huber: 0.0558, swd: 0.0497, target_std: 0.7443
      Epoch 2 composite train-obj: 0.062398
            No improvement (0.0777), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1503, mae: 0.2272, huber: 0.0621, swd: 0.0615, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1515, mae: 0.2574, huber: 0.0730, swd: 0.0676, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1171, mae: 0.2308, huber: 0.0570, swd: 0.0517, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062080
            Val objective improved 0.0741 → 0.0730, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1498, mae: 0.2270, huber: 0.0619, swd: 0.0613, target_std: 0.7857
    Epoch [4/50], Val Losses: mse: 0.1527, mae: 0.2543, huber: 0.0733, swd: 0.0662, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1128, mae: 0.2251, huber: 0.0549, swd: 0.0471, target_std: 0.7443
      Epoch 4 composite train-obj: 0.061949
            No improvement (0.0733), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.1499, mae: 0.2268, huber: 0.0619, swd: 0.0613, target_std: 0.7857
    Epoch [5/50], Val Losses: mse: 0.1522, mae: 0.2537, huber: 0.0732, swd: 0.0648, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1148, mae: 0.2273, huber: 0.0558, swd: 0.0476, target_std: 0.7443
      Epoch 5 composite train-obj: 0.061936
            No improvement (0.0732), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.1500, mae: 0.2271, huber: 0.0620, swd: 0.0613, target_std: 0.7858
    Epoch [6/50], Val Losses: mse: 0.1539, mae: 0.2561, huber: 0.0740, swd: 0.0676, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1128, mae: 0.2259, huber: 0.0549, swd: 0.0472, target_std: 0.7443
      Epoch 6 composite train-obj: 0.061984
            No improvement (0.0740), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.1497, mae: 0.2268, huber: 0.0619, swd: 0.0613, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1540, mae: 0.2611, huber: 0.0741, swd: 0.0684, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1176, mae: 0.2312, huber: 0.0572, swd: 0.0526, target_std: 0.7443
      Epoch 7 composite train-obj: 0.061872
            No improvement (0.0741), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.1502, mae: 0.2273, huber: 0.0621, swd: 0.0615, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1525, mae: 0.2568, huber: 0.0733, swd: 0.0667, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1158, mae: 0.2279, huber: 0.0562, swd: 0.0498, target_std: 0.7443
      Epoch 8 composite train-obj: 0.062053
    Epoch [8/50], Test Losses: mse: 0.1171, mae: 0.2308, huber: 0.0570, swd: 0.0517, target_std: 0.7443
    Best round's Test MSE: 0.1171, MAE: 0.2308, SWD: 0.0517
    Best round's Validation MSE: 0.1515, MAE: 0.2574
    Best round's Test verification MSE : 0.1171, MAE: 0.2308, SWD: 0.0517
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.1816, mae: 0.2514, huber: 0.0741, swd: 0.0652, target_std: 0.7857
    Epoch [1/50], Val Losses: mse: 0.1547, mae: 0.2568, huber: 0.0744, swd: 0.0629, target_std: 0.9665
    Epoch [1/50], Test Losses: mse: 0.1143, mae: 0.2271, huber: 0.0556, swd: 0.0453, target_std: 0.7443
      Epoch 1 composite train-obj: 0.074089
            Val objective improved inf → 0.0744, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1508, mae: 0.2276, huber: 0.0623, swd: 0.0573, target_std: 0.7857
    Epoch [2/50], Val Losses: mse: 0.1550, mae: 0.2589, huber: 0.0745, swd: 0.0632, target_std: 0.9665
    Epoch [2/50], Test Losses: mse: 0.1140, mae: 0.2260, huber: 0.0554, swd: 0.0453, target_std: 0.7443
      Epoch 2 composite train-obj: 0.062285
            No improvement (0.0745), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1502, mae: 0.2271, huber: 0.0620, swd: 0.0571, target_std: 0.7857
    Epoch [3/50], Val Losses: mse: 0.1536, mae: 0.2537, huber: 0.0738, swd: 0.0608, target_std: 0.9665
    Epoch [3/50], Test Losses: mse: 0.1149, mae: 0.2281, huber: 0.0559, swd: 0.0439, target_std: 0.7443
      Epoch 3 composite train-obj: 0.062042
            Val objective improved 0.0744 → 0.0738, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.1504, mae: 0.2272, huber: 0.0621, swd: 0.0572, target_std: 0.7858
    Epoch [4/50], Val Losses: mse: 0.1533, mae: 0.2601, huber: 0.0738, swd: 0.0642, target_std: 0.9665
    Epoch [4/50], Test Losses: mse: 0.1141, mae: 0.2261, huber: 0.0555, swd: 0.0463, target_std: 0.7443
      Epoch 4 composite train-obj: 0.062075
            Val objective improved 0.0738 → 0.0738, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.1501, mae: 0.2270, huber: 0.0620, swd: 0.0571, target_std: 0.7858
    Epoch [5/50], Val Losses: mse: 0.1527, mae: 0.2545, huber: 0.0734, swd: 0.0611, target_std: 0.9665
    Epoch [5/50], Test Losses: mse: 0.1132, mae: 0.2255, huber: 0.0551, swd: 0.0444, target_std: 0.7443
      Epoch 5 composite train-obj: 0.061991
            Val objective improved 0.0738 → 0.0734, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.1499, mae: 0.2270, huber: 0.0619, swd: 0.0570, target_std: 0.7857
    Epoch [6/50], Val Losses: mse: 0.1548, mae: 0.2630, huber: 0.0745, swd: 0.0651, target_std: 0.9665
    Epoch [6/50], Test Losses: mse: 0.1161, mae: 0.2285, huber: 0.0564, swd: 0.0485, target_std: 0.7443
      Epoch 6 composite train-obj: 0.061927
            No improvement (0.0745), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.1502, mae: 0.2273, huber: 0.0620, swd: 0.0571, target_std: 0.7858
    Epoch [7/50], Val Losses: mse: 0.1576, mae: 0.2659, huber: 0.0758, swd: 0.0694, target_std: 0.9665
    Epoch [7/50], Test Losses: mse: 0.1207, mae: 0.2327, huber: 0.0585, swd: 0.0527, target_std: 0.7443
      Epoch 7 composite train-obj: 0.062044
            No improvement (0.0758), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.1502, mae: 0.2272, huber: 0.0620, swd: 0.0571, target_std: 0.7857
    Epoch [8/50], Val Losses: mse: 0.1518, mae: 0.2567, huber: 0.0731, swd: 0.0631, target_std: 0.9665
    Epoch [8/50], Test Losses: mse: 0.1183, mae: 0.2303, huber: 0.0575, swd: 0.0497, target_std: 0.7443
      Epoch 8 composite train-obj: 0.062041
            Val objective improved 0.0734 → 0.0731, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.1501, mae: 0.2272, huber: 0.0620, swd: 0.0571, target_std: 0.7857
    Epoch [9/50], Val Losses: mse: 0.1528, mae: 0.2548, huber: 0.0735, swd: 0.0623, target_std: 0.9665
    Epoch [9/50], Test Losses: mse: 0.1136, mae: 0.2266, huber: 0.0553, swd: 0.0447, target_std: 0.7443
      Epoch 9 composite train-obj: 0.062010
            No improvement (0.0735), counter 1/5
    Epoch [10/50], Train Losses: mse: 0.1500, mae: 0.2271, huber: 0.0620, swd: 0.0570, target_std: 0.7857
    Epoch [10/50], Val Losses: mse: 0.1542, mae: 0.2555, huber: 0.0740, swd: 0.0612, target_std: 0.9665
    Epoch [10/50], Test Losses: mse: 0.1140, mae: 0.2263, huber: 0.0554, swd: 0.0441, target_std: 0.7443
      Epoch 10 composite train-obj: 0.061991
            No improvement (0.0740), counter 2/5
    Epoch [11/50], Train Losses: mse: 0.1500, mae: 0.2271, huber: 0.0619, swd: 0.0570, target_std: 0.7857
    Epoch [11/50], Val Losses: mse: 0.1546, mae: 0.2612, huber: 0.0745, swd: 0.0638, target_std: 0.9665
    Epoch [11/50], Test Losses: mse: 0.1166, mae: 0.2300, huber: 0.0567, swd: 0.0486, target_std: 0.7443
      Epoch 11 composite train-obj: 0.061945
            No improvement (0.0745), counter 3/5
    Epoch [12/50], Train Losses: mse: 0.1500, mae: 0.2273, huber: 0.0620, swd: 0.0570, target_std: 0.7858
    Epoch [12/50], Val Losses: mse: 0.1537, mae: 0.2587, huber: 0.0738, swd: 0.0627, target_std: 0.9665
    Epoch [12/50], Test Losses: mse: 0.1164, mae: 0.2287, huber: 0.0565, swd: 0.0471, target_std: 0.7443
      Epoch 12 composite train-obj: 0.061991
            No improvement (0.0738), counter 4/5
    Epoch [13/50], Train Losses: mse: 0.1499, mae: 0.2271, huber: 0.0620, swd: 0.0569, target_std: 0.7857
    Epoch [13/50], Val Losses: mse: 0.1558, mae: 0.2623, huber: 0.0750, swd: 0.0657, target_std: 0.9665
    Epoch [13/50], Test Losses: mse: 0.1141, mae: 0.2268, huber: 0.0554, swd: 0.0459, target_std: 0.7443
      Epoch 13 composite train-obj: 0.061974
    Epoch [13/50], Test Losses: mse: 0.1183, mae: 0.2303, huber: 0.0575, swd: 0.0497, target_std: 0.7443
    Best round's Test MSE: 0.1183, MAE: 0.2303, SWD: 0.0497
    Best round's Validation MSE: 0.1518, MAE: 0.2567
    Best round's Test verification MSE : 0.1183, MAE: 0.2303, SWD: 0.0497
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq196_pred96_20250430_2345)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1162 ± 0.0022
      mae: 0.2293 ± 0.0018
      huber: 0.0565 ± 0.0011
      swd: 0.0502 ± 0.0011
      target_std: 0.7443 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.1519 ± 0.0003
      mae: 0.2568 ± 0.0004
      huber: 0.0731 ± 0.0001
      swd: 0.0663 ± 0.0023
      target_std: 0.9665 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq196_pred96_20250430_2345
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196

#### pred=336


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2989, mae: 0.3195, huber: 0.1139, swd: 0.1126, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2654, mae: 0.3423, huber: 0.1244, swd: 0.1183, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1730, mae: 0.2807, huber: 0.0821, swd: 0.0656, target_std: 0.7399
      Epoch 1 composite train-obj: 0.113897
            Val objective improved inf → 0.1244, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2733, mae: 0.3015, huber: 0.1044, swd: 0.1066, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2645, mae: 0.3457, huber: 0.1240, swd: 0.1206, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1738, mae: 0.2829, huber: 0.0826, swd: 0.0685, target_std: 0.7399
      Epoch 2 composite train-obj: 0.104363
            Val objective improved 0.1244 → 0.1240, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2729, mae: 0.3015, huber: 0.1043, swd: 0.1067, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2686, mae: 0.3493, huber: 0.1258, swd: 0.1227, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1719, mae: 0.2816, huber: 0.0816, swd: 0.0673, target_std: 0.7399
      Epoch 3 composite train-obj: 0.104271
            No improvement (0.1258), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2724, mae: 0.3012, huber: 0.1041, swd: 0.1064, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2610, mae: 0.3465, huber: 0.1226, swd: 0.1226, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1807, mae: 0.2906, huber: 0.0857, swd: 0.0782, target_std: 0.7399
      Epoch 4 composite train-obj: 0.104055
            Val objective improved 0.1240 → 0.1226, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2723, mae: 0.3011, huber: 0.1040, swd: 0.1063, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2636, mae: 0.3464, huber: 0.1235, swd: 0.1227, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1763, mae: 0.2849, huber: 0.0836, swd: 0.0721, target_std: 0.7399
      Epoch 5 composite train-obj: 0.103977
            No improvement (0.1235), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2721, mae: 0.3011, huber: 0.1040, swd: 0.1062, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2607, mae: 0.3395, huber: 0.1223, swd: 0.1171, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1767, mae: 0.2863, huber: 0.0839, swd: 0.0719, target_std: 0.7399
      Epoch 6 composite train-obj: 0.103972
            Val objective improved 0.1226 → 0.1223, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.2722, mae: 0.3012, huber: 0.1040, swd: 0.1063, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2687, mae: 0.3504, huber: 0.1254, swd: 0.1305, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1763, mae: 0.2822, huber: 0.0835, swd: 0.0732, target_std: 0.7399
      Epoch 7 composite train-obj: 0.103997
            No improvement (0.1254), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.2725, mae: 0.3016, huber: 0.1042, swd: 0.1065, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2687, mae: 0.3511, huber: 0.1254, swd: 0.1284, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.1763, mae: 0.2826, huber: 0.0835, swd: 0.0753, target_std: 0.7399
      Epoch 8 composite train-obj: 0.104173
            No improvement (0.1254), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.2719, mae: 0.3010, huber: 0.1039, swd: 0.1061, target_std: 0.7864
    Epoch [9/50], Val Losses: mse: 0.2624, mae: 0.3429, huber: 0.1225, swd: 0.1229, target_std: 0.9653
    Epoch [9/50], Test Losses: mse: 0.1784, mae: 0.2853, huber: 0.0846, swd: 0.0745, target_std: 0.7399
      Epoch 9 composite train-obj: 0.103900
            No improvement (0.1225), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.2719, mae: 0.3012, huber: 0.1040, swd: 0.1063, target_std: 0.7864
    Epoch [10/50], Val Losses: mse: 0.2771, mae: 0.3545, huber: 0.1284, swd: 0.1392, target_std: 0.9653
    Epoch [10/50], Test Losses: mse: 0.1857, mae: 0.2912, huber: 0.0878, swd: 0.0832, target_std: 0.7399
      Epoch 10 composite train-obj: 0.103983
            No improvement (0.1284), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.2719, mae: 0.3012, huber: 0.1040, swd: 0.1063, target_std: 0.7864
    Epoch [11/50], Val Losses: mse: 0.2667, mae: 0.3441, huber: 0.1244, swd: 0.1273, target_std: 0.9653
    Epoch [11/50], Test Losses: mse: 0.1863, mae: 0.2916, huber: 0.0881, swd: 0.0783, target_std: 0.7399
      Epoch 11 composite train-obj: 0.103988
    Epoch [11/50], Test Losses: mse: 0.1767, mae: 0.2863, huber: 0.0839, swd: 0.0719, target_std: 0.7399
    Best round's Test MSE: 0.1767, MAE: 0.2863, SWD: 0.0719
    Best round's Validation MSE: 0.2607, MAE: 0.3395
    Best round's Test verification MSE : 0.1767, MAE: 0.2863, SWD: 0.0719
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2982, mae: 0.3192, huber: 0.1137, swd: 0.1167, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2715, mae: 0.3533, huber: 0.1266, swd: 0.1385, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1810, mae: 0.2886, huber: 0.0859, swd: 0.0815, target_std: 0.7399
      Epoch 1 composite train-obj: 0.113748
            Val objective improved inf → 0.1266, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2732, mae: 0.3015, huber: 0.1043, swd: 0.1104, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2807, mae: 0.3609, huber: 0.1302, swd: 0.1544, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1862, mae: 0.2899, huber: 0.0879, swd: 0.0887, target_std: 0.7399
      Epoch 2 composite train-obj: 0.104327
            No improvement (0.1302), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2725, mae: 0.3013, huber: 0.1041, swd: 0.1103, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2611, mae: 0.3438, huber: 0.1223, swd: 0.1259, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1755, mae: 0.2841, huber: 0.0832, swd: 0.0736, target_std: 0.7399
      Epoch 3 composite train-obj: 0.104106
            Val objective improved 0.1266 → 0.1223, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2721, mae: 0.3012, huber: 0.1040, swd: 0.1102, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2681, mae: 0.3464, huber: 0.1250, swd: 0.1304, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1747, mae: 0.2856, huber: 0.0830, swd: 0.0756, target_std: 0.7399
      Epoch 4 composite train-obj: 0.104018
            No improvement (0.1250), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2721, mae: 0.3011, huber: 0.1040, swd: 0.1101, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2618, mae: 0.3392, huber: 0.1226, swd: 0.1225, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1728, mae: 0.2803, huber: 0.0820, swd: 0.0691, target_std: 0.7399
      Epoch 5 composite train-obj: 0.104003
            No improvement (0.1226), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.2722, mae: 0.3011, huber: 0.1040, swd: 0.1098, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2731, mae: 0.3541, huber: 0.1271, swd: 0.1382, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1809, mae: 0.2878, huber: 0.0857, swd: 0.0814, target_std: 0.7399
      Epoch 6 composite train-obj: 0.103992
            No improvement (0.1271), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.2720, mae: 0.3011, huber: 0.1039, swd: 0.1102, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2761, mae: 0.3580, huber: 0.1286, swd: 0.1469, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1840, mae: 0.2899, huber: 0.0871, swd: 0.0876, target_std: 0.7399
      Epoch 7 composite train-obj: 0.103945
            No improvement (0.1286), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.2722, mae: 0.3013, huber: 0.1040, swd: 0.1102, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2655, mae: 0.3492, huber: 0.1245, swd: 0.1314, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.1760, mae: 0.2853, huber: 0.0836, swd: 0.0782, target_std: 0.7399
      Epoch 8 composite train-obj: 0.104021
    Epoch [8/50], Test Losses: mse: 0.1755, mae: 0.2841, huber: 0.0832, swd: 0.0736, target_std: 0.7399
    Best round's Test MSE: 0.1755, MAE: 0.2841, SWD: 0.0736
    Best round's Validation MSE: 0.2611, MAE: 0.3438
    Best round's Test verification MSE : 0.1755, MAE: 0.2841, SWD: 0.0736
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2989, mae: 0.3193, huber: 0.1138, swd: 0.1117, target_std: 0.7864
    Epoch [1/50], Val Losses: mse: 0.2711, mae: 0.3514, huber: 0.1264, swd: 0.1265, target_std: 0.9653
    Epoch [1/50], Test Losses: mse: 0.1742, mae: 0.2810, huber: 0.0826, swd: 0.0689, target_std: 0.7399
      Epoch 1 composite train-obj: 0.113808
            Val objective improved inf → 0.1264, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2735, mae: 0.3019, huber: 0.1045, swd: 0.1067, target_std: 0.7864
    Epoch [2/50], Val Losses: mse: 0.2892, mae: 0.3672, huber: 0.1338, swd: 0.1492, target_std: 0.9653
    Epoch [2/50], Test Losses: mse: 0.1890, mae: 0.2946, huber: 0.0893, swd: 0.0848, target_std: 0.7399
      Epoch 2 composite train-obj: 0.104477
            No improvement (0.1338), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2723, mae: 0.3009, huber: 0.1040, swd: 0.1062, target_std: 0.7864
    Epoch [3/50], Val Losses: mse: 0.2687, mae: 0.3523, huber: 0.1257, swd: 0.1280, target_std: 0.9653
    Epoch [3/50], Test Losses: mse: 0.1766, mae: 0.2869, huber: 0.0838, swd: 0.0729, target_std: 0.7399
      Epoch 3 composite train-obj: 0.104018
            Val objective improved 0.1264 → 0.1257, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2723, mae: 0.3011, huber: 0.1040, swd: 0.1063, target_std: 0.7864
    Epoch [4/50], Val Losses: mse: 0.2600, mae: 0.3426, huber: 0.1217, swd: 0.1220, target_std: 0.9653
    Epoch [4/50], Test Losses: mse: 0.1850, mae: 0.2915, huber: 0.0876, swd: 0.0792, target_std: 0.7399
      Epoch 4 composite train-obj: 0.104000
            Val objective improved 0.1257 → 0.1217, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2721, mae: 0.3013, huber: 0.1040, swd: 0.1062, target_std: 0.7864
    Epoch [5/50], Val Losses: mse: 0.2627, mae: 0.3430, huber: 0.1228, swd: 0.1203, target_std: 0.9653
    Epoch [5/50], Test Losses: mse: 0.1748, mae: 0.2824, huber: 0.0829, swd: 0.0706, target_std: 0.7399
      Epoch 5 composite train-obj: 0.104026
            No improvement (0.1228), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2726, mae: 0.3012, huber: 0.1041, swd: 0.1063, target_std: 0.7864
    Epoch [6/50], Val Losses: mse: 0.2665, mae: 0.3466, huber: 0.1247, swd: 0.1178, target_std: 0.9653
    Epoch [6/50], Test Losses: mse: 0.1738, mae: 0.2834, huber: 0.0825, swd: 0.0658, target_std: 0.7399
      Epoch 6 composite train-obj: 0.104067
            No improvement (0.1247), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.2720, mae: 0.3011, huber: 0.1039, swd: 0.1060, target_std: 0.7864
    Epoch [7/50], Val Losses: mse: 0.2635, mae: 0.3420, huber: 0.1235, swd: 0.1164, target_std: 0.9653
    Epoch [7/50], Test Losses: mse: 0.1728, mae: 0.2810, huber: 0.0820, swd: 0.0640, target_std: 0.7399
      Epoch 7 composite train-obj: 0.103950
            No improvement (0.1235), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.2720, mae: 0.3012, huber: 0.1040, swd: 0.1061, target_std: 0.7864
    Epoch [8/50], Val Losses: mse: 0.2650, mae: 0.3485, huber: 0.1239, swd: 0.1266, target_std: 0.9653
    Epoch [8/50], Test Losses: mse: 0.1826, mae: 0.2902, huber: 0.0865, swd: 0.0785, target_std: 0.7399
      Epoch 8 composite train-obj: 0.103984
            No improvement (0.1239), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.2721, mae: 0.3012, huber: 0.1040, swd: 0.1061, target_std: 0.7864
    Epoch [9/50], Val Losses: mse: 0.2635, mae: 0.3437, huber: 0.1235, swd: 0.1162, target_std: 0.9653
    Epoch [9/50], Test Losses: mse: 0.1721, mae: 0.2793, huber: 0.0816, swd: 0.0650, target_std: 0.7399
      Epoch 9 composite train-obj: 0.103994
    Epoch [9/50], Test Losses: mse: 0.1850, mae: 0.2915, huber: 0.0876, swd: 0.0792, target_std: 0.7399
    Best round's Test MSE: 0.1850, MAE: 0.2915, SWD: 0.0792
    Best round's Validation MSE: 0.2600, MAE: 0.3426
    Best round's Test verification MSE : 0.1850, MAE: 0.2915, SWD: 0.0792
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq196_pred336_20250501_0011)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1791 ± 0.0042
      mae: 0.2873 ± 0.0031
      huber: 0.0849 ± 0.0019
      swd: 0.0749 ± 0.0031
      target_std: 0.7399 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2606 ± 0.0004
      mae: 0.3420 ± 0.0018
      huber: 0.1221 ± 0.0003
      swd: 0.1217 ± 0.0036
      target_std: 0.9653 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq196_pred336_20250501_0011
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3834, mae: 0.3680, huber: 0.1439, swd: 0.1489, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3444, mae: 0.4056, huber: 0.1582, swd: 0.1637, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2185, mae: 0.3209, huber: 0.1032, swd: 0.0921, target_std: 0.7348
      Epoch 1 composite train-obj: 0.143850
            Val objective improved inf → 0.1582, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3622, mae: 0.3532, huber: 0.1358, swd: 0.1451, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3417, mae: 0.4031, huber: 0.1567, swd: 0.1645, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2236, mae: 0.3214, huber: 0.1054, swd: 0.0980, target_std: 0.7348
      Epoch 2 composite train-obj: 0.135777
            Val objective improved 0.1582 → 0.1567, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3621, mae: 0.3531, huber: 0.1357, swd: 0.1454, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3345, mae: 0.3966, huber: 0.1544, swd: 0.1498, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2190, mae: 0.3207, huber: 0.1034, swd: 0.0903, target_std: 0.7348
      Epoch 3 composite train-obj: 0.135722
            Val objective improved 0.1567 → 0.1544, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3617, mae: 0.3530, huber: 0.1356, swd: 0.1452, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3446, mae: 0.4066, huber: 0.1583, swd: 0.1689, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2182, mae: 0.3199, huber: 0.1030, swd: 0.0960, target_std: 0.7348
      Epoch 4 composite train-obj: 0.135591
            No improvement (0.1583), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.3618, mae: 0.3531, huber: 0.1356, swd: 0.1453, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3416, mae: 0.4043, huber: 0.1568, swd: 0.1630, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2202, mae: 0.3220, huber: 0.1040, swd: 0.0971, target_std: 0.7348
      Epoch 5 composite train-obj: 0.135618
            No improvement (0.1568), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.3616, mae: 0.3531, huber: 0.1356, swd: 0.1451, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3317, mae: 0.3948, huber: 0.1531, swd: 0.1474, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2170, mae: 0.3171, huber: 0.1023, swd: 0.0871, target_std: 0.7348
      Epoch 6 composite train-obj: 0.135571
            Val objective improved 0.1544 → 0.1531, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.3613, mae: 0.3529, huber: 0.1355, swd: 0.1449, target_std: 0.7879
    Epoch [7/50], Val Losses: mse: 0.3376, mae: 0.4014, huber: 0.1558, swd: 0.1544, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2110, mae: 0.3113, huber: 0.0996, swd: 0.0850, target_std: 0.7348
      Epoch 7 composite train-obj: 0.135496
            No improvement (0.1558), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.3619, mae: 0.3532, huber: 0.1356, swd: 0.1451, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3367, mae: 0.3997, huber: 0.1552, swd: 0.1546, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2156, mae: 0.3161, huber: 0.1018, swd: 0.0902, target_std: 0.7348
      Epoch 8 composite train-obj: 0.135599
            No improvement (0.1552), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.3614, mae: 0.3531, huber: 0.1356, swd: 0.1450, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3373, mae: 0.4046, huber: 0.1553, swd: 0.1597, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2241, mae: 0.3266, huber: 0.1057, swd: 0.0986, target_std: 0.7348
      Epoch 9 composite train-obj: 0.135563
            No improvement (0.1553), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.3617, mae: 0.3533, huber: 0.1356, swd: 0.1452, target_std: 0.7878
    Epoch [10/50], Val Losses: mse: 0.3410, mae: 0.4033, huber: 0.1572, swd: 0.1554, target_std: 0.9639
    Epoch [10/50], Test Losses: mse: 0.2164, mae: 0.3197, huber: 0.1022, swd: 0.0889, target_std: 0.7348
      Epoch 10 composite train-obj: 0.135638
            No improvement (0.1572), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.3618, mae: 0.3532, huber: 0.1356, swd: 0.1453, target_std: 0.7878
    Epoch [11/50], Val Losses: mse: 0.3495, mae: 0.4094, huber: 0.1601, swd: 0.1709, target_std: 0.9639
    Epoch [11/50], Test Losses: mse: 0.2141, mae: 0.3158, huber: 0.1012, swd: 0.0917, target_std: 0.7348
      Epoch 11 composite train-obj: 0.135629
    Epoch [11/50], Test Losses: mse: 0.2170, mae: 0.3171, huber: 0.1023, swd: 0.0871, target_std: 0.7348
    Best round's Test MSE: 0.2170, MAE: 0.3171, SWD: 0.0871
    Best round's Validation MSE: 0.3317, MAE: 0.3948
    Best round's Test verification MSE : 0.2170, MAE: 0.3171, SWD: 0.0871
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3836, mae: 0.3679, huber: 0.1439, swd: 0.1429, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3429, mae: 0.4031, huber: 0.1573, swd: 0.1550, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2213, mae: 0.3206, huber: 0.1044, swd: 0.0887, target_std: 0.7348
      Epoch 1 composite train-obj: 0.143893
            Val objective improved inf → 0.1573, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3625, mae: 0.3532, huber: 0.1358, swd: 0.1389, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3499, mae: 0.4080, huber: 0.1608, swd: 0.1514, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2073, mae: 0.3106, huber: 0.0981, swd: 0.0767, target_std: 0.7348
      Epoch 2 composite train-obj: 0.135812
            No improvement (0.1608), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3619, mae: 0.3531, huber: 0.1357, swd: 0.1389, target_std: 0.7879
    Epoch [3/50], Val Losses: mse: 0.3462, mae: 0.4066, huber: 0.1588, swd: 0.1595, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2163, mae: 0.3161, huber: 0.1020, swd: 0.0878, target_std: 0.7348
      Epoch 3 composite train-obj: 0.135665
            No improvement (0.1588), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.3615, mae: 0.3529, huber: 0.1355, swd: 0.1389, target_std: 0.7878
    Epoch [4/50], Val Losses: mse: 0.3365, mae: 0.4019, huber: 0.1549, swd: 0.1487, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2166, mae: 0.3176, huber: 0.1023, swd: 0.0853, target_std: 0.7348
      Epoch 4 composite train-obj: 0.135542
            Val objective improved 0.1573 → 0.1549, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3613, mae: 0.3530, huber: 0.1355, swd: 0.1388, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3331, mae: 0.3967, huber: 0.1536, swd: 0.1445, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2269, mae: 0.3308, huber: 0.1072, swd: 0.0939, target_std: 0.7348
      Epoch 5 composite train-obj: 0.135518
            Val objective improved 0.1549 → 0.1536, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.3619, mae: 0.3533, huber: 0.1357, swd: 0.1391, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3442, mae: 0.4055, huber: 0.1579, swd: 0.1529, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2152, mae: 0.3142, huber: 0.1015, swd: 0.0843, target_std: 0.7348
      Epoch 6 composite train-obj: 0.135691
            No improvement (0.1579), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.3616, mae: 0.3531, huber: 0.1356, swd: 0.1389, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3429, mae: 0.4028, huber: 0.1572, swd: 0.1530, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2168, mae: 0.3167, huber: 0.1024, swd: 0.0860, target_std: 0.7348
      Epoch 7 composite train-obj: 0.135584
            No improvement (0.1572), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.3616, mae: 0.3529, huber: 0.1355, swd: 0.1389, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3422, mae: 0.4078, huber: 0.1576, swd: 0.1532, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2188, mae: 0.3218, huber: 0.1034, swd: 0.0880, target_std: 0.7348
      Epoch 8 composite train-obj: 0.135530
            No improvement (0.1576), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.3613, mae: 0.3529, huber: 0.1355, swd: 0.1388, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3298, mae: 0.3977, huber: 0.1519, swd: 0.1444, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2323, mae: 0.3356, huber: 0.1097, swd: 0.0953, target_std: 0.7348
      Epoch 9 composite train-obj: 0.135458
            Val objective improved 0.1536 → 0.1519, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 0.3618, mae: 0.3532, huber: 0.1356, swd: 0.1391, target_std: 0.7878
    Epoch [10/50], Val Losses: mse: 0.3346, mae: 0.4002, huber: 0.1546, swd: 0.1423, target_std: 0.9639
    Epoch [10/50], Test Losses: mse: 0.2179, mae: 0.3198, huber: 0.1028, swd: 0.0832, target_std: 0.7348
      Epoch 10 composite train-obj: 0.135648
            No improvement (0.1546), counter 1/5
    Epoch [11/50], Train Losses: mse: 0.3615, mae: 0.3531, huber: 0.1356, swd: 0.1389, target_std: 0.7878
    Epoch [11/50], Val Losses: mse: 0.3325, mae: 0.3974, huber: 0.1536, swd: 0.1412, target_std: 0.9639
    Epoch [11/50], Test Losses: mse: 0.2170, mae: 0.3188, huber: 0.1024, swd: 0.0832, target_std: 0.7348
      Epoch 11 composite train-obj: 0.135593
            No improvement (0.1536), counter 2/5
    Epoch [12/50], Train Losses: mse: 0.3615, mae: 0.3529, huber: 0.1355, swd: 0.1388, target_std: 0.7878
    Epoch [12/50], Val Losses: mse: 0.3293, mae: 0.3933, huber: 0.1518, swd: 0.1408, target_std: 0.9639
    Epoch [12/50], Test Losses: mse: 0.2197, mae: 0.3205, huber: 0.1037, swd: 0.0864, target_std: 0.7348
      Epoch 12 composite train-obj: 0.135464
            Val objective improved 0.1519 → 0.1518, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 0.3614, mae: 0.3530, huber: 0.1355, swd: 0.1390, target_std: 0.7878
    Epoch [13/50], Val Losses: mse: 0.3432, mae: 0.4064, huber: 0.1575, swd: 0.1576, target_std: 0.9639
    Epoch [13/50], Test Losses: mse: 0.2233, mae: 0.3205, huber: 0.1051, swd: 0.0898, target_std: 0.7348
      Epoch 13 composite train-obj: 0.135482
            No improvement (0.1575), counter 1/5
    Epoch [14/50], Train Losses: mse: 0.3617, mae: 0.3530, huber: 0.1355, swd: 0.1391, target_std: 0.7878
    Epoch [14/50], Val Losses: mse: 0.3349, mae: 0.3964, huber: 0.1545, swd: 0.1400, target_std: 0.9639
    Epoch [14/50], Test Losses: mse: 0.2161, mae: 0.3189, huber: 0.1021, swd: 0.0814, target_std: 0.7348
      Epoch 14 composite train-obj: 0.135527
            No improvement (0.1545), counter 2/5
    Epoch [15/50], Train Losses: mse: 0.3617, mae: 0.3533, huber: 0.1357, swd: 0.1391, target_std: 0.7878
    Epoch [15/50], Val Losses: mse: 0.3370, mae: 0.3986, huber: 0.1557, swd: 0.1382, target_std: 0.9639
    Epoch [15/50], Test Losses: mse: 0.2126, mae: 0.3126, huber: 0.1002, swd: 0.0765, target_std: 0.7348
      Epoch 15 composite train-obj: 0.135684
            No improvement (0.1557), counter 3/5
    Epoch [16/50], Train Losses: mse: 0.3615, mae: 0.3531, huber: 0.1355, swd: 0.1390, target_std: 0.7879
    Epoch [16/50], Val Losses: mse: 0.3335, mae: 0.3959, huber: 0.1541, swd: 0.1392, target_std: 0.9639
    Epoch [16/50], Test Losses: mse: 0.2176, mae: 0.3227, huber: 0.1029, swd: 0.0828, target_std: 0.7348
      Epoch 16 composite train-obj: 0.135526
            No improvement (0.1541), counter 4/5
    Epoch [17/50], Train Losses: mse: 0.3615, mae: 0.3531, huber: 0.1355, swd: 0.1391, target_std: 0.7879
    Epoch [17/50], Val Losses: mse: 0.3365, mae: 0.3981, huber: 0.1554, swd: 0.1449, target_std: 0.9639
    Epoch [17/50], Test Losses: mse: 0.2139, mae: 0.3159, huber: 0.1011, swd: 0.0818, target_std: 0.7348
      Epoch 17 composite train-obj: 0.135517
    Epoch [17/50], Test Losses: mse: 0.2197, mae: 0.3205, huber: 0.1037, swd: 0.0864, target_std: 0.7348
    Best round's Test MSE: 0.2197, MAE: 0.3205, SWD: 0.0864
    Best round's Validation MSE: 0.3293, MAE: 0.3933
    Best round's Test verification MSE : 0.2197, MAE: 0.3205, SWD: 0.0864
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3847, mae: 0.3684, huber: 0.1442, swd: 0.1570, target_std: 0.7878
    Epoch [1/50], Val Losses: mse: 0.3549, mae: 0.4134, huber: 0.1625, swd: 0.1811, target_std: 0.9639
    Epoch [1/50], Test Losses: mse: 0.2147, mae: 0.3167, huber: 0.1014, swd: 0.0957, target_std: 0.7348
      Epoch 1 composite train-obj: 0.144150
            Val objective improved inf → 0.1625, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3625, mae: 0.3533, huber: 0.1358, swd: 0.1523, target_std: 0.7878
    Epoch [2/50], Val Losses: mse: 0.3489, mae: 0.4140, huber: 0.1600, swd: 0.1881, target_std: 0.9639
    Epoch [2/50], Test Losses: mse: 0.2422, mae: 0.3381, huber: 0.1137, swd: 0.1217, target_std: 0.7348
      Epoch 2 composite train-obj: 0.135842
            Val objective improved 0.1625 → 0.1600, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3617, mae: 0.3530, huber: 0.1356, swd: 0.1522, target_std: 0.7878
    Epoch [3/50], Val Losses: mse: 0.3385, mae: 0.4012, huber: 0.1560, swd: 0.1627, target_std: 0.9639
    Epoch [3/50], Test Losses: mse: 0.2150, mae: 0.3171, huber: 0.1016, swd: 0.0927, target_std: 0.7348
      Epoch 3 composite train-obj: 0.135592
            Val objective improved 0.1600 → 0.1560, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3615, mae: 0.3528, huber: 0.1355, swd: 0.1522, target_std: 0.7879
    Epoch [4/50], Val Losses: mse: 0.3420, mae: 0.4027, huber: 0.1570, swd: 0.1666, target_std: 0.9639
    Epoch [4/50], Test Losses: mse: 0.2164, mae: 0.3204, huber: 0.1024, swd: 0.0945, target_std: 0.7348
      Epoch 4 composite train-obj: 0.135496
            No improvement (0.1570), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.3612, mae: 0.3526, huber: 0.1354, swd: 0.1519, target_std: 0.7878
    Epoch [5/50], Val Losses: mse: 0.3369, mae: 0.3991, huber: 0.1551, swd: 0.1576, target_std: 0.9639
    Epoch [5/50], Test Losses: mse: 0.2152, mae: 0.3147, huber: 0.1015, swd: 0.0900, target_std: 0.7348
      Epoch 5 composite train-obj: 0.135359
            Val objective improved 0.1560 → 0.1551, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.3616, mae: 0.3530, huber: 0.1356, swd: 0.1522, target_std: 0.7878
    Epoch [6/50], Val Losses: mse: 0.3474, mae: 0.4094, huber: 0.1595, swd: 0.1767, target_std: 0.9639
    Epoch [6/50], Test Losses: mse: 0.2168, mae: 0.3185, huber: 0.1024, swd: 0.0976, target_std: 0.7348
      Epoch 6 composite train-obj: 0.135556
            No improvement (0.1595), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.3618, mae: 0.3533, huber: 0.1357, swd: 0.1524, target_std: 0.7878
    Epoch [7/50], Val Losses: mse: 0.3389, mae: 0.4024, huber: 0.1560, swd: 0.1621, target_std: 0.9639
    Epoch [7/50], Test Losses: mse: 0.2146, mae: 0.3191, huber: 0.1016, swd: 0.0923, target_std: 0.7348
      Epoch 7 composite train-obj: 0.135651
            No improvement (0.1560), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.3616, mae: 0.3532, huber: 0.1356, swd: 0.1523, target_std: 0.7878
    Epoch [8/50], Val Losses: mse: 0.3405, mae: 0.4019, huber: 0.1570, swd: 0.1647, target_std: 0.9639
    Epoch [8/50], Test Losses: mse: 0.2161, mae: 0.3179, huber: 0.1021, swd: 0.0945, target_std: 0.7348
      Epoch 8 composite train-obj: 0.135583
            No improvement (0.1570), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.3615, mae: 0.3531, huber: 0.1356, swd: 0.1522, target_std: 0.7878
    Epoch [9/50], Val Losses: mse: 0.3348, mae: 0.3996, huber: 0.1548, swd: 0.1592, target_std: 0.9639
    Epoch [9/50], Test Losses: mse: 0.2205, mae: 0.3198, huber: 0.1038, swd: 0.0961, target_std: 0.7348
      Epoch 9 composite train-obj: 0.135569
            Val objective improved 0.1551 → 0.1548, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 0.3618, mae: 0.3533, huber: 0.1357, swd: 0.1524, target_std: 0.7878
    Epoch [10/50], Val Losses: mse: 0.3395, mae: 0.4008, huber: 0.1566, swd: 0.1548, target_std: 0.9639
    Epoch [10/50], Test Losses: mse: 0.2109, mae: 0.3116, huber: 0.0996, swd: 0.0854, target_std: 0.7348
      Epoch 10 composite train-obj: 0.135656
            No improvement (0.1566), counter 1/5
    Epoch [11/50], Train Losses: mse: 0.3615, mae: 0.3530, huber: 0.1356, swd: 0.1520, target_std: 0.7878
    Epoch [11/50], Val Losses: mse: 0.3564, mae: 0.4174, huber: 0.1633, swd: 0.1822, target_std: 0.9639
    Epoch [11/50], Test Losses: mse: 0.2201, mae: 0.3241, huber: 0.1040, swd: 0.0995, target_std: 0.7348
      Epoch 11 composite train-obj: 0.135556
            No improvement (0.1633), counter 2/5
    Epoch [12/50], Train Losses: mse: 0.3617, mae: 0.3531, huber: 0.1356, swd: 0.1523, target_std: 0.7878
    Epoch [12/50], Val Losses: mse: 0.3381, mae: 0.4024, huber: 0.1554, swd: 0.1704, target_std: 0.9639
    Epoch [12/50], Test Losses: mse: 0.2274, mae: 0.3277, huber: 0.1072, swd: 0.1084, target_std: 0.7348
      Epoch 12 composite train-obj: 0.135617
            No improvement (0.1554), counter 3/5
    Epoch [13/50], Train Losses: mse: 0.3614, mae: 0.3530, huber: 0.1355, swd: 0.1522, target_std: 0.7878
    Epoch [13/50], Val Losses: mse: 0.3439, mae: 0.4079, huber: 0.1586, swd: 0.1682, target_std: 0.9639
    Epoch [13/50], Test Losses: mse: 0.2130, mae: 0.3162, huber: 0.1007, swd: 0.0928, target_std: 0.7348
      Epoch 13 composite train-obj: 0.135504
            No improvement (0.1586), counter 4/5
    Epoch [14/50], Train Losses: mse: 0.3615, mae: 0.3532, huber: 0.1356, swd: 0.1522, target_std: 0.7878
    Epoch [14/50], Val Losses: mse: 0.3355, mae: 0.3987, huber: 0.1546, swd: 0.1610, target_std: 0.9639
    Epoch [14/50], Test Losses: mse: 0.2201, mae: 0.3201, huber: 0.1038, swd: 0.0962, target_std: 0.7348
      Epoch 14 composite train-obj: 0.135581
            Val objective improved 0.1548 → 0.1546, saving checkpoint.
    Epoch [15/50], Train Losses: mse: 0.3614, mae: 0.3531, huber: 0.1355, swd: 0.1521, target_std: 0.7878
    Epoch [15/50], Val Losses: mse: 0.3450, mae: 0.4081, huber: 0.1587, swd: 0.1703, target_std: 0.9639
    Epoch [15/50], Test Losses: mse: 0.2150, mae: 0.3139, huber: 0.1013, swd: 0.0938, target_std: 0.7348
      Epoch 15 composite train-obj: 0.135546
            No improvement (0.1587), counter 1/5
    Epoch [16/50], Train Losses: mse: 0.3615, mae: 0.3531, huber: 0.1355, swd: 0.1523, target_std: 0.7878
    Epoch [16/50], Val Losses: mse: 0.3398, mae: 0.4025, huber: 0.1566, swd: 0.1617, target_std: 0.9639
    Epoch [16/50], Test Losses: mse: 0.2106, mae: 0.3131, huber: 0.0996, swd: 0.0896, target_std: 0.7348
      Epoch 16 composite train-obj: 0.135532
            No improvement (0.1566), counter 2/5
    Epoch [17/50], Train Losses: mse: 0.3619, mae: 0.3533, huber: 0.1357, swd: 0.1523, target_std: 0.7878
    Epoch [17/50], Val Losses: mse: 0.3347, mae: 0.3974, huber: 0.1540, swd: 0.1618, target_std: 0.9639
    Epoch [17/50], Test Losses: mse: 0.2287, mae: 0.3286, huber: 0.1078, swd: 0.1050, target_std: 0.7348
      Epoch 17 composite train-obj: 0.135671
            Val objective improved 0.1546 → 0.1540, saving checkpoint.
    Epoch [18/50], Train Losses: mse: 0.3616, mae: 0.3531, huber: 0.1355, swd: 0.1522, target_std: 0.7878
    Epoch [18/50], Val Losses: mse: 0.3370, mae: 0.3998, huber: 0.1556, swd: 0.1571, target_std: 0.9639
    Epoch [18/50], Test Losses: mse: 0.2151, mae: 0.3144, huber: 0.1014, swd: 0.0912, target_std: 0.7348
      Epoch 18 composite train-obj: 0.135512
            No improvement (0.1556), counter 1/5
    Epoch [19/50], Train Losses: mse: 0.3618, mae: 0.3532, huber: 0.1356, swd: 0.1522, target_std: 0.7878
    Epoch [19/50], Val Losses: mse: 0.3498, mae: 0.4103, huber: 0.1607, swd: 0.1802, target_std: 0.9639
    Epoch [19/50], Test Losses: mse: 0.2226, mae: 0.3242, huber: 0.1051, swd: 0.1046, target_std: 0.7348
      Epoch 19 composite train-obj: 0.135632
            No improvement (0.1607), counter 2/5
    Epoch [20/50], Train Losses: mse: 0.3613, mae: 0.3531, huber: 0.1355, swd: 0.1520, target_std: 0.7878
    Epoch [20/50], Val Losses: mse: 0.3529, mae: 0.4148, huber: 0.1620, swd: 0.1834, target_std: 0.9639
    Epoch [20/50], Test Losses: mse: 0.2217, mae: 0.3212, huber: 0.1045, swd: 0.1043, target_std: 0.7348
      Epoch 20 composite train-obj: 0.135513
            No improvement (0.1620), counter 3/5
    Epoch [21/50], Train Losses: mse: 0.3613, mae: 0.3530, huber: 0.1355, swd: 0.1523, target_std: 0.7878
    Epoch [21/50], Val Losses: mse: 0.3343, mae: 0.3956, huber: 0.1547, swd: 0.1551, target_std: 0.9639
    Epoch [21/50], Test Losses: mse: 0.2179, mae: 0.3197, huber: 0.1029, swd: 0.0921, target_std: 0.7348
      Epoch 21 composite train-obj: 0.135481
            No improvement (0.1547), counter 4/5
    Epoch [22/50], Train Losses: mse: 0.3616, mae: 0.3530, huber: 0.1355, swd: 0.1521, target_std: 0.7879
    Epoch [22/50], Val Losses: mse: 0.3428, mae: 0.4046, huber: 0.1574, swd: 0.1684, target_std: 0.9639
    Epoch [22/50], Test Losses: mse: 0.2147, mae: 0.3151, huber: 0.1014, swd: 0.0949, target_std: 0.7348
      Epoch 22 composite train-obj: 0.135544
    Epoch [22/50], Test Losses: mse: 0.2287, mae: 0.3286, huber: 0.1078, swd: 0.1050, target_std: 0.7348
    Best round's Test MSE: 0.2287, MAE: 0.3286, SWD: 0.1050
    Best round's Validation MSE: 0.3347, MAE: 0.3974
    Best round's Test verification MSE : 0.2287, MAE: 0.3286, SWD: 0.1050
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq196_pred720_20250501_1915)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2218 ± 0.0050
      mae: 0.3221 ± 0.0048
      huber: 0.1046 ± 0.0023
      swd: 0.0928 ± 0.0086
      target_std: 0.7348 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3319 ± 0.0022
      mae: 0.3952 ± 0.0017
      huber: 0.1529 ± 0.0009
      swd: 0.1500 ± 0.0088
      target_std: 0.9639 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq196_pred720_20250501_1915
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


