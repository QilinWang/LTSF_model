# data


```python
import torch 
import importlib
import monotonic
import data_manager
import metrics
import utils
importlib.reload(utils)
import train as Train
from train import execute_model_evaluation
import train_config
from data_manager import DatasetManager
data_mgr = DatasetManager(device='cuda')

# Load a synthetic dataset
data_mgr.load_csv('etth2', './etth2.csv')
```

    
    ==================================================
    Dataset: etth2 (csv)
    ==================================================
    Shape: torch.Size([17420, 7])
    Channels: 7
    Length: 17420
    Source: ./etth2.csv
    
    Sample data (first 2 rows):
    tensor([[41.1300, 12.4810, 36.5360,  9.3550,  4.4240,  1.3110, 38.6620],
            [37.5280, 10.1360, 33.9360,  7.5320,  4.4350,  1.2150, 37.1240]])
    ==================================================
    




    <data_manager.DatasetManager at 0x26c87804380>



## Seq=196 Normalized

### EigenACL

#### pred=96


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['etth2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth2: tensor([1.0258, 1.0527, 0.8852, 1.0967, 1.0979, 0.8402, 1.0425],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 12
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3919, mae: 0.3908, huber: 0.1527, swd: 0.2203, ept: 70.0932
    Epoch [1/50], Val Losses: mse: 0.3055, mae: 0.3850, huber: 0.1429, swd: 0.1504, ept: 63.0332
    Epoch [1/50], Test Losses: mse: 0.1726, mae: 0.2977, huber: 0.0843, swd: 0.0668, ept: 75.4087
      Epoch 1 composite train-obj: 0.152738
            Val objective improved inf → 0.1429, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2861, mae: 0.3272, huber: 0.1127, swd: 0.1297, ept: 77.1088
    Epoch [2/50], Val Losses: mse: 0.2987, mae: 0.3784, huber: 0.1392, swd: 0.1450, ept: 63.8336
    Epoch [2/50], Test Losses: mse: 0.1655, mae: 0.2922, huber: 0.0811, swd: 0.0640, ept: 75.7068
      Epoch 2 composite train-obj: 0.112679
            Val objective improved 0.1429 → 0.1392, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2495, mae: 0.3022, huber: 0.0992, swd: 0.1099, ept: 79.8618
    Epoch [3/50], Val Losses: mse: 0.2921, mae: 0.3693, huber: 0.1352, swd: 0.1328, ept: 65.7399
    Epoch [3/50], Test Losses: mse: 0.1600, mae: 0.2856, huber: 0.0783, swd: 0.0589, ept: 77.4977
      Epoch 3 composite train-obj: 0.099188
            Val objective improved 0.1392 → 0.1352, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2270, mae: 0.2916, huber: 0.0923, swd: 0.0980, ept: 81.1942
    Epoch [4/50], Val Losses: mse: 0.2858, mae: 0.3668, huber: 0.1332, swd: 0.1216, ept: 66.4699
    Epoch [4/50], Test Losses: mse: 0.1630, mae: 0.2895, huber: 0.0800, swd: 0.0556, ept: 78.0868
      Epoch 4 composite train-obj: 0.092253
            Val objective improved 0.1352 → 0.1332, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2112, mae: 0.2826, huber: 0.0868, swd: 0.0874, ept: 82.1806
    Epoch [5/50], Val Losses: mse: 0.2854, mae: 0.3673, huber: 0.1327, swd: 0.1289, ept: 67.7096
    Epoch [5/50], Test Losses: mse: 0.1630, mae: 0.2930, huber: 0.0800, swd: 0.0610, ept: 78.6876
      Epoch 5 composite train-obj: 0.086843
            Val objective improved 0.1332 → 0.1327, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2017, mae: 0.2786, huber: 0.0837, swd: 0.0819, ept: 82.5049
    Epoch [6/50], Val Losses: mse: 0.2885, mae: 0.3681, huber: 0.1336, swd: 0.1303, ept: 68.4595
    Epoch [6/50], Test Losses: mse: 0.1725, mae: 0.3007, huber: 0.0842, swd: 0.0689, ept: 77.9794
      Epoch 6 composite train-obj: 0.083731
            No improvement (0.1336), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.1907, mae: 0.2711, huber: 0.0796, swd: 0.0755, ept: 83.3183
    Epoch [7/50], Val Losses: mse: 0.2945, mae: 0.3736, huber: 0.1374, swd: 0.1251, ept: 66.1468
    Epoch [7/50], Test Losses: mse: 0.1782, mae: 0.3045, huber: 0.0869, swd: 0.0660, ept: 78.1345
      Epoch 7 composite train-obj: 0.079574
            No improvement (0.1374), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.1856, mae: 0.2679, huber: 0.0776, swd: 0.0730, ept: 83.4460
    Epoch [8/50], Val Losses: mse: 0.2896, mae: 0.3685, huber: 0.1347, swd: 0.1265, ept: 67.6860
    Epoch [8/50], Test Losses: mse: 0.1786, mae: 0.3040, huber: 0.0870, swd: 0.0689, ept: 77.8661
      Epoch 8 composite train-obj: 0.077607
            No improvement (0.1347), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.1787, mae: 0.2643, huber: 0.0752, swd: 0.0690, ept: 83.8753
    Epoch [9/50], Val Losses: mse: 0.3016, mae: 0.3861, huber: 0.1402, swd: 0.1449, ept: 68.0793
    Epoch [9/50], Test Losses: mse: 0.1830, mae: 0.3129, huber: 0.0893, swd: 0.0773, ept: 77.5959
      Epoch 9 composite train-obj: 0.075188
            No improvement (0.1402), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.1730, mae: 0.2609, huber: 0.0730, swd: 0.0649, ept: 84.0776
    Epoch [10/50], Val Losses: mse: 0.2867, mae: 0.3646, huber: 0.1325, swd: 0.1218, ept: 68.8692
    Epoch [10/50], Test Losses: mse: 0.1786, mae: 0.3067, huber: 0.0868, swd: 0.0665, ept: 78.1172
      Epoch 10 composite train-obj: 0.072991
            Val objective improved 0.1327 → 0.1325, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 0.1658, mae: 0.2544, huber: 0.0700, swd: 0.0599, ept: 84.5448
    Epoch [11/50], Val Losses: mse: 0.2848, mae: 0.3692, huber: 0.1335, swd: 0.1175, ept: 67.3943
    Epoch [11/50], Test Losses: mse: 0.1889, mae: 0.3143, huber: 0.0918, swd: 0.0697, ept: 77.6769
      Epoch 11 composite train-obj: 0.069953
            No improvement (0.1335), counter 1/5
    Epoch [12/50], Train Losses: mse: 0.1613, mae: 0.2508, huber: 0.0681, swd: 0.0570, ept: 84.7358
    Epoch [12/50], Val Losses: mse: 0.2847, mae: 0.3681, huber: 0.1332, swd: 0.1193, ept: 68.0207
    Epoch [12/50], Test Losses: mse: 0.1829, mae: 0.3102, huber: 0.0893, swd: 0.0707, ept: 77.6124
      Epoch 12 composite train-obj: 0.068050
            No improvement (0.1332), counter 2/5
    Epoch [13/50], Train Losses: mse: 0.1574, mae: 0.2478, huber: 0.0664, swd: 0.0547, ept: 85.1080
    Epoch [13/50], Val Losses: mse: 0.2875, mae: 0.3674, huber: 0.1337, swd: 0.1180, ept: 67.5720
    Epoch [13/50], Test Losses: mse: 0.1914, mae: 0.3150, huber: 0.0927, swd: 0.0733, ept: 77.4163
      Epoch 13 composite train-obj: 0.066426
            No improvement (0.1337), counter 3/5
    Epoch [14/50], Train Losses: mse: 0.1543, mae: 0.2452, huber: 0.0651, swd: 0.0531, ept: 85.2899
    Epoch [14/50], Val Losses: mse: 0.2986, mae: 0.3785, huber: 0.1396, swd: 0.1211, ept: 66.0810
    Epoch [14/50], Test Losses: mse: 0.2006, mae: 0.3206, huber: 0.0969, swd: 0.0745, ept: 76.7143
      Epoch 14 composite train-obj: 0.065120
            No improvement (0.1396), counter 4/5
    Epoch [15/50], Train Losses: mse: 0.1510, mae: 0.2426, huber: 0.0638, swd: 0.0511, ept: 85.4620
    Epoch [15/50], Val Losses: mse: 0.2882, mae: 0.3694, huber: 0.1343, swd: 0.1176, ept: 67.8979
    Epoch [15/50], Test Losses: mse: 0.1957, mae: 0.3205, huber: 0.0950, swd: 0.0764, ept: 77.6491
      Epoch 15 composite train-obj: 0.063794
    Epoch [15/50], Test Losses: mse: 0.1786, mae: 0.3067, huber: 0.0868, swd: 0.0665, ept: 78.1114
    Best round's Test MSE: 0.1786, MAE: 0.3067, SWD: 0.0665
    Best round's Validation MSE: 0.2867, MAE: 0.3646, SWD: 0.1218
    Best round's Test verification MSE : 0.1786, MAE: 0.3067, SWD: 0.0665
    Time taken: 40.06 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3967, mae: 0.3941, huber: 0.1549, swd: 0.2237, ept: 70.1088
    Epoch [1/50], Val Losses: mse: 0.3083, mae: 0.3914, huber: 0.1441, swd: 0.1542, ept: 63.8960
    Epoch [1/50], Test Losses: mse: 0.1722, mae: 0.2978, huber: 0.0841, swd: 0.0690, ept: 75.3248
      Epoch 1 composite train-obj: 0.154939
            Val objective improved inf → 0.1441, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2840, mae: 0.3249, huber: 0.1119, swd: 0.1271, ept: 77.5144
    Epoch [2/50], Val Losses: mse: 0.2960, mae: 0.3763, huber: 0.1383, swd: 0.1309, ept: 63.3819
    Epoch [2/50], Test Losses: mse: 0.1652, mae: 0.2899, huber: 0.0807, swd: 0.0581, ept: 76.1362
      Epoch 2 composite train-obj: 0.111855
            Val objective improved 0.1441 → 0.1383, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2523, mae: 0.3054, huber: 0.1004, swd: 0.1128, ept: 79.4224
    Epoch [3/50], Val Losses: mse: 0.2849, mae: 0.3698, huber: 0.1336, swd: 0.1276, ept: 66.5440
    Epoch [3/50], Test Losses: mse: 0.1577, mae: 0.2853, huber: 0.0773, swd: 0.0559, ept: 77.3460
      Epoch 3 composite train-obj: 0.100385
            Val objective improved 0.1383 → 0.1336, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2291, mae: 0.2910, huber: 0.0925, swd: 0.0988, ept: 81.1953
    Epoch [4/50], Val Losses: mse: 0.2791, mae: 0.3632, huber: 0.1308, swd: 0.1209, ept: 66.7868
    Epoch [4/50], Test Losses: mse: 0.1614, mae: 0.2891, huber: 0.0790, swd: 0.0561, ept: 78.3340
      Epoch 4 composite train-obj: 0.092541
            Val objective improved 0.1336 → 0.1308, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2161, mae: 0.2842, huber: 0.0883, swd: 0.0910, ept: 81.9239
    Epoch [5/50], Val Losses: mse: 0.2833, mae: 0.3669, huber: 0.1323, swd: 0.1177, ept: 67.0409
    Epoch [5/50], Test Losses: mse: 0.1669, mae: 0.2908, huber: 0.0814, swd: 0.0581, ept: 78.1167
      Epoch 5 composite train-obj: 0.088282
            No improvement (0.1323), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2048, mae: 0.2786, huber: 0.0845, swd: 0.0843, ept: 82.5545
    Epoch [6/50], Val Losses: mse: 0.2867, mae: 0.3713, huber: 0.1343, swd: 0.1206, ept: 66.5039
    Epoch [6/50], Test Losses: mse: 0.1758, mae: 0.3009, huber: 0.0857, swd: 0.0635, ept: 77.7223
      Epoch 6 composite train-obj: 0.084495
            No improvement (0.1343), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.1937, mae: 0.2722, huber: 0.0805, swd: 0.0784, ept: 83.1115
    Epoch [7/50], Val Losses: mse: 0.2799, mae: 0.3643, huber: 0.1303, swd: 0.1228, ept: 68.6702
    Epoch [7/50], Test Losses: mse: 0.1776, mae: 0.3091, huber: 0.0870, swd: 0.0706, ept: 78.2633
      Epoch 7 composite train-obj: 0.080534
            Val objective improved 0.1308 → 0.1303, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.1871, mae: 0.2688, huber: 0.0781, swd: 0.0752, ept: 83.4526
    Epoch [8/50], Val Losses: mse: 0.2769, mae: 0.3625, huber: 0.1294, swd: 0.1156, ept: 67.4504
    Epoch [8/50], Test Losses: mse: 0.1811, mae: 0.3058, huber: 0.0882, swd: 0.0690, ept: 77.8604
      Epoch 8 composite train-obj: 0.078150
            Val objective improved 0.1303 → 0.1294, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.1788, mae: 0.2635, huber: 0.0750, swd: 0.0701, ept: 83.9382
    Epoch [9/50], Val Losses: mse: 0.2758, mae: 0.3610, huber: 0.1287, swd: 0.1142, ept: 68.1777
    Epoch [9/50], Test Losses: mse: 0.1822, mae: 0.3102, huber: 0.0887, swd: 0.0698, ept: 77.6620
      Epoch 9 composite train-obj: 0.075043
            Val objective improved 0.1294 → 0.1287, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 0.1724, mae: 0.2596, huber: 0.0726, swd: 0.0654, ept: 84.2571
    Epoch [10/50], Val Losses: mse: 0.2783, mae: 0.3632, huber: 0.1298, swd: 0.1134, ept: 68.4975
    Epoch [10/50], Test Losses: mse: 0.1841, mae: 0.3081, huber: 0.0897, swd: 0.0702, ept: 77.1425
      Epoch 10 composite train-obj: 0.072622
            No improvement (0.1298), counter 1/5
    Epoch [11/50], Train Losses: mse: 0.1665, mae: 0.2562, huber: 0.0704, swd: 0.0608, ept: 84.5493
    Epoch [11/50], Val Losses: mse: 0.2877, mae: 0.3699, huber: 0.1335, swd: 0.1231, ept: 67.8974
    Epoch [11/50], Test Losses: mse: 0.1941, mae: 0.3200, huber: 0.0943, swd: 0.0771, ept: 77.1732
      Epoch 11 composite train-obj: 0.070406
            No improvement (0.1335), counter 2/5
    Epoch [12/50], Train Losses: mse: 0.1615, mae: 0.2524, huber: 0.0683, swd: 0.0574, ept: 84.6844
    Epoch [12/50], Val Losses: mse: 0.2812, mae: 0.3664, huber: 0.1317, swd: 0.1126, ept: 66.9625
    Epoch [12/50], Test Losses: mse: 0.1999, mae: 0.3219, huber: 0.0971, swd: 0.0755, ept: 76.6214
      Epoch 12 composite train-obj: 0.068330
            No improvement (0.1317), counter 3/5
    Epoch [13/50], Train Losses: mse: 0.1561, mae: 0.2471, huber: 0.0659, swd: 0.0543, ept: 85.2165
    Epoch [13/50], Val Losses: mse: 0.2963, mae: 0.3733, huber: 0.1367, swd: 0.1239, ept: 67.6442
    Epoch [13/50], Test Losses: mse: 0.1928, mae: 0.3176, huber: 0.0935, swd: 0.0776, ept: 77.2986
      Epoch 13 composite train-obj: 0.065923
            No improvement (0.1367), counter 4/5
    Epoch [14/50], Train Losses: mse: 0.1528, mae: 0.2448, huber: 0.0646, swd: 0.0524, ept: 85.3155
    Epoch [14/50], Val Losses: mse: 0.2829, mae: 0.3654, huber: 0.1315, swd: 0.1154, ept: 68.0863
    Epoch [14/50], Test Losses: mse: 0.1959, mae: 0.3183, huber: 0.0947, swd: 0.0746, ept: 77.5176
      Epoch 14 composite train-obj: 0.064593
    Epoch [14/50], Test Losses: mse: 0.1822, mae: 0.3102, huber: 0.0887, swd: 0.0698, ept: 77.6626
    Best round's Test MSE: 0.1822, MAE: 0.3102, SWD: 0.0698
    Best round's Validation MSE: 0.2758, MAE: 0.3610, SWD: 0.1142
    Best round's Test verification MSE : 0.1822, MAE: 0.3102, SWD: 0.0698
    Time taken: 35.57 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3950, mae: 0.3936, huber: 0.1542, swd: 0.2010, ept: 69.8685
    Epoch [1/50], Val Losses: mse: 0.3053, mae: 0.3893, huber: 0.1428, swd: 0.1437, ept: 63.8090
    Epoch [1/50], Test Losses: mse: 0.1742, mae: 0.3000, huber: 0.0851, swd: 0.0674, ept: 75.3363
      Epoch 1 composite train-obj: 0.154201
            Val objective improved inf → 0.1428, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2882, mae: 0.3292, huber: 0.1137, swd: 0.1207, ept: 77.3601
    Epoch [2/50], Val Losses: mse: 0.2968, mae: 0.3793, huber: 0.1384, swd: 0.1369, ept: 63.8529
    Epoch [2/50], Test Losses: mse: 0.1688, mae: 0.2961, huber: 0.0826, swd: 0.0648, ept: 75.9428
      Epoch 2 composite train-obj: 0.113650
            Val objective improved 0.1428 → 0.1384, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2584, mae: 0.3072, huber: 0.1020, swd: 0.1072, ept: 79.4835
    Epoch [3/50], Val Losses: mse: 0.2859, mae: 0.3709, huber: 0.1334, swd: 0.1246, ept: 66.2339
    Epoch [3/50], Test Losses: mse: 0.1632, mae: 0.2938, huber: 0.0801, swd: 0.0596, ept: 77.2636
      Epoch 3 composite train-obj: 0.102017
            Val objective improved 0.1384 → 0.1334, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2356, mae: 0.2941, huber: 0.0946, swd: 0.0958, ept: 80.8755
    Epoch [4/50], Val Losses: mse: 0.2856, mae: 0.3709, huber: 0.1341, swd: 0.1127, ept: 65.3142
    Epoch [4/50], Test Losses: mse: 0.1681, mae: 0.2915, huber: 0.0819, swd: 0.0542, ept: 77.2769
      Epoch 4 composite train-obj: 0.094610
            No improvement (0.1341), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2191, mae: 0.2867, huber: 0.0897, swd: 0.0852, ept: 81.5330
    Epoch [5/50], Val Losses: mse: 0.2786, mae: 0.3604, huber: 0.1294, swd: 0.1111, ept: 67.5764
    Epoch [5/50], Test Losses: mse: 0.1699, mae: 0.2984, huber: 0.0828, swd: 0.0575, ept: 77.9595
      Epoch 5 composite train-obj: 0.089702
            Val objective improved 0.1334 → 0.1294, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2059, mae: 0.2798, huber: 0.0854, swd: 0.0780, ept: 82.1522
    Epoch [6/50], Val Losses: mse: 0.2869, mae: 0.3729, huber: 0.1341, swd: 0.1093, ept: 65.9116
    Epoch [6/50], Test Losses: mse: 0.1792, mae: 0.3029, huber: 0.0871, swd: 0.0592, ept: 77.6556
      Epoch 6 composite train-obj: 0.085360
            No improvement (0.1341), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.1974, mae: 0.2754, huber: 0.0824, swd: 0.0745, ept: 82.6893
    Epoch [7/50], Val Losses: mse: 0.2783, mae: 0.3613, huber: 0.1296, swd: 0.1076, ept: 67.8589
    Epoch [7/50], Test Losses: mse: 0.1743, mae: 0.3002, huber: 0.0848, swd: 0.0587, ept: 78.0307
      Epoch 7 composite train-obj: 0.082370
            No improvement (0.1296), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.1889, mae: 0.2710, huber: 0.0793, swd: 0.0706, ept: 83.0607
    Epoch [8/50], Val Losses: mse: 0.2967, mae: 0.3796, huber: 0.1366, swd: 0.1291, ept: 68.0604
    Epoch [8/50], Test Losses: mse: 0.1819, mae: 0.3107, huber: 0.0885, swd: 0.0712, ept: 77.7168
      Epoch 8 composite train-obj: 0.079338
            No improvement (0.1366), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.1806, mae: 0.2652, huber: 0.0761, swd: 0.0659, ept: 83.6115
    Epoch [9/50], Val Losses: mse: 0.2906, mae: 0.3733, huber: 0.1356, swd: 0.1082, ept: 66.5771
    Epoch [9/50], Test Losses: mse: 0.1866, mae: 0.3087, huber: 0.0905, swd: 0.0626, ept: 77.0160
      Epoch 9 composite train-obj: 0.076051
            No improvement (0.1356), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.1742, mae: 0.2617, huber: 0.0736, swd: 0.0616, ept: 83.9612
    Epoch [10/50], Val Losses: mse: 0.2770, mae: 0.3642, huber: 0.1297, swd: 0.1044, ept: 68.6478
    Epoch [10/50], Test Losses: mse: 0.1820, mae: 0.3106, huber: 0.0889, swd: 0.0632, ept: 77.8717
      Epoch 10 composite train-obj: 0.073588
    Epoch [10/50], Test Losses: mse: 0.1699, mae: 0.2984, huber: 0.0828, swd: 0.0575, ept: 77.9602
    Best round's Test MSE: 0.1699, MAE: 0.2984, SWD: 0.0575
    Best round's Validation MSE: 0.2786, MAE: 0.3604, SWD: 0.1111
    Best round's Test verification MSE : 0.1699, MAE: 0.2984, SWD: 0.0575
    Time taken: 26.07 seconds
    
    ==================================================
    Experiment Summary (ACL_etth2_seq196_pred96_20250510_2103)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1769 ± 0.0051
      mae: 0.3051 ± 0.0049
      huber: 0.0861 ± 0.0025
      swd: 0.0646 ± 0.0052
      ept: 77.9129 ± 0.1887
      count: 12.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2804 ± 0.0046
      mae: 0.3620 ± 0.0019
      huber: 0.1302 ± 0.0016
      swd: 0.1157 ± 0.0045
      ept: 68.2078 ± 0.5282
      count: 12.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 103.27 seconds
    
    Experiment complete: ACL_etth2_seq196_pred96_20250510_2103
    Model: ACL
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['etth2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth2: tensor([1.0258, 1.0527, 0.8852, 1.0967, 1.0979, 0.8402, 1.0425],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 11
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4563, mae: 0.4243, huber: 0.1752, swd: 0.2610, ept: 120.2361
    Epoch [1/50], Val Losses: mse: 0.3798, mae: 0.4378, huber: 0.1756, swd: 0.1824, ept: 98.0632
    Epoch [1/50], Test Losses: mse: 0.2027, mae: 0.3230, huber: 0.0983, swd: 0.0822, ept: 130.4904
      Epoch 1 composite train-obj: 0.175208
            Val objective improved inf → 0.1756, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3657, mae: 0.3699, huber: 0.1402, swd: 0.1814, ept: 132.8646
    Epoch [2/50], Val Losses: mse: 0.3593, mae: 0.4253, huber: 0.1667, swd: 0.1754, ept: 102.1242
    Epoch [2/50], Test Losses: mse: 0.1930, mae: 0.3179, huber: 0.0941, swd: 0.0751, ept: 131.6983
      Epoch 2 composite train-obj: 0.140158
            Val objective improved 0.1756 → 0.1667, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3267, mae: 0.3464, huber: 0.1257, swd: 0.1601, ept: 137.9851
    Epoch [3/50], Val Losses: mse: 0.3454, mae: 0.4110, huber: 0.1598, swd: 0.1628, ept: 105.4672
    Epoch [3/50], Test Losses: mse: 0.1880, mae: 0.3165, huber: 0.0918, swd: 0.0750, ept: 131.8460
      Epoch 3 composite train-obj: 0.125740
            Val objective improved 0.1667 → 0.1598, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3037, mae: 0.3293, huber: 0.1164, swd: 0.1468, ept: 143.0280
    Epoch [4/50], Val Losses: mse: 0.3439, mae: 0.4098, huber: 0.1593, swd: 0.1594, ept: 107.3376
    Epoch [4/50], Test Losses: mse: 0.1841, mae: 0.3109, huber: 0.0898, swd: 0.0718, ept: 134.2852
      Epoch 4 composite train-obj: 0.116440
            Val objective improved 0.1598 → 0.1593, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2886, mae: 0.3204, huber: 0.1109, swd: 0.1351, ept: 145.3977
    Epoch [5/50], Val Losses: mse: 0.3546, mae: 0.4201, huber: 0.1637, swd: 0.1758, ept: 107.4232
    Epoch [5/50], Test Losses: mse: 0.1974, mae: 0.3298, huber: 0.0968, swd: 0.0915, ept: 134.1246
      Epoch 5 composite train-obj: 0.110944
            No improvement (0.1637), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2816, mae: 0.3160, huber: 0.1081, swd: 0.1312, ept: 146.7674
    Epoch [6/50], Val Losses: mse: 0.3413, mae: 0.4083, huber: 0.1586, swd: 0.1521, ept: 109.3249
    Epoch [6/50], Test Losses: mse: 0.1903, mae: 0.3194, huber: 0.0931, swd: 0.0767, ept: 134.7396
      Epoch 6 composite train-obj: 0.108091
            Val objective improved 0.1593 → 0.1586, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.2710, mae: 0.3106, huber: 0.1045, swd: 0.1234, ept: 148.1589
    Epoch [7/50], Val Losses: mse: 0.3425, mae: 0.4069, huber: 0.1586, swd: 0.1435, ept: 110.3046
    Epoch [7/50], Test Losses: mse: 0.1928, mae: 0.3214, huber: 0.0942, swd: 0.0765, ept: 134.8366
      Epoch 7 composite train-obj: 0.104537
            Val objective improved 0.1586 → 0.1586, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.2609, mae: 0.3057, huber: 0.1013, swd: 0.1155, ept: 149.3636
    Epoch [8/50], Val Losses: mse: 0.3528, mae: 0.4152, huber: 0.1627, swd: 0.1545, ept: 110.2959
    Epoch [8/50], Test Losses: mse: 0.2015, mae: 0.3309, huber: 0.0985, swd: 0.0878, ept: 134.9202
      Epoch 8 composite train-obj: 0.101302
            No improvement (0.1627), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.2517, mae: 0.3016, huber: 0.0985, swd: 0.1077, ept: 150.0184
    Epoch [9/50], Val Losses: mse: 0.3546, mae: 0.4181, huber: 0.1642, swd: 0.1427, ept: 108.8891
    Epoch [9/50], Test Losses: mse: 0.1947, mae: 0.3197, huber: 0.0951, swd: 0.0734, ept: 133.6233
      Epoch 9 composite train-obj: 0.098496
            No improvement (0.1642), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.2419, mae: 0.2976, huber: 0.0955, swd: 0.0994, ept: 150.6224
    Epoch [10/50], Val Losses: mse: 0.3488, mae: 0.4148, huber: 0.1622, swd: 0.1408, ept: 109.4944
    Epoch [10/50], Test Losses: mse: 0.1961, mae: 0.3227, huber: 0.0959, swd: 0.0752, ept: 135.0153
      Epoch 10 composite train-obj: 0.095494
            No improvement (0.1622), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.2324, mae: 0.2923, huber: 0.0922, swd: 0.0919, ept: 151.1202
    Epoch [11/50], Val Losses: mse: 0.3480, mae: 0.4147, huber: 0.1618, swd: 0.1374, ept: 109.4339
    Epoch [11/50], Test Losses: mse: 0.1973, mae: 0.3254, huber: 0.0965, swd: 0.0752, ept: 135.5833
      Epoch 11 composite train-obj: 0.092154
            No improvement (0.1618), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.2247, mae: 0.2885, huber: 0.0895, swd: 0.0868, ept: 151.7062
    Epoch [12/50], Val Losses: mse: 0.3523, mae: 0.4143, huber: 0.1630, swd: 0.1408, ept: 110.3912
    Epoch [12/50], Test Losses: mse: 0.1998, mae: 0.3268, huber: 0.0974, swd: 0.0800, ept: 134.7166
      Epoch 12 composite train-obj: 0.089525
    Epoch [12/50], Test Losses: mse: 0.1928, mae: 0.3214, huber: 0.0942, swd: 0.0765, ept: 134.8415
    Best round's Test MSE: 0.1928, MAE: 0.3214, SWD: 0.0765
    Best round's Validation MSE: 0.3425, MAE: 0.4069, SWD: 0.1435
    Best round's Test verification MSE : 0.1928, MAE: 0.3214, SWD: 0.0765
    Time taken: 31.14 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4635, mae: 0.4283, huber: 0.1780, swd: 0.2762, ept: 119.8502
    Epoch [1/50], Val Losses: mse: 0.3702, mae: 0.4320, huber: 0.1712, swd: 0.1853, ept: 99.0352
    Epoch [1/50], Test Losses: mse: 0.1950, mae: 0.3161, huber: 0.0949, swd: 0.0813, ept: 130.4781
      Epoch 1 composite train-obj: 0.177971
            Val objective improved inf → 0.1712, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3573, mae: 0.3664, huber: 0.1377, swd: 0.1771, ept: 133.2310
    Epoch [2/50], Val Losses: mse: 0.3614, mae: 0.4260, huber: 0.1674, swd: 0.1814, ept: 101.9873
    Epoch [2/50], Test Losses: mse: 0.1904, mae: 0.3173, huber: 0.0931, swd: 0.0772, ept: 131.0418
      Epoch 2 composite train-obj: 0.137658
            Val objective improved 0.1712 → 0.1674, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3222, mae: 0.3424, huber: 0.1239, swd: 0.1575, ept: 139.6542
    Epoch [3/50], Val Losses: mse: 0.3380, mae: 0.4073, huber: 0.1574, swd: 0.1522, ept: 105.6180
    Epoch [3/50], Test Losses: mse: 0.1846, mae: 0.3098, huber: 0.0903, swd: 0.0700, ept: 133.0994
      Epoch 3 composite train-obj: 0.123881
            Val objective improved 0.1674 → 0.1574, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2997, mae: 0.3274, huber: 0.1152, swd: 0.1439, ept: 143.6937
    Epoch [4/50], Val Losses: mse: 0.3416, mae: 0.4063, huber: 0.1580, swd: 0.1629, ept: 107.8794
    Epoch [4/50], Test Losses: mse: 0.1872, mae: 0.3164, huber: 0.0916, swd: 0.0790, ept: 134.4048
      Epoch 4 composite train-obj: 0.115205
            No improvement (0.1580), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2903, mae: 0.3217, huber: 0.1115, swd: 0.1381, ept: 145.6239
    Epoch [5/50], Val Losses: mse: 0.3746, mae: 0.4301, huber: 0.1713, swd: 0.1979, ept: 106.7403
    Epoch [5/50], Test Losses: mse: 0.1980, mae: 0.3247, huber: 0.0963, swd: 0.0951, ept: 134.0529
      Epoch 5 composite train-obj: 0.111488
            No improvement (0.1713), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.2799, mae: 0.3147, huber: 0.1075, swd: 0.1312, ept: 147.3516
    Epoch [6/50], Val Losses: mse: 0.3455, mae: 0.4109, huber: 0.1598, swd: 0.1619, ept: 109.1116
    Epoch [6/50], Test Losses: mse: 0.1885, mae: 0.3183, huber: 0.0922, swd: 0.0787, ept: 135.6433
      Epoch 6 composite train-obj: 0.107480
            No improvement (0.1598), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.2713, mae: 0.3101, huber: 0.1045, swd: 0.1257, ept: 148.4139
    Epoch [7/50], Val Losses: mse: 0.3381, mae: 0.4067, huber: 0.1571, swd: 0.1431, ept: 110.8887
    Epoch [7/50], Test Losses: mse: 0.1936, mae: 0.3229, huber: 0.0947, swd: 0.0774, ept: 135.6131
      Epoch 7 composite train-obj: 0.104478
            Val objective improved 0.1574 → 0.1571, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.2623, mae: 0.3070, huber: 0.1017, swd: 0.1198, ept: 149.2244
    Epoch [8/50], Val Losses: mse: 0.3445, mae: 0.4109, huber: 0.1594, swd: 0.1564, ept: 110.0060
    Epoch [8/50], Test Losses: mse: 0.1970, mae: 0.3276, huber: 0.0962, swd: 0.0831, ept: 135.7748
      Epoch 8 composite train-obj: 0.101732
            No improvement (0.1594), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.2512, mae: 0.3006, huber: 0.0981, swd: 0.1100, ept: 150.2071
    Epoch [9/50], Val Losses: mse: 0.3459, mae: 0.4109, huber: 0.1599, swd: 0.1461, ept: 108.7359
    Epoch [9/50], Test Losses: mse: 0.1983, mae: 0.3209, huber: 0.0955, swd: 0.0761, ept: 133.7671
      Epoch 9 composite train-obj: 0.098106
            No improvement (0.1599), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.2426, mae: 0.2971, huber: 0.0953, swd: 0.1023, ept: 150.4786
    Epoch [10/50], Val Losses: mse: 0.3501, mae: 0.4150, huber: 0.1621, swd: 0.1471, ept: 109.4072
    Epoch [10/50], Test Losses: mse: 0.2003, mae: 0.3283, huber: 0.0973, swd: 0.0799, ept: 134.3920
      Epoch 10 composite train-obj: 0.095348
            No improvement (0.1621), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.2334, mae: 0.2923, huber: 0.0922, swd: 0.0944, ept: 151.1729
    Epoch [11/50], Val Losses: mse: 0.3427, mae: 0.4107, huber: 0.1587, swd: 0.1446, ept: 110.0716
    Epoch [11/50], Test Losses: mse: 0.2032, mae: 0.3307, huber: 0.0990, swd: 0.0871, ept: 134.4964
      Epoch 11 composite train-obj: 0.092234
            No improvement (0.1587), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.2252, mae: 0.2881, huber: 0.0895, swd: 0.0888, ept: 151.7892
    Epoch [12/50], Val Losses: mse: 0.3561, mae: 0.4210, huber: 0.1642, swd: 0.1530, ept: 109.3630
    Epoch [12/50], Test Losses: mse: 0.2042, mae: 0.3320, huber: 0.0993, swd: 0.0859, ept: 134.3854
      Epoch 12 composite train-obj: 0.089543
    Epoch [12/50], Test Losses: mse: 0.1936, mae: 0.3229, huber: 0.0947, swd: 0.0774, ept: 135.6144
    Best round's Test MSE: 0.1936, MAE: 0.3229, SWD: 0.0774
    Best round's Validation MSE: 0.3381, MAE: 0.4067, SWD: 0.1431
    Best round's Test verification MSE : 0.1936, MAE: 0.3229, SWD: 0.0774
    Time taken: 31.15 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4642, mae: 0.4274, huber: 0.1780, swd: 0.2447, ept: 120.2888
    Epoch [1/50], Val Losses: mse: 0.3624, mae: 0.4272, huber: 0.1682, swd: 0.1595, ept: 100.6677
    Epoch [1/50], Test Losses: mse: 0.1971, mae: 0.3178, huber: 0.0959, swd: 0.0739, ept: 131.1380
      Epoch 1 composite train-obj: 0.178006
            Val objective improved inf → 0.1682, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3601, mae: 0.3669, huber: 0.1384, swd: 0.1652, ept: 133.7118
    Epoch [2/50], Val Losses: mse: 0.3579, mae: 0.4264, huber: 0.1661, swd: 0.1565, ept: 100.4396
    Epoch [2/50], Test Losses: mse: 0.1987, mae: 0.3219, huber: 0.0967, swd: 0.0681, ept: 130.9787
      Epoch 2 composite train-obj: 0.138430
            Val objective improved 0.1682 → 0.1661, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3233, mae: 0.3433, huber: 0.1244, swd: 0.1476, ept: 138.3553
    Epoch [3/50], Val Losses: mse: 0.3391, mae: 0.4087, huber: 0.1578, swd: 0.1409, ept: 106.0992
    Epoch [3/50], Test Losses: mse: 0.1877, mae: 0.3111, huber: 0.0914, swd: 0.0652, ept: 132.6539
      Epoch 3 composite train-obj: 0.124386
            Val objective improved 0.1661 → 0.1578, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2994, mae: 0.3271, huber: 0.1152, swd: 0.1344, ept: 143.6151
    Epoch [4/50], Val Losses: mse: 0.3450, mae: 0.4073, huber: 0.1589, swd: 0.1422, ept: 109.0136
    Epoch [4/50], Test Losses: mse: 0.1942, mae: 0.3229, huber: 0.0948, swd: 0.0698, ept: 135.2108
      Epoch 4 composite train-obj: 0.115178
            No improvement (0.1589), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.2847, mae: 0.3185, huber: 0.1098, swd: 0.1254, ept: 146.0837
    Epoch [5/50], Val Losses: mse: 0.3390, mae: 0.4036, huber: 0.1561, swd: 0.1357, ept: 108.2604
    Epoch [5/50], Test Losses: mse: 0.1898, mae: 0.3172, huber: 0.0925, swd: 0.0681, ept: 135.0020
      Epoch 5 composite train-obj: 0.109761
            Val objective improved 0.1578 → 0.1561, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2754, mae: 0.3138, huber: 0.1064, swd: 0.1196, ept: 147.2571
    Epoch [6/50], Val Losses: mse: 0.3327, mae: 0.4032, huber: 0.1545, swd: 0.1247, ept: 109.4863
    Epoch [6/50], Test Losses: mse: 0.2048, mae: 0.3347, huber: 0.0999, swd: 0.0729, ept: 135.1080
      Epoch 6 composite train-obj: 0.106396
            Val objective improved 0.1561 → 0.1545, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.2666, mae: 0.3086, huber: 0.1031, swd: 0.1142, ept: 148.6356
    Epoch [7/50], Val Losses: mse: 0.3389, mae: 0.4043, huber: 0.1559, swd: 0.1374, ept: 110.7379
    Epoch [7/50], Test Losses: mse: 0.2057, mae: 0.3390, huber: 0.1009, swd: 0.0778, ept: 135.8141
      Epoch 7 composite train-obj: 0.103115
            No improvement (0.1559), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.2565, mae: 0.3034, huber: 0.0998, swd: 0.1067, ept: 149.8931
    Epoch [8/50], Val Losses: mse: 0.3440, mae: 0.4121, huber: 0.1592, swd: 0.1248, ept: 108.5545
    Epoch [8/50], Test Losses: mse: 0.2072, mae: 0.3320, huber: 0.1007, swd: 0.0703, ept: 134.8411
      Epoch 8 composite train-obj: 0.099830
            No improvement (0.1592), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.2468, mae: 0.2987, huber: 0.0968, swd: 0.0986, ept: 150.5405
    Epoch [9/50], Val Losses: mse: 0.3449, mae: 0.4113, huber: 0.1599, swd: 0.1244, ept: 109.5670
    Epoch [9/50], Test Losses: mse: 0.2140, mae: 0.3446, huber: 0.1047, swd: 0.0764, ept: 135.1806
      Epoch 9 composite train-obj: 0.096764
            No improvement (0.1599), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.2385, mae: 0.2952, huber: 0.0942, swd: 0.0912, ept: 150.8766
    Epoch [10/50], Val Losses: mse: 0.3531, mae: 0.4130, huber: 0.1620, swd: 0.1293, ept: 110.2495
    Epoch [10/50], Test Losses: mse: 0.2144, mae: 0.3424, huber: 0.1043, swd: 0.0797, ept: 134.3006
      Epoch 10 composite train-obj: 0.094177
            No improvement (0.1620), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.2299, mae: 0.2901, huber: 0.0911, swd: 0.0852, ept: 151.5320
    Epoch [11/50], Val Losses: mse: 0.3566, mae: 0.4191, huber: 0.1643, swd: 0.1242, ept: 108.6005
    Epoch [11/50], Test Losses: mse: 0.2214, mae: 0.3482, huber: 0.1077, swd: 0.0766, ept: 134.4015
      Epoch 11 composite train-obj: 0.091105
    Epoch [11/50], Test Losses: mse: 0.2048, mae: 0.3347, huber: 0.0999, swd: 0.0729, ept: 135.1115
    Best round's Test MSE: 0.2048, MAE: 0.3347, SWD: 0.0729
    Best round's Validation MSE: 0.3327, MAE: 0.4032, SWD: 0.1247
    Best round's Test verification MSE : 0.2048, MAE: 0.3347, SWD: 0.0729
    Time taken: 28.64 seconds
    
    ==================================================
    Experiment Summary (ACL_etth2_seq196_pred196_20250510_2105)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1971 ± 0.0055
      mae: 0.3263 ± 0.0060
      huber: 0.0963 ± 0.0026
      swd: 0.0756 ± 0.0019
      ept: 135.1859 ± 0.3217
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3378 ± 0.0040
      mae: 0.4056 ± 0.0017
      huber: 0.1567 ± 0.0017
      swd: 0.1371 ± 0.0088
      ept: 110.2266 ± 0.5752
      count: 11.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 91.00 seconds
    
    Experiment complete: ACL_etth2_seq196_pred196_20250510_2105
    Model: ACL
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['etth2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth2: tensor([1.0258, 1.0527, 0.8852, 1.0967, 1.0979, 0.8402, 1.0425],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5288, mae: 0.4593, huber: 0.1996, swd: 0.2988, ept: 172.0586
    Epoch [1/50], Val Losses: mse: 0.3952, mae: 0.4542, huber: 0.1829, swd: 0.1865, ept: 137.3588
    Epoch [1/50], Test Losses: mse: 0.2154, mae: 0.3306, huber: 0.1042, swd: 0.0873, ept: 184.4754
      Epoch 1 composite train-obj: 0.199611
            Val objective improved inf → 0.1829, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4317, mae: 0.4044, huber: 0.1632, swd: 0.2171, ept: 190.4179
    Epoch [2/50], Val Losses: mse: 0.3870, mae: 0.4467, huber: 0.1786, swd: 0.1814, ept: 136.9519
    Epoch [2/50], Test Losses: mse: 0.2165, mae: 0.3399, huber: 0.1052, swd: 0.0883, ept: 185.8336
      Epoch 2 composite train-obj: 0.163160
            Val objective improved 0.1829 → 0.1786, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3908, mae: 0.3794, huber: 0.1475, swd: 0.1896, ept: 199.4208
    Epoch [3/50], Val Losses: mse: 0.3704, mae: 0.4353, huber: 0.1716, swd: 0.1643, ept: 145.1184
    Epoch [3/50], Test Losses: mse: 0.2329, mae: 0.3628, huber: 0.1137, swd: 0.1062, ept: 185.3402
      Epoch 3 composite train-obj: 0.147506
            Val objective improved 0.1786 → 0.1716, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3672, mae: 0.3636, huber: 0.1379, swd: 0.1722, ept: 207.4055
    Epoch [4/50], Val Losses: mse: 0.3670, mae: 0.4342, huber: 0.1705, swd: 0.1545, ept: 152.4915
    Epoch [4/50], Test Losses: mse: 0.2353, mae: 0.3672, huber: 0.1155, swd: 0.1058, ept: 184.9295
      Epoch 4 composite train-obj: 0.137925
            Val objective improved 0.1716 → 0.1705, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3559, mae: 0.3554, huber: 0.1331, swd: 0.1630, ept: 212.1352
    Epoch [5/50], Val Losses: mse: 0.3771, mae: 0.4427, huber: 0.1748, swd: 0.1656, ept: 150.6944
    Epoch [5/50], Test Losses: mse: 0.2351, mae: 0.3674, huber: 0.1155, swd: 0.1075, ept: 184.0263
      Epoch 5 composite train-obj: 0.133091
            No improvement (0.1748), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3461, mae: 0.3503, huber: 0.1294, swd: 0.1574, ept: 213.9373
    Epoch [6/50], Val Losses: mse: 0.3568, mae: 0.4239, huber: 0.1660, swd: 0.1412, ept: 153.6530
    Epoch [6/50], Test Losses: mse: 0.2430, mae: 0.3716, huber: 0.1191, swd: 0.1104, ept: 185.8554
      Epoch 6 composite train-obj: 0.129433
            Val objective improved 0.1705 → 0.1660, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.3353, mae: 0.3449, huber: 0.1258, swd: 0.1498, ept: 216.2358
    Epoch [7/50], Val Losses: mse: 0.3703, mae: 0.4388, huber: 0.1737, swd: 0.1312, ept: 150.3730
    Epoch [7/50], Test Losses: mse: 0.2489, mae: 0.3733, huber: 0.1210, swd: 0.0972, ept: 189.0213
      Epoch 7 composite train-obj: 0.125792
            No improvement (0.1737), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.3258, mae: 0.3397, huber: 0.1224, swd: 0.1432, ept: 217.8890
    Epoch [8/50], Val Losses: mse: 0.3609, mae: 0.4355, huber: 0.1687, swd: 0.1458, ept: 154.8754
    Epoch [8/50], Test Losses: mse: 0.2654, mae: 0.3880, huber: 0.1302, swd: 0.1249, ept: 176.8216
      Epoch 8 composite train-obj: 0.122428
            No improvement (0.1687), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.3154, mae: 0.3356, huber: 0.1193, swd: 0.1360, ept: 218.9581
    Epoch [9/50], Val Losses: mse: 0.3584, mae: 0.4287, huber: 0.1677, swd: 0.1225, ept: 155.5476
    Epoch [9/50], Test Losses: mse: 0.2479, mae: 0.3742, huber: 0.1208, swd: 0.0986, ept: 188.7930
      Epoch 9 composite train-obj: 0.119259
            No improvement (0.1677), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.3037, mae: 0.3292, huber: 0.1151, swd: 0.1291, ept: 220.5142
    Epoch [10/50], Val Losses: mse: 0.3677, mae: 0.4317, huber: 0.1707, swd: 0.1261, ept: 156.5089
    Epoch [10/50], Test Losses: mse: 0.2526, mae: 0.3773, huber: 0.1235, swd: 0.1025, ept: 182.1175
      Epoch 10 composite train-obj: 0.115124
            No improvement (0.1707), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.2991, mae: 0.3260, huber: 0.1132, swd: 0.1248, ept: 221.2018
    Epoch [11/50], Val Losses: mse: 0.3688, mae: 0.4359, huber: 0.1713, swd: 0.1325, ept: 156.7355
    Epoch [11/50], Test Losses: mse: 0.2672, mae: 0.3914, huber: 0.1310, swd: 0.1185, ept: 176.7470
      Epoch 11 composite train-obj: 0.113231
    Epoch [11/50], Test Losses: mse: 0.2430, mae: 0.3716, huber: 0.1191, swd: 0.1104, ept: 185.8591
    Best round's Test MSE: 0.2430, MAE: 0.3716, SWD: 0.1104
    Best round's Validation MSE: 0.3568, MAE: 0.4239, SWD: 0.1412
    Best round's Test verification MSE : 0.2430, MAE: 0.3716, SWD: 0.1104
    Time taken: 28.17 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5218, mae: 0.4554, huber: 0.1969, swd: 0.3015, ept: 173.6132
    Epoch [1/50], Val Losses: mse: 0.4014, mae: 0.4594, huber: 0.1850, swd: 0.1948, ept: 135.8236
    Epoch [1/50], Test Losses: mse: 0.2157, mae: 0.3354, huber: 0.1047, swd: 0.0905, ept: 185.4038
      Epoch 1 composite train-obj: 0.196875
            Val objective improved inf → 0.1850, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4321, mae: 0.4038, huber: 0.1630, swd: 0.2209, ept: 191.1322
    Epoch [2/50], Val Losses: mse: 0.4090, mae: 0.4657, huber: 0.1879, swd: 0.2165, ept: 127.7911
    Epoch [2/50], Test Losses: mse: 0.2269, mae: 0.3560, huber: 0.1106, swd: 0.1066, ept: 183.0671
      Epoch 2 composite train-obj: 0.163004
            No improvement (0.1879), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3881, mae: 0.3780, huber: 0.1464, swd: 0.1940, ept: 199.6692
    Epoch [3/50], Val Losses: mse: 0.3792, mae: 0.4417, huber: 0.1752, swd: 0.1879, ept: 143.6418
    Epoch [3/50], Test Losses: mse: 0.2306, mae: 0.3588, huber: 0.1126, swd: 0.1189, ept: 182.3601
      Epoch 3 composite train-obj: 0.146431
            Val objective improved 0.1850 → 0.1752, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3647, mae: 0.3615, huber: 0.1369, swd: 0.1767, ept: 209.8657
    Epoch [4/50], Val Losses: mse: 0.3758, mae: 0.4387, huber: 0.1746, swd: 0.1483, ept: 149.6177
    Epoch [4/50], Test Losses: mse: 0.2299, mae: 0.3483, huber: 0.1106, swd: 0.0954, ept: 191.3199
      Epoch 4 composite train-obj: 0.136858
            Val objective improved 0.1752 → 0.1746, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3547, mae: 0.3559, huber: 0.1330, swd: 0.1695, ept: 212.8949
    Epoch [5/50], Val Losses: mse: 0.3654, mae: 0.4316, huber: 0.1694, swd: 0.1644, ept: 148.1567
    Epoch [5/50], Test Losses: mse: 0.2272, mae: 0.3543, huber: 0.1108, swd: 0.1124, ept: 190.6106
      Epoch 5 composite train-obj: 0.133025
            Val objective improved 0.1746 → 0.1694, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.3426, mae: 0.3487, huber: 0.1285, swd: 0.1594, ept: 215.9735
    Epoch [6/50], Val Losses: mse: 0.3562, mae: 0.4243, huber: 0.1658, swd: 0.1429, ept: 151.9461
    Epoch [6/50], Test Losses: mse: 0.2396, mae: 0.3701, huber: 0.1173, swd: 0.1117, ept: 187.1001
      Epoch 6 composite train-obj: 0.128487
            Val objective improved 0.1694 → 0.1658, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.3332, mae: 0.3447, huber: 0.1255, swd: 0.1530, ept: 216.4221
    Epoch [7/50], Val Losses: mse: 0.3662, mae: 0.4308, huber: 0.1706, swd: 0.1353, ept: 152.9393
    Epoch [7/50], Test Losses: mse: 0.2334, mae: 0.3616, huber: 0.1138, swd: 0.0972, ept: 189.3891
      Epoch 7 composite train-obj: 0.125465
            No improvement (0.1706), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.3247, mae: 0.3400, huber: 0.1224, swd: 0.1461, ept: 218.2080
    Epoch [8/50], Val Losses: mse: 0.3791, mae: 0.4367, huber: 0.1750, swd: 0.1373, ept: 150.2398
    Epoch [8/50], Test Losses: mse: 0.2500, mae: 0.3774, huber: 0.1220, swd: 0.1148, ept: 186.6640
      Epoch 8 composite train-obj: 0.122391
            No improvement (0.1750), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.3188, mae: 0.3375, huber: 0.1203, swd: 0.1420, ept: 218.5531
    Epoch [9/50], Val Losses: mse: 0.3896, mae: 0.4427, huber: 0.1789, swd: 0.1451, ept: 149.2096
    Epoch [9/50], Test Losses: mse: 0.2462, mae: 0.3681, huber: 0.1196, swd: 0.1131, ept: 187.8994
      Epoch 9 composite train-obj: 0.120288
            No improvement (0.1789), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.3045, mae: 0.3300, huber: 0.1154, swd: 0.1309, ept: 220.5212
    Epoch [10/50], Val Losses: mse: 0.3699, mae: 0.4331, huber: 0.1714, swd: 0.1306, ept: 154.5510
    Epoch [10/50], Test Losses: mse: 0.2542, mae: 0.3791, huber: 0.1242, swd: 0.1138, ept: 184.5803
      Epoch 10 composite train-obj: 0.115418
            No improvement (0.1714), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.2981, mae: 0.3261, huber: 0.1130, swd: 0.1269, ept: 221.6401
    Epoch [11/50], Val Losses: mse: 0.3728, mae: 0.4316, huber: 0.1723, swd: 0.1240, ept: 155.4295
    Epoch [11/50], Test Losses: mse: 0.2515, mae: 0.3750, huber: 0.1222, swd: 0.1071, ept: 189.8359
      Epoch 11 composite train-obj: 0.112988
    Epoch [11/50], Test Losses: mse: 0.2396, mae: 0.3701, huber: 0.1173, swd: 0.1117, ept: 187.0990
    Best round's Test MSE: 0.2396, MAE: 0.3701, SWD: 0.1117
    Best round's Validation MSE: 0.3562, MAE: 0.4243, SWD: 0.1429
    Best round's Test verification MSE : 0.2396, MAE: 0.3701, SWD: 0.1117
    Time taken: 28.81 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5174, mae: 0.4533, huber: 0.1955, swd: 0.2886, ept: 174.2881
    Epoch [1/50], Val Losses: mse: 0.3990, mae: 0.4601, huber: 0.1852, swd: 0.1742, ept: 136.6873
    Epoch [1/50], Test Losses: mse: 0.2248, mae: 0.3401, huber: 0.1082, swd: 0.0859, ept: 186.9545
      Epoch 1 composite train-obj: 0.195541
            Val objective improved inf → 0.1852, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4289, mae: 0.4047, huber: 0.1628, swd: 0.2154, ept: 190.6571
    Epoch [2/50], Val Losses: mse: 0.3843, mae: 0.4466, huber: 0.1777, swd: 0.1816, ept: 136.9760
    Epoch [2/50], Test Losses: mse: 0.2172, mae: 0.3405, huber: 0.1053, swd: 0.0854, ept: 188.5862
      Epoch 2 composite train-obj: 0.162829
            Val objective improved 0.1852 → 0.1777, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3931, mae: 0.3824, huber: 0.1488, swd: 0.1958, ept: 196.6642
    Epoch [3/50], Val Losses: mse: 0.3795, mae: 0.4408, huber: 0.1765, swd: 0.1412, ept: 144.5171
    Epoch [3/50], Test Losses: mse: 0.2197, mae: 0.3374, huber: 0.1058, swd: 0.0766, ept: 190.1339
      Epoch 3 composite train-obj: 0.148775
            Val objective improved 0.1777 → 0.1765, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3655, mae: 0.3618, huber: 0.1373, swd: 0.1750, ept: 208.5452
    Epoch [4/50], Val Losses: mse: 0.3510, mae: 0.4226, huber: 0.1644, swd: 0.1300, ept: 153.9636
    Epoch [4/50], Test Losses: mse: 0.2187, mae: 0.3473, huber: 0.1066, swd: 0.0815, ept: 193.2291
      Epoch 4 composite train-obj: 0.137281
            Val objective improved 0.1765 → 0.1644, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3567, mae: 0.3556, huber: 0.1334, swd: 0.1696, ept: 211.7568
    Epoch [5/50], Val Losses: mse: 0.3650, mae: 0.4292, huber: 0.1700, swd: 0.1338, ept: 148.5584
    Epoch [5/50], Test Losses: mse: 0.2249, mae: 0.3508, huber: 0.1093, swd: 0.0881, ept: 191.6715
      Epoch 5 composite train-obj: 0.133377
            No improvement (0.1700), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3431, mae: 0.3477, huber: 0.1285, swd: 0.1586, ept: 214.8690
    Epoch [6/50], Val Losses: mse: 0.3661, mae: 0.4318, huber: 0.1706, swd: 0.1331, ept: 152.1416
    Epoch [6/50], Test Losses: mse: 0.2272, mae: 0.3541, huber: 0.1104, swd: 0.0885, ept: 192.1049
      Epoch 6 composite train-obj: 0.128461
            No improvement (0.1706), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.3363, mae: 0.3438, huber: 0.1259, swd: 0.1540, ept: 216.0853
    Epoch [7/50], Val Losses: mse: 0.3710, mae: 0.4356, huber: 0.1729, swd: 0.1318, ept: 152.5234
    Epoch [7/50], Test Losses: mse: 0.2283, mae: 0.3553, huber: 0.1111, swd: 0.0848, ept: 192.1062
      Epoch 7 composite train-obj: 0.125859
            No improvement (0.1729), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.3265, mae: 0.3403, huber: 0.1230, swd: 0.1474, ept: 217.1692
    Epoch [8/50], Val Losses: mse: 0.3705, mae: 0.4328, huber: 0.1728, swd: 0.1238, ept: 154.6868
    Epoch [8/50], Test Losses: mse: 0.2524, mae: 0.3797, huber: 0.1231, swd: 0.0995, ept: 186.6512
      Epoch 8 composite train-obj: 0.122952
            No improvement (0.1728), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.3164, mae: 0.3350, huber: 0.1194, swd: 0.1392, ept: 218.0631
    Epoch [9/50], Val Losses: mse: 0.3875, mae: 0.4385, huber: 0.1781, swd: 0.1332, ept: 152.6041
    Epoch [9/50], Test Losses: mse: 0.2429, mae: 0.3704, huber: 0.1187, swd: 0.0956, ept: 186.6393
      Epoch 9 composite train-obj: 0.119428
    Epoch [9/50], Test Losses: mse: 0.2187, mae: 0.3473, huber: 0.1066, swd: 0.0815, ept: 193.2505
    Best round's Test MSE: 0.2187, MAE: 0.3473, SWD: 0.0815
    Best round's Validation MSE: 0.3510, MAE: 0.4226, SWD: 0.1300
    Best round's Test verification MSE : 0.2187, MAE: 0.3473, SWD: 0.0815
    Time taken: 24.47 seconds
    
    ==================================================
    Experiment Summary (ACL_etth2_seq196_pred336_20250510_2106)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2338 ± 0.0107
      mae: 0.3630 ± 0.0111
      huber: 0.1144 ± 0.0055
      swd: 0.1012 ± 0.0139
      ept: 188.7282 ± 3.2230
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3547 ± 0.0026
      mae: 0.4236 ± 0.0007
      huber: 0.1654 ± 0.0007
      swd: 0.1380 ± 0.0057
      ept: 153.1875 ± 0.8870
      count: 10.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 81.52 seconds
    
    Experiment complete: ACL_etth2_seq196_pred336_20250510_2106
    Model: ACL
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['etth2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth2: tensor([1.0258, 1.0527, 0.8852, 1.0967, 1.0979, 0.8402, 1.0425],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 89
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 89
    Validation Batches: 7
    Test Batches: 21
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6399, mae: 0.5204, huber: 0.2402, swd: 0.3677, ept: 262.1100
    Epoch [1/50], Val Losses: mse: 0.3869, mae: 0.4650, huber: 0.1817, swd: 0.1458, ept: 224.9488
    Epoch [1/50], Test Losses: mse: 0.2538, mae: 0.3618, huber: 0.1215, swd: 0.1126, ept: 299.7869
      Epoch 1 composite train-obj: 0.240226
            Val objective improved inf → 0.1817, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5556, mae: 0.4696, huber: 0.2068, swd: 0.2967, ept: 288.6446
    Epoch [2/50], Val Losses: mse: 0.3886, mae: 0.4609, huber: 0.1820, swd: 0.1557, ept: 219.6383
    Epoch [2/50], Test Losses: mse: 0.2793, mae: 0.3952, huber: 0.1348, swd: 0.1337, ept: 261.3616
      Epoch 2 composite train-obj: 0.206831
            No improvement (0.1820), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.5112, mae: 0.4418, huber: 0.1886, swd: 0.2646, ept: 301.8003
    Epoch [3/50], Val Losses: mse: 0.3583, mae: 0.4324, huber: 0.1682, swd: 0.1096, ept: 237.8529
    Epoch [3/50], Test Losses: mse: 0.3151, mae: 0.4129, huber: 0.1517, swd: 0.1446, ept: 244.6183
      Epoch 3 composite train-obj: 0.188638
            Val objective improved 0.1817 → 0.1682, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4857, mae: 0.4241, huber: 0.1776, swd: 0.2422, ept: 318.5966
    Epoch [4/50], Val Losses: mse: 0.3378, mae: 0.4245, huber: 0.1600, swd: 0.1055, ept: 247.8731
    Epoch [4/50], Test Losses: mse: 0.3060, mae: 0.4102, huber: 0.1484, swd: 0.1413, ept: 251.0547
      Epoch 4 composite train-obj: 0.177632
            Val objective improved 0.1682 → 0.1600, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.4666, mae: 0.4138, huber: 0.1705, swd: 0.2290, ept: 324.3819
    Epoch [5/50], Val Losses: mse: 0.3427, mae: 0.4243, huber: 0.1617, swd: 0.0982, ept: 254.9382
    Epoch [5/50], Test Losses: mse: 0.3140, mae: 0.4171, huber: 0.1513, swd: 0.1545, ept: 254.8105
      Epoch 5 composite train-obj: 0.170491
            No improvement (0.1617), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.4521, mae: 0.4065, huber: 0.1652, swd: 0.2192, ept: 328.2209
    Epoch [6/50], Val Losses: mse: 0.3863, mae: 0.4471, huber: 0.1799, swd: 0.1050, ept: 263.5710
    Epoch [6/50], Test Losses: mse: 0.2939, mae: 0.4070, huber: 0.1414, swd: 0.1149, ept: 274.5685
      Epoch 6 composite train-obj: 0.165237
            No improvement (0.1799), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.4349, mae: 0.3993, huber: 0.1595, swd: 0.2065, ept: 330.3078
    Epoch [7/50], Val Losses: mse: 0.3962, mae: 0.4559, huber: 0.1845, swd: 0.1190, ept: 258.3217
    Epoch [7/50], Test Losses: mse: 0.2886, mae: 0.4077, huber: 0.1401, swd: 0.1227, ept: 266.5220
      Epoch 7 composite train-obj: 0.159494
            No improvement (0.1845), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.4230, mae: 0.3916, huber: 0.1546, swd: 0.1977, ept: 333.5626
    Epoch [8/50], Val Losses: mse: 0.4118, mae: 0.4799, huber: 0.1925, swd: 0.1376, ept: 241.5171
    Epoch [8/50], Test Losses: mse: 0.3325, mae: 0.4385, huber: 0.1595, swd: 0.1576, ept: 255.3969
      Epoch 8 composite train-obj: 0.154596
            No improvement (0.1925), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.4062, mae: 0.3843, huber: 0.1492, swd: 0.1842, ept: 336.2213
    Epoch [9/50], Val Losses: mse: 0.3901, mae: 0.4481, huber: 0.1817, swd: 0.1062, ept: 262.3630
    Epoch [9/50], Test Losses: mse: 0.3018, mae: 0.4214, huber: 0.1464, swd: 0.1315, ept: 254.4625
      Epoch 9 composite train-obj: 0.149213
    Epoch [9/50], Test Losses: mse: 0.3060, mae: 0.4102, huber: 0.1484, swd: 0.1413, ept: 251.0223
    Best round's Test MSE: 0.3060, MAE: 0.4102, SWD: 0.1413
    Best round's Validation MSE: 0.3378, MAE: 0.4245, SWD: 0.1055
    Best round's Test verification MSE : 0.3060, MAE: 0.4102, SWD: 0.1413
    Time taken: 22.63 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6387, mae: 0.5201, huber: 0.2401, swd: 0.3588, ept: 262.9731
    Epoch [1/50], Val Losses: mse: 0.3875, mae: 0.4665, huber: 0.1820, swd: 0.1361, ept: 224.0489
    Epoch [1/50], Test Losses: mse: 0.2536, mae: 0.3626, huber: 0.1214, swd: 0.1036, ept: 302.2511
      Epoch 1 composite train-obj: 0.240085
            Val objective improved inf → 0.1820, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5478, mae: 0.4656, huber: 0.2041, swd: 0.2849, ept: 291.9204
    Epoch [2/50], Val Losses: mse: 0.4878, mae: 0.5252, huber: 0.2239, swd: 0.1692, ept: 221.3519
    Epoch [2/50], Test Losses: mse: 0.3107, mae: 0.4034, huber: 0.1455, swd: 0.1101, ept: 267.7660
      Epoch 2 composite train-obj: 0.204072
            No improvement (0.2239), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.5112, mae: 0.4407, huber: 0.1882, swd: 0.2569, ept: 305.7937
    Epoch [3/50], Val Losses: mse: 0.3580, mae: 0.4340, huber: 0.1683, swd: 0.1215, ept: 239.4721
    Epoch [3/50], Test Losses: mse: 0.3176, mae: 0.4194, huber: 0.1538, swd: 0.1644, ept: 229.3291
      Epoch 3 composite train-obj: 0.188193
            Val objective improved 0.1820 → 0.1683, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4846, mae: 0.4236, huber: 0.1772, swd: 0.2383, ept: 318.6288
    Epoch [4/50], Val Losses: mse: 0.3555, mae: 0.4320, huber: 0.1674, swd: 0.1062, ept: 254.8721
    Epoch [4/50], Test Losses: mse: 0.2980, mae: 0.4078, huber: 0.1447, swd: 0.1347, ept: 259.7016
      Epoch 4 composite train-obj: 0.177233
            Val objective improved 0.1683 → 0.1674, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.4646, mae: 0.4123, huber: 0.1698, swd: 0.2245, ept: 325.6291
    Epoch [5/50], Val Losses: mse: 0.3536, mae: 0.4254, huber: 0.1665, swd: 0.0952, ept: 267.5812
    Epoch [5/50], Test Losses: mse: 0.2972, mae: 0.4118, huber: 0.1447, swd: 0.1233, ept: 262.9885
      Epoch 5 composite train-obj: 0.169792
            Val objective improved 0.1674 → 0.1665, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.4501, mae: 0.4064, huber: 0.1650, swd: 0.2162, ept: 326.2382
    Epoch [6/50], Val Losses: mse: 0.3896, mae: 0.4519, huber: 0.1817, swd: 0.0963, ept: 276.1908
    Epoch [6/50], Test Losses: mse: 0.3148, mae: 0.4231, huber: 0.1520, swd: 0.1158, ept: 267.5525
      Epoch 6 composite train-obj: 0.164995
            No improvement (0.1817), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.4331, mae: 0.3986, huber: 0.1591, swd: 0.2028, ept: 327.0544
    Epoch [7/50], Val Losses: mse: 0.3958, mae: 0.4492, huber: 0.1838, swd: 0.0968, ept: 254.3749
    Epoch [7/50], Test Losses: mse: 0.3086, mae: 0.4194, huber: 0.1486, swd: 0.1267, ept: 257.0393
      Epoch 7 composite train-obj: 0.159094
            No improvement (0.1838), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.4163, mae: 0.3904, huber: 0.1532, swd: 0.1897, ept: 331.2941
    Epoch [8/50], Val Losses: mse: 0.3629, mae: 0.4401, huber: 0.1707, swd: 0.0962, ept: 258.0776
    Epoch [8/50], Test Losses: mse: 0.3117, mae: 0.4228, huber: 0.1514, swd: 0.1400, ept: 245.9139
      Epoch 8 composite train-obj: 0.153245
            No improvement (0.1707), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.4028, mae: 0.3812, huber: 0.1477, swd: 0.1798, ept: 334.2339
    Epoch [9/50], Val Losses: mse: 0.3979, mae: 0.4537, huber: 0.1850, swd: 0.0891, ept: 281.4791
    Epoch [9/50], Test Losses: mse: 0.3007, mae: 0.4138, huber: 0.1453, swd: 0.1102, ept: 262.1346
      Epoch 9 composite train-obj: 0.147681
            No improvement (0.1850), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.3958, mae: 0.3787, huber: 0.1454, swd: 0.1750, ept: 335.0003
    Epoch [10/50], Val Losses: mse: 0.3790, mae: 0.4514, huber: 0.1771, swd: 0.0921, ept: 261.8178
    Epoch [10/50], Test Losses: mse: 0.3079, mae: 0.4185, huber: 0.1491, swd: 0.1232, ept: 256.4671
      Epoch 10 composite train-obj: 0.145385
    Epoch [10/50], Test Losses: mse: 0.2973, mae: 0.4118, huber: 0.1447, swd: 0.1233, ept: 262.8987
    Best round's Test MSE: 0.2972, MAE: 0.4118, SWD: 0.1233
    Best round's Validation MSE: 0.3536, MAE: 0.4254, SWD: 0.0952
    Best round's Test verification MSE : 0.2973, MAE: 0.4118, SWD: 0.1233
    Time taken: 25.09 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6345, mae: 0.5183, huber: 0.2388, swd: 0.3795, ept: 261.2299
    Epoch [1/50], Val Losses: mse: 0.3867, mae: 0.4701, huber: 0.1818, swd: 0.1628, ept: 219.2144
    Epoch [1/50], Test Losses: mse: 0.2555, mae: 0.3668, huber: 0.1225, swd: 0.1236, ept: 296.7267
      Epoch 1 composite train-obj: 0.238839
            Val objective improved inf → 0.1818, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5507, mae: 0.4678, huber: 0.2053, swd: 0.3056, ept: 290.6606
    Epoch [2/50], Val Losses: mse: 0.3722, mae: 0.4514, huber: 0.1754, swd: 0.1390, ept: 222.6841
    Epoch [2/50], Test Losses: mse: 0.2826, mae: 0.3984, huber: 0.1367, swd: 0.1428, ept: 254.6206
      Epoch 2 composite train-obj: 0.205269
            Val objective improved 0.1818 → 0.1754, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.5106, mae: 0.4424, huber: 0.1885, swd: 0.2780, ept: 302.0352
    Epoch [3/50], Val Losses: mse: 0.3538, mae: 0.4291, huber: 0.1670, swd: 0.1075, ept: 254.0193
    Epoch [3/50], Test Losses: mse: 0.2789, mae: 0.3928, huber: 0.1349, swd: 0.1169, ept: 271.5690
      Epoch 3 composite train-obj: 0.188488
            Val objective improved 0.1754 → 0.1670, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4833, mae: 0.4227, huber: 0.1767, swd: 0.2529, ept: 318.7779
    Epoch [4/50], Val Losses: mse: 0.3489, mae: 0.4231, huber: 0.1643, swd: 0.1048, ept: 259.8891
    Epoch [4/50], Test Losses: mse: 0.2916, mae: 0.4016, huber: 0.1411, swd: 0.1328, ept: 262.3877
      Epoch 4 composite train-obj: 0.176697
            Val objective improved 0.1670 → 0.1643, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.4679, mae: 0.4137, huber: 0.1705, swd: 0.2414, ept: 323.3904
    Epoch [5/50], Val Losses: mse: 0.3488, mae: 0.4264, huber: 0.1644, swd: 0.0965, ept: 263.1320
    Epoch [5/50], Test Losses: mse: 0.2934, mae: 0.4048, huber: 0.1411, swd: 0.1366, ept: 258.0479
      Epoch 5 composite train-obj: 0.170520
            No improvement (0.1644), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.4509, mae: 0.4061, huber: 0.1649, swd: 0.2282, ept: 326.9279
    Epoch [6/50], Val Losses: mse: 0.3552, mae: 0.4348, huber: 0.1673, swd: 0.1098, ept: 265.4209
    Epoch [6/50], Test Losses: mse: 0.2959, mae: 0.4097, huber: 0.1438, swd: 0.1328, ept: 262.9369
      Epoch 6 composite train-obj: 0.164858
            No improvement (0.1673), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.4402, mae: 0.3990, huber: 0.1602, swd: 0.2200, ept: 330.4729
    Epoch [7/50], Val Losses: mse: 0.3474, mae: 0.4275, huber: 0.1638, swd: 0.0945, ept: 265.8842
    Epoch [7/50], Test Losses: mse: 0.3269, mae: 0.4286, huber: 0.1579, swd: 0.1542, ept: 256.1121
      Epoch 7 composite train-obj: 0.160183
            Val objective improved 0.1643 → 0.1638, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.4251, mae: 0.3922, huber: 0.1552, swd: 0.2107, ept: 333.1152
    Epoch [8/50], Val Losses: mse: 0.3799, mae: 0.4497, huber: 0.1780, swd: 0.0909, ept: 272.9202
    Epoch [8/50], Test Losses: mse: 0.3100, mae: 0.4240, huber: 0.1498, swd: 0.1232, ept: 278.1383
      Epoch 8 composite train-obj: 0.155223
            No improvement (0.1780), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.4071, mae: 0.3842, huber: 0.1495, swd: 0.1975, ept: 334.9324
    Epoch [9/50], Val Losses: mse: 0.3612, mae: 0.4347, huber: 0.1701, swd: 0.0938, ept: 271.0112
    Epoch [9/50], Test Losses: mse: 0.2718, mae: 0.3931, huber: 0.1318, swd: 0.1087, ept: 296.0404
      Epoch 9 composite train-obj: 0.149462
            No improvement (0.1701), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.3956, mae: 0.3771, huber: 0.1449, swd: 0.1873, ept: 338.5431
    Epoch [10/50], Val Losses: mse: 0.3853, mae: 0.4466, huber: 0.1795, swd: 0.1081, ept: 262.9951
    Epoch [10/50], Test Losses: mse: 0.3064, mae: 0.4152, huber: 0.1478, swd: 0.1397, ept: 262.7358
      Epoch 10 composite train-obj: 0.144890
            No improvement (0.1795), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.3818, mae: 0.3705, huber: 0.1402, swd: 0.1777, ept: 339.0445
    Epoch [11/50], Val Losses: mse: 0.3800, mae: 0.4481, huber: 0.1782, swd: 0.0840, ept: 270.4474
    Epoch [11/50], Test Losses: mse: 0.2974, mae: 0.4084, huber: 0.1432, swd: 0.1148, ept: 288.9617
      Epoch 11 composite train-obj: 0.140200
            No improvement (0.1782), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.3792, mae: 0.3669, huber: 0.1384, swd: 0.1743, ept: 340.1186
    Epoch [12/50], Val Losses: mse: 0.3683, mae: 0.4415, huber: 0.1727, swd: 0.0901, ept: 270.1105
    Epoch [12/50], Test Losses: mse: 0.3077, mae: 0.4173, huber: 0.1490, swd: 0.1332, ept: 262.1241
      Epoch 12 composite train-obj: 0.138373
    Epoch [12/50], Test Losses: mse: 0.3269, mae: 0.4287, huber: 0.1579, swd: 0.1542, ept: 256.0948
    Best round's Test MSE: 0.3269, MAE: 0.4286, SWD: 0.1542
    Best round's Validation MSE: 0.3474, MAE: 0.4275, SWD: 0.0945
    Best round's Test verification MSE : 0.3269, MAE: 0.4287, SWD: 0.1542
    Time taken: 29.65 seconds
    
    ==================================================
    Experiment Summary (ACL_etth2_seq196_pred720_20250510_2107)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.3100 ± 0.0124
      mae: 0.4169 ± 0.0083
      huber: 0.1503 ± 0.0056
      swd: 0.1396 ± 0.0127
      ept: 256.7184 ± 4.8908
      count: 7.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3462 ± 0.0065
      mae: 0.4258 ± 0.0013
      huber: 0.1634 ± 0.0026
      swd: 0.0984 ± 0.0050
      ept: 260.4462 ± 8.9175
      count: 7.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 77.45 seconds
    
    Experiment complete: ACL_etth2_seq196_pred720_20250510_2107
    Model: ACL
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### Timemixer

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 12
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3179, mae: 0.3296, huber: 0.1211, swd: 0.1218, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2703, mae: 0.3523, huber: 0.1277, swd: 0.1122, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1514, mae: 0.2729, huber: 0.0742, swd: 0.0506, target_std: 0.7274
      Epoch 1 composite train-obj: 0.121065
            Val objective improved inf → 0.1277, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2778, mae: 0.3039, huber: 0.1061, swd: 0.1085, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2703, mae: 0.3530, huber: 0.1275, swd: 0.1146, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1468, mae: 0.2690, huber: 0.0722, swd: 0.0505, target_std: 0.7274
      Epoch 2 composite train-obj: 0.106110
            Val objective improved 0.1277 → 0.1275, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2628, mae: 0.2967, huber: 0.1013, swd: 0.1055, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2729, mae: 0.3551, huber: 0.1284, swd: 0.1157, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1501, mae: 0.2728, huber: 0.0738, swd: 0.0523, target_std: 0.7274
      Epoch 3 composite train-obj: 0.101284
            No improvement (0.1284), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2512, mae: 0.2922, huber: 0.0978, swd: 0.1015, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2744, mae: 0.3549, huber: 0.1285, swd: 0.1174, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1512, mae: 0.2733, huber: 0.0743, swd: 0.0526, target_std: 0.7274
      Epoch 4 composite train-obj: 0.097792
            No improvement (0.1285), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2389, mae: 0.2873, huber: 0.0942, swd: 0.0981, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2733, mae: 0.3551, huber: 0.1281, swd: 0.1153, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1551, mae: 0.2777, huber: 0.0762, swd: 0.0540, target_std: 0.7274
      Epoch 5 composite train-obj: 0.094192
            No improvement (0.1281), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2268, mae: 0.2826, huber: 0.0907, swd: 0.0939, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2897, mae: 0.3640, huber: 0.1341, swd: 0.1246, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1551, mae: 0.2755, huber: 0.0759, swd: 0.0533, target_std: 0.7274
      Epoch 6 composite train-obj: 0.090693
            No improvement (0.1341), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2154, mae: 0.2774, huber: 0.0872, swd: 0.0895, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2954, mae: 0.3664, huber: 0.1358, swd: 0.1244, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1581, mae: 0.2776, huber: 0.0770, swd: 0.0537, target_std: 0.7274
      Epoch 7 composite train-obj: 0.087168
    Epoch [7/50], Test Losses: mse: 0.1468, mae: 0.2690, huber: 0.0722, swd: 0.0505, target_std: 0.7274
    Best round's Test MSE: 0.1468, MAE: 0.2690, SWD: 0.0505
    Best round's Validation MSE: 0.2703, MAE: 0.3530
    Best round's Test verification MSE : 0.1468, MAE: 0.2690, SWD: 0.0505
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3162, mae: 0.3274, huber: 0.1201, swd: 0.1204, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2647, mae: 0.3510, huber: 0.1255, swd: 0.1090, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1481, mae: 0.2696, huber: 0.0727, swd: 0.0495, target_std: 0.7274
      Epoch 1 composite train-obj: 0.120080
            Val objective improved inf → 0.1255, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2803, mae: 0.3046, huber: 0.1067, swd: 0.1104, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2674, mae: 0.3521, huber: 0.1261, swd: 0.1148, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1463, mae: 0.2682, huber: 0.0720, swd: 0.0514, target_std: 0.7274
      Epoch 2 composite train-obj: 0.106650
            No improvement (0.1261), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2668, mae: 0.2981, huber: 0.1022, swd: 0.1055, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2782, mae: 0.3569, huber: 0.1303, swd: 0.1166, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1484, mae: 0.2709, huber: 0.0730, swd: 0.0491, target_std: 0.7274
      Epoch 3 composite train-obj: 0.102177
            No improvement (0.1303), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2571, mae: 0.2942, huber: 0.0992, swd: 0.1029, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2783, mae: 0.3585, huber: 0.1303, swd: 0.1159, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1515, mae: 0.2754, huber: 0.0746, swd: 0.0493, target_std: 0.7274
      Epoch 4 composite train-obj: 0.099175
            No improvement (0.1303), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2431, mae: 0.2887, huber: 0.0950, swd: 0.0980, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2813, mae: 0.3568, huber: 0.1305, swd: 0.1203, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1513, mae: 0.2716, huber: 0.0740, swd: 0.0500, target_std: 0.7274
      Epoch 5 composite train-obj: 0.095046
            No improvement (0.1305), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.2303, mae: 0.2835, huber: 0.0912, swd: 0.0939, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2989, mae: 0.3666, huber: 0.1365, swd: 0.1241, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1575, mae: 0.2786, huber: 0.0768, swd: 0.0500, target_std: 0.7274
      Epoch 6 composite train-obj: 0.091181
    Epoch [6/50], Test Losses: mse: 0.1481, mae: 0.2696, huber: 0.0727, swd: 0.0495, target_std: 0.7274
    Best round's Test MSE: 0.1481, MAE: 0.2696, SWD: 0.0495
    Best round's Validation MSE: 0.2647, MAE: 0.3510
    Best round's Test verification MSE : 0.1481, MAE: 0.2696, SWD: 0.0495
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3323, mae: 0.3360, huber: 0.1254, swd: 0.1145, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2703, mae: 0.3554, huber: 0.1278, swd: 0.1032, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1491, mae: 0.2715, huber: 0.0732, swd: 0.0463, target_std: 0.7274
      Epoch 1 composite train-obj: 0.125381
            Val objective improved inf → 0.1278, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2801, mae: 0.3051, huber: 0.1069, swd: 0.1008, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2690, mae: 0.3542, huber: 0.1270, swd: 0.1036, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1481, mae: 0.2709, huber: 0.0728, swd: 0.0466, target_std: 0.7274
      Epoch 2 composite train-obj: 0.106851
            Val objective improved 0.1278 → 0.1270, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2666, mae: 0.2990, huber: 0.1026, swd: 0.0985, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2764, mae: 0.3579, huber: 0.1299, swd: 0.1070, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1504, mae: 0.2731, huber: 0.0741, swd: 0.0476, target_std: 0.7274
      Epoch 3 composite train-obj: 0.102622
            No improvement (0.1299), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2565, mae: 0.2942, huber: 0.0993, swd: 0.0959, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2701, mae: 0.3541, huber: 0.1270, swd: 0.1042, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1536, mae: 0.2760, huber: 0.0756, swd: 0.0494, target_std: 0.7274
      Epoch 4 composite train-obj: 0.099267
            No improvement (0.1270), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2446, mae: 0.2897, huber: 0.0957, swd: 0.0918, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2727, mae: 0.3534, huber: 0.1276, swd: 0.1055, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1531, mae: 0.2729, huber: 0.0751, swd: 0.0495, target_std: 0.7274
      Epoch 5 composite train-obj: 0.095718
            No improvement (0.1276), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2350, mae: 0.2856, huber: 0.0928, swd: 0.0892, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2740, mae: 0.3551, huber: 0.1282, swd: 0.1080, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1584, mae: 0.2768, huber: 0.0776, swd: 0.0532, target_std: 0.7274
      Epoch 6 composite train-obj: 0.092838
            No improvement (0.1282), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2211, mae: 0.2797, huber: 0.0886, swd: 0.0849, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2872, mae: 0.3643, huber: 0.1335, swd: 0.1086, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1634, mae: 0.2819, huber: 0.0797, swd: 0.0522, target_std: 0.7274
      Epoch 7 composite train-obj: 0.088627
    Epoch [7/50], Test Losses: mse: 0.1481, mae: 0.2709, huber: 0.0728, swd: 0.0466, target_std: 0.7274
    Best round's Test MSE: 0.1481, MAE: 0.2709, SWD: 0.0466
    Best round's Validation MSE: 0.2690, MAE: 0.3542
    Best round's Test verification MSE : 0.1481, MAE: 0.2709, SWD: 0.0466
    
    ==================================================
    Experiment Summary (TimeMixer_etth2_seq196_pred96_20250502_1200)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1477 ± 0.0006
      mae: 0.2698 ± 0.0008
      huber: 0.0725 ± 0.0003
      swd: 0.0488 ± 0.0016
      target_std: 0.7274 ± 0.0000
      count: 12.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2680 ± 0.0024
      mae: 0.3527 ± 0.0013
      huber: 0.1267 ± 0.0009
      swd: 0.1091 ± 0.0045
      target_std: 0.9930 ± 0.0000
      count: 12.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_etth2_seq196_pred96_20250502_1200
    Model: TimeMixer
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 11
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4090, mae: 0.3736, huber: 0.1505, swd: 0.1626, target_std: 0.7928
    Epoch [1/50], Val Losses: mse: 0.3420, mae: 0.4072, huber: 0.1597, swd: 0.1376, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1759, mae: 0.2955, huber: 0.0862, swd: 0.0602, target_std: 0.7295
      Epoch 1 composite train-obj: 0.150539
            Val objective improved inf → 0.1597, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3597, mae: 0.3475, huber: 0.1337, swd: 0.1487, target_std: 0.7927
    Epoch [2/50], Val Losses: mse: 0.3493, mae: 0.4111, huber: 0.1623, swd: 0.1477, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1729, mae: 0.2912, huber: 0.0847, swd: 0.0617, target_std: 0.7295
      Epoch 2 composite train-obj: 0.133665
            No improvement (0.1623), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3391, mae: 0.3389, huber: 0.1270, swd: 0.1427, target_std: 0.7932
    Epoch [3/50], Val Losses: mse: 0.3451, mae: 0.4114, huber: 0.1609, swd: 0.1431, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1797, mae: 0.2974, huber: 0.0879, swd: 0.0645, target_std: 0.7295
      Epoch 3 composite train-obj: 0.127022
            No improvement (0.1609), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.3212, mae: 0.3314, huber: 0.1212, swd: 0.1393, target_std: 0.7933
    Epoch [4/50], Val Losses: mse: 0.3423, mae: 0.4074, huber: 0.1588, swd: 0.1431, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1836, mae: 0.2998, huber: 0.0896, swd: 0.0683, target_std: 0.7295
      Epoch 4 composite train-obj: 0.121175
            Val objective improved 0.1597 → 0.1588, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3064, mae: 0.3243, huber: 0.1160, swd: 0.1353, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3488, mae: 0.4133, huber: 0.1620, swd: 0.1430, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1872, mae: 0.3033, huber: 0.0912, swd: 0.0669, target_std: 0.7295
      Epoch 5 composite train-obj: 0.116022
            No improvement (0.1620), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2969, mae: 0.3194, huber: 0.1128, swd: 0.1316, target_std: 0.7918
    Epoch [6/50], Val Losses: mse: 0.3618, mae: 0.4167, huber: 0.1658, swd: 0.1551, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1857, mae: 0.2992, huber: 0.0899, swd: 0.0692, target_std: 0.7295
      Epoch 6 composite train-obj: 0.112787
            No improvement (0.1658), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.2906, mae: 0.3168, huber: 0.1109, swd: 0.1291, target_std: 0.7924
    Epoch [7/50], Val Losses: mse: 0.3549, mae: 0.4131, huber: 0.1633, swd: 0.1527, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1880, mae: 0.3019, huber: 0.0910, swd: 0.0697, target_std: 0.7295
      Epoch 7 composite train-obj: 0.110875
            No improvement (0.1633), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.2822, mae: 0.3119, huber: 0.1079, swd: 0.1259, target_std: 0.7930
    Epoch [8/50], Val Losses: mse: 0.3565, mae: 0.4194, huber: 0.1648, swd: 0.1444, target_std: 0.9936
    Epoch [8/50], Test Losses: mse: 0.2002, mae: 0.3165, huber: 0.0975, swd: 0.0724, target_std: 0.7295
      Epoch 8 composite train-obj: 0.107908
            No improvement (0.1648), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.2726, mae: 0.3076, huber: 0.1048, swd: 0.1218, target_std: 0.7925
    Epoch [9/50], Val Losses: mse: 0.3796, mae: 0.4276, huber: 0.1730, swd: 0.1626, target_std: 0.9936
    Epoch [9/50], Test Losses: mse: 0.1979, mae: 0.3113, huber: 0.0957, swd: 0.0755, target_std: 0.7295
      Epoch 9 composite train-obj: 0.104761
    Epoch [9/50], Test Losses: mse: 0.1836, mae: 0.2998, huber: 0.0896, swd: 0.0683, target_std: 0.7295
    Best round's Test MSE: 0.1836, MAE: 0.2998, SWD: 0.0683
    Best round's Validation MSE: 0.3423, MAE: 0.4074
    Best round's Test verification MSE : 0.1836, MAE: 0.2998, SWD: 0.0683
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4042, mae: 0.3712, huber: 0.1492, swd: 0.1642, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3408, mae: 0.4074, huber: 0.1591, swd: 0.1397, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1748, mae: 0.2942, huber: 0.0856, swd: 0.0632, target_std: 0.7295
      Epoch 1 composite train-obj: 0.149194
            Val objective improved inf → 0.1591, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3616, mae: 0.3478, huber: 0.1342, swd: 0.1507, target_std: 0.7930
    Epoch [2/50], Val Losses: mse: 0.3428, mae: 0.4072, huber: 0.1593, swd: 0.1499, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1725, mae: 0.2912, huber: 0.0845, swd: 0.0640, target_std: 0.7295
      Epoch 2 composite train-obj: 0.134195
            No improvement (0.1593), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3435, mae: 0.3400, huber: 0.1285, swd: 0.1465, target_std: 0.7913
    Epoch [3/50], Val Losses: mse: 0.3614, mae: 0.4193, huber: 0.1670, swd: 0.1580, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1766, mae: 0.2954, huber: 0.0865, swd: 0.0663, target_std: 0.7295
      Epoch 3 composite train-obj: 0.128480
            No improvement (0.1670), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.3287, mae: 0.3340, huber: 0.1237, swd: 0.1422, target_std: 0.7919
    Epoch [4/50], Val Losses: mse: 0.3520, mae: 0.4142, huber: 0.1628, swd: 0.1566, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1750, mae: 0.2930, huber: 0.0858, swd: 0.0665, target_std: 0.7295
      Epoch 4 composite train-obj: 0.123740
            No improvement (0.1628), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.3161, mae: 0.3276, huber: 0.1193, swd: 0.1384, target_std: 0.7924
    Epoch [5/50], Val Losses: mse: 0.3553, mae: 0.4161, huber: 0.1645, swd: 0.1580, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1811, mae: 0.2978, huber: 0.0885, swd: 0.0687, target_std: 0.7295
      Epoch 5 composite train-obj: 0.119271
            No improvement (0.1645), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.3032, mae: 0.3217, huber: 0.1151, swd: 0.1353, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3513, mae: 0.4135, huber: 0.1625, swd: 0.1538, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1828, mae: 0.2997, huber: 0.0892, swd: 0.0682, target_std: 0.7295
      Epoch 6 composite train-obj: 0.115080
    Epoch [6/50], Test Losses: mse: 0.1748, mae: 0.2942, huber: 0.0856, swd: 0.0632, target_std: 0.7295
    Best round's Test MSE: 0.1748, MAE: 0.2942, SWD: 0.0632
    Best round's Validation MSE: 0.3408, MAE: 0.4074
    Best round's Test verification MSE : 0.1748, MAE: 0.2942, SWD: 0.0632
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4218, mae: 0.3802, huber: 0.1548, swd: 0.1487, target_std: 0.7929
    Epoch [1/50], Val Losses: mse: 0.3412, mae: 0.4099, huber: 0.1596, swd: 0.1259, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1783, mae: 0.2971, huber: 0.0873, swd: 0.0554, target_std: 0.7295
      Epoch 1 composite train-obj: 0.154758
            Val objective improved inf → 0.1596, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3624, mae: 0.3494, huber: 0.1348, swd: 0.1379, target_std: 0.7934
    Epoch [2/50], Val Losses: mse: 0.3490, mae: 0.4103, huber: 0.1615, swd: 0.1398, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1726, mae: 0.2900, huber: 0.0845, swd: 0.0587, target_std: 0.7295
      Epoch 2 composite train-obj: 0.134840
            No improvement (0.1615), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3425, mae: 0.3405, huber: 0.1284, swd: 0.1342, target_std: 0.7926
    Epoch [3/50], Val Losses: mse: 0.3532, mae: 0.4138, huber: 0.1636, swd: 0.1378, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1771, mae: 0.2941, huber: 0.0867, swd: 0.0593, target_std: 0.7295
      Epoch 3 composite train-obj: 0.128415
            No improvement (0.1636), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.3252, mae: 0.3334, huber: 0.1228, swd: 0.1298, target_std: 0.7923
    Epoch [4/50], Val Losses: mse: 0.3590, mae: 0.4156, huber: 0.1655, swd: 0.1371, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1827, mae: 0.2971, huber: 0.0889, swd: 0.0612, target_std: 0.7295
      Epoch 4 composite train-obj: 0.122752
            No improvement (0.1655), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.3105, mae: 0.3265, huber: 0.1177, swd: 0.1256, target_std: 0.7913
    Epoch [5/50], Val Losses: mse: 0.3570, mae: 0.4135, huber: 0.1640, swd: 0.1385, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1866, mae: 0.2993, huber: 0.0903, swd: 0.0628, target_std: 0.7295
      Epoch 5 composite train-obj: 0.117692
            No improvement (0.1640), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.3004, mae: 0.3216, huber: 0.1142, swd: 0.1225, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3550, mae: 0.4109, huber: 0.1630, swd: 0.1365, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1896, mae: 0.3007, huber: 0.0912, swd: 0.0643, target_std: 0.7295
      Epoch 6 composite train-obj: 0.114204
    Epoch [6/50], Test Losses: mse: 0.1783, mae: 0.2971, huber: 0.0873, swd: 0.0554, target_std: 0.7295
    Best round's Test MSE: 0.1783, MAE: 0.2971, SWD: 0.0554
    Best round's Validation MSE: 0.3412, MAE: 0.4099
    Best round's Test verification MSE : 0.1783, MAE: 0.2971, SWD: 0.0554
    
    ==================================================
    Experiment Summary (TimeMixer_etth2_seq196_pred196_20250502_1201)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1789 ± 0.0036
      mae: 0.2970 ± 0.0023
      huber: 0.0875 ± 0.0016
      swd: 0.0623 ± 0.0053
      target_std: 0.7295 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3414 ± 0.0006
      mae: 0.4083 ± 0.0012
      huber: 0.1592 ± 0.0003
      swd: 0.1362 ± 0.0075
      target_std: 0.9936 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_etth2_seq196_pred196_20250502_1201
    Model: TimeMixer
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4995, mae: 0.4188, huber: 0.1805, swd: 0.1904, target_std: 0.7940
    Epoch [1/50], Val Losses: mse: 0.3733, mae: 0.4342, huber: 0.1737, swd: 0.1361, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.1989, mae: 0.3157, huber: 0.0969, swd: 0.0649, target_std: 0.7299
      Epoch 1 composite train-obj: 0.180520
            Val objective improved inf → 0.1737, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4512, mae: 0.3916, huber: 0.1629, swd: 0.1797, target_std: 0.7924
    Epoch [2/50], Val Losses: mse: 0.3641, mae: 0.4272, huber: 0.1695, swd: 0.1359, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1970, mae: 0.3138, huber: 0.0962, swd: 0.0664, target_std: 0.7299
      Epoch 2 composite train-obj: 0.162936
            Val objective improved 0.1737 → 0.1695, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4265, mae: 0.3811, huber: 0.1548, swd: 0.1750, target_std: 0.7934
    Epoch [3/50], Val Losses: mse: 0.3727, mae: 0.4334, huber: 0.1733, swd: 0.1342, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2035, mae: 0.3202, huber: 0.0994, swd: 0.0673, target_std: 0.7299
      Epoch 3 composite train-obj: 0.154835
            No improvement (0.1733), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.4037, mae: 0.3716, huber: 0.1474, swd: 0.1699, target_std: 0.7973
    Epoch [4/50], Val Losses: mse: 0.3818, mae: 0.4359, huber: 0.1758, swd: 0.1441, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.1960, mae: 0.3107, huber: 0.0954, swd: 0.0657, target_std: 0.7299
      Epoch 4 composite train-obj: 0.147389
            No improvement (0.1758), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.3873, mae: 0.3637, huber: 0.1418, swd: 0.1658, target_std: 0.7954
    Epoch [5/50], Val Losses: mse: 0.3707, mae: 0.4305, huber: 0.1718, swd: 0.1302, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2064, mae: 0.3213, huber: 0.1006, swd: 0.0694, target_std: 0.7299
      Epoch 5 composite train-obj: 0.141806
            No improvement (0.1718), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.3793, mae: 0.3586, huber: 0.1385, swd: 0.1649, target_std: 0.7943
    Epoch [6/50], Val Losses: mse: 0.3773, mae: 0.4344, huber: 0.1743, swd: 0.1343, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2111, mae: 0.3242, huber: 0.1025, swd: 0.0698, target_std: 0.7299
      Epoch 6 composite train-obj: 0.138530
            No improvement (0.1743), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.3644, mae: 0.3515, huber: 0.1337, swd: 0.1585, target_std: 0.7935
    Epoch [7/50], Val Losses: mse: 0.3773, mae: 0.4344, huber: 0.1742, swd: 0.1318, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.2106, mae: 0.3238, huber: 0.1021, swd: 0.0697, target_std: 0.7299
      Epoch 7 composite train-obj: 0.133704
    Epoch [7/50], Test Losses: mse: 0.1970, mae: 0.3138, huber: 0.0962, swd: 0.0664, target_std: 0.7299
    Best round's Test MSE: 0.1970, MAE: 0.3138, SWD: 0.0664
    Best round's Validation MSE: 0.3641, MAE: 0.4272
    Best round's Test verification MSE : 0.1970, MAE: 0.3138, SWD: 0.0664
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5009, mae: 0.4191, huber: 0.1809, swd: 0.2041, target_std: 0.7928
    Epoch [1/50], Val Losses: mse: 0.3736, mae: 0.4318, huber: 0.1733, swd: 0.1453, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.1959, mae: 0.3133, huber: 0.0957, swd: 0.0672, target_std: 0.7299
      Epoch 1 composite train-obj: 0.180886
            Val objective improved inf → 0.1733, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4423, mae: 0.3887, huber: 0.1606, swd: 0.1867, target_std: 0.7935
    Epoch [2/50], Val Losses: mse: 0.3768, mae: 0.4333, huber: 0.1745, swd: 0.1482, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1988, mae: 0.3158, huber: 0.0972, swd: 0.0688, target_std: 0.7299
      Epoch 2 composite train-obj: 0.160639
            No improvement (0.1745), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.4197, mae: 0.3794, huber: 0.1532, swd: 0.1804, target_std: 0.7940
    Epoch [3/50], Val Losses: mse: 0.3730, mae: 0.4347, huber: 0.1737, swd: 0.1351, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2134, mae: 0.3301, huber: 0.1041, swd: 0.0762, target_std: 0.7299
      Epoch 3 composite train-obj: 0.153168
            No improvement (0.1737), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.4081, mae: 0.3735, huber: 0.1489, swd: 0.1803, target_std: 0.7951
    Epoch [4/50], Val Losses: mse: 0.3786, mae: 0.4320, huber: 0.1743, swd: 0.1518, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.1947, mae: 0.3090, huber: 0.0947, swd: 0.0710, target_std: 0.7299
      Epoch 4 composite train-obj: 0.148910
            No improvement (0.1743), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.3960, mae: 0.3689, huber: 0.1454, swd: 0.1764, target_std: 0.7934
    Epoch [5/50], Val Losses: mse: 0.3668, mae: 0.4285, huber: 0.1704, swd: 0.1336, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2064, mae: 0.3227, huber: 0.1007, swd: 0.0724, target_std: 0.7299
      Epoch 5 composite train-obj: 0.145357
            Val objective improved 0.1733 → 0.1704, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.3827, mae: 0.3616, huber: 0.1404, swd: 0.1717, target_std: 0.7930
    Epoch [6/50], Val Losses: mse: 0.3676, mae: 0.4292, huber: 0.1707, swd: 0.1318, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2088, mae: 0.3249, huber: 0.1018, swd: 0.0736, target_std: 0.7299
      Epoch 6 composite train-obj: 0.140438
            No improvement (0.1707), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.3769, mae: 0.3586, huber: 0.1383, swd: 0.1689, target_std: 0.7936
    Epoch [7/50], Val Losses: mse: 0.3647, mae: 0.4255, huber: 0.1690, swd: 0.1351, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.2021, mae: 0.3172, huber: 0.0983, swd: 0.0692, target_std: 0.7299
      Epoch 7 composite train-obj: 0.138273
            Val objective improved 0.1704 → 0.1690, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.3707, mae: 0.3552, huber: 0.1361, swd: 0.1664, target_std: 0.7928
    Epoch [8/50], Val Losses: mse: 0.3726, mae: 0.4301, huber: 0.1724, swd: 0.1358, target_std: 0.9871
    Epoch [8/50], Test Losses: mse: 0.2023, mae: 0.3164, huber: 0.0981, swd: 0.0695, target_std: 0.7299
      Epoch 8 composite train-obj: 0.136055
            No improvement (0.1724), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.3674, mae: 0.3530, huber: 0.1346, swd: 0.1657, target_std: 0.7940
    Epoch [9/50], Val Losses: mse: 0.3697, mae: 0.4282, huber: 0.1709, swd: 0.1341, target_std: 0.9871
    Epoch [9/50], Test Losses: mse: 0.2057, mae: 0.3194, huber: 0.0994, swd: 0.0691, target_std: 0.7299
      Epoch 9 composite train-obj: 0.134630
            No improvement (0.1709), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.3607, mae: 0.3493, huber: 0.1321, swd: 0.1621, target_std: 0.7950
    Epoch [10/50], Val Losses: mse: 0.3731, mae: 0.4310, huber: 0.1721, swd: 0.1338, target_std: 0.9871
    Epoch [10/50], Test Losses: mse: 0.2094, mae: 0.3232, huber: 0.1009, swd: 0.0695, target_std: 0.7299
      Epoch 10 composite train-obj: 0.132144
            No improvement (0.1721), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.3529, mae: 0.3458, huber: 0.1296, swd: 0.1584, target_std: 0.7932
    Epoch [11/50], Val Losses: mse: 0.3810, mae: 0.4358, huber: 0.1757, swd: 0.1336, target_std: 0.9871
    Epoch [11/50], Test Losses: mse: 0.2138, mae: 0.3262, huber: 0.1031, swd: 0.0734, target_std: 0.7299
      Epoch 11 composite train-obj: 0.129596
            No improvement (0.1757), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.3458, mae: 0.3421, huber: 0.1270, swd: 0.1551, target_std: 0.7927
    Epoch [12/50], Val Losses: mse: 0.3839, mae: 0.4342, huber: 0.1758, swd: 0.1414, target_std: 0.9871
    Epoch [12/50], Test Losses: mse: 0.2077, mae: 0.3200, huber: 0.1001, swd: 0.0724, target_std: 0.7299
      Epoch 12 composite train-obj: 0.127042
    Epoch [12/50], Test Losses: mse: 0.2021, mae: 0.3172, huber: 0.0983, swd: 0.0692, target_std: 0.7299
    Best round's Test MSE: 0.2021, MAE: 0.3172, SWD: 0.0692
    Best round's Validation MSE: 0.3647, MAE: 0.4255
    Best round's Test verification MSE : 0.2021, MAE: 0.3172, SWD: 0.0692
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5568, mae: 0.4487, huber: 0.2008, swd: 0.2015, target_std: 0.7956
    Epoch [1/50], Val Losses: mse: 0.3758, mae: 0.4407, huber: 0.1758, swd: 0.1203, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.2196, mae: 0.3327, huber: 0.1064, swd: 0.0702, target_std: 0.7299
      Epoch 1 composite train-obj: 0.200758
            Val objective improved inf → 0.1758, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4557, mae: 0.3937, huber: 0.1645, swd: 0.1871, target_std: 0.7950
    Epoch [2/50], Val Losses: mse: 0.3683, mae: 0.4281, huber: 0.1708, swd: 0.1382, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1933, mae: 0.3099, huber: 0.0945, swd: 0.0623, target_std: 0.7299
      Epoch 2 composite train-obj: 0.164494
            Val objective improved 0.1758 → 0.1708, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4289, mae: 0.3838, huber: 0.1567, swd: 0.1790, target_std: 0.7968
    Epoch [3/50], Val Losses: mse: 0.3779, mae: 0.4392, huber: 0.1762, swd: 0.1289, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2178, mae: 0.3299, huber: 0.1054, swd: 0.0725, target_std: 0.7299
      Epoch 3 composite train-obj: 0.156692
            No improvement (0.1762), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.4108, mae: 0.3765, huber: 0.1507, swd: 0.1740, target_std: 0.7953
    Epoch [4/50], Val Losses: mse: 0.3728, mae: 0.4332, huber: 0.1733, swd: 0.1287, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.2109, mae: 0.3252, huber: 0.1028, swd: 0.0701, target_std: 0.7299
      Epoch 4 composite train-obj: 0.150668
            No improvement (0.1733), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.3957, mae: 0.3695, huber: 0.1454, swd: 0.1719, target_std: 0.7940
    Epoch [5/50], Val Losses: mse: 0.3691, mae: 0.4292, huber: 0.1711, swd: 0.1304, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2033, mae: 0.3197, huber: 0.0993, swd: 0.0644, target_std: 0.7299
      Epoch 5 composite train-obj: 0.145401
            No improvement (0.1711), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.3873, mae: 0.3636, huber: 0.1417, swd: 0.1705, target_std: 0.7947
    Epoch [6/50], Val Losses: mse: 0.3736, mae: 0.4321, huber: 0.1728, swd: 0.1302, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2092, mae: 0.3251, huber: 0.1020, swd: 0.0664, target_std: 0.7299
      Epoch 6 composite train-obj: 0.141734
            No improvement (0.1728), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.3772, mae: 0.3585, huber: 0.1382, swd: 0.1668, target_std: 0.7932
    Epoch [7/50], Val Losses: mse: 0.3824, mae: 0.4348, huber: 0.1757, swd: 0.1363, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.2063, mae: 0.3203, huber: 0.0999, swd: 0.0659, target_std: 0.7299
      Epoch 7 composite train-obj: 0.138246
    Epoch [7/50], Test Losses: mse: 0.1933, mae: 0.3099, huber: 0.0945, swd: 0.0623, target_std: 0.7299
    Best round's Test MSE: 0.1933, MAE: 0.3099, SWD: 0.0623
    Best round's Validation MSE: 0.3683, MAE: 0.4281
    Best round's Test verification MSE : 0.1933, MAE: 0.3099, SWD: 0.0623
    
    ==================================================
    Experiment Summary (TimeMixer_etth2_seq196_pred336_20250502_1203)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1975 ± 0.0036
      mae: 0.3136 ± 0.0030
      huber: 0.0963 ± 0.0015
      swd: 0.0660 ± 0.0028
      target_std: 0.7299 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3657 ± 0.0018
      mae: 0.4269 ± 0.0011
      huber: 0.1698 ± 0.0008
      swd: 0.1364 ± 0.0013
      target_std: 0.9871 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_etth2_seq196_pred336_20250502_1203
    Model: TimeMixer
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 89
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 89
    Validation Batches: 7
    Test Batches: 21
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.7036, mae: 0.5095, huber: 0.2456, swd: 0.2716, target_std: 0.7971
    Epoch [1/50], Val Losses: mse: 0.4116, mae: 0.4624, huber: 0.1908, swd: 0.0970, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2502, mae: 0.3533, huber: 0.1202, swd: 0.0794, target_std: 0.7295
      Epoch 1 composite train-obj: 0.245553
            Val objective improved inf → 0.1908, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6598, mae: 0.4864, huber: 0.2295, swd: 0.2719, target_std: 0.7978
    Epoch [2/50], Val Losses: mse: 0.4190, mae: 0.4644, huber: 0.1936, swd: 0.1050, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2615, mae: 0.3607, huber: 0.1252, swd: 0.0848, target_std: 0.7295
      Epoch 2 composite train-obj: 0.229484
            No improvement (0.1936), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.6385, mae: 0.4785, huber: 0.2230, swd: 0.2685, target_std: 0.7972
    Epoch [3/50], Val Losses: mse: 0.4007, mae: 0.4515, huber: 0.1855, swd: 0.0961, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2541, mae: 0.3576, huber: 0.1221, swd: 0.0816, target_std: 0.7295
      Epoch 3 composite train-obj: 0.222952
            Val objective improved 0.1908 → 0.1855, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.6176, mae: 0.4691, huber: 0.2157, swd: 0.2624, target_std: 0.7977
    Epoch [4/50], Val Losses: mse: 0.4298, mae: 0.4683, huber: 0.1969, swd: 0.0906, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2906, mae: 0.3859, huber: 0.1385, swd: 0.0977, target_std: 0.7295
      Epoch 4 composite train-obj: 0.215710
            No improvement (0.1969), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.5932, mae: 0.4576, huber: 0.2071, swd: 0.2540, target_std: 0.7981
    Epoch [5/50], Val Losses: mse: 0.4154, mae: 0.4608, huber: 0.1908, swd: 0.0959, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2634, mae: 0.3663, huber: 0.1264, swd: 0.0875, target_std: 0.7295
      Epoch 5 composite train-obj: 0.207111
            No improvement (0.1908), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.5773, mae: 0.4480, huber: 0.2008, swd: 0.2477, target_std: 0.7980
    Epoch [6/50], Val Losses: mse: 0.4018, mae: 0.4508, huber: 0.1842, swd: 0.0960, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2603, mae: 0.3660, huber: 0.1252, swd: 0.0859, target_std: 0.7295
      Epoch 6 composite train-obj: 0.200771
            Val objective improved 0.1855 → 0.1842, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.5620, mae: 0.4393, huber: 0.1950, swd: 0.2428, target_std: 0.7971
    Epoch [7/50], Val Losses: mse: 0.4064, mae: 0.4525, huber: 0.1857, swd: 0.1020, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2687, mae: 0.3727, huber: 0.1290, swd: 0.0904, target_std: 0.7295
      Epoch 7 composite train-obj: 0.194954
            No improvement (0.1857), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.5488, mae: 0.4316, huber: 0.1898, swd: 0.2363, target_std: 0.7968
    Epoch [8/50], Val Losses: mse: 0.4223, mae: 0.4600, huber: 0.1916, swd: 0.1061, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2859, mae: 0.3836, huber: 0.1366, swd: 0.0991, target_std: 0.7295
      Epoch 8 composite train-obj: 0.189791
            No improvement (0.1916), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.5366, mae: 0.4255, huber: 0.1854, swd: 0.2312, target_std: 0.7974
    Epoch [9/50], Val Losses: mse: 0.4206, mae: 0.4593, huber: 0.1908, swd: 0.1117, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2863, mae: 0.3844, huber: 0.1367, swd: 0.0970, target_std: 0.7295
      Epoch 9 composite train-obj: 0.185388
            No improvement (0.1908), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.5260, mae: 0.4198, huber: 0.1814, swd: 0.2249, target_std: 0.7967
    Epoch [10/50], Val Losses: mse: 0.4240, mae: 0.4626, huber: 0.1928, swd: 0.1114, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.3049, mae: 0.3962, huber: 0.1449, swd: 0.1077, target_std: 0.7295
      Epoch 10 composite train-obj: 0.181437
            No improvement (0.1928), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.5168, mae: 0.4151, huber: 0.1779, swd: 0.2194, target_std: 0.7971
    Epoch [11/50], Val Losses: mse: 0.4402, mae: 0.4705, huber: 0.1986, swd: 0.1146, target_std: 0.9872
    Epoch [11/50], Test Losses: mse: 0.2988, mae: 0.3912, huber: 0.1420, swd: 0.1021, target_std: 0.7295
      Epoch 11 composite train-obj: 0.177856
    Epoch [11/50], Test Losses: mse: 0.2603, mae: 0.3660, huber: 0.1252, swd: 0.0859, target_std: 0.7295
    Best round's Test MSE: 0.2603, MAE: 0.3660, SWD: 0.0859
    Best round's Validation MSE: 0.4018, MAE: 0.4508
    Best round's Test verification MSE : 0.2603, MAE: 0.3660, SWD: 0.0859
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.7068, mae: 0.5096, huber: 0.2459, swd: 0.2666, target_std: 0.7988
    Epoch [1/50], Val Losses: mse: 0.4080, mae: 0.4615, huber: 0.1895, swd: 0.0790, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2591, mae: 0.3594, huber: 0.1241, swd: 0.0771, target_std: 0.7295
      Epoch 1 composite train-obj: 0.245939
            Val objective improved inf → 0.1895, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6556, mae: 0.4851, huber: 0.2281, swd: 0.2600, target_std: 0.7993
    Epoch [2/50], Val Losses: mse: 0.4050, mae: 0.4554, huber: 0.1876, swd: 0.0926, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2542, mae: 0.3581, huber: 0.1225, swd: 0.0770, target_std: 0.7295
      Epoch 2 composite train-obj: 0.228061
            Val objective improved 0.1895 → 0.1876, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.6310, mae: 0.4752, huber: 0.2200, swd: 0.2550, target_std: 0.7991
    Epoch [3/50], Val Losses: mse: 0.4056, mae: 0.4556, huber: 0.1874, swd: 0.0816, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2682, mae: 0.3695, huber: 0.1286, swd: 0.0847, target_std: 0.7295
      Epoch 3 composite train-obj: 0.219983
            Val objective improved 0.1876 → 0.1874, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.6031, mae: 0.4640, huber: 0.2109, swd: 0.2463, target_std: 0.7967
    Epoch [4/50], Val Losses: mse: 0.3754, mae: 0.4371, huber: 0.1747, swd: 0.0778, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2494, mae: 0.3567, huber: 0.1203, swd: 0.0759, target_std: 0.7295
      Epoch 4 composite train-obj: 0.210928
            Val objective improved 0.1874 → 0.1747, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.5886, mae: 0.4554, huber: 0.2051, swd: 0.2432, target_std: 0.7981
    Epoch [5/50], Val Losses: mse: 0.3969, mae: 0.4490, huber: 0.1831, swd: 0.0805, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2758, mae: 0.3761, huber: 0.1323, swd: 0.0864, target_std: 0.7295
      Epoch 5 composite train-obj: 0.205112
            No improvement (0.1831), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.5736, mae: 0.4467, huber: 0.1993, swd: 0.2397, target_std: 0.7976
    Epoch [6/50], Val Losses: mse: 0.3939, mae: 0.4480, huber: 0.1811, swd: 0.1004, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2656, mae: 0.3687, huber: 0.1274, swd: 0.0809, target_std: 0.7295
      Epoch 6 composite train-obj: 0.199271
            No improvement (0.1811), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.5632, mae: 0.4398, huber: 0.1951, swd: 0.2362, target_std: 0.7987
    Epoch [7/50], Val Losses: mse: 0.3880, mae: 0.4450, huber: 0.1791, swd: 0.0930, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2757, mae: 0.3770, huber: 0.1321, swd: 0.0871, target_std: 0.7295
      Epoch 7 composite train-obj: 0.195074
            No improvement (0.1791), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.5554, mae: 0.4347, huber: 0.1918, swd: 0.2346, target_std: 0.7985
    Epoch [8/50], Val Losses: mse: 0.4049, mae: 0.4548, huber: 0.1856, swd: 0.0983, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2850, mae: 0.3831, huber: 0.1362, swd: 0.0892, target_std: 0.7295
      Epoch 8 composite train-obj: 0.191839
            No improvement (0.1856), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.5500, mae: 0.4302, huber: 0.1892, swd: 0.2319, target_std: 0.7984
    Epoch [9/50], Val Losses: mse: 0.4248, mae: 0.4632, huber: 0.1924, swd: 0.1090, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.3019, mae: 0.3949, huber: 0.1436, swd: 0.0919, target_std: 0.7295
      Epoch 9 composite train-obj: 0.189234
    Epoch [9/50], Test Losses: mse: 0.2494, mae: 0.3567, huber: 0.1203, swd: 0.0759, target_std: 0.7295
    Best round's Test MSE: 0.2494, MAE: 0.3567, SWD: 0.0759
    Best round's Validation MSE: 0.3754, MAE: 0.4371
    Best round's Test verification MSE : 0.2494, MAE: 0.3567, SWD: 0.0759
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.7191, mae: 0.5180, huber: 0.2512, swd: 0.3023, target_std: 0.7970
    Epoch [1/50], Val Losses: mse: 0.4138, mae: 0.4637, huber: 0.1918, swd: 0.0919, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2607, mae: 0.3614, huber: 0.1249, swd: 0.0865, target_std: 0.7295
      Epoch 1 composite train-obj: 0.251153
            Val objective improved inf → 0.1918, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6563, mae: 0.4868, huber: 0.2291, swd: 0.2867, target_std: 0.7993
    Epoch [2/50], Val Losses: mse: 0.4262, mae: 0.4680, huber: 0.1965, swd: 0.0962, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2790, mae: 0.3738, huber: 0.1330, swd: 0.0972, target_std: 0.7295
      Epoch 2 composite train-obj: 0.229086
            No improvement (0.1965), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.6310, mae: 0.4764, huber: 0.2210, swd: 0.2811, target_std: 0.7988
    Epoch [3/50], Val Losses: mse: 0.4098, mae: 0.4594, huber: 0.1901, swd: 0.0889, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2760, mae: 0.3711, huber: 0.1316, swd: 0.0976, target_std: 0.7295
      Epoch 3 composite train-obj: 0.221004
            Val objective improved 0.1918 → 0.1901, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.6156, mae: 0.4693, huber: 0.2155, swd: 0.2767, target_std: 0.7983
    Epoch [4/50], Val Losses: mse: 0.3983, mae: 0.4514, huber: 0.1842, swd: 0.0932, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2563, mae: 0.3588, huber: 0.1231, swd: 0.0862, target_std: 0.7295
      Epoch 4 composite train-obj: 0.215462
            Val objective improved 0.1901 → 0.1842, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.5960, mae: 0.4595, huber: 0.2083, swd: 0.2696, target_std: 0.7973
    Epoch [5/50], Val Losses: mse: 0.4041, mae: 0.4551, huber: 0.1865, swd: 0.0956, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2562, mae: 0.3586, huber: 0.1230, swd: 0.0863, target_std: 0.7295
      Epoch 5 composite train-obj: 0.208323
            No improvement (0.1865), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.5936, mae: 0.4550, huber: 0.2061, swd: 0.2717, target_std: 0.8011
    Epoch [6/50], Val Losses: mse: 0.4024, mae: 0.4498, huber: 0.1845, swd: 0.0903, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2630, mae: 0.3626, huber: 0.1259, swd: 0.0921, target_std: 0.7295
      Epoch 6 composite train-obj: 0.206073
            No improvement (0.1845), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.5730, mae: 0.4461, huber: 0.1994, swd: 0.2618, target_std: 0.7970
    Epoch [7/50], Val Losses: mse: 0.4408, mae: 0.4717, huber: 0.1995, swd: 0.1009, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2764, mae: 0.3728, huber: 0.1319, swd: 0.0978, target_std: 0.7295
      Epoch 7 composite train-obj: 0.199423
            No improvement (0.1995), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.5637, mae: 0.4403, huber: 0.1958, swd: 0.2585, target_std: 0.7977
    Epoch [8/50], Val Losses: mse: 0.4363, mae: 0.4673, huber: 0.1971, swd: 0.1007, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2719, mae: 0.3696, huber: 0.1299, swd: 0.0933, target_std: 0.7295
      Epoch 8 composite train-obj: 0.195791
            No improvement (0.1971), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.5550, mae: 0.4358, huber: 0.1927, swd: 0.2544, target_std: 0.7980
    Epoch [9/50], Val Losses: mse: 0.4608, mae: 0.4816, huber: 0.2068, swd: 0.1104, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2869, mae: 0.3810, huber: 0.1367, swd: 0.1023, target_std: 0.7295
      Epoch 9 composite train-obj: 0.192663
    Epoch [9/50], Test Losses: mse: 0.2563, mae: 0.3588, huber: 0.1231, swd: 0.0862, target_std: 0.7295
    Best round's Test MSE: 0.2563, MAE: 0.3588, SWD: 0.0862
    Best round's Validation MSE: 0.3983, MAE: 0.4514
    Best round's Test verification MSE : 0.2563, MAE: 0.3588, SWD: 0.0862
    
    ==================================================
    Experiment Summary (TimeMixer_etth2_seq196_pred720_20250502_1204)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2553 ± 0.0045
      mae: 0.3605 ± 0.0040
      huber: 0.1229 ± 0.0020
      swd: 0.0826 ± 0.0048
      target_std: 0.7295 ± 0.0000
      count: 7.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3918 ± 0.0117
      mae: 0.4464 ± 0.0066
      huber: 0.1810 ± 0.0045
      swd: 0.0890 ± 0.0080
      target_std: 0.9872 ± 0.0000
      count: 7.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_etth2_seq196_pred720_20250502_1204
    Model: TimeMixer
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### PatchTST

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 12
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3183, mae: 0.3305, huber: 0.1212, swd: 0.1122, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2685, mae: 0.3536, huber: 0.1259, swd: 0.1222, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1517, mae: 0.2729, huber: 0.0745, swd: 0.0583, target_std: 0.7274
      Epoch 1 composite train-obj: 0.121219
            Val objective improved inf → 0.1259, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2863, mae: 0.3130, huber: 0.1102, swd: 0.1059, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2817, mae: 0.3609, huber: 0.1314, swd: 0.1208, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1569, mae: 0.2805, huber: 0.0771, swd: 0.0539, target_std: 0.7274
      Epoch 2 composite train-obj: 0.110223
            No improvement (0.1314), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2700, mae: 0.3056, huber: 0.1051, swd: 0.1009, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2782, mae: 0.3582, huber: 0.1294, swd: 0.1229, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1608, mae: 0.2821, huber: 0.0787, swd: 0.0556, target_std: 0.7274
      Epoch 3 composite train-obj: 0.105110
            No improvement (0.1294), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2578, mae: 0.3003, huber: 0.1014, swd: 0.0967, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2947, mae: 0.3682, huber: 0.1356, swd: 0.1297, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1631, mae: 0.2796, huber: 0.0791, swd: 0.0580, target_std: 0.7274
      Epoch 4 composite train-obj: 0.101405
            No improvement (0.1356), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2492, mae: 0.2970, huber: 0.0990, swd: 0.0921, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2932, mae: 0.3683, huber: 0.1354, swd: 0.1274, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1690, mae: 0.2856, huber: 0.0815, swd: 0.0581, target_std: 0.7274
      Epoch 5 composite train-obj: 0.099003
            No improvement (0.1354), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.2417, mae: 0.2941, huber: 0.0968, swd: 0.0889, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2897, mae: 0.3655, huber: 0.1343, swd: 0.1260, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1737, mae: 0.2924, huber: 0.0843, swd: 0.0573, target_std: 0.7274
      Epoch 6 composite train-obj: 0.096848
    Epoch [6/50], Test Losses: mse: 0.1517, mae: 0.2729, huber: 0.0745, swd: 0.0583, target_std: 0.7274
    Best round's Test MSE: 0.1517, MAE: 0.2729, SWD: 0.0583
    Best round's Validation MSE: 0.2685, MAE: 0.3536
    Best round's Test verification MSE : 0.1517, MAE: 0.2729, SWD: 0.0583
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3181, mae: 0.3303, huber: 0.1210, swd: 0.1111, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2771, mae: 0.3592, huber: 0.1291, swd: 0.1258, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1579, mae: 0.2782, huber: 0.0774, swd: 0.0580, target_std: 0.7274
      Epoch 1 composite train-obj: 0.121026
            Val objective improved inf → 0.1291, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2854, mae: 0.3123, huber: 0.1097, swd: 0.1044, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2675, mae: 0.3536, huber: 0.1253, swd: 0.1157, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1590, mae: 0.2808, huber: 0.0780, swd: 0.0550, target_std: 0.7274
      Epoch 2 composite train-obj: 0.109724
            Val objective improved 0.1291 → 0.1253, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2726, mae: 0.3070, huber: 0.1058, swd: 0.1011, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2792, mae: 0.3613, huber: 0.1309, swd: 0.1233, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1585, mae: 0.2795, huber: 0.0778, swd: 0.0575, target_std: 0.7274
      Epoch 3 composite train-obj: 0.105789
            No improvement (0.1309), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2600, mae: 0.3018, huber: 0.1022, swd: 0.0980, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2848, mae: 0.3639, huber: 0.1325, swd: 0.1214, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1607, mae: 0.2825, huber: 0.0787, swd: 0.0552, target_std: 0.7274
      Epoch 4 composite train-obj: 0.102204
            No improvement (0.1325), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.2490, mae: 0.2969, huber: 0.0988, swd: 0.0940, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2680, mae: 0.3559, huber: 0.1261, swd: 0.1093, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1613, mae: 0.2849, huber: 0.0792, swd: 0.0554, target_std: 0.7274
      Epoch 5 composite train-obj: 0.098820
            No improvement (0.1261), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.2389, mae: 0.2928, huber: 0.0959, swd: 0.0880, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2709, mae: 0.3569, huber: 0.1272, swd: 0.1162, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1567, mae: 0.2790, huber: 0.0769, swd: 0.0540, target_std: 0.7274
      Epoch 6 composite train-obj: 0.095922
            No improvement (0.1272), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.2314, mae: 0.2895, huber: 0.0935, swd: 0.0846, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2782, mae: 0.3610, huber: 0.1298, swd: 0.1165, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1606, mae: 0.2841, huber: 0.0788, swd: 0.0545, target_std: 0.7274
      Epoch 7 composite train-obj: 0.093523
    Epoch [7/50], Test Losses: mse: 0.1590, mae: 0.2808, huber: 0.0780, swd: 0.0550, target_std: 0.7274
    Best round's Test MSE: 0.1590, MAE: 0.2808, SWD: 0.0550
    Best round's Validation MSE: 0.2675, MAE: 0.3536
    Best round's Test verification MSE : 0.1590, MAE: 0.2808, SWD: 0.0550
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3160, mae: 0.3304, huber: 0.1208, swd: 0.1034, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2749, mae: 0.3648, huber: 0.1304, swd: 0.0999, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1616, mae: 0.2847, huber: 0.0793, swd: 0.0488, target_std: 0.7274
      Epoch 1 composite train-obj: 0.120777
            Val objective improved inf → 0.1304, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2865, mae: 0.3136, huber: 0.1105, swd: 0.0979, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2875, mae: 0.3626, huber: 0.1332, swd: 0.1177, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1560, mae: 0.2787, huber: 0.0764, swd: 0.0486, target_std: 0.7274
      Epoch 2 composite train-obj: 0.110456
            No improvement (0.1332), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2693, mae: 0.3067, huber: 0.1054, swd: 0.0935, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2855, mae: 0.3629, huber: 0.1329, swd: 0.1152, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1571, mae: 0.2774, huber: 0.0768, swd: 0.0481, target_std: 0.7274
      Epoch 3 composite train-obj: 0.105410
            No improvement (0.1329), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2562, mae: 0.3011, huber: 0.1014, swd: 0.0890, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2802, mae: 0.3603, huber: 0.1308, swd: 0.1086, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1566, mae: 0.2797, huber: 0.0769, swd: 0.0469, target_std: 0.7274
      Epoch 4 composite train-obj: 0.101379
            No improvement (0.1308), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.2455, mae: 0.2968, huber: 0.0984, swd: 0.0837, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2732, mae: 0.3561, huber: 0.1278, swd: 0.1076, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1550, mae: 0.2759, huber: 0.0759, swd: 0.0482, target_std: 0.7274
      Epoch 5 composite train-obj: 0.098414
            Val objective improved 0.1304 → 0.1278, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2353, mae: 0.2917, huber: 0.0951, swd: 0.0787, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2856, mae: 0.3642, huber: 0.1320, swd: 0.1171, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1635, mae: 0.2810, huber: 0.0793, swd: 0.0540, target_std: 0.7274
      Epoch 6 composite train-obj: 0.095096
            No improvement (0.1320), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.2276, mae: 0.2880, huber: 0.0926, swd: 0.0754, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2747, mae: 0.3587, huber: 0.1284, swd: 0.1117, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1634, mae: 0.2846, huber: 0.0799, swd: 0.0537, target_std: 0.7274
      Epoch 7 composite train-obj: 0.092605
            No improvement (0.1284), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.2226, mae: 0.2854, huber: 0.0909, swd: 0.0736, target_std: 0.7909
    Epoch [8/50], Val Losses: mse: 0.2852, mae: 0.3638, huber: 0.1325, swd: 0.1115, target_std: 0.9930
    Epoch [8/50], Test Losses: mse: 0.1643, mae: 0.2837, huber: 0.0802, swd: 0.0526, target_std: 0.7274
      Epoch 8 composite train-obj: 0.090883
            No improvement (0.1325), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.2169, mae: 0.2822, huber: 0.0887, swd: 0.0710, target_std: 0.7909
    Epoch [9/50], Val Losses: mse: 0.2835, mae: 0.3632, huber: 0.1318, swd: 0.1112, target_std: 0.9930
    Epoch [9/50], Test Losses: mse: 0.1629, mae: 0.2846, huber: 0.0798, swd: 0.0526, target_std: 0.7274
      Epoch 9 composite train-obj: 0.088742
            No improvement (0.1318), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.2120, mae: 0.2791, huber: 0.0868, swd: 0.0694, target_std: 0.7909
    Epoch [10/50], Val Losses: mse: 0.2901, mae: 0.3684, huber: 0.1348, swd: 0.1135, target_std: 0.9930
    Epoch [10/50], Test Losses: mse: 0.1676, mae: 0.2875, huber: 0.0817, swd: 0.0547, target_std: 0.7274
      Epoch 10 composite train-obj: 0.086797
    Epoch [10/50], Test Losses: mse: 0.1550, mae: 0.2759, huber: 0.0759, swd: 0.0482, target_std: 0.7274
    Best round's Test MSE: 0.1550, MAE: 0.2759, SWD: 0.0482
    Best round's Validation MSE: 0.2732, MAE: 0.3561
    Best round's Test verification MSE : 0.1550, MAE: 0.2759, SWD: 0.0482
    
    ==================================================
    Experiment Summary (PatchTST_etth2_seq196_pred96_20250502_1206)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1553 ± 0.0030
      mae: 0.2765 ± 0.0033
      huber: 0.0761 ± 0.0014
      swd: 0.0538 ± 0.0042
      target_std: 0.7274 ± 0.0000
      count: 12.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2698 ± 0.0025
      mae: 0.3544 ± 0.0012
      huber: 0.1263 ± 0.0011
      swd: 0.1152 ± 0.0060
      target_std: 0.9930 ± 0.0000
      count: 12.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_etth2_seq196_pred96_20250502_1206
    Model: PatchTST
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 11
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3986, mae: 0.3704, huber: 0.1475, swd: 0.1505, target_std: 0.7921
    Epoch [1/50], Val Losses: mse: 0.3535, mae: 0.4190, huber: 0.1652, swd: 0.1400, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1885, mae: 0.3064, huber: 0.0921, swd: 0.0638, target_std: 0.7295
      Epoch 1 composite train-obj: 0.147497
            Val objective improved inf → 0.1652, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3708, mae: 0.3545, huber: 0.1372, swd: 0.1473, target_std: 0.7929
    Epoch [2/50], Val Losses: mse: 0.3458, mae: 0.4143, huber: 0.1611, swd: 0.1432, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.2019, mae: 0.3185, huber: 0.0979, swd: 0.0712, target_std: 0.7295
      Epoch 2 composite train-obj: 0.137189
            Val objective improved 0.1652 → 0.1611, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3448, mae: 0.3443, huber: 0.1295, swd: 0.1379, target_std: 0.7916
    Epoch [3/50], Val Losses: mse: 0.3602, mae: 0.4166, huber: 0.1656, swd: 0.1642, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1889, mae: 0.3054, huber: 0.0917, swd: 0.0678, target_std: 0.7295
      Epoch 3 composite train-obj: 0.129488
            No improvement (0.1656), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.3321, mae: 0.3386, huber: 0.1254, swd: 0.1345, target_std: 0.7914
    Epoch [4/50], Val Losses: mse: 0.3590, mae: 0.4173, huber: 0.1654, swd: 0.1639, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1870, mae: 0.3031, huber: 0.0909, swd: 0.0658, target_std: 0.7295
      Epoch 4 composite train-obj: 0.125449
            No improvement (0.1654), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.3223, mae: 0.3340, huber: 0.1224, swd: 0.1311, target_std: 0.7921
    Epoch [5/50], Val Losses: mse: 0.3576, mae: 0.4154, huber: 0.1647, swd: 0.1560, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1851, mae: 0.3018, huber: 0.0899, swd: 0.0670, target_std: 0.7295
      Epoch 5 composite train-obj: 0.122411
            No improvement (0.1647), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.3140, mae: 0.3300, huber: 0.1197, swd: 0.1277, target_std: 0.7924
    Epoch [6/50], Val Losses: mse: 0.3834, mae: 0.4303, huber: 0.1752, swd: 0.1667, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.2025, mae: 0.3173, huber: 0.0981, swd: 0.0742, target_std: 0.7295
      Epoch 6 composite train-obj: 0.119672
            No improvement (0.1752), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.3048, mae: 0.3260, huber: 0.1167, swd: 0.1237, target_std: 0.7922
    Epoch [7/50], Val Losses: mse: 0.3712, mae: 0.4230, huber: 0.1707, swd: 0.1665, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1936, mae: 0.3066, huber: 0.0935, swd: 0.0706, target_std: 0.7295
      Epoch 7 composite train-obj: 0.116713
    Epoch [7/50], Test Losses: mse: 0.2019, mae: 0.3185, huber: 0.0979, swd: 0.0712, target_std: 0.7295
    Best round's Test MSE: 0.2019, MAE: 0.3185, SWD: 0.0712
    Best round's Validation MSE: 0.3458, MAE: 0.4143
    Best round's Test verification MSE : 0.2019, MAE: 0.3185, SWD: 0.0712
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4001, mae: 0.3716, huber: 0.1482, swd: 0.1534, target_std: 0.7927
    Epoch [1/50], Val Losses: mse: 0.3449, mae: 0.4103, huber: 0.1602, swd: 0.1519, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1784, mae: 0.2967, huber: 0.0873, swd: 0.0670, target_std: 0.7295
      Epoch 1 composite train-obj: 0.148187
            Val objective improved inf → 0.1602, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3624, mae: 0.3525, huber: 0.1352, swd: 0.1448, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3615, mae: 0.4233, huber: 0.1678, swd: 0.1538, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1955, mae: 0.3133, huber: 0.0953, swd: 0.0703, target_std: 0.7295
      Epoch 2 composite train-obj: 0.135245
            No improvement (0.1678), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3428, mae: 0.3440, huber: 0.1291, swd: 0.1400, target_std: 0.7936
    Epoch [3/50], Val Losses: mse: 0.3547, mae: 0.4167, huber: 0.1641, swd: 0.1565, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1948, mae: 0.3127, huber: 0.0948, swd: 0.0743, target_std: 0.7295
      Epoch 3 composite train-obj: 0.129121
            No improvement (0.1641), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.3325, mae: 0.3384, huber: 0.1254, swd: 0.1370, target_std: 0.7924
    Epoch [4/50], Val Losses: mse: 0.3525, mae: 0.4145, huber: 0.1627, swd: 0.1467, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1980, mae: 0.3131, huber: 0.0959, swd: 0.0748, target_std: 0.7295
      Epoch 4 composite train-obj: 0.125427
            No improvement (0.1627), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.3183, mae: 0.3313, huber: 0.1208, swd: 0.1310, target_std: 0.7924
    Epoch [5/50], Val Losses: mse: 0.3614, mae: 0.4169, huber: 0.1660, swd: 0.1622, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1930, mae: 0.3069, huber: 0.0934, swd: 0.0763, target_std: 0.7295
      Epoch 5 composite train-obj: 0.120770
            No improvement (0.1660), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.3082, mae: 0.3270, huber: 0.1178, swd: 0.1264, target_std: 0.7926
    Epoch [6/50], Val Losses: mse: 0.3819, mae: 0.4312, huber: 0.1746, swd: 0.1625, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.2087, mae: 0.3199, huber: 0.1004, swd: 0.0782, target_std: 0.7295
      Epoch 6 composite train-obj: 0.117789
    Epoch [6/50], Test Losses: mse: 0.1784, mae: 0.2967, huber: 0.0873, swd: 0.0670, target_std: 0.7295
    Best round's Test MSE: 0.1784, MAE: 0.2967, SWD: 0.0670
    Best round's Validation MSE: 0.3449, MAE: 0.4103
    Best round's Test verification MSE : 0.1784, MAE: 0.2967, SWD: 0.0670
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4024, mae: 0.3719, huber: 0.1485, swd: 0.1376, target_std: 0.7931
    Epoch [1/50], Val Losses: mse: 0.3467, mae: 0.4120, huber: 0.1607, swd: 0.1407, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1811, mae: 0.2998, huber: 0.0886, swd: 0.0598, target_std: 0.7295
      Epoch 1 composite train-obj: 0.148537
            Val objective improved inf → 0.1607, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3670, mae: 0.3547, huber: 0.1369, swd: 0.1312, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3582, mae: 0.4247, huber: 0.1667, swd: 0.1353, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1985, mae: 0.3184, huber: 0.0969, swd: 0.0602, target_std: 0.7295
      Epoch 2 composite train-obj: 0.136851
            No improvement (0.1667), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.3460, mae: 0.3456, huber: 0.1302, swd: 0.1261, target_std: 0.7921
    Epoch [3/50], Val Losses: mse: 0.3388, mae: 0.4100, huber: 0.1580, swd: 0.1318, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1952, mae: 0.3125, huber: 0.0950, swd: 0.0614, target_std: 0.7295
      Epoch 3 composite train-obj: 0.130177
            Val objective improved 0.1607 → 0.1580, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3341, mae: 0.3395, huber: 0.1261, swd: 0.1236, target_std: 0.7926
    Epoch [4/50], Val Losses: mse: 0.3452, mae: 0.4124, huber: 0.1604, swd: 0.1330, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1882, mae: 0.3067, huber: 0.0918, swd: 0.0578, target_std: 0.7295
      Epoch 4 composite train-obj: 0.126141
            No improvement (0.1604), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.3247, mae: 0.3348, huber: 0.1229, swd: 0.1209, target_std: 0.7926
    Epoch [5/50], Val Losses: mse: 0.3672, mae: 0.4232, huber: 0.1689, swd: 0.1374, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1950, mae: 0.3092, huber: 0.0942, swd: 0.0606, target_std: 0.7295
      Epoch 5 composite train-obj: 0.122855
            No improvement (0.1689), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.3164, mae: 0.3312, huber: 0.1203, swd: 0.1185, target_std: 0.7939
    Epoch [6/50], Val Losses: mse: 0.3574, mae: 0.4202, huber: 0.1656, swd: 0.1366, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1937, mae: 0.3105, huber: 0.0939, swd: 0.0585, target_std: 0.7295
      Epoch 6 composite train-obj: 0.120280
            No improvement (0.1656), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.3047, mae: 0.3260, huber: 0.1166, swd: 0.1129, target_std: 0.7933
    Epoch [7/50], Val Losses: mse: 0.3543, mae: 0.4168, huber: 0.1641, swd: 0.1338, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1942, mae: 0.3113, huber: 0.0944, swd: 0.0609, target_std: 0.7295
      Epoch 7 composite train-obj: 0.116584
            No improvement (0.1641), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.3001, mae: 0.3239, huber: 0.1151, swd: 0.1112, target_std: 0.7920
    Epoch [8/50], Val Losses: mse: 0.3675, mae: 0.4250, huber: 0.1695, swd: 0.1429, target_std: 0.9936
    Epoch [8/50], Test Losses: mse: 0.2017, mae: 0.3166, huber: 0.0975, swd: 0.0634, target_std: 0.7295
      Epoch 8 composite train-obj: 0.115082
    Epoch [8/50], Test Losses: mse: 0.1952, mae: 0.3125, huber: 0.0950, swd: 0.0614, target_std: 0.7295
    Best round's Test MSE: 0.1952, MAE: 0.3125, SWD: 0.0614
    Best round's Validation MSE: 0.3388, MAE: 0.4100
    Best round's Test verification MSE : 0.1952, MAE: 0.3125, SWD: 0.0614
    
    ==================================================
    Experiment Summary (PatchTST_etth2_seq196_pred196_20250502_1207)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1918 ± 0.0099
      mae: 0.3092 ± 0.0092
      huber: 0.0934 ± 0.0045
      swd: 0.0665 ± 0.0040
      target_std: 0.7295 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3432 ± 0.0031
      mae: 0.4115 ± 0.0020
      huber: 0.1598 ± 0.0013
      swd: 0.1423 ± 0.0082
      target_std: 0.9936 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_etth2_seq196_pred196_20250502_1207
    Model: PatchTST
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4857, mae: 0.4118, huber: 0.1755, swd: 0.1806, target_std: 0.7933
    Epoch [1/50], Val Losses: mse: 0.3874, mae: 0.4436, huber: 0.1795, swd: 0.1297, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.2368, mae: 0.3513, huber: 0.1148, swd: 0.0792, target_std: 0.7299
      Epoch 1 composite train-obj: 0.175504
            Val objective improved inf → 0.1795, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4506, mae: 0.3943, huber: 0.1635, swd: 0.1764, target_std: 0.7935
    Epoch [2/50], Val Losses: mse: 0.3875, mae: 0.4383, huber: 0.1783, swd: 0.1519, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.2126, mae: 0.3264, huber: 0.1032, swd: 0.0680, target_std: 0.7299
      Epoch 2 composite train-obj: 0.163467
            Val objective improved 0.1795 → 0.1783, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4346, mae: 0.3868, huber: 0.1581, swd: 0.1722, target_std: 0.7957
    Epoch [3/50], Val Losses: mse: 0.3691, mae: 0.4314, huber: 0.1715, swd: 0.1354, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2154, mae: 0.3292, huber: 0.1043, swd: 0.0710, target_std: 0.7299
      Epoch 3 composite train-obj: 0.158052
            Val objective improved 0.1783 → 0.1715, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4190, mae: 0.3793, huber: 0.1528, swd: 0.1665, target_std: 0.7938
    Epoch [4/50], Val Losses: mse: 0.3926, mae: 0.4419, huber: 0.1802, swd: 0.1496, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.2278, mae: 0.3394, huber: 0.1100, swd: 0.0776, target_std: 0.7299
      Epoch 4 composite train-obj: 0.152795
            No improvement (0.1802), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.4084, mae: 0.3737, huber: 0.1490, swd: 0.1639, target_std: 0.7942
    Epoch [5/50], Val Losses: mse: 0.3973, mae: 0.4484, huber: 0.1825, swd: 0.1422, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2270, mae: 0.3418, huber: 0.1099, swd: 0.0760, target_std: 0.7299
      Epoch 5 composite train-obj: 0.148988
            No improvement (0.1825), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.4031, mae: 0.3703, huber: 0.1468, swd: 0.1622, target_std: 0.7949
    Epoch [6/50], Val Losses: mse: 0.3810, mae: 0.4385, huber: 0.1761, swd: 0.1333, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2276, mae: 0.3424, huber: 0.1103, swd: 0.0766, target_std: 0.7299
      Epoch 6 composite train-obj: 0.146829
            No improvement (0.1761), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.3921, mae: 0.3659, huber: 0.1435, swd: 0.1581, target_std: 0.7939
    Epoch [7/50], Val Losses: mse: 0.3900, mae: 0.4434, huber: 0.1797, swd: 0.1362, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.2359, mae: 0.3489, huber: 0.1141, swd: 0.0816, target_std: 0.7299
      Epoch 7 composite train-obj: 0.143489
            No improvement (0.1797), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.3856, mae: 0.3620, huber: 0.1412, swd: 0.1547, target_std: 0.7935
    Epoch [8/50], Val Losses: mse: 0.3982, mae: 0.4470, huber: 0.1827, swd: 0.1375, target_std: 0.9871
    Epoch [8/50], Test Losses: mse: 0.2397, mae: 0.3515, huber: 0.1157, swd: 0.0844, target_std: 0.7299
      Epoch 8 composite train-obj: 0.141150
    Epoch [8/50], Test Losses: mse: 0.2154, mae: 0.3292, huber: 0.1043, swd: 0.0710, target_std: 0.7299
    Best round's Test MSE: 0.2154, MAE: 0.3292, SWD: 0.0710
    Best round's Validation MSE: 0.3691, MAE: 0.4314
    Best round's Test verification MSE : 0.2154, MAE: 0.3292, SWD: 0.0710
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4816, mae: 0.4099, huber: 0.1741, swd: 0.1861, target_std: 0.7933
    Epoch [1/50], Val Losses: mse: 0.3722, mae: 0.4361, huber: 0.1732, swd: 0.1310, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.2311, mae: 0.3410, huber: 0.1116, swd: 0.0840, target_std: 0.7299
      Epoch 1 composite train-obj: 0.174148
            Val objective improved inf → 0.1732, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4437, mae: 0.3920, huber: 0.1615, swd: 0.1785, target_std: 0.7937
    Epoch [2/50], Val Losses: mse: 0.4147, mae: 0.4537, huber: 0.1880, swd: 0.1833, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.2007, mae: 0.3120, huber: 0.0970, swd: 0.0776, target_std: 0.7299
      Epoch 2 composite train-obj: 0.161535
            No improvement (0.1880), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.4263, mae: 0.3839, huber: 0.1557, swd: 0.1738, target_std: 0.7937
    Epoch [3/50], Val Losses: mse: 0.3812, mae: 0.4391, huber: 0.1762, swd: 0.1420, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2239, mae: 0.3393, huber: 0.1087, swd: 0.0818, target_std: 0.7299
      Epoch 3 composite train-obj: 0.155711
            No improvement (0.1762), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.4160, mae: 0.3785, huber: 0.1521, swd: 0.1718, target_std: 0.7931
    Epoch [4/50], Val Losses: mse: 0.3755, mae: 0.4348, huber: 0.1737, swd: 0.1426, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.2163, mae: 0.3332, huber: 0.1053, swd: 0.0757, target_std: 0.7299
      Epoch 4 composite train-obj: 0.152054
            No improvement (0.1737), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.4030, mae: 0.3717, huber: 0.1474, swd: 0.1657, target_std: 0.7940
    Epoch [5/50], Val Losses: mse: 0.3954, mae: 0.4455, huber: 0.1814, swd: 0.1538, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2194, mae: 0.3315, huber: 0.1060, swd: 0.0789, target_std: 0.7299
      Epoch 5 composite train-obj: 0.147431
            No improvement (0.1814), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.3944, mae: 0.3680, huber: 0.1447, swd: 0.1638, target_std: 0.7938
    Epoch [6/50], Val Losses: mse: 0.3928, mae: 0.4426, huber: 0.1802, swd: 0.1560, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2186, mae: 0.3323, huber: 0.1058, swd: 0.0788, target_std: 0.7299
      Epoch 6 composite train-obj: 0.144670
    Epoch [6/50], Test Losses: mse: 0.2311, mae: 0.3410, huber: 0.1116, swd: 0.0840, target_std: 0.7299
    Best round's Test MSE: 0.2311, MAE: 0.3410, SWD: 0.0840
    Best round's Validation MSE: 0.3722, MAE: 0.4361
    Best round's Test verification MSE : 0.2311, MAE: 0.3410, SWD: 0.0840
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4948, mae: 0.4140, huber: 0.1775, swd: 0.1859, target_std: 0.7968
    Epoch [1/50], Val Losses: mse: 0.3675, mae: 0.4361, huber: 0.1721, swd: 0.1222, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.2190, mae: 0.3316, huber: 0.1063, swd: 0.0736, target_std: 0.7299
      Epoch 1 composite train-obj: 0.177459
            Val objective improved inf → 0.1721, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4620, mae: 0.4000, huber: 0.1673, swd: 0.1846, target_std: 0.7936
    Epoch [2/50], Val Losses: mse: 0.3842, mae: 0.4387, huber: 0.1765, swd: 0.1456, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.2176, mae: 0.3334, huber: 0.1057, swd: 0.0688, target_std: 0.7299
      Epoch 2 composite train-obj: 0.167291
            No improvement (0.1765), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.4378, mae: 0.3879, huber: 0.1591, swd: 0.1761, target_std: 0.7962
    Epoch [3/50], Val Losses: mse: 0.3909, mae: 0.4428, huber: 0.1796, swd: 0.1539, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2033, mae: 0.3187, huber: 0.0987, swd: 0.0637, target_std: 0.7299
      Epoch 3 composite train-obj: 0.159079
            No improvement (0.1796), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.4205, mae: 0.3802, huber: 0.1534, swd: 0.1698, target_std: 0.7930
    Epoch [4/50], Val Losses: mse: 0.3785, mae: 0.4347, huber: 0.1748, swd: 0.1427, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.2103, mae: 0.3233, huber: 0.1018, swd: 0.0662, target_std: 0.7299
      Epoch 4 composite train-obj: 0.153363
            No improvement (0.1748), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.4097, mae: 0.3746, huber: 0.1496, swd: 0.1664, target_std: 0.7934
    Epoch [5/50], Val Losses: mse: 0.3848, mae: 0.4366, huber: 0.1771, swd: 0.1494, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.2149, mae: 0.3280, huber: 0.1040, swd: 0.0690, target_std: 0.7299
      Epoch 5 composite train-obj: 0.149608
            No improvement (0.1771), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.4000, mae: 0.3700, huber: 0.1463, swd: 0.1636, target_std: 0.7934
    Epoch [6/50], Val Losses: mse: 0.3972, mae: 0.4453, huber: 0.1823, swd: 0.1497, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.2189, mae: 0.3348, huber: 0.1062, swd: 0.0667, target_std: 0.7299
      Epoch 6 composite train-obj: 0.146334
    Epoch [6/50], Test Losses: mse: 0.2190, mae: 0.3316, huber: 0.1063, swd: 0.0736, target_std: 0.7299
    Best round's Test MSE: 0.2190, MAE: 0.3316, SWD: 0.0736
    Best round's Validation MSE: 0.3675, MAE: 0.4361
    Best round's Test verification MSE : 0.2190, MAE: 0.3316, SWD: 0.0736
    
    ==================================================
    Experiment Summary (PatchTST_etth2_seq196_pred336_20250502_1208)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2218 ± 0.0067
      mae: 0.3339 ± 0.0051
      huber: 0.1074 ± 0.0031
      swd: 0.0762 ± 0.0056
      target_std: 0.7299 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3696 ± 0.0019
      mae: 0.4345 ± 0.0022
      huber: 0.1722 ± 0.0007
      swd: 0.1295 ± 0.0055
      target_std: 0.9871 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_etth2_seq196_pred336_20250502_1208
    Model: PatchTST
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['etth2']['channels'],
    enc_in=data_mgr.datasets['etth2']['channels'],
    dec_in=data_mgr.datasets['etth2']['channels'],
    c_out=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 89
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 89
    Validation Batches: 7
    Test Batches: 21
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6995, mae: 0.5067, huber: 0.2431, swd: 0.2711, target_std: 0.7985
    Epoch [1/50], Val Losses: mse: 0.4110, mae: 0.4647, huber: 0.1907, swd: 0.0925, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2551, mae: 0.3619, huber: 0.1229, swd: 0.0800, target_std: 0.7295
      Epoch 1 composite train-obj: 0.243135
            Val objective improved inf → 0.1907, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6638, mae: 0.4909, huber: 0.2314, swd: 0.2660, target_std: 0.7973
    Epoch [2/50], Val Losses: mse: 0.4306, mae: 0.4737, huber: 0.1983, swd: 0.0987, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2870, mae: 0.3826, huber: 0.1367, swd: 0.0952, target_std: 0.7295
      Epoch 2 composite train-obj: 0.231440
            No improvement (0.1983), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.6384, mae: 0.4787, huber: 0.2223, swd: 0.2590, target_std: 0.7983
    Epoch [3/50], Val Losses: mse: 0.4209, mae: 0.4700, huber: 0.1946, swd: 0.0979, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.3014, mae: 0.3928, huber: 0.1427, swd: 0.1012, target_std: 0.7295
      Epoch 3 composite train-obj: 0.222289
            No improvement (0.1946), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.6135, mae: 0.4667, huber: 0.2136, swd: 0.2502, target_std: 0.7970
    Epoch [4/50], Val Losses: mse: 0.4044, mae: 0.4600, huber: 0.1879, swd: 0.1089, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2850, mae: 0.3807, huber: 0.1356, swd: 0.0959, target_std: 0.7295
      Epoch 4 composite train-obj: 0.213602
            Val objective improved 0.1907 → 0.1879, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.6050, mae: 0.4612, huber: 0.2100, swd: 0.2470, target_std: 0.7989
    Epoch [5/50], Val Losses: mse: 0.3796, mae: 0.4447, huber: 0.1769, swd: 0.1119, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2693, mae: 0.3651, huber: 0.1281, swd: 0.0966, target_std: 0.7295
      Epoch 5 composite train-obj: 0.210000
            Val objective improved 0.1879 → 0.1769, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.5894, mae: 0.4532, huber: 0.2043, swd: 0.2404, target_std: 0.7987
    Epoch [6/50], Val Losses: mse: 0.4019, mae: 0.4583, huber: 0.1858, swd: 0.1129, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2851, mae: 0.3748, huber: 0.1342, swd: 0.1005, target_std: 0.7295
      Epoch 6 composite train-obj: 0.204275
            No improvement (0.1858), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.5733, mae: 0.4449, huber: 0.1983, swd: 0.2326, target_std: 0.7966
    Epoch [7/50], Val Losses: mse: 0.4145, mae: 0.4668, huber: 0.1916, swd: 0.1165, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2914, mae: 0.3832, huber: 0.1383, swd: 0.1021, target_std: 0.7295
      Epoch 7 composite train-obj: 0.198314
            No improvement (0.1916), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.5669, mae: 0.4400, huber: 0.1952, swd: 0.2290, target_std: 0.7982
    Epoch [8/50], Val Losses: mse: 0.4373, mae: 0.4744, huber: 0.1987, swd: 0.1283, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.3491, mae: 0.4110, huber: 0.1604, swd: 0.1371, target_std: 0.7295
      Epoch 8 composite train-obj: 0.195153
            No improvement (0.1987), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.5715, mae: 0.4418, huber: 0.1965, swd: 0.2327, target_std: 0.7993
    Epoch [9/50], Val Losses: mse: 0.4523, mae: 0.4827, huber: 0.2049, swd: 0.1274, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.3124, mae: 0.3933, huber: 0.1463, swd: 0.1120, target_std: 0.7295
      Epoch 9 composite train-obj: 0.196466
            No improvement (0.2049), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.5497, mae: 0.4307, huber: 0.1887, swd: 0.2209, target_std: 0.7971
    Epoch [10/50], Val Losses: mse: 0.4043, mae: 0.4578, huber: 0.1862, swd: 0.1095, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.3049, mae: 0.3859, huber: 0.1426, swd: 0.1077, target_std: 0.7295
      Epoch 10 composite train-obj: 0.188707
    Epoch [10/50], Test Losses: mse: 0.2693, mae: 0.3651, huber: 0.1281, swd: 0.0966, target_std: 0.7295
    Best round's Test MSE: 0.2693, MAE: 0.3651, SWD: 0.0966
    Best round's Validation MSE: 0.3796, MAE: 0.4447
    Best round's Test verification MSE : 0.2693, MAE: 0.3651, SWD: 0.0966
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6888, mae: 0.5035, huber: 0.2403, swd: 0.2527, target_std: 0.7972
    Epoch [1/50], Val Losses: mse: 0.4467, mae: 0.4864, huber: 0.2053, swd: 0.0886, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2892, mae: 0.3799, huber: 0.1370, swd: 0.0872, target_std: 0.7295
      Epoch 1 composite train-obj: 0.240295
            Val objective improved inf → 0.2053, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6542, mae: 0.4869, huber: 0.2283, swd: 0.2489, target_std: 0.7976
    Epoch [2/50], Val Losses: mse: 0.4267, mae: 0.4745, huber: 0.1972, swd: 0.1032, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2662, mae: 0.3694, huber: 0.1277, swd: 0.0797, target_std: 0.7295
      Epoch 2 composite train-obj: 0.228266
            Val objective improved 0.2053 → 0.1972, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.6319, mae: 0.4754, huber: 0.2200, swd: 0.2425, target_std: 0.7976
    Epoch [3/50], Val Losses: mse: 0.4076, mae: 0.4623, huber: 0.1883, swd: 0.1072, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2716, mae: 0.3683, huber: 0.1295, swd: 0.0816, target_std: 0.7295
      Epoch 3 composite train-obj: 0.219961
            Val objective improved 0.1972 → 0.1883, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.6148, mae: 0.4660, huber: 0.2135, swd: 0.2370, target_std: 0.7978
    Epoch [4/50], Val Losses: mse: 0.3894, mae: 0.4504, huber: 0.1808, swd: 0.1105, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2666, mae: 0.3625, huber: 0.1269, swd: 0.0815, target_std: 0.7295
      Epoch 4 composite train-obj: 0.213464
            Val objective improved 0.1883 → 0.1808, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.5998, mae: 0.4585, huber: 0.2081, swd: 0.2308, target_std: 0.7971
    Epoch [5/50], Val Losses: mse: 0.3838, mae: 0.4484, huber: 0.1793, swd: 0.1081, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2535, mae: 0.3557, huber: 0.1213, swd: 0.0763, target_std: 0.7295
      Epoch 5 composite train-obj: 0.208091
            Val objective improved 0.1808 → 0.1793, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.5870, mae: 0.4521, huber: 0.2035, swd: 0.2269, target_std: 0.7970
    Epoch [6/50], Val Losses: mse: 0.3935, mae: 0.4512, huber: 0.1823, swd: 0.1123, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2816, mae: 0.3728, huber: 0.1331, swd: 0.0903, target_std: 0.7295
      Epoch 6 composite train-obj: 0.203474
            No improvement (0.1823), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.5800, mae: 0.4476, huber: 0.2003, swd: 0.2257, target_std: 0.7979
    Epoch [7/50], Val Losses: mse: 0.3784, mae: 0.4465, huber: 0.1767, swd: 0.1125, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2689, mae: 0.3636, huber: 0.1277, swd: 0.0850, target_std: 0.7295
      Epoch 7 composite train-obj: 0.200329
            Val objective improved 0.1793 → 0.1767, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.5706, mae: 0.4424, huber: 0.1968, swd: 0.2208, target_std: 0.7972
    Epoch [8/50], Val Losses: mse: 0.3845, mae: 0.4484, huber: 0.1793, swd: 0.1029, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2998, mae: 0.3841, huber: 0.1408, swd: 0.0973, target_std: 0.7295
      Epoch 8 composite train-obj: 0.196776
            No improvement (0.1793), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.5649, mae: 0.4394, huber: 0.1946, swd: 0.2194, target_std: 0.7969
    Epoch [9/50], Val Losses: mse: 0.3802, mae: 0.4459, huber: 0.1772, swd: 0.1053, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2922, mae: 0.3788, huber: 0.1376, swd: 0.0930, target_std: 0.7295
      Epoch 9 composite train-obj: 0.194586
            No improvement (0.1772), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.5544, mae: 0.4329, huber: 0.1903, swd: 0.2146, target_std: 0.7976
    Epoch [10/50], Val Losses: mse: 0.3751, mae: 0.4441, huber: 0.1754, swd: 0.1030, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.2811, mae: 0.3712, huber: 0.1328, swd: 0.0896, target_std: 0.7295
      Epoch 10 composite train-obj: 0.190347
            Val objective improved 0.1767 → 0.1754, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 0.5457, mae: 0.4284, huber: 0.1872, swd: 0.2106, target_std: 0.7967
    Epoch [11/50], Val Losses: mse: 0.4030, mae: 0.4577, huber: 0.1863, swd: 0.1111, target_std: 0.9872
    Epoch [11/50], Test Losses: mse: 0.3139, mae: 0.3932, huber: 0.1468, swd: 0.1018, target_std: 0.7295
      Epoch 11 composite train-obj: 0.187194
            No improvement (0.1863), counter 1/5
    Epoch [12/50], Train Losses: mse: 0.5411, mae: 0.4245, huber: 0.1848, swd: 0.2089, target_std: 0.7984
    Epoch [12/50], Val Losses: mse: 0.4154, mae: 0.4634, huber: 0.1906, swd: 0.1162, target_std: 0.9872
    Epoch [12/50], Test Losses: mse: 0.3465, mae: 0.4078, huber: 0.1588, swd: 0.1161, target_std: 0.7295
      Epoch 12 composite train-obj: 0.184806
            No improvement (0.1906), counter 2/5
    Epoch [13/50], Train Losses: mse: 0.5356, mae: 0.4214, huber: 0.1828, swd: 0.2062, target_std: 0.7984
    Epoch [13/50], Val Losses: mse: 0.4026, mae: 0.4593, huber: 0.1864, swd: 0.1070, target_std: 0.9872
    Epoch [13/50], Test Losses: mse: 0.3196, mae: 0.3939, huber: 0.1484, swd: 0.1052, target_std: 0.7295
      Epoch 13 composite train-obj: 0.182776
            No improvement (0.1864), counter 3/5
    Epoch [14/50], Train Losses: mse: 0.5292, mae: 0.4170, huber: 0.1800, swd: 0.2042, target_std: 0.7984
    Epoch [14/50], Val Losses: mse: 0.4034, mae: 0.4600, huber: 0.1871, swd: 0.0999, target_std: 0.9872
    Epoch [14/50], Test Losses: mse: 0.3467, mae: 0.4106, huber: 0.1595, swd: 0.1192, target_std: 0.7295
      Epoch 14 composite train-obj: 0.179997
            No improvement (0.1871), counter 4/5
    Epoch [15/50], Train Losses: mse: 0.5248, mae: 0.4150, huber: 0.1786, swd: 0.2019, target_std: 0.7968
    Epoch [15/50], Val Losses: mse: 0.4224, mae: 0.4699, huber: 0.1945, swd: 0.1106, target_std: 0.9872
    Epoch [15/50], Test Losses: mse: 0.3529, mae: 0.4171, huber: 0.1630, swd: 0.1172, target_std: 0.7295
      Epoch 15 composite train-obj: 0.178601
    Epoch [15/50], Test Losses: mse: 0.2811, mae: 0.3712, huber: 0.1328, swd: 0.0896, target_std: 0.7295
    Best round's Test MSE: 0.2811, MAE: 0.3712, SWD: 0.0896
    Best round's Validation MSE: 0.3751, MAE: 0.4441
    Best round's Test verification MSE : 0.2811, MAE: 0.3712, SWD: 0.0896
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6942, mae: 0.5055, huber: 0.2419, swd: 0.2833, target_std: 0.7971
    Epoch [1/50], Val Losses: mse: 0.4184, mae: 0.4686, huber: 0.1939, swd: 0.1044, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2594, mae: 0.3635, huber: 0.1249, swd: 0.0835, target_std: 0.7295
      Epoch 1 composite train-obj: 0.241907
            Val objective improved inf → 0.1939, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.6499, mae: 0.4855, huber: 0.2269, swd: 0.2728, target_std: 0.7965
    Epoch [2/50], Val Losses: mse: 0.3970, mae: 0.4572, huber: 0.1849, swd: 0.1067, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2670, mae: 0.3671, huber: 0.1279, swd: 0.0885, target_std: 0.7295
      Epoch 2 composite train-obj: 0.226944
            Val objective improved 0.1939 → 0.1849, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.6343, mae: 0.4763, huber: 0.2206, swd: 0.2668, target_std: 0.7992
    Epoch [3/50], Val Losses: mse: 0.4096, mae: 0.4629, huber: 0.1887, swd: 0.1203, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2857, mae: 0.3857, huber: 0.1370, swd: 0.0931, target_std: 0.7295
      Epoch 3 composite train-obj: 0.220569
            No improvement (0.1887), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.6178, mae: 0.4674, huber: 0.2143, swd: 0.2611, target_std: 0.7987
    Epoch [4/50], Val Losses: mse: 0.3922, mae: 0.4516, huber: 0.1817, swd: 0.1223, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2679, mae: 0.3712, huber: 0.1287, swd: 0.0895, target_std: 0.7295
      Epoch 4 composite train-obj: 0.214299
            Val objective improved 0.1849 → 0.1817, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.6044, mae: 0.4593, huber: 0.2087, swd: 0.2565, target_std: 0.8006
    Epoch [5/50], Val Losses: mse: 0.4134, mae: 0.4624, huber: 0.1902, swd: 0.1171, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.3184, mae: 0.4040, huber: 0.1508, swd: 0.1168, target_std: 0.7295
      Epoch 5 composite train-obj: 0.208746
            No improvement (0.1902), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.5925, mae: 0.4541, huber: 0.2047, swd: 0.2505, target_std: 0.7984
    Epoch [6/50], Val Losses: mse: 0.4236, mae: 0.4688, huber: 0.1938, swd: 0.1305, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.3269, mae: 0.4024, huber: 0.1531, swd: 0.1248, target_std: 0.7295
      Epoch 6 composite train-obj: 0.204717
            No improvement (0.1938), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.5753, mae: 0.4448, huber: 0.1984, swd: 0.2430, target_std: 0.7984
    Epoch [7/50], Val Losses: mse: 0.4050, mae: 0.4623, huber: 0.1873, swd: 0.1173, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.3117, mae: 0.3968, huber: 0.1475, swd: 0.1152, target_std: 0.7295
      Epoch 7 composite train-obj: 0.198415
            No improvement (0.1873), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.5636, mae: 0.4389, huber: 0.1943, swd: 0.2378, target_std: 0.7978
    Epoch [8/50], Val Losses: mse: 0.3965, mae: 0.4559, huber: 0.1834, swd: 0.1138, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2995, mae: 0.3906, huber: 0.1426, swd: 0.1041, target_std: 0.7295
      Epoch 8 composite train-obj: 0.194272
            No improvement (0.1834), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.5551, mae: 0.4339, huber: 0.1910, swd: 0.2340, target_std: 0.7978
    Epoch [9/50], Val Losses: mse: 0.3959, mae: 0.4571, huber: 0.1838, swd: 0.1173, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2939, mae: 0.3826, huber: 0.1392, swd: 0.1096, target_std: 0.7295
      Epoch 9 composite train-obj: 0.190957
    Epoch [9/50], Test Losses: mse: 0.2679, mae: 0.3712, huber: 0.1287, swd: 0.0895, target_std: 0.7295
    Best round's Test MSE: 0.2679, MAE: 0.3712, SWD: 0.0895
    Best round's Validation MSE: 0.3922, MAE: 0.4516
    Best round's Test verification MSE : 0.2679, MAE: 0.3712, SWD: 0.0895
    
    ==================================================
    Experiment Summary (PatchTST_etth2_seq196_pred720_20250502_1209)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2728 ± 0.0059
      mae: 0.3691 ± 0.0029
      huber: 0.1299 ± 0.0021
      swd: 0.0919 ± 0.0033
      target_std: 0.7295 ± 0.0000
      count: 7.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3823 ± 0.0073
      mae: 0.4468 ± 0.0034
      huber: 0.1780 ± 0.0027
      swd: 0.1124 ± 0.0079
      target_std: 0.9872 ± 0.0000
      count: 7.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_etth2_seq196_pred720_20250502_1209
    Model: PatchTST
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### pred=96


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 12
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3773, mae: 0.3710, huber: 0.1438, swd: 0.1410, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2809, mae: 0.3692, huber: 0.1326, swd: 0.1185, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1568, mae: 0.2794, huber: 0.0768, swd: 0.0543, target_std: 0.7274
      Epoch 1 composite train-obj: 0.143758
            Val objective improved inf → 0.1326, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2819, mae: 0.3107, huber: 0.1085, swd: 0.1167, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2744, mae: 0.3611, huber: 0.1292, swd: 0.1238, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1483, mae: 0.2699, huber: 0.0726, swd: 0.0551, target_std: 0.7274
      Epoch 2 composite train-obj: 0.108514
            Val objective improved 0.1326 → 0.1292, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2733, mae: 0.3036, huber: 0.1049, swd: 0.1121, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2673, mae: 0.3545, huber: 0.1261, swd: 0.1182, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1491, mae: 0.2715, huber: 0.0731, swd: 0.0560, target_std: 0.7274
      Epoch 3 composite train-obj: 0.104941
            Val objective improved 0.1292 → 0.1261, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2693, mae: 0.3004, huber: 0.1034, swd: 0.1103, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2648, mae: 0.3528, huber: 0.1252, swd: 0.1148, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1459, mae: 0.2669, huber: 0.0715, swd: 0.0535, target_std: 0.7274
      Epoch 4 composite train-obj: 0.103377
            Val objective improved 0.1261 → 0.1252, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2673, mae: 0.2992, huber: 0.1027, swd: 0.1093, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2616, mae: 0.3499, huber: 0.1237, swd: 0.1134, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1500, mae: 0.2708, huber: 0.0734, swd: 0.0575, target_std: 0.7274
      Epoch 5 composite train-obj: 0.102672
            Val objective improved 0.1252 → 0.1237, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2666, mae: 0.2988, huber: 0.1024, swd: 0.1092, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2624, mae: 0.3507, huber: 0.1244, swd: 0.1098, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1472, mae: 0.2689, huber: 0.0721, swd: 0.0534, target_std: 0.7274
      Epoch 6 composite train-obj: 0.102371
            No improvement (0.1244), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.2661, mae: 0.2983, huber: 0.1021, swd: 0.1084, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2648, mae: 0.3533, huber: 0.1255, swd: 0.1144, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1445, mae: 0.2658, huber: 0.0709, swd: 0.0521, target_std: 0.7274
      Epoch 7 composite train-obj: 0.102139
            No improvement (0.1255), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.2657, mae: 0.2981, huber: 0.1021, swd: 0.1088, target_std: 0.7909
    Epoch [8/50], Val Losses: mse: 0.2624, mae: 0.3507, huber: 0.1242, swd: 0.1094, target_std: 0.9930
    Epoch [8/50], Test Losses: mse: 0.1431, mae: 0.2650, huber: 0.0702, swd: 0.0491, target_std: 0.7274
      Epoch 8 composite train-obj: 0.102081
            No improvement (0.1242), counter 3/5
    Epoch [9/50], Train Losses: mse: 0.2660, mae: 0.2987, huber: 0.1022, swd: 0.1090, target_std: 0.7909
    Epoch [9/50], Val Losses: mse: 0.2656, mae: 0.3539, huber: 0.1255, swd: 0.1162, target_std: 0.9930
    Epoch [9/50], Test Losses: mse: 0.1451, mae: 0.2668, huber: 0.0712, swd: 0.0540, target_std: 0.7274
      Epoch 9 composite train-obj: 0.102228
            No improvement (0.1255), counter 4/5
    Epoch [10/50], Train Losses: mse: 0.2649, mae: 0.2978, huber: 0.1018, swd: 0.1086, target_std: 0.7909
    Epoch [10/50], Val Losses: mse: 0.2666, mae: 0.3536, huber: 0.1256, swd: 0.1181, target_std: 0.9930
    Epoch [10/50], Test Losses: mse: 0.1466, mae: 0.2669, huber: 0.0718, swd: 0.0550, target_std: 0.7274
      Epoch 10 composite train-obj: 0.101810
    Epoch [10/50], Test Losses: mse: 0.1500, mae: 0.2708, huber: 0.0734, swd: 0.0575, target_std: 0.7274
    Best round's Test MSE: 0.1500, MAE: 0.2708, SWD: 0.0575
    Best round's Validation MSE: 0.2616, MAE: 0.3499
    Best round's Test verification MSE : 0.1500, MAE: 0.2708, SWD: 0.0575
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3737, mae: 0.3695, huber: 0.1429, swd: 0.1382, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2803, mae: 0.3690, huber: 0.1323, swd: 0.1173, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1565, mae: 0.2790, huber: 0.0766, swd: 0.0542, target_std: 0.7274
      Epoch 1 composite train-obj: 0.142886
            Val objective improved inf → 0.1323, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2822, mae: 0.3107, huber: 0.1086, swd: 0.1152, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2697, mae: 0.3579, huber: 0.1271, swd: 0.1183, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1506, mae: 0.2723, huber: 0.0738, swd: 0.0555, target_std: 0.7274
      Epoch 2 composite train-obj: 0.108577
            Val objective improved 0.1323 → 0.1271, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2728, mae: 0.3037, huber: 0.1049, swd: 0.1113, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2645, mae: 0.3524, huber: 0.1251, swd: 0.1108, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1460, mae: 0.2675, huber: 0.0716, swd: 0.0499, target_std: 0.7274
      Epoch 3 composite train-obj: 0.104926
            Val objective improved 0.1271 → 0.1251, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.2694, mae: 0.3005, huber: 0.1034, swd: 0.1091, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2626, mae: 0.3506, huber: 0.1245, swd: 0.1080, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1474, mae: 0.2683, huber: 0.0723, swd: 0.0521, target_std: 0.7274
      Epoch 4 composite train-obj: 0.103402
            Val objective improved 0.1251 → 0.1245, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2678, mae: 0.2997, huber: 0.1029, swd: 0.1087, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2631, mae: 0.3520, huber: 0.1242, swd: 0.1132, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1493, mae: 0.2710, huber: 0.0731, swd: 0.0566, target_std: 0.7274
      Epoch 5 composite train-obj: 0.102875
            Val objective improved 0.1245 → 0.1242, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.2666, mae: 0.2988, huber: 0.1024, swd: 0.1082, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2684, mae: 0.3562, huber: 0.1273, swd: 0.1123, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1443, mae: 0.2660, huber: 0.0708, swd: 0.0497, target_std: 0.7274
      Epoch 6 composite train-obj: 0.102435
            No improvement (0.1273), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.2659, mae: 0.2982, huber: 0.1021, swd: 0.1082, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2643, mae: 0.3526, huber: 0.1256, swd: 0.1074, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1458, mae: 0.2671, huber: 0.0714, swd: 0.0497, target_std: 0.7274
      Epoch 7 composite train-obj: 0.102066
            No improvement (0.1256), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.2656, mae: 0.2982, huber: 0.1021, swd: 0.1076, target_std: 0.7909
    Epoch [8/50], Val Losses: mse: 0.2603, mae: 0.3490, huber: 0.1232, swd: 0.1099, target_std: 0.9930
    Epoch [8/50], Test Losses: mse: 0.1536, mae: 0.2743, huber: 0.0750, swd: 0.0580, target_std: 0.7274
      Epoch 8 composite train-obj: 0.102066
            Val objective improved 0.1242 → 0.1232, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.2652, mae: 0.2979, huber: 0.1019, swd: 0.1076, target_std: 0.7909
    Epoch [9/50], Val Losses: mse: 0.2661, mae: 0.3539, huber: 0.1263, swd: 0.1060, target_std: 0.9930
    Epoch [9/50], Test Losses: mse: 0.1461, mae: 0.2672, huber: 0.0716, swd: 0.0486, target_std: 0.7274
      Epoch 9 composite train-obj: 0.101859
            No improvement (0.1263), counter 1/5
    Epoch [10/50], Train Losses: mse: 0.2657, mae: 0.2982, huber: 0.1020, swd: 0.1076, target_std: 0.7909
    Epoch [10/50], Val Losses: mse: 0.2621, mae: 0.3492, huber: 0.1236, swd: 0.1145, target_std: 0.9930
    Epoch [10/50], Test Losses: mse: 0.1521, mae: 0.2731, huber: 0.0744, swd: 0.0583, target_std: 0.7274
      Epoch 10 composite train-obj: 0.101997
            No improvement (0.1236), counter 2/5
    Epoch [11/50], Train Losses: mse: 0.2648, mae: 0.2977, huber: 0.1017, swd: 0.1073, target_std: 0.7909
    Epoch [11/50], Val Losses: mse: 0.2635, mae: 0.3517, huber: 0.1247, swd: 0.1110, target_std: 0.9930
    Epoch [11/50], Test Losses: mse: 0.1445, mae: 0.2660, huber: 0.0708, swd: 0.0511, target_std: 0.7274
      Epoch 11 composite train-obj: 0.101747
            No improvement (0.1247), counter 3/5
    Epoch [12/50], Train Losses: mse: 0.2652, mae: 0.2982, huber: 0.1019, swd: 0.1076, target_std: 0.7909
    Epoch [12/50], Val Losses: mse: 0.2705, mae: 0.3576, huber: 0.1280, swd: 0.1159, target_std: 0.9930
    Epoch [12/50], Test Losses: mse: 0.1418, mae: 0.2640, huber: 0.0696, swd: 0.0492, target_std: 0.7274
      Epoch 12 composite train-obj: 0.101910
            No improvement (0.1280), counter 4/5
    Epoch [13/50], Train Losses: mse: 0.2650, mae: 0.2977, huber: 0.1018, swd: 0.1076, target_std: 0.7909
    Epoch [13/50], Val Losses: mse: 0.2615, mae: 0.3486, huber: 0.1235, swd: 0.1095, target_std: 0.9930
    Epoch [13/50], Test Losses: mse: 0.1471, mae: 0.2688, huber: 0.0721, swd: 0.0527, target_std: 0.7274
      Epoch 13 composite train-obj: 0.101753
    Epoch [13/50], Test Losses: mse: 0.1536, mae: 0.2743, huber: 0.0750, swd: 0.0580, target_std: 0.7274
    Best round's Test MSE: 0.1536, MAE: 0.2743, SWD: 0.0580
    Best round's Validation MSE: 0.2603, MAE: 0.3490
    Best round's Test verification MSE : 0.1536, MAE: 0.2743, SWD: 0.0580
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3812, mae: 0.3723, huber: 0.1448, swd: 0.1272, target_std: 0.7909
    Epoch [1/50], Val Losses: mse: 0.2816, mae: 0.3697, huber: 0.1328, swd: 0.1097, target_std: 0.9930
    Epoch [1/50], Test Losses: mse: 0.1579, mae: 0.2808, huber: 0.0773, swd: 0.0517, target_std: 0.7274
      Epoch 1 composite train-obj: 0.144786
            Val objective improved inf → 0.1328, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2837, mae: 0.3119, huber: 0.1091, swd: 0.1077, target_std: 0.7909
    Epoch [2/50], Val Losses: mse: 0.2696, mae: 0.3575, huber: 0.1274, swd: 0.1058, target_std: 0.9930
    Epoch [2/50], Test Losses: mse: 0.1482, mae: 0.2704, huber: 0.0726, swd: 0.0488, target_std: 0.7274
      Epoch 2 composite train-obj: 0.109093
            Val objective improved 0.1328 → 0.1274, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2731, mae: 0.3037, huber: 0.1050, swd: 0.1035, target_std: 0.7909
    Epoch [3/50], Val Losses: mse: 0.2697, mae: 0.3590, huber: 0.1276, swd: 0.1062, target_std: 0.9930
    Epoch [3/50], Test Losses: mse: 0.1426, mae: 0.2654, huber: 0.0700, swd: 0.0448, target_std: 0.7274
      Epoch 3 composite train-obj: 0.105019
            No improvement (0.1276), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2696, mae: 0.3010, huber: 0.1036, swd: 0.1022, target_std: 0.7909
    Epoch [4/50], Val Losses: mse: 0.2644, mae: 0.3524, huber: 0.1251, swd: 0.1022, target_std: 0.9930
    Epoch [4/50], Test Losses: mse: 0.1449, mae: 0.2669, huber: 0.0711, swd: 0.0471, target_std: 0.7274
      Epoch 4 composite train-obj: 0.103564
            Val objective improved 0.1274 → 0.1251, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.2680, mae: 0.2993, huber: 0.1028, swd: 0.1011, target_std: 0.7909
    Epoch [5/50], Val Losses: mse: 0.2664, mae: 0.3541, huber: 0.1256, swd: 0.1080, target_std: 0.9930
    Epoch [5/50], Test Losses: mse: 0.1464, mae: 0.2666, huber: 0.0718, swd: 0.0499, target_std: 0.7274
      Epoch 5 composite train-obj: 0.102783
            No improvement (0.1256), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.2669, mae: 0.2986, huber: 0.1024, swd: 0.1009, target_std: 0.7909
    Epoch [6/50], Val Losses: mse: 0.2645, mae: 0.3535, huber: 0.1256, swd: 0.1018, target_std: 0.9930
    Epoch [6/50], Test Losses: mse: 0.1492, mae: 0.2693, huber: 0.0729, swd: 0.0497, target_std: 0.7274
      Epoch 6 composite train-obj: 0.102414
            No improvement (0.1256), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.2663, mae: 0.2985, huber: 0.1023, swd: 0.1003, target_std: 0.7909
    Epoch [7/50], Val Losses: mse: 0.2608, mae: 0.3496, huber: 0.1235, swd: 0.1009, target_std: 0.9930
    Epoch [7/50], Test Losses: mse: 0.1473, mae: 0.2675, huber: 0.0722, swd: 0.0493, target_std: 0.7274
      Epoch 7 composite train-obj: 0.102263
            Val objective improved 0.1251 → 0.1235, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.2656, mae: 0.2980, huber: 0.1020, swd: 0.1002, target_std: 0.7909
    Epoch [8/50], Val Losses: mse: 0.2618, mae: 0.3486, huber: 0.1235, swd: 0.1011, target_std: 0.9930
    Epoch [8/50], Test Losses: mse: 0.1491, mae: 0.2719, huber: 0.0731, swd: 0.0510, target_std: 0.7274
      Epoch 8 composite train-obj: 0.102007
            No improvement (0.1235), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.2651, mae: 0.2978, huber: 0.1019, swd: 0.1001, target_std: 0.7909
    Epoch [9/50], Val Losses: mse: 0.2624, mae: 0.3511, huber: 0.1237, swd: 0.1046, target_std: 0.9930
    Epoch [9/50], Test Losses: mse: 0.1515, mae: 0.2708, huber: 0.0740, swd: 0.0539, target_std: 0.7274
      Epoch 9 composite train-obj: 0.101868
            No improvement (0.1237), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.2653, mae: 0.2978, huber: 0.1019, swd: 0.1002, target_std: 0.7909
    Epoch [10/50], Val Losses: mse: 0.2647, mae: 0.3534, huber: 0.1250, swd: 0.1051, target_std: 0.9930
    Epoch [10/50], Test Losses: mse: 0.1440, mae: 0.2653, huber: 0.0706, swd: 0.0488, target_std: 0.7274
      Epoch 10 composite train-obj: 0.101867
            No improvement (0.1250), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.2649, mae: 0.2979, huber: 0.1018, swd: 0.1000, target_std: 0.7909
    Epoch [11/50], Val Losses: mse: 0.2617, mae: 0.3502, huber: 0.1239, swd: 0.1001, target_std: 0.9930
    Epoch [11/50], Test Losses: mse: 0.1495, mae: 0.2715, huber: 0.0733, swd: 0.0487, target_std: 0.7274
      Epoch 11 composite train-obj: 0.101849
            No improvement (0.1239), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.2656, mae: 0.2983, huber: 0.1020, swd: 0.1001, target_std: 0.7909
    Epoch [12/50], Val Losses: mse: 0.2595, mae: 0.3482, huber: 0.1227, swd: 0.1017, target_std: 0.9930
    Epoch [12/50], Test Losses: mse: 0.1534, mae: 0.2778, huber: 0.0751, swd: 0.0543, target_std: 0.7274
      Epoch 12 composite train-obj: 0.101984
            Val objective improved 0.1235 → 0.1227, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 0.2649, mae: 0.2975, huber: 0.1017, swd: 0.0998, target_std: 0.7909
    Epoch [13/50], Val Losses: mse: 0.2644, mae: 0.3519, huber: 0.1252, swd: 0.0992, target_std: 0.9930
    Epoch [13/50], Test Losses: mse: 0.1470, mae: 0.2683, huber: 0.0721, swd: 0.0483, target_std: 0.7274
      Epoch 13 composite train-obj: 0.101692
            No improvement (0.1252), counter 1/5
    Epoch [14/50], Train Losses: mse: 0.2648, mae: 0.2981, huber: 0.1018, swd: 0.1001, target_std: 0.7909
    Epoch [14/50], Val Losses: mse: 0.2614, mae: 0.3495, huber: 0.1236, swd: 0.1016, target_std: 0.9930
    Epoch [14/50], Test Losses: mse: 0.1472, mae: 0.2696, huber: 0.0722, swd: 0.0488, target_std: 0.7274
      Epoch 14 composite train-obj: 0.101822
            No improvement (0.1236), counter 2/5
    Epoch [15/50], Train Losses: mse: 0.2655, mae: 0.2981, huber: 0.1020, swd: 0.0999, target_std: 0.7909
    Epoch [15/50], Val Losses: mse: 0.2615, mae: 0.3519, huber: 0.1239, swd: 0.1008, target_std: 0.9930
    Epoch [15/50], Test Losses: mse: 0.1427, mae: 0.2644, huber: 0.0700, swd: 0.0466, target_std: 0.7274
      Epoch 15 composite train-obj: 0.102006
            No improvement (0.1239), counter 3/5
    Epoch [16/50], Train Losses: mse: 0.2649, mae: 0.2981, huber: 0.1018, swd: 0.1001, target_std: 0.7909
    Epoch [16/50], Val Losses: mse: 0.2701, mae: 0.3570, huber: 0.1269, swd: 0.1145, target_std: 0.9930
    Epoch [16/50], Test Losses: mse: 0.1516, mae: 0.2729, huber: 0.0742, swd: 0.0546, target_std: 0.7274
      Epoch 16 composite train-obj: 0.101832
            No improvement (0.1269), counter 4/5
    Epoch [17/50], Train Losses: mse: 0.2651, mae: 0.2982, huber: 0.1018, swd: 0.1000, target_std: 0.7909
    Epoch [17/50], Val Losses: mse: 0.2671, mae: 0.3537, huber: 0.1259, swd: 0.1083, target_std: 0.9930
    Epoch [17/50], Test Losses: mse: 0.1453, mae: 0.2668, huber: 0.0712, swd: 0.0501, target_std: 0.7274
      Epoch 17 composite train-obj: 0.101847
    Epoch [17/50], Test Losses: mse: 0.1534, mae: 0.2778, huber: 0.0751, swd: 0.0543, target_std: 0.7274
    Best round's Test MSE: 0.1534, MAE: 0.2778, SWD: 0.0543
    Best round's Validation MSE: 0.2595, MAE: 0.3482
    Best round's Test verification MSE : 0.1534, MAE: 0.2778, SWD: 0.0543
    
    ==================================================
    Experiment Summary (DLinear_etth2_seq196_pred96_20250502_1210)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1524 ± 0.0016
      mae: 0.2743 ± 0.0028
      huber: 0.0745 ± 0.0008
      swd: 0.0566 ± 0.0016
      target_std: 0.7274 ± 0.0000
      count: 12.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2604 ± 0.0009
      mae: 0.3491 ± 0.0007
      huber: 0.1232 ± 0.0004
      swd: 0.1083 ± 0.0049
      target_std: 0.9930 ± 0.0000
      count: 12.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_etth2_seq196_pred96_20250502_1210
    Model: DLinear
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 93
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 93
    Validation Batches: 11
    Test Batches: 25
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4452, mae: 0.4059, huber: 0.1665, swd: 0.1726, target_std: 0.7923
    Epoch [1/50], Val Losses: mse: 0.3548, mae: 0.4219, huber: 0.1647, swd: 0.1523, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1810, mae: 0.3004, huber: 0.0883, swd: 0.0676, target_std: 0.7295
      Epoch 1 composite train-obj: 0.166534
            Val objective improved inf → 0.1647, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3588, mae: 0.3533, huber: 0.1349, swd: 0.1544, target_std: 0.7922
    Epoch [2/50], Val Losses: mse: 0.3544, mae: 0.4181, huber: 0.1641, swd: 0.1604, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1739, mae: 0.2923, huber: 0.0848, swd: 0.0677, target_std: 0.7295
      Epoch 2 composite train-obj: 0.134890
            Val objective improved 0.1647 → 0.1641, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3537, mae: 0.3482, huber: 0.1325, swd: 0.1527, target_std: 0.7921
    Epoch [3/50], Val Losses: mse: 0.3545, mae: 0.4173, huber: 0.1639, swd: 0.1617, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1734, mae: 0.2935, huber: 0.0846, swd: 0.0689, target_std: 0.7295
      Epoch 3 composite train-obj: 0.132512
            Val objective improved 0.1641 → 0.1639, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3483, mae: 0.3456, huber: 0.1308, swd: 0.1504, target_std: 0.7918
    Epoch [4/50], Val Losses: mse: 0.3361, mae: 0.4056, huber: 0.1571, swd: 0.1389, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1761, mae: 0.2961, huber: 0.0860, swd: 0.0685, target_std: 0.7295
      Epoch 4 composite train-obj: 0.130777
            Val objective improved 0.1639 → 0.1571, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3473, mae: 0.3446, huber: 0.1303, swd: 0.1499, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3337, mae: 0.4044, huber: 0.1558, swd: 0.1411, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1721, mae: 0.2922, huber: 0.0841, swd: 0.0650, target_std: 0.7295
      Epoch 5 composite train-obj: 0.130267
            Val objective improved 0.1571 → 0.1558, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.3485, mae: 0.3444, huber: 0.1304, swd: 0.1503, target_std: 0.7922
    Epoch [6/50], Val Losses: mse: 0.3380, mae: 0.4068, huber: 0.1577, swd: 0.1458, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1713, mae: 0.2903, huber: 0.0838, swd: 0.0670, target_std: 0.7295
      Epoch 6 composite train-obj: 0.130423
            No improvement (0.1577), counter 1/5
    Epoch [7/50], Train Losses: mse: 0.3453, mae: 0.3434, huber: 0.1296, swd: 0.1492, target_std: 0.7912
    Epoch [7/50], Val Losses: mse: 0.3333, mae: 0.4049, huber: 0.1560, swd: 0.1379, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1740, mae: 0.2946, huber: 0.0850, swd: 0.0672, target_std: 0.7295
      Epoch 7 composite train-obj: 0.129601
            No improvement (0.1560), counter 2/5
    Epoch [8/50], Train Losses: mse: 0.3451, mae: 0.3431, huber: 0.1294, swd: 0.1488, target_std: 0.7922
    Epoch [8/50], Val Losses: mse: 0.3335, mae: 0.4044, huber: 0.1556, swd: 0.1389, target_std: 0.9936
    Epoch [8/50], Test Losses: mse: 0.1796, mae: 0.3040, huber: 0.0878, swd: 0.0719, target_std: 0.7295
      Epoch 8 composite train-obj: 0.129430
            Val objective improved 0.1558 → 0.1556, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.3448, mae: 0.3427, huber: 0.1292, swd: 0.1486, target_std: 0.7912
    Epoch [9/50], Val Losses: mse: 0.3346, mae: 0.4044, huber: 0.1560, swd: 0.1431, target_std: 0.9936
    Epoch [9/50], Test Losses: mse: 0.1804, mae: 0.2999, huber: 0.0879, swd: 0.0739, target_std: 0.7295
      Epoch 9 composite train-obj: 0.129191
            No improvement (0.1560), counter 1/5
    Epoch [10/50], Train Losses: mse: 0.3462, mae: 0.3431, huber: 0.1295, swd: 0.1491, target_std: 0.7920
    Epoch [10/50], Val Losses: mse: 0.3319, mae: 0.4032, huber: 0.1553, swd: 0.1373, target_std: 0.9936
    Epoch [10/50], Test Losses: mse: 0.1725, mae: 0.2907, huber: 0.0843, swd: 0.0655, target_std: 0.7295
      Epoch 10 composite train-obj: 0.129520
            Val objective improved 0.1556 → 0.1553, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 0.3472, mae: 0.3433, huber: 0.1298, swd: 0.1497, target_std: 0.7925
    Epoch [11/50], Val Losses: mse: 0.3353, mae: 0.4073, huber: 0.1571, swd: 0.1405, target_std: 0.9936
    Epoch [11/50], Test Losses: mse: 0.1751, mae: 0.2939, huber: 0.0854, swd: 0.0693, target_std: 0.7295
      Epoch 11 composite train-obj: 0.129768
            No improvement (0.1571), counter 1/5
    Epoch [12/50], Train Losses: mse: 0.3456, mae: 0.3429, huber: 0.1293, swd: 0.1491, target_std: 0.7927
    Epoch [12/50], Val Losses: mse: 0.3446, mae: 0.4109, huber: 0.1601, swd: 0.1524, target_std: 0.9936
    Epoch [12/50], Test Losses: mse: 0.1683, mae: 0.2880, huber: 0.0823, swd: 0.0635, target_std: 0.7295
      Epoch 12 composite train-obj: 0.129255
            No improvement (0.1601), counter 2/5
    Epoch [13/50], Train Losses: mse: 0.3485, mae: 0.3440, huber: 0.1302, swd: 0.1510, target_std: 0.7935
    Epoch [13/50], Val Losses: mse: 0.3533, mae: 0.4183, huber: 0.1638, swd: 0.1616, target_std: 0.9936
    Epoch [13/50], Test Losses: mse: 0.1687, mae: 0.2877, huber: 0.0825, swd: 0.0665, target_std: 0.7295
      Epoch 13 composite train-obj: 0.130166
            No improvement (0.1638), counter 3/5
    Epoch [14/50], Train Losses: mse: 0.3444, mae: 0.3429, huber: 0.1292, swd: 0.1483, target_std: 0.7916
    Epoch [14/50], Val Losses: mse: 0.3314, mae: 0.4036, huber: 0.1550, swd: 0.1358, target_std: 0.9936
    Epoch [14/50], Test Losses: mse: 0.1748, mae: 0.2928, huber: 0.0853, swd: 0.0668, target_std: 0.7295
      Epoch 14 composite train-obj: 0.129224
            Val objective improved 0.1553 → 0.1550, saving checkpoint.
    Epoch [15/50], Train Losses: mse: 0.3452, mae: 0.3431, huber: 0.1294, swd: 0.1487, target_std: 0.7914
    Epoch [15/50], Val Losses: mse: 0.3426, mae: 0.4106, huber: 0.1595, swd: 0.1472, target_std: 0.9936
    Epoch [15/50], Test Losses: mse: 0.1659, mae: 0.2862, huber: 0.0814, swd: 0.0609, target_std: 0.7295
      Epoch 15 composite train-obj: 0.129353
            No improvement (0.1595), counter 1/5
    Epoch [16/50], Train Losses: mse: 0.3450, mae: 0.3429, huber: 0.1292, swd: 0.1491, target_std: 0.7926
    Epoch [16/50], Val Losses: mse: 0.3390, mae: 0.4076, huber: 0.1585, swd: 0.1450, target_std: 0.9936
    Epoch [16/50], Test Losses: mse: 0.1749, mae: 0.2942, huber: 0.0854, swd: 0.0702, target_std: 0.7295
      Epoch 16 composite train-obj: 0.129216
            No improvement (0.1585), counter 2/5
    Epoch [17/50], Train Losses: mse: 0.3453, mae: 0.3434, huber: 0.1295, swd: 0.1485, target_std: 0.7913
    Epoch [17/50], Val Losses: mse: 0.3342, mae: 0.4064, huber: 0.1562, swd: 0.1460, target_std: 0.9936
    Epoch [17/50], Test Losses: mse: 0.1770, mae: 0.2948, huber: 0.0862, swd: 0.0733, target_std: 0.7295
      Epoch 17 composite train-obj: 0.129456
            No improvement (0.1562), counter 3/5
    Epoch [18/50], Train Losses: mse: 0.3463, mae: 0.3440, huber: 0.1298, swd: 0.1489, target_std: 0.7922
    Epoch [18/50], Val Losses: mse: 0.3498, mae: 0.4162, huber: 0.1621, swd: 0.1601, target_std: 0.9936
    Epoch [18/50], Test Losses: mse: 0.1684, mae: 0.2889, huber: 0.0824, swd: 0.0655, target_std: 0.7295
      Epoch 18 composite train-obj: 0.129784
            No improvement (0.1621), counter 4/5
    Epoch [19/50], Train Losses: mse: 0.3449, mae: 0.3438, huber: 0.1294, swd: 0.1484, target_std: 0.7929
    Epoch [19/50], Val Losses: mse: 0.3309, mae: 0.4022, huber: 0.1547, swd: 0.1390, target_std: 0.9936
    Epoch [19/50], Test Losses: mse: 0.1798, mae: 0.3020, huber: 0.0878, swd: 0.0728, target_std: 0.7295
      Epoch 19 composite train-obj: 0.129449
            Val objective improved 0.1550 → 0.1547, saving checkpoint.
    Epoch [20/50], Train Losses: mse: 0.3442, mae: 0.3431, huber: 0.1291, swd: 0.1488, target_std: 0.7920
    Epoch [20/50], Val Losses: mse: 0.3338, mae: 0.4041, huber: 0.1558, swd: 0.1416, target_std: 0.9936
    Epoch [20/50], Test Losses: mse: 0.1794, mae: 0.2977, huber: 0.0874, swd: 0.0728, target_std: 0.7295
      Epoch 20 composite train-obj: 0.129092
            No improvement (0.1558), counter 1/5
    Epoch [21/50], Train Losses: mse: 0.3471, mae: 0.3436, huber: 0.1297, swd: 0.1506, target_std: 0.7930
    Epoch [21/50], Val Losses: mse: 0.3365, mae: 0.4054, huber: 0.1573, swd: 0.1393, target_std: 0.9936
    Epoch [21/50], Test Losses: mse: 0.1697, mae: 0.2899, huber: 0.0831, swd: 0.0627, target_std: 0.7295
      Epoch 21 composite train-obj: 0.129730
            No improvement (0.1573), counter 2/5
    Epoch [22/50], Train Losses: mse: 0.3444, mae: 0.3429, huber: 0.1291, swd: 0.1486, target_std: 0.7918
    Epoch [22/50], Val Losses: mse: 0.3428, mae: 0.4103, huber: 0.1592, swd: 0.1501, target_std: 0.9936
    Epoch [22/50], Test Losses: mse: 0.1714, mae: 0.2901, huber: 0.0837, swd: 0.0666, target_std: 0.7295
      Epoch 22 composite train-obj: 0.129100
            No improvement (0.1592), counter 3/5
    Epoch [23/50], Train Losses: mse: 0.3470, mae: 0.3436, huber: 0.1297, swd: 0.1502, target_std: 0.7924
    Epoch [23/50], Val Losses: mse: 0.3440, mae: 0.4101, huber: 0.1600, swd: 0.1493, target_std: 0.9936
    Epoch [23/50], Test Losses: mse: 0.1657, mae: 0.2867, huber: 0.0812, swd: 0.0617, target_std: 0.7295
      Epoch 23 composite train-obj: 0.129710
            No improvement (0.1600), counter 4/5
    Epoch [24/50], Train Losses: mse: 0.3446, mae: 0.3430, huber: 0.1292, swd: 0.1481, target_std: 0.7916
    Epoch [24/50], Val Losses: mse: 0.3421, mae: 0.4105, huber: 0.1590, swd: 0.1546, target_std: 0.9936
    Epoch [24/50], Test Losses: mse: 0.1740, mae: 0.2933, huber: 0.0849, swd: 0.0704, target_std: 0.7295
      Epoch 24 composite train-obj: 0.129179
    Epoch [24/50], Test Losses: mse: 0.1798, mae: 0.3020, huber: 0.0878, swd: 0.0728, target_std: 0.7295
    Best round's Test MSE: 0.1798, MAE: 0.3020, SWD: 0.0728
    Best round's Validation MSE: 0.3309, MAE: 0.4022
    Best round's Test verification MSE : 0.1798, MAE: 0.3020, SWD: 0.0728
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4427, mae: 0.4039, huber: 0.1657, swd: 0.1745, target_std: 0.7926
    Epoch [1/50], Val Losses: mse: 0.3531, mae: 0.4200, huber: 0.1642, swd: 0.1552, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1823, mae: 0.3023, huber: 0.0889, swd: 0.0721, target_std: 0.7295
      Epoch 1 composite train-obj: 0.165697
            Val objective improved inf → 0.1642, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3602, mae: 0.3538, huber: 0.1353, swd: 0.1575, target_std: 0.7927
    Epoch [2/50], Val Losses: mse: 0.3421, mae: 0.4112, huber: 0.1589, swd: 0.1551, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1848, mae: 0.3056, huber: 0.0900, swd: 0.0788, target_std: 0.7295
      Epoch 2 composite train-obj: 0.135327
            Val objective improved 0.1642 → 0.1589, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3525, mae: 0.3483, huber: 0.1323, swd: 0.1546, target_std: 0.7930
    Epoch [3/50], Val Losses: mse: 0.3441, mae: 0.4116, huber: 0.1602, swd: 0.1548, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1719, mae: 0.2915, huber: 0.0840, swd: 0.0685, target_std: 0.7295
      Epoch 3 composite train-obj: 0.132258
            No improvement (0.1602), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.3490, mae: 0.3455, huber: 0.1309, swd: 0.1533, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.3320, mae: 0.4029, huber: 0.1551, swd: 0.1438, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1766, mae: 0.2944, huber: 0.0861, swd: 0.0721, target_std: 0.7295
      Epoch 4 composite train-obj: 0.130888
            Val objective improved 0.1589 → 0.1551, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3484, mae: 0.3451, huber: 0.1306, swd: 0.1524, target_std: 0.7929
    Epoch [5/50], Val Losses: mse: 0.3364, mae: 0.4048, huber: 0.1569, swd: 0.1426, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1713, mae: 0.2906, huber: 0.0838, swd: 0.0653, target_std: 0.7295
      Epoch 5 composite train-obj: 0.130640
            No improvement (0.1569), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3465, mae: 0.3437, huber: 0.1299, swd: 0.1510, target_std: 0.7934
    Epoch [6/50], Val Losses: mse: 0.3480, mae: 0.4144, huber: 0.1613, swd: 0.1645, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1779, mae: 0.2961, huber: 0.0866, swd: 0.0774, target_std: 0.7295
      Epoch 6 composite train-obj: 0.129862
            No improvement (0.1613), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.3465, mae: 0.3442, huber: 0.1300, swd: 0.1519, target_std: 0.7922
    Epoch [7/50], Val Losses: mse: 0.3385, mae: 0.4098, huber: 0.1581, swd: 0.1523, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1745, mae: 0.2933, huber: 0.0851, swd: 0.0722, target_std: 0.7295
      Epoch 7 composite train-obj: 0.129956
            No improvement (0.1581), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.3450, mae: 0.3431, huber: 0.1294, swd: 0.1517, target_std: 0.7914
    Epoch [8/50], Val Losses: mse: 0.3392, mae: 0.4068, huber: 0.1581, swd: 0.1470, target_std: 0.9936
    Epoch [8/50], Test Losses: mse: 0.1715, mae: 0.2909, huber: 0.0838, swd: 0.0674, target_std: 0.7295
      Epoch 8 composite train-obj: 0.129447
            No improvement (0.1581), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.3451, mae: 0.3427, huber: 0.1293, swd: 0.1507, target_std: 0.7918
    Epoch [9/50], Val Losses: mse: 0.3430, mae: 0.4131, huber: 0.1596, swd: 0.1562, target_std: 0.9936
    Epoch [9/50], Test Losses: mse: 0.1713, mae: 0.2896, huber: 0.0836, swd: 0.0705, target_std: 0.7295
      Epoch 9 composite train-obj: 0.129313
    Epoch [9/50], Test Losses: mse: 0.1766, mae: 0.2944, huber: 0.0861, swd: 0.0721, target_std: 0.7295
    Best round's Test MSE: 0.1766, MAE: 0.2944, SWD: 0.0721
    Best round's Validation MSE: 0.3320, MAE: 0.4029
    Best round's Test verification MSE : 0.1766, MAE: 0.2944, SWD: 0.0721
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.4412, mae: 0.4034, huber: 0.1652, swd: 0.1547, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3509, mae: 0.4205, huber: 0.1633, swd: 0.1353, target_std: 0.9936
    Epoch [1/50], Test Losses: mse: 0.1821, mae: 0.3006, huber: 0.0887, swd: 0.0614, target_std: 0.7295
      Epoch 1 composite train-obj: 0.165238
            Val objective improved inf → 0.1633, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.3583, mae: 0.3530, huber: 0.1347, swd: 0.1411, target_std: 0.7915
    Epoch [2/50], Val Losses: mse: 0.3445, mae: 0.4121, huber: 0.1605, swd: 0.1323, target_std: 0.9936
    Epoch [2/50], Test Losses: mse: 0.1737, mae: 0.2944, huber: 0.0850, swd: 0.0586, target_std: 0.7295
      Epoch 2 composite train-obj: 0.134696
            Val objective improved 0.1633 → 0.1605, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.3515, mae: 0.3479, huber: 0.1320, swd: 0.1394, target_std: 0.7922
    Epoch [3/50], Val Losses: mse: 0.3385, mae: 0.4083, huber: 0.1578, swd: 0.1301, target_std: 0.9936
    Epoch [3/50], Test Losses: mse: 0.1752, mae: 0.2939, huber: 0.0855, swd: 0.0611, target_std: 0.7295
      Epoch 3 composite train-obj: 0.132036
            Val objective improved 0.1605 → 0.1578, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.3485, mae: 0.3453, huber: 0.1307, swd: 0.1376, target_std: 0.7924
    Epoch [4/50], Val Losses: mse: 0.3366, mae: 0.4059, huber: 0.1573, swd: 0.1267, target_std: 0.9936
    Epoch [4/50], Test Losses: mse: 0.1741, mae: 0.2934, huber: 0.0850, swd: 0.0591, target_std: 0.7295
      Epoch 4 composite train-obj: 0.130705
            Val objective improved 0.1578 → 0.1573, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.3482, mae: 0.3447, huber: 0.1305, swd: 0.1374, target_std: 0.7923
    Epoch [5/50], Val Losses: mse: 0.3380, mae: 0.4082, huber: 0.1576, swd: 0.1282, target_std: 0.9936
    Epoch [5/50], Test Losses: mse: 0.1704, mae: 0.2900, huber: 0.0833, swd: 0.0576, target_std: 0.7295
      Epoch 5 composite train-obj: 0.130452
            No improvement (0.1576), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.3457, mae: 0.3435, huber: 0.1297, swd: 0.1370, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3420, mae: 0.4085, huber: 0.1591, swd: 0.1352, target_std: 0.9936
    Epoch [6/50], Test Losses: mse: 0.1794, mae: 0.2995, huber: 0.0874, swd: 0.0668, target_std: 0.7295
      Epoch 6 composite train-obj: 0.129708
            No improvement (0.1591), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.3458, mae: 0.3433, huber: 0.1296, swd: 0.1369, target_std: 0.7911
    Epoch [7/50], Val Losses: mse: 0.3372, mae: 0.4070, huber: 0.1579, swd: 0.1240, target_std: 0.9936
    Epoch [7/50], Test Losses: mse: 0.1691, mae: 0.2883, huber: 0.0827, swd: 0.0549, target_std: 0.7295
      Epoch 7 composite train-obj: 0.129626
            No improvement (0.1579), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.3461, mae: 0.3432, huber: 0.1297, swd: 0.1367, target_std: 0.7929
    Epoch [8/50], Val Losses: mse: 0.3433, mae: 0.4088, huber: 0.1595, swd: 0.1378, target_std: 0.9936
    Epoch [8/50], Test Losses: mse: 0.1775, mae: 0.2958, huber: 0.0865, swd: 0.0661, target_std: 0.7295
      Epoch 8 composite train-obj: 0.129656
            No improvement (0.1595), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.3458, mae: 0.3436, huber: 0.1297, swd: 0.1371, target_std: 0.7924
    Epoch [9/50], Val Losses: mse: 0.3361, mae: 0.4077, huber: 0.1573, swd: 0.1246, target_std: 0.9936
    Epoch [9/50], Test Losses: mse: 0.1701, mae: 0.2901, huber: 0.0832, swd: 0.0565, target_std: 0.7295
      Epoch 9 composite train-obj: 0.129665
    Epoch [9/50], Test Losses: mse: 0.1741, mae: 0.2934, huber: 0.0850, swd: 0.0591, target_std: 0.7295
    Best round's Test MSE: 0.1741, MAE: 0.2934, SWD: 0.0591
    Best round's Validation MSE: 0.3366, MAE: 0.4059
    Best round's Test verification MSE : 0.1741, MAE: 0.2934, SWD: 0.0591
    
    ==================================================
    Experiment Summary (DLinear_etth2_seq196_pred196_20250502_1211)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.1768 ± 0.0023
      mae: 0.2966 ± 0.0038
      huber: 0.0863 ± 0.0012
      swd: 0.0680 ± 0.0063
      target_std: 0.7295 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3332 ± 0.0025
      mae: 0.4037 ± 0.0016
      huber: 0.1557 ± 0.0011
      swd: 0.1365 ± 0.0072
      target_std: 0.9936 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_etth2_seq196_pred196_20250502_1211
    Model: DLinear
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5143, mae: 0.4412, huber: 0.1904, swd: 0.1952, target_std: 0.7949
    Epoch [1/50], Val Losses: mse: 0.3687, mae: 0.4346, huber: 0.1713, swd: 0.1386, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.2043, mae: 0.3221, huber: 0.0992, swd: 0.0758, target_std: 0.7299
      Epoch 1 composite train-obj: 0.190396
            Val objective improved inf → 0.1713, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4363, mae: 0.3950, huber: 0.1616, swd: 0.1849, target_std: 0.7939
    Epoch [2/50], Val Losses: mse: 0.3652, mae: 0.4323, huber: 0.1702, swd: 0.1394, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1908, mae: 0.3076, huber: 0.0930, swd: 0.0675, target_std: 0.7299
      Epoch 2 composite train-obj: 0.161572
            Val objective improved 0.1713 → 0.1702, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4289, mae: 0.3901, huber: 0.1587, swd: 0.1826, target_std: 0.7941
    Epoch [3/50], Val Losses: mse: 0.3615, mae: 0.4273, huber: 0.1679, swd: 0.1426, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.1965, mae: 0.3136, huber: 0.0955, swd: 0.0751, target_std: 0.7299
      Epoch 3 composite train-obj: 0.158693
            Val objective improved 0.1702 → 0.1679, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4267, mae: 0.3882, huber: 0.1577, swd: 0.1815, target_std: 0.7949
    Epoch [4/50], Val Losses: mse: 0.3636, mae: 0.4302, huber: 0.1694, swd: 0.1411, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.1865, mae: 0.3043, huber: 0.0910, swd: 0.0647, target_std: 0.7299
      Epoch 4 composite train-obj: 0.157678
            No improvement (0.1694), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.4325, mae: 0.3897, huber: 0.1591, swd: 0.1846, target_std: 0.7958
    Epoch [5/50], Val Losses: mse: 0.3824, mae: 0.4403, huber: 0.1764, swd: 0.1673, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.1907, mae: 0.3093, huber: 0.0928, swd: 0.0746, target_std: 0.7299
      Epoch 5 composite train-obj: 0.159115
            No improvement (0.1764), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.4286, mae: 0.3884, huber: 0.1581, swd: 0.1827, target_std: 0.7967
    Epoch [6/50], Val Losses: mse: 0.3650, mae: 0.4314, huber: 0.1696, swd: 0.1477, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.1912, mae: 0.3096, huber: 0.0931, swd: 0.0713, target_std: 0.7299
      Epoch 6 composite train-obj: 0.158103
            No improvement (0.1696), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.4218, mae: 0.3861, huber: 0.1561, swd: 0.1808, target_std: 0.7935
    Epoch [7/50], Val Losses: mse: 0.3736, mae: 0.4366, huber: 0.1730, swd: 0.1538, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.1854, mae: 0.3032, huber: 0.0905, swd: 0.0679, target_std: 0.7299
      Epoch 7 composite train-obj: 0.156135
            No improvement (0.1730), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.4241, mae: 0.3859, huber: 0.1564, swd: 0.1808, target_std: 0.7935
    Epoch [8/50], Val Losses: mse: 0.3557, mae: 0.4272, huber: 0.1667, swd: 0.1330, target_std: 0.9871
    Epoch [8/50], Test Losses: mse: 0.1934, mae: 0.3141, huber: 0.0942, swd: 0.0727, target_std: 0.7299
      Epoch 8 composite train-obj: 0.156382
            Val objective improved 0.1679 → 0.1667, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.4247, mae: 0.3869, huber: 0.1570, swd: 0.1806, target_std: 0.7952
    Epoch [9/50], Val Losses: mse: 0.3520, mae: 0.4221, huber: 0.1646, swd: 0.1308, target_std: 0.9871
    Epoch [9/50], Test Losses: mse: 0.2004, mae: 0.3197, huber: 0.0976, swd: 0.0761, target_std: 0.7299
      Epoch 9 composite train-obj: 0.156991
            Val objective improved 0.1667 → 0.1646, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 0.4219, mae: 0.3857, huber: 0.1560, swd: 0.1797, target_std: 0.7947
    Epoch [10/50], Val Losses: mse: 0.3572, mae: 0.4278, huber: 0.1670, swd: 0.1369, target_std: 0.9871
    Epoch [10/50], Test Losses: mse: 0.1906, mae: 0.3074, huber: 0.0928, swd: 0.0701, target_std: 0.7299
      Epoch 10 composite train-obj: 0.156013
            No improvement (0.1670), counter 1/5
    Epoch [11/50], Train Losses: mse: 0.4248, mae: 0.3861, huber: 0.1565, swd: 0.1814, target_std: 0.7957
    Epoch [11/50], Val Losses: mse: 0.3609, mae: 0.4276, huber: 0.1681, swd: 0.1349, target_std: 0.9871
    Epoch [11/50], Test Losses: mse: 0.1912, mae: 0.3090, huber: 0.0932, swd: 0.0706, target_std: 0.7299
      Epoch 11 composite train-obj: 0.156548
            No improvement (0.1681), counter 2/5
    Epoch [12/50], Train Losses: mse: 0.4216, mae: 0.3853, huber: 0.1558, swd: 0.1798, target_std: 0.7939
    Epoch [12/50], Val Losses: mse: 0.3537, mae: 0.4244, huber: 0.1650, swd: 0.1357, target_std: 0.9871
    Epoch [12/50], Test Losses: mse: 0.1949, mae: 0.3103, huber: 0.0948, swd: 0.0740, target_std: 0.7299
      Epoch 12 composite train-obj: 0.155803
            No improvement (0.1650), counter 3/5
    Epoch [13/50], Train Losses: mse: 0.4242, mae: 0.3857, huber: 0.1564, swd: 0.1821, target_std: 0.7947
    Epoch [13/50], Val Losses: mse: 0.3603, mae: 0.4285, huber: 0.1682, swd: 0.1343, target_std: 0.9871
    Epoch [13/50], Test Losses: mse: 0.1892, mae: 0.3066, huber: 0.0922, swd: 0.0671, target_std: 0.7299
      Epoch 13 composite train-obj: 0.156400
            No improvement (0.1682), counter 4/5
    Epoch [14/50], Train Losses: mse: 0.4254, mae: 0.3861, huber: 0.1567, swd: 0.1815, target_std: 0.7959
    Epoch [14/50], Val Losses: mse: 0.3637, mae: 0.4307, huber: 0.1696, swd: 0.1452, target_std: 0.9871
    Epoch [14/50], Test Losses: mse: 0.1889, mae: 0.3068, huber: 0.0921, swd: 0.0707, target_std: 0.7299
      Epoch 14 composite train-obj: 0.156659
    Epoch [14/50], Test Losses: mse: 0.2004, mae: 0.3197, huber: 0.0976, swd: 0.0761, target_std: 0.7299
    Best round's Test MSE: 0.2004, MAE: 0.3197, SWD: 0.0761
    Best round's Validation MSE: 0.3520, MAE: 0.4221
    Best round's Test verification MSE : 0.2004, MAE: 0.3197, SWD: 0.0761
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5122, mae: 0.4412, huber: 0.1901, swd: 0.2027, target_std: 0.7957
    Epoch [1/50], Val Losses: mse: 0.3751, mae: 0.4382, huber: 0.1736, swd: 0.1513, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.1988, mae: 0.3157, huber: 0.0967, swd: 0.0752, target_std: 0.7299
      Epoch 1 composite train-obj: 0.190141
            Val objective improved inf → 0.1736, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4342, mae: 0.3946, huber: 0.1611, swd: 0.1895, target_std: 0.7955
    Epoch [2/50], Val Losses: mse: 0.3663, mae: 0.4324, huber: 0.1702, swd: 0.1522, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1936, mae: 0.3098, huber: 0.0942, swd: 0.0744, target_std: 0.7299
      Epoch 2 composite train-obj: 0.161122
            Val objective improved 0.1736 → 0.1702, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4281, mae: 0.3897, huber: 0.1585, swd: 0.1878, target_std: 0.7936
    Epoch [3/50], Val Losses: mse: 0.3479, mae: 0.4202, huber: 0.1625, swd: 0.1344, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.2023, mae: 0.3187, huber: 0.0982, swd: 0.0809, target_std: 0.7299
      Epoch 3 composite train-obj: 0.158518
            Val objective improved 0.1702 → 0.1625, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4293, mae: 0.3892, huber: 0.1584, swd: 0.1888, target_std: 0.7955
    Epoch [4/50], Val Losses: mse: 0.3676, mae: 0.4312, huber: 0.1705, swd: 0.1527, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.1946, mae: 0.3122, huber: 0.0946, swd: 0.0782, target_std: 0.7299
      Epoch 4 composite train-obj: 0.158396
            No improvement (0.1705), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.4247, mae: 0.3871, huber: 0.1570, swd: 0.1864, target_std: 0.7942
    Epoch [5/50], Val Losses: mse: 0.3629, mae: 0.4288, huber: 0.1683, swd: 0.1583, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.1978, mae: 0.3143, huber: 0.0960, swd: 0.0816, target_std: 0.7299
      Epoch 5 composite train-obj: 0.156974
            No improvement (0.1683), counter 2/5
    Epoch [6/50], Train Losses: mse: 0.4232, mae: 0.3857, huber: 0.1562, swd: 0.1864, target_std: 0.7946
    Epoch [6/50], Val Losses: mse: 0.3553, mae: 0.4259, huber: 0.1659, swd: 0.1401, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.1903, mae: 0.3072, huber: 0.0927, swd: 0.0728, target_std: 0.7299
      Epoch 6 composite train-obj: 0.156226
            No improvement (0.1659), counter 3/5
    Epoch [7/50], Train Losses: mse: 0.4226, mae: 0.3855, huber: 0.1561, swd: 0.1852, target_std: 0.7948
    Epoch [7/50], Val Losses: mse: 0.3671, mae: 0.4321, huber: 0.1704, swd: 0.1543, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.1885, mae: 0.3071, huber: 0.0919, swd: 0.0721, target_std: 0.7299
      Epoch 7 composite train-obj: 0.156108
            No improvement (0.1704), counter 4/5
    Epoch [8/50], Train Losses: mse: 0.4219, mae: 0.3852, huber: 0.1559, swd: 0.1855, target_std: 0.7953
    Epoch [8/50], Val Losses: mse: 0.3589, mae: 0.4268, huber: 0.1675, swd: 0.1407, target_std: 0.9871
    Epoch [8/50], Test Losses: mse: 0.1909, mae: 0.3083, huber: 0.0930, swd: 0.0717, target_std: 0.7299
      Epoch 8 composite train-obj: 0.155923
    Epoch [8/50], Test Losses: mse: 0.2023, mae: 0.3187, huber: 0.0982, swd: 0.0809, target_std: 0.7299
    Best round's Test MSE: 0.2023, MAE: 0.3187, SWD: 0.0809
    Best round's Validation MSE: 0.3479, MAE: 0.4202
    Best round's Test verification MSE : 0.2023, MAE: 0.3187, SWD: 0.0809
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.5146, mae: 0.4412, huber: 0.1904, swd: 0.1952, target_std: 0.7963
    Epoch [1/50], Val Losses: mse: 0.3766, mae: 0.4407, huber: 0.1745, swd: 0.1432, target_std: 0.9871
    Epoch [1/50], Test Losses: mse: 0.1970, mae: 0.3137, huber: 0.0957, swd: 0.0678, target_std: 0.7299
      Epoch 1 composite train-obj: 0.190417
            Val objective improved inf → 0.1745, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.4343, mae: 0.3944, huber: 0.1610, swd: 0.1844, target_std: 0.7947
    Epoch [2/50], Val Losses: mse: 0.3654, mae: 0.4322, huber: 0.1701, swd: 0.1393, target_std: 0.9871
    Epoch [2/50], Test Losses: mse: 0.1915, mae: 0.3093, huber: 0.0933, swd: 0.0667, target_std: 0.7299
      Epoch 2 composite train-obj: 0.160996
            Val objective improved 0.1745 → 0.1701, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.4278, mae: 0.3897, huber: 0.1584, swd: 0.1827, target_std: 0.7933
    Epoch [3/50], Val Losses: mse: 0.3652, mae: 0.4326, huber: 0.1698, swd: 0.1456, target_std: 0.9871
    Epoch [3/50], Test Losses: mse: 0.1959, mae: 0.3122, huber: 0.0951, swd: 0.0730, target_std: 0.7299
      Epoch 3 composite train-obj: 0.158386
            Val objective improved 0.1701 → 0.1698, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.4240, mae: 0.3874, huber: 0.1571, swd: 0.1825, target_std: 0.7925
    Epoch [4/50], Val Losses: mse: 0.3636, mae: 0.4303, huber: 0.1689, swd: 0.1448, target_std: 0.9871
    Epoch [4/50], Test Losses: mse: 0.1954, mae: 0.3138, huber: 0.0950, swd: 0.0747, target_std: 0.7299
      Epoch 4 composite train-obj: 0.157080
            Val objective improved 0.1698 → 0.1689, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.4250, mae: 0.3873, huber: 0.1572, swd: 0.1821, target_std: 0.7952
    Epoch [5/50], Val Losses: mse: 0.3674, mae: 0.4325, huber: 0.1704, swd: 0.1498, target_std: 0.9871
    Epoch [5/50], Test Losses: mse: 0.1941, mae: 0.3135, huber: 0.0945, swd: 0.0741, target_std: 0.7299
      Epoch 5 composite train-obj: 0.157161
            No improvement (0.1704), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.4236, mae: 0.3864, huber: 0.1566, swd: 0.1821, target_std: 0.7951
    Epoch [6/50], Val Losses: mse: 0.3699, mae: 0.4348, huber: 0.1716, swd: 0.1519, target_std: 0.9871
    Epoch [6/50], Test Losses: mse: 0.1887, mae: 0.3058, huber: 0.0919, swd: 0.0693, target_std: 0.7299
      Epoch 6 composite train-obj: 0.156593
            No improvement (0.1716), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.4224, mae: 0.3861, huber: 0.1563, swd: 0.1815, target_std: 0.7951
    Epoch [7/50], Val Losses: mse: 0.3642, mae: 0.4305, huber: 0.1699, swd: 0.1433, target_std: 0.9871
    Epoch [7/50], Test Losses: mse: 0.1904, mae: 0.3100, huber: 0.0928, swd: 0.0697, target_std: 0.7299
      Epoch 7 composite train-obj: 0.156250
            No improvement (0.1699), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.4267, mae: 0.3869, huber: 0.1572, swd: 0.1841, target_std: 0.7948
    Epoch [8/50], Val Losses: mse: 0.3630, mae: 0.4306, huber: 0.1685, swd: 0.1478, target_std: 0.9871
    Epoch [8/50], Test Losses: mse: 0.1947, mae: 0.3111, huber: 0.0945, swd: 0.0737, target_std: 0.7299
      Epoch 8 composite train-obj: 0.157194
            Val objective improved 0.1689 → 0.1685, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 0.4222, mae: 0.3859, huber: 0.1562, swd: 0.1823, target_std: 0.7938
    Epoch [9/50], Val Losses: mse: 0.3661, mae: 0.4306, huber: 0.1701, swd: 0.1452, target_std: 0.9871
    Epoch [9/50], Test Losses: mse: 0.1912, mae: 0.3079, huber: 0.0930, swd: 0.0696, target_std: 0.7299
      Epoch 9 composite train-obj: 0.156198
            No improvement (0.1701), counter 1/5
    Epoch [10/50], Train Losses: mse: 0.4278, mae: 0.3870, huber: 0.1575, swd: 0.1833, target_std: 0.7971
    Epoch [10/50], Val Losses: mse: 0.3679, mae: 0.4345, huber: 0.1702, swd: 0.1587, target_std: 0.9871
    Epoch [10/50], Test Losses: mse: 0.2078, mae: 0.3249, huber: 0.1005, swd: 0.0882, target_std: 0.7299
      Epoch 10 composite train-obj: 0.157456
            No improvement (0.1702), counter 2/5
    Epoch [11/50], Train Losses: mse: 0.4251, mae: 0.3868, huber: 0.1567, swd: 0.1846, target_std: 0.7939
    Epoch [11/50], Val Losses: mse: 0.3685, mae: 0.4364, huber: 0.1716, swd: 0.1491, target_std: 0.9871
    Epoch [11/50], Test Losses: mse: 0.1898, mae: 0.3068, huber: 0.0923, swd: 0.0703, target_std: 0.7299
      Epoch 11 composite train-obj: 0.156681
            No improvement (0.1716), counter 3/5
    Epoch [12/50], Train Losses: mse: 0.4225, mae: 0.3853, huber: 0.1561, swd: 0.1822, target_std: 0.7938
    Epoch [12/50], Val Losses: mse: 0.3543, mae: 0.4243, huber: 0.1658, swd: 0.1282, target_std: 0.9871
    Epoch [12/50], Test Losses: mse: 0.1931, mae: 0.3091, huber: 0.0940, swd: 0.0687, target_std: 0.7299
      Epoch 12 composite train-obj: 0.156068
            Val objective improved 0.1685 → 0.1658, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 0.4224, mae: 0.3856, huber: 0.1561, swd: 0.1825, target_std: 0.7938
    Epoch [13/50], Val Losses: mse: 0.3621, mae: 0.4280, huber: 0.1683, swd: 0.1351, target_std: 0.9871
    Epoch [13/50], Test Losses: mse: 0.1866, mae: 0.3061, huber: 0.0912, swd: 0.0644, target_std: 0.7299
      Epoch 13 composite train-obj: 0.156060
            No improvement (0.1683), counter 1/5
    Epoch [14/50], Train Losses: mse: 0.4207, mae: 0.3853, huber: 0.1557, swd: 0.1811, target_std: 0.7942
    Epoch [14/50], Val Losses: mse: 0.3540, mae: 0.4245, huber: 0.1654, swd: 0.1347, target_std: 0.9871
    Epoch [14/50], Test Losses: mse: 0.2012, mae: 0.3168, huber: 0.0975, swd: 0.0783, target_std: 0.7299
      Epoch 14 composite train-obj: 0.155684
            Val objective improved 0.1658 → 0.1654, saving checkpoint.
    Epoch [15/50], Train Losses: mse: 0.4202, mae: 0.3845, huber: 0.1552, swd: 0.1813, target_std: 0.7926
    Epoch [15/50], Val Losses: mse: 0.3604, mae: 0.4293, huber: 0.1689, swd: 0.1251, target_std: 0.9871
    Epoch [15/50], Test Losses: mse: 0.1939, mae: 0.3110, huber: 0.0945, swd: 0.0656, target_std: 0.7299
      Epoch 15 composite train-obj: 0.155193
            No improvement (0.1689), counter 1/5
    Epoch [16/50], Train Losses: mse: 0.4246, mae: 0.3862, huber: 0.1565, swd: 0.1823, target_std: 0.7949
    Epoch [16/50], Val Losses: mse: 0.3481, mae: 0.4203, huber: 0.1627, swd: 0.1241, target_std: 0.9871
    Epoch [16/50], Test Losses: mse: 0.1987, mae: 0.3166, huber: 0.0967, swd: 0.0728, target_std: 0.7299
      Epoch 16 composite train-obj: 0.156496
            Val objective improved 0.1654 → 0.1627, saving checkpoint.
    Epoch [17/50], Train Losses: mse: 0.4275, mae: 0.3873, huber: 0.1571, swd: 0.1857, target_std: 0.7951
    Epoch [17/50], Val Losses: mse: 0.3640, mae: 0.4295, huber: 0.1693, swd: 0.1381, target_std: 0.9871
    Epoch [17/50], Test Losses: mse: 0.1999, mae: 0.3155, huber: 0.0970, swd: 0.0773, target_std: 0.7299
      Epoch 17 composite train-obj: 0.157139
            No improvement (0.1693), counter 1/5
    Epoch [18/50], Train Losses: mse: 0.4214, mae: 0.3854, huber: 0.1558, swd: 0.1815, target_std: 0.7936
    Epoch [18/50], Val Losses: mse: 0.3699, mae: 0.4353, huber: 0.1720, swd: 0.1465, target_std: 0.9871
    Epoch [18/50], Test Losses: mse: 0.1888, mae: 0.3058, huber: 0.0919, swd: 0.0682, target_std: 0.7299
      Epoch 18 composite train-obj: 0.155774
            No improvement (0.1720), counter 2/5
    Epoch [19/50], Train Losses: mse: 0.4238, mae: 0.3859, huber: 0.1563, swd: 0.1829, target_std: 0.7948
    Epoch [19/50], Val Losses: mse: 0.3644, mae: 0.4307, huber: 0.1693, swd: 0.1408, target_std: 0.9871
    Epoch [19/50], Test Losses: mse: 0.1854, mae: 0.3044, huber: 0.0906, swd: 0.0627, target_std: 0.7299
      Epoch 19 composite train-obj: 0.156305
            No improvement (0.1693), counter 3/5
    Epoch [20/50], Train Losses: mse: 0.4204, mae: 0.3847, huber: 0.1554, swd: 0.1813, target_std: 0.7947
    Epoch [20/50], Val Losses: mse: 0.3597, mae: 0.4289, huber: 0.1684, swd: 0.1288, target_std: 0.9871
    Epoch [20/50], Test Losses: mse: 0.1917, mae: 0.3089, huber: 0.0934, swd: 0.0653, target_std: 0.7299
      Epoch 20 composite train-obj: 0.155363
            No improvement (0.1684), counter 4/5
    Epoch [21/50], Train Losses: mse: 0.4219, mae: 0.3855, huber: 0.1559, swd: 0.1811, target_std: 0.7944
    Epoch [21/50], Val Losses: mse: 0.3563, mae: 0.4250, huber: 0.1653, swd: 0.1422, target_std: 0.9871
    Epoch [21/50], Test Losses: mse: 0.2023, mae: 0.3211, huber: 0.0982, swd: 0.0798, target_std: 0.7299
      Epoch 21 composite train-obj: 0.155881
    Epoch [21/50], Test Losses: mse: 0.1987, mae: 0.3166, huber: 0.0967, swd: 0.0728, target_std: 0.7299
    Best round's Test MSE: 0.1987, MAE: 0.3166, SWD: 0.0728
    Best round's Validation MSE: 0.3481, MAE: 0.4203
    Best round's Test verification MSE : 0.1987, MAE: 0.3166, SWD: 0.0728
    
    ==================================================
    Experiment Summary (DLinear_etth2_seq196_pred336_20250502_1212)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2005 ± 0.0015
      mae: 0.3183 ± 0.0013
      huber: 0.0975 ± 0.0006
      swd: 0.0766 ± 0.0033
      target_std: 0.7299 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3493 ± 0.0019
      mae: 0.4209 ± 0.0009
      huber: 0.1633 ± 0.0009
      swd: 0.1297 ± 0.0043
      target_std: 0.9871 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_etth2_seq196_pred336_20250502_1212
    Model: DLinear
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['etth2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth2', cfg, data_mgr, scale=True)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 89
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth2
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 89
    Validation Batches: 7
    Test Batches: 21
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6363, mae: 0.5114, huber: 0.2351, swd: 0.2722, target_std: 0.7978
    Epoch [1/50], Val Losses: mse: 0.3726, mae: 0.4500, huber: 0.1755, swd: 0.1115, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2417, mae: 0.3518, huber: 0.1162, swd: 0.0864, target_std: 0.7295
      Epoch 1 composite train-obj: 0.235074
            Val objective improved inf → 0.1755, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5681, mae: 0.4720, huber: 0.2098, swd: 0.2647, target_std: 0.7971
    Epoch [2/50], Val Losses: mse: 0.3591, mae: 0.4389, huber: 0.1695, swd: 0.0965, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2409, mae: 0.3497, huber: 0.1157, swd: 0.0861, target_std: 0.7295
      Epoch 2 composite train-obj: 0.209766
            Val objective improved 0.1755 → 0.1695, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.5679, mae: 0.4688, huber: 0.2085, swd: 0.2656, target_std: 0.7977
    Epoch [3/50], Val Losses: mse: 0.3737, mae: 0.4525, huber: 0.1764, swd: 0.1115, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2324, mae: 0.3418, huber: 0.1117, swd: 0.0838, target_std: 0.7295
      Epoch 3 composite train-obj: 0.208541
            No improvement (0.1764), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.5688, mae: 0.4687, huber: 0.2086, swd: 0.2674, target_std: 0.7997
    Epoch [4/50], Val Losses: mse: 0.3622, mae: 0.4452, huber: 0.1713, swd: 0.1110, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2398, mae: 0.3501, huber: 0.1151, swd: 0.0939, target_std: 0.7295
      Epoch 4 composite train-obj: 0.208596
            No improvement (0.1713), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.5670, mae: 0.4677, huber: 0.2079, swd: 0.2677, target_std: 0.7994
    Epoch [5/50], Val Losses: mse: 0.3649, mae: 0.4459, huber: 0.1723, swd: 0.1149, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2372, mae: 0.3490, huber: 0.1140, swd: 0.0905, target_std: 0.7295
      Epoch 5 composite train-obj: 0.207907
            No improvement (0.1723), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.5614, mae: 0.4656, huber: 0.2064, swd: 0.2629, target_std: 0.7982
    Epoch [6/50], Val Losses: mse: 0.3581, mae: 0.4445, huber: 0.1694, swd: 0.1194, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2517, mae: 0.3621, huber: 0.1204, swd: 0.1059, target_std: 0.7295
      Epoch 6 composite train-obj: 0.206367
            Val objective improved 0.1695 → 0.1694, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.5639, mae: 0.4665, huber: 0.2071, swd: 0.2647, target_std: 0.7989
    Epoch [7/50], Val Losses: mse: 0.3512, mae: 0.4367, huber: 0.1663, swd: 0.1031, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2447, mae: 0.3560, huber: 0.1174, swd: 0.0947, target_std: 0.7295
      Epoch 7 composite train-obj: 0.207139
            Val objective improved 0.1694 → 0.1663, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 0.5584, mae: 0.4650, huber: 0.2057, swd: 0.2630, target_std: 0.7966
    Epoch [8/50], Val Losses: mse: 0.3593, mae: 0.4411, huber: 0.1699, swd: 0.1099, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2351, mae: 0.3469, huber: 0.1131, swd: 0.0860, target_std: 0.7295
      Epoch 8 composite train-obj: 0.205718
            No improvement (0.1699), counter 1/5
    Epoch [9/50], Train Losses: mse: 0.5601, mae: 0.4644, huber: 0.2057, swd: 0.2632, target_std: 0.7978
    Epoch [9/50], Val Losses: mse: 0.3559, mae: 0.4408, huber: 0.1684, swd: 0.0950, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2351, mae: 0.3450, huber: 0.1131, swd: 0.0858, target_std: 0.7295
      Epoch 9 composite train-obj: 0.205719
            No improvement (0.1684), counter 2/5
    Epoch [10/50], Train Losses: mse: 0.5582, mae: 0.4644, huber: 0.2054, swd: 0.2619, target_std: 0.7971
    Epoch [10/50], Val Losses: mse: 0.3664, mae: 0.4492, huber: 0.1732, swd: 0.1103, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.2282, mae: 0.3401, huber: 0.1099, swd: 0.0837, target_std: 0.7295
      Epoch 10 composite train-obj: 0.205409
            No improvement (0.1732), counter 3/5
    Epoch [11/50], Train Losses: mse: 0.5596, mae: 0.4648, huber: 0.2058, swd: 0.2629, target_std: 0.7982
    Epoch [11/50], Val Losses: mse: 0.3640, mae: 0.4419, huber: 0.1718, swd: 0.1169, target_std: 0.9872
    Epoch [11/50], Test Losses: mse: 0.2462, mae: 0.3528, huber: 0.1178, swd: 0.0985, target_std: 0.7295
      Epoch 11 composite train-obj: 0.205839
            No improvement (0.1718), counter 4/5
    Epoch [12/50], Train Losses: mse: 0.5576, mae: 0.4641, huber: 0.2052, swd: 0.2616, target_std: 0.7968
    Epoch [12/50], Val Losses: mse: 0.3737, mae: 0.4540, huber: 0.1755, swd: 0.1363, target_std: 0.9872
    Epoch [12/50], Test Losses: mse: 0.2386, mae: 0.3487, huber: 0.1144, swd: 0.0950, target_std: 0.7295
      Epoch 12 composite train-obj: 0.205238
    Epoch [12/50], Test Losses: mse: 0.2447, mae: 0.3560, huber: 0.1174, swd: 0.0947, target_std: 0.7295
    Best round's Test MSE: 0.2447, MAE: 0.3560, SWD: 0.0947
    Best round's Validation MSE: 0.3512, MAE: 0.4367
    Best round's Test verification MSE : 0.2447, MAE: 0.3560, SWD: 0.0947
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6329, mae: 0.5106, huber: 0.2343, swd: 0.2609, target_std: 0.7980
    Epoch [1/50], Val Losses: mse: 0.3754, mae: 0.4547, huber: 0.1764, swd: 0.1144, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2498, mae: 0.3556, huber: 0.1194, swd: 0.0900, target_std: 0.7295
      Epoch 1 composite train-obj: 0.234296
            Val objective improved inf → 0.1764, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5720, mae: 0.4730, huber: 0.2107, swd: 0.2586, target_std: 0.7986
    Epoch [2/50], Val Losses: mse: 0.3856, mae: 0.4625, huber: 0.1814, swd: 0.1211, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2357, mae: 0.3456, huber: 0.1131, swd: 0.0831, target_std: 0.7295
      Epoch 2 composite train-obj: 0.210719
            No improvement (0.1814), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.5666, mae: 0.4693, huber: 0.2086, swd: 0.2568, target_std: 0.7981
    Epoch [3/50], Val Losses: mse: 0.3674, mae: 0.4429, huber: 0.1728, swd: 0.1067, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2448, mae: 0.3542, huber: 0.1173, swd: 0.0884, target_std: 0.7295
      Epoch 3 composite train-obj: 0.208566
            Val objective improved 0.1764 → 0.1728, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.5612, mae: 0.4669, huber: 0.2069, swd: 0.2556, target_std: 0.7985
    Epoch [4/50], Val Losses: mse: 0.3550, mae: 0.4355, huber: 0.1680, swd: 0.0940, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2459, mae: 0.3544, huber: 0.1178, swd: 0.0872, target_std: 0.7295
      Epoch 4 composite train-obj: 0.206894
            Val objective improved 0.1728 → 0.1680, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 0.5626, mae: 0.4660, huber: 0.2067, swd: 0.2554, target_std: 0.7980
    Epoch [5/50], Val Losses: mse: 0.3616, mae: 0.4393, huber: 0.1708, swd: 0.0855, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2355, mae: 0.3441, huber: 0.1132, swd: 0.0772, target_std: 0.7295
      Epoch 5 composite train-obj: 0.206652
            No improvement (0.1708), counter 1/5
    Epoch [6/50], Train Losses: mse: 0.5612, mae: 0.4654, huber: 0.2063, swd: 0.2561, target_std: 0.7975
    Epoch [6/50], Val Losses: mse: 0.3557, mae: 0.4379, huber: 0.1684, swd: 0.0883, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2362, mae: 0.3467, huber: 0.1136, swd: 0.0789, target_std: 0.7295
      Epoch 6 composite train-obj: 0.206295
            No improvement (0.1684), counter 2/5
    Epoch [7/50], Train Losses: mse: 0.5606, mae: 0.4655, huber: 0.2063, swd: 0.2538, target_std: 0.7983
    Epoch [7/50], Val Losses: mse: 0.3578, mae: 0.4399, huber: 0.1690, swd: 0.1066, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2557, mae: 0.3638, huber: 0.1222, swd: 0.1016, target_std: 0.7295
      Epoch 7 composite train-obj: 0.206260
            No improvement (0.1690), counter 3/5
    Epoch [8/50], Train Losses: mse: 0.5589, mae: 0.4645, huber: 0.2055, swd: 0.2553, target_std: 0.7970
    Epoch [8/50], Val Losses: mse: 0.3732, mae: 0.4526, huber: 0.1759, swd: 0.1022, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2296, mae: 0.3400, huber: 0.1105, swd: 0.0767, target_std: 0.7295
      Epoch 8 composite train-obj: 0.205488
            No improvement (0.1759), counter 4/5
    Epoch [9/50], Train Losses: mse: 0.5567, mae: 0.4637, huber: 0.2049, swd: 0.2538, target_std: 0.7969
    Epoch [9/50], Val Losses: mse: 0.3434, mae: 0.4293, huber: 0.1629, swd: 0.0839, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2435, mae: 0.3560, huber: 0.1170, swd: 0.0828, target_std: 0.7295
      Epoch 9 composite train-obj: 0.204929
            Val objective improved 0.1680 → 0.1629, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 0.5583, mae: 0.4638, huber: 0.2053, swd: 0.2540, target_std: 0.7967
    Epoch [10/50], Val Losses: mse: 0.3641, mae: 0.4449, huber: 0.1719, swd: 0.0977, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.2328, mae: 0.3434, huber: 0.1119, swd: 0.0805, target_std: 0.7295
      Epoch 10 composite train-obj: 0.205275
            No improvement (0.1719), counter 1/5
    Epoch [11/50], Train Losses: mse: 0.5606, mae: 0.4650, huber: 0.2059, swd: 0.2557, target_std: 0.7983
    Epoch [11/50], Val Losses: mse: 0.3775, mae: 0.4548, huber: 0.1777, swd: 0.1233, target_std: 0.9872
    Epoch [11/50], Test Losses: mse: 0.2358, mae: 0.3514, huber: 0.1135, swd: 0.0883, target_std: 0.7295
      Epoch 11 composite train-obj: 0.205948
            No improvement (0.1777), counter 2/5
    Epoch [12/50], Train Losses: mse: 0.5589, mae: 0.4644, huber: 0.2055, swd: 0.2560, target_std: 0.7978
    Epoch [12/50], Val Losses: mse: 0.3441, mae: 0.4341, huber: 0.1632, swd: 0.0795, target_std: 0.9872
    Epoch [12/50], Test Losses: mse: 0.2425, mae: 0.3508, huber: 0.1162, swd: 0.0839, target_std: 0.7295
      Epoch 12 composite train-obj: 0.205467
            No improvement (0.1632), counter 3/5
    Epoch [13/50], Train Losses: mse: 0.5603, mae: 0.4647, huber: 0.2058, swd: 0.2566, target_std: 0.7979
    Epoch [13/50], Val Losses: mse: 0.3630, mae: 0.4445, huber: 0.1717, swd: 0.0972, target_std: 0.9872
    Epoch [13/50], Test Losses: mse: 0.2352, mae: 0.3434, huber: 0.1130, swd: 0.0819, target_std: 0.7295
      Epoch 13 composite train-obj: 0.205780
            No improvement (0.1717), counter 4/5
    Epoch [14/50], Train Losses: mse: 0.5587, mae: 0.4647, huber: 0.2056, swd: 0.2547, target_std: 0.7985
    Epoch [14/50], Val Losses: mse: 0.3566, mae: 0.4369, huber: 0.1686, swd: 0.0897, target_std: 0.9872
    Epoch [14/50], Test Losses: mse: 0.2394, mae: 0.3462, huber: 0.1149, swd: 0.0824, target_std: 0.7295
      Epoch 14 composite train-obj: 0.205554
    Epoch [14/50], Test Losses: mse: 0.2435, mae: 0.3560, huber: 0.1170, swd: 0.0828, target_std: 0.7295
    Best round's Test MSE: 0.2435, MAE: 0.3560, SWD: 0.0828
    Best round's Validation MSE: 0.3434, MAE: 0.4293
    Best round's Test verification MSE : 0.2435, MAE: 0.3560, SWD: 0.0828
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.6334, mae: 0.5100, huber: 0.2342, swd: 0.2839, target_std: 0.7969
    Epoch [1/50], Val Losses: mse: 0.3677, mae: 0.4480, huber: 0.1737, swd: 0.1056, target_std: 0.9872
    Epoch [1/50], Test Losses: mse: 0.2491, mae: 0.3572, huber: 0.1194, swd: 0.0970, target_std: 0.7295
      Epoch 1 composite train-obj: 0.234159
            Val objective improved inf → 0.1737, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.5705, mae: 0.4722, huber: 0.2102, swd: 0.2792, target_std: 0.7975
    Epoch [2/50], Val Losses: mse: 0.3652, mae: 0.4467, huber: 0.1727, swd: 0.1021, target_std: 0.9872
    Epoch [2/50], Test Losses: mse: 0.2351, mae: 0.3448, huber: 0.1130, swd: 0.0863, target_std: 0.7295
      Epoch 2 composite train-obj: 0.210165
            Val objective improved 0.1737 → 0.1727, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.5642, mae: 0.4682, huber: 0.2078, swd: 0.2774, target_std: 0.7992
    Epoch [3/50], Val Losses: mse: 0.3617, mae: 0.4434, huber: 0.1708, swd: 0.1076, target_std: 0.9872
    Epoch [3/50], Test Losses: mse: 0.2406, mae: 0.3477, huber: 0.1153, swd: 0.0916, target_std: 0.7295
      Epoch 3 composite train-obj: 0.207760
            Val objective improved 0.1727 → 0.1708, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 0.5625, mae: 0.4665, huber: 0.2068, swd: 0.2769, target_std: 0.7974
    Epoch [4/50], Val Losses: mse: 0.3731, mae: 0.4536, huber: 0.1757, swd: 0.1205, target_std: 0.9872
    Epoch [4/50], Test Losses: mse: 0.2340, mae: 0.3413, huber: 0.1122, swd: 0.0900, target_std: 0.7295
      Epoch 4 composite train-obj: 0.206817
            No improvement (0.1757), counter 1/5
    Epoch [5/50], Train Losses: mse: 0.5615, mae: 0.4660, huber: 0.2067, swd: 0.2775, target_std: 0.7974
    Epoch [5/50], Val Losses: mse: 0.3570, mae: 0.4396, huber: 0.1686, swd: 0.1063, target_std: 0.9872
    Epoch [5/50], Test Losses: mse: 0.2428, mae: 0.3506, huber: 0.1163, swd: 0.0968, target_std: 0.7295
      Epoch 5 composite train-obj: 0.206655
            Val objective improved 0.1708 → 0.1686, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 0.5612, mae: 0.4663, huber: 0.2067, swd: 0.2775, target_std: 0.7972
    Epoch [6/50], Val Losses: mse: 0.3395, mae: 0.4281, huber: 0.1612, swd: 0.0866, target_std: 0.9872
    Epoch [6/50], Test Losses: mse: 0.2503, mae: 0.3589, huber: 0.1198, swd: 0.0996, target_std: 0.7295
      Epoch 6 composite train-obj: 0.206670
            Val objective improved 0.1686 → 0.1612, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 0.5584, mae: 0.4646, huber: 0.2055, swd: 0.2765, target_std: 0.7976
    Epoch [7/50], Val Losses: mse: 0.3584, mae: 0.4389, huber: 0.1695, swd: 0.0950, target_std: 0.9872
    Epoch [7/50], Test Losses: mse: 0.2379, mae: 0.3452, huber: 0.1142, swd: 0.0872, target_std: 0.7295
      Epoch 7 composite train-obj: 0.205544
            No improvement (0.1695), counter 1/5
    Epoch [8/50], Train Losses: mse: 0.5599, mae: 0.4651, huber: 0.2060, swd: 0.2774, target_std: 0.7983
    Epoch [8/50], Val Losses: mse: 0.3608, mae: 0.4391, huber: 0.1706, swd: 0.0973, target_std: 0.9872
    Epoch [8/50], Test Losses: mse: 0.2375, mae: 0.3452, huber: 0.1140, swd: 0.0883, target_std: 0.7295
      Epoch 8 composite train-obj: 0.205958
            No improvement (0.1706), counter 2/5
    Epoch [9/50], Train Losses: mse: 0.5583, mae: 0.4644, huber: 0.2056, swd: 0.2756, target_std: 0.7971
    Epoch [9/50], Val Losses: mse: 0.3835, mae: 0.4605, huber: 0.1805, swd: 0.1406, target_std: 0.9872
    Epoch [9/50], Test Losses: mse: 0.2336, mae: 0.3453, huber: 0.1121, swd: 0.0934, target_std: 0.7295
      Epoch 9 composite train-obj: 0.205550
            No improvement (0.1805), counter 3/5
    Epoch [10/50], Train Losses: mse: 0.5594, mae: 0.4645, huber: 0.2057, swd: 0.2768, target_std: 0.7985
    Epoch [10/50], Val Losses: mse: 0.3539, mae: 0.4363, huber: 0.1677, swd: 0.0976, target_std: 0.9872
    Epoch [10/50], Test Losses: mse: 0.2395, mae: 0.3502, huber: 0.1151, swd: 0.0918, target_std: 0.7295
      Epoch 10 composite train-obj: 0.205717
            No improvement (0.1677), counter 4/5
    Epoch [11/50], Train Losses: mse: 0.5660, mae: 0.4666, huber: 0.2073, swd: 0.2820, target_std: 0.7995
    Epoch [11/50], Val Losses: mse: 0.3579, mae: 0.4458, huber: 0.1694, swd: 0.1141, target_std: 0.9872
    Epoch [11/50], Test Losses: mse: 0.2375, mae: 0.3499, huber: 0.1141, swd: 0.0942, target_std: 0.7295
      Epoch 11 composite train-obj: 0.207332
    Epoch [11/50], Test Losses: mse: 0.2503, mae: 0.3589, huber: 0.1198, swd: 0.0996, target_std: 0.7295
    Best round's Test MSE: 0.2503, MAE: 0.3589, SWD: 0.0996
    Best round's Validation MSE: 0.3395, MAE: 0.4281
    Best round's Test verification MSE : 0.2503, MAE: 0.3589, SWD: 0.0996
    
    ==================================================
    Experiment Summary (DLinear_etth2_seq196_pred720_20250502_1212)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.2462 ± 0.0030
      mae: 0.3570 ± 0.0014
      huber: 0.1181 ± 0.0012
      swd: 0.0924 ± 0.0070
      target_std: 0.7295 ± 0.0000
      count: 7.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3447 ± 0.0049
      mae: 0.4314 ± 0.0038
      huber: 0.1634 ± 0.0021
      swd: 0.0912 ± 0.0085
      target_std: 0.9872 ± 0.0000
      count: 7.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_etth2_seq196_pred720_20250502_1212
    Model: DLinear
    Dataset: etth2
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    




