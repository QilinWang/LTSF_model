# data


```python
import torch 
import importlib
import monotonic
import data_manager
import metrics
import utils
importlib.reload(utils)
import train as Train
from train import execute_model_evaluation
import train_config
from data_manager import DatasetManager
from train_config import FlatACLConfig, FlatDLinearConfig, FlatNaiveConfig, FlatPatchTSTConfig, FlatTimeMixerConfig
from dataclasses import replace

%load_ext autoreload
%autoreload 2
modules_to_reload_list = [
    data_manager,
    Train,
    train_config,
    monotonic,
    # data_manager, # Reloaded only once even if listed twice
    utils,
    # train_config, # Reloaded only once even if listed twice
    metrics
]
data_mgr = DatasetManager(device='cuda')

# Load a synthetic dataset
data_mgr.load_csv('etth1', './etth1.csv')
```

    
    ==================================================
    Dataset: etth1 (csv)
    ==================================================
    Shape: torch.Size([17420, 7])
    Channels: 7
    Length: 17420
    Source: ./etth1.csv
    
    Sample data (first 2 rows):
    tensor([[ 5.8270,  2.0090,  1.5990,  0.4620,  4.2030,  1.3400, 30.5310],
            [ 5.6930,  2.0760,  1.4920,  0.4260,  4.1420,  1.3710, 27.7870]])
    ==================================================
    




    <data_manager.DatasetManager at 0x19ebc32dcd0>



## Seq=336

### EigenACL

#### pred=96


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['etth1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth1: tensor([7.0675, 2.0423, 6.8268, 1.8092, 1.1645, 0.5995, 8.5667],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 11
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 16.1968, mae: 2.2487, huber: 1.8440, swd: 7.9321, ept: 30.0474
    Epoch [1/50], Val Losses: mse: 9.5795, mae: 1.6938, huber: 1.3235, swd: 2.0567, ept: 43.4882
    Epoch [1/50], Test Losses: mse: 13.4613, mae: 1.9975, huber: 1.6126, swd: 3.6984, ept: 31.3479
      Epoch 1 composite train-obj: 1.844026
            Val objective improved inf → 1.3235, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9972, mae: 1.5915, huber: 1.2104, swd: 2.0410, ept: 43.0868
    Epoch [2/50], Val Losses: mse: 9.1159, mae: 1.6718, huber: 1.3038, swd: 2.0035, ept: 43.1756
    Epoch [2/50], Test Losses: mse: 10.5142, mae: 1.8510, huber: 1.4699, swd: 3.0780, ept: 32.4300
      Epoch 2 composite train-obj: 1.210373
            Val objective improved 1.3235 → 1.3038, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3989, mae: 1.5319, huber: 1.1551, swd: 1.7795, ept: 45.0779
    Epoch [3/50], Val Losses: mse: 8.6803, mae: 1.6240, huber: 1.2544, swd: 1.3142, ept: 42.5243
    Epoch [3/50], Test Losses: mse: 10.1141, mae: 1.8056, huber: 1.4252, swd: 2.0852, ept: 33.2357
      Epoch 3 composite train-obj: 1.155105
            Val objective improved 1.3038 → 1.2544, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.1485, mae: 1.4953, huber: 1.1218, swd: 1.6552, ept: 46.8000
    Epoch [4/50], Val Losses: mse: 8.5930, mae: 1.5936, huber: 1.2294, swd: 1.3391, ept: 45.1998
    Epoch [4/50], Test Losses: mse: 9.8290, mae: 1.7636, huber: 1.3886, swd: 1.8883, ept: 35.3232
      Epoch 4 composite train-obj: 1.121816
            Val objective improved 1.2544 → 1.2294, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.9165, mae: 1.4576, huber: 1.0872, swd: 1.5271, ept: 48.1674
    Epoch [5/50], Val Losses: mse: 8.4631, mae: 1.5815, huber: 1.2188, swd: 1.5657, ept: 45.5111
    Epoch [5/50], Test Losses: mse: 9.7355, mae: 1.7432, huber: 1.3697, swd: 2.0444, ept: 36.1535
      Epoch 5 composite train-obj: 1.087189
            Val objective improved 1.2294 → 1.2188, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.7682, mae: 1.4315, huber: 1.0632, swd: 1.4488, ept: 49.0851
    Epoch [6/50], Val Losses: mse: 8.4966, mae: 1.5946, huber: 1.2313, swd: 1.8229, ept: 45.9148
    Epoch [6/50], Test Losses: mse: 9.6626, mae: 1.7356, huber: 1.3629, swd: 2.2061, ept: 36.9981
      Epoch 6 composite train-obj: 1.063155
            No improvement (1.2313), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.7023, mae: 1.4207, huber: 1.0531, swd: 1.4372, ept: 49.6590
    Epoch [7/50], Val Losses: mse: 8.4527, mae: 1.5826, huber: 1.2195, swd: 1.6305, ept: 45.8092
    Epoch [7/50], Test Losses: mse: 9.7213, mae: 1.7299, huber: 1.3568, swd: 1.9380, ept: 36.8680
      Epoch 7 composite train-obj: 1.053110
            No improvement (1.2195), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.5658, mae: 1.4007, huber: 1.0343, swd: 1.3764, ept: 50.2841
    Epoch [8/50], Val Losses: mse: 8.5400, mae: 1.5917, huber: 1.2291, swd: 1.8768, ept: 46.3924
    Epoch [8/50], Test Losses: mse: 9.7861, mae: 1.7303, huber: 1.3592, swd: 2.2383, ept: 37.1477
      Epoch 8 composite train-obj: 1.034299
            No improvement (1.2291), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.4325, mae: 1.3791, huber: 1.0141, swd: 1.3061, ept: 50.9925
    Epoch [9/50], Val Losses: mse: 9.0903, mae: 1.6338, huber: 1.2694, swd: 1.7824, ept: 45.7328
    Epoch [9/50], Test Losses: mse: 9.7733, mae: 1.7248, huber: 1.3522, swd: 1.7969, ept: 37.3791
      Epoch 9 composite train-obj: 1.014098
            No improvement (1.2694), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.3393, mae: 1.3652, huber: 1.0010, swd: 1.2692, ept: 51.2320
    Epoch [10/50], Val Losses: mse: 9.0288, mae: 1.6512, huber: 1.2874, swd: 2.3469, ept: 46.7955
    Epoch [10/50], Test Losses: mse: 9.8519, mae: 1.7667, huber: 1.3927, swd: 2.6066, ept: 36.7381
      Epoch 10 composite train-obj: 1.001026
    Epoch [10/50], Test Losses: mse: 9.7357, mae: 1.7432, huber: 1.3697, swd: 2.0441, ept: 36.1493
    Best round's Test MSE: 9.7355, MAE: 1.7432, SWD: 2.0444
    Best round's Validation MSE: 8.4631, MAE: 1.5815, SWD: 1.5657
    Best round's Test verification MSE : 9.7357, MAE: 1.7432, SWD: 2.0441
    Time taken: 24.28 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 15.2502, mae: 2.1763, huber: 1.7741, swd: 6.8606, ept: 31.4233
    Epoch [1/50], Val Losses: mse: 9.3458, mae: 1.6677, huber: 1.2965, swd: 1.5628, ept: 44.2562
    Epoch [1/50], Test Losses: mse: 13.5442, mae: 1.9717, huber: 1.5884, swd: 3.1349, ept: 32.1401
      Epoch 1 composite train-obj: 1.774050
            Val objective improved inf → 1.2965, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1224, mae: 1.5980, huber: 1.2171, swd: 2.0381, ept: 43.7114
    Epoch [2/50], Val Losses: mse: 8.8156, mae: 1.6486, huber: 1.2817, swd: 1.9787, ept: 44.2302
    Epoch [2/50], Test Losses: mse: 10.5658, mae: 1.8390, huber: 1.4587, swd: 2.9653, ept: 32.8382
      Epoch 2 composite train-obj: 1.217139
            Val objective improved 1.2965 → 1.2817, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2963, mae: 1.5134, huber: 1.1378, swd: 1.6840, ept: 46.0458
    Epoch [3/50], Val Losses: mse: 8.5398, mae: 1.5982, huber: 1.2346, swd: 1.4604, ept: 44.7456
    Epoch [3/50], Test Losses: mse: 9.8356, mae: 1.7713, huber: 1.3954, swd: 2.1896, ept: 34.3439
      Epoch 3 composite train-obj: 1.137834
            Val objective improved 1.2817 → 1.2346, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.0126, mae: 1.4756, huber: 1.1033, swd: 1.5544, ept: 47.5220
    Epoch [4/50], Val Losses: mse: 8.5317, mae: 1.5944, huber: 1.2315, swd: 1.6743, ept: 45.6448
    Epoch [4/50], Test Losses: mse: 9.5931, mae: 1.7492, huber: 1.3748, swd: 2.1876, ept: 35.3779
      Epoch 4 composite train-obj: 1.103311
            Val objective improved 1.2346 → 1.2315, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.8533, mae: 1.4480, huber: 1.0783, swd: 1.4799, ept: 48.8481
    Epoch [5/50], Val Losses: mse: 8.2019, mae: 1.5531, huber: 1.1898, swd: 1.3226, ept: 45.4373
    Epoch [5/50], Test Losses: mse: 9.6436, mae: 1.7403, huber: 1.3654, swd: 1.8914, ept: 36.1797
      Epoch 5 composite train-obj: 1.078286
            Val objective improved 1.2315 → 1.1898, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.7021, mae: 1.4221, huber: 1.0541, swd: 1.3844, ept: 49.6693
    Epoch [6/50], Val Losses: mse: 8.4094, mae: 1.5763, huber: 1.2135, swd: 1.6378, ept: 46.2835
    Epoch [6/50], Test Losses: mse: 9.4953, mae: 1.7272, huber: 1.3545, swd: 2.0609, ept: 37.1520
      Epoch 6 composite train-obj: 1.054133
            No improvement (1.2135), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.6055, mae: 1.4051, huber: 1.0386, swd: 1.3437, ept: 50.4547
    Epoch [7/50], Val Losses: mse: 8.4393, mae: 1.5768, huber: 1.2145, swd: 1.7134, ept: 46.3702
    Epoch [7/50], Test Losses: mse: 9.4794, mae: 1.7194, huber: 1.3462, swd: 1.9710, ept: 37.6819
      Epoch 7 composite train-obj: 1.038630
            No improvement (1.2145), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.5440, mae: 1.3942, huber: 1.0286, swd: 1.3165, ept: 50.9116
    Epoch [8/50], Val Losses: mse: 8.6119, mae: 1.5913, huber: 1.2265, swd: 1.5527, ept: 45.5812
    Epoch [8/50], Test Losses: mse: 9.6148, mae: 1.7239, huber: 1.3503, swd: 1.7515, ept: 37.6241
      Epoch 8 composite train-obj: 1.028641
            No improvement (1.2265), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.4557, mae: 1.3813, huber: 1.0166, swd: 1.2809, ept: 51.3654
    Epoch [9/50], Val Losses: mse: 8.5803, mae: 1.6090, huber: 1.2468, swd: 2.0726, ept: 46.9857
    Epoch [9/50], Test Losses: mse: 9.5478, mae: 1.7301, huber: 1.3577, swd: 2.3404, ept: 37.1106
      Epoch 9 composite train-obj: 1.016637
            No improvement (1.2468), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.3927, mae: 1.3712, huber: 1.0074, swd: 1.2542, ept: 51.6324
    Epoch [10/50], Val Losses: mse: 8.3616, mae: 1.5695, huber: 1.2076, swd: 1.7197, ept: 47.2243
    Epoch [10/50], Test Losses: mse: 9.6459, mae: 1.7253, huber: 1.3533, swd: 2.0426, ept: 37.8193
      Epoch 10 composite train-obj: 1.007433
    Epoch [10/50], Test Losses: mse: 9.6433, mae: 1.7403, huber: 1.3654, swd: 1.8914, ept: 36.1901
    Best round's Test MSE: 9.6436, MAE: 1.7403, SWD: 1.8914
    Best round's Validation MSE: 8.2019, MAE: 1.5531, SWD: 1.3226
    Best round's Test verification MSE : 9.6433, MAE: 1.7403, SWD: 1.8914
    Time taken: 24.63 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 16.2507, mae: 2.2483, huber: 1.8447, swd: 7.4826, ept: 30.6738
    Epoch [1/50], Val Losses: mse: 9.4742, mae: 1.6842, huber: 1.3125, swd: 1.7469, ept: 44.2919
    Epoch [1/50], Test Losses: mse: 13.6426, mae: 1.9895, huber: 1.6055, swd: 3.4004, ept: 31.7523
      Epoch 1 composite train-obj: 1.844701
            Val objective improved inf → 1.3125, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1411, mae: 1.6007, huber: 1.2195, swd: 1.9767, ept: 43.1798
    Epoch [2/50], Val Losses: mse: 9.0322, mae: 1.6512, huber: 1.2833, swd: 1.4659, ept: 43.3554
    Epoch [2/50], Test Losses: mse: 10.5743, mae: 1.8328, huber: 1.4528, swd: 2.5124, ept: 32.3480
      Epoch 2 composite train-obj: 1.219528
            Val objective improved 1.3125 → 1.2833, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3748, mae: 1.5237, huber: 1.1473, swd: 1.6463, ept: 45.2204
    Epoch [3/50], Val Losses: mse: 9.0075, mae: 1.6518, huber: 1.2862, swd: 1.8433, ept: 44.4509
    Epoch [3/50], Test Losses: mse: 9.9217, mae: 1.7905, huber: 1.4130, swd: 2.4936, ept: 33.6707
      Epoch 3 composite train-obj: 1.147325
            No improvement (1.2862), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.0921, mae: 1.4845, huber: 1.1118, swd: 1.5151, ept: 46.9114
    Epoch [4/50], Val Losses: mse: 8.7191, mae: 1.6146, huber: 1.2515, swd: 1.6684, ept: 45.0693
    Epoch [4/50], Test Losses: mse: 9.6310, mae: 1.7473, huber: 1.3738, swd: 2.1686, ept: 35.0015
      Epoch 4 composite train-obj: 1.111821
            Val objective improved 1.2833 → 1.2515, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.9630, mae: 1.4632, huber: 1.0930, swd: 1.4828, ept: 48.1130
    Epoch [5/50], Val Losses: mse: 8.6017, mae: 1.5965, huber: 1.2340, swd: 1.6273, ept: 45.8983
    Epoch [5/50], Test Losses: mse: 9.6640, mae: 1.7487, huber: 1.3755, swd: 2.1935, ept: 35.6276
      Epoch 5 composite train-obj: 1.092964
            Val objective improved 1.2515 → 1.2340, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.8468, mae: 1.4442, huber: 1.0753, swd: 1.4233, ept: 48.9030
    Epoch [6/50], Val Losses: mse: 8.6772, mae: 1.6139, huber: 1.2505, swd: 1.8884, ept: 46.0685
    Epoch [6/50], Test Losses: mse: 9.6147, mae: 1.7400, huber: 1.3670, swd: 2.1892, ept: 36.3274
      Epoch 6 composite train-obj: 1.075254
            No improvement (1.2505), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.6491, mae: 1.4132, huber: 1.0462, swd: 1.2825, ept: 49.8490
    Epoch [7/50], Val Losses: mse: 9.2367, mae: 1.6979, huber: 1.3305, swd: 2.4637, ept: 45.9519
    Epoch [7/50], Test Losses: mse: 9.7950, mae: 1.7892, huber: 1.4118, swd: 2.6414, ept: 35.8221
      Epoch 7 composite train-obj: 1.046179
            No improvement (1.3305), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.5590, mae: 1.3983, huber: 1.0324, swd: 1.2505, ept: 50.5144
    Epoch [8/50], Val Losses: mse: 8.8317, mae: 1.6071, huber: 1.2452, swd: 1.5841, ept: 45.9468
    Epoch [8/50], Test Losses: mse: 9.5901, mae: 1.7222, huber: 1.3504, swd: 1.8888, ept: 36.9248
      Epoch 8 composite train-obj: 1.032441
            No improvement (1.2452), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.4471, mae: 1.3803, huber: 1.0157, swd: 1.1927, ept: 50.9769
    Epoch [9/50], Val Losses: mse: 8.8015, mae: 1.6247, huber: 1.2601, swd: 1.8383, ept: 46.1111
    Epoch [9/50], Test Losses: mse: 9.6993, mae: 1.7302, huber: 1.3583, swd: 2.0946, ept: 37.6682
      Epoch 9 composite train-obj: 1.015693
            No improvement (1.2601), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.3224, mae: 1.3622, huber: 0.9986, swd: 1.1371, ept: 51.5546
    Epoch [10/50], Val Losses: mse: 9.0466, mae: 1.6440, huber: 1.2770, swd: 1.6567, ept: 45.0647
    Epoch [10/50], Test Losses: mse: 9.9944, mae: 1.7546, huber: 1.3811, swd: 1.9827, ept: 37.2387
      Epoch 10 composite train-obj: 0.998650
    Epoch [10/50], Test Losses: mse: 9.6640, mae: 1.7487, huber: 1.3755, swd: 2.1935, ept: 35.6235
    Best round's Test MSE: 9.6640, MAE: 1.7487, SWD: 2.1935
    Best round's Validation MSE: 8.6017, MAE: 1.5965, SWD: 1.6273
    Best round's Test verification MSE : 9.6640, MAE: 1.7487, SWD: 2.1935
    Time taken: 24.17 seconds
    
    ==================================================
    Experiment Summary (ACL_etth1_seq336_pred96_20250510_1543)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.6810 ± 0.0394
      mae: 1.7441 ± 0.0035
      huber: 1.3702 ± 0.0041
      swd: 2.0431 ± 0.1233
      ept: 35.9869 ± 0.2543
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.4222 ± 0.1658
      mae: 1.5771 ± 0.0180
      huber: 1.2142 ± 0.0183
      swd: 1.5052 ± 0.1316
      ept: 45.6156 ± 0.2022
      count: 11.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 74.10 seconds
    
    Experiment complete: ACL_etth1_seq336_pred96_20250510_1543
    Model: ACL
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['etth1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth1: tensor([7.0675, 2.0423, 6.8268, 1.8092, 1.1645, 0.5995, 8.5667],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 16.9857, mae: 2.3436, huber: 1.9355, swd: 7.8115, ept: 42.4131
    Epoch [1/50], Val Losses: mse: 11.1763, mae: 1.8531, huber: 1.4761, swd: 2.6635, ept: 60.1210
    Epoch [1/50], Test Losses: mse: 15.6077, mae: 2.1408, huber: 1.7490, swd: 4.3467, ept: 46.6200
      Epoch 1 composite train-obj: 1.935460
            Val objective improved inf → 1.4761, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.1208, mae: 1.7152, huber: 1.3267, swd: 2.2429, ept: 61.8034
    Epoch [2/50], Val Losses: mse: 10.9395, mae: 1.8456, huber: 1.4699, swd: 1.5054, ept: 55.2037
    Epoch [2/50], Test Losses: mse: 11.2907, mae: 1.9168, huber: 1.5292, swd: 2.1102, ept: 47.6114
      Epoch 2 composite train-obj: 1.326670
            Val objective improved 1.4761 → 1.4699, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.0924, mae: 1.6307, huber: 1.2457, swd: 1.8285, ept: 65.5066
    Epoch [3/50], Val Losses: mse: 11.5032, mae: 1.9195, huber: 1.5422, swd: 3.1692, ept: 55.8873
    Epoch [3/50], Test Losses: mse: 10.8469, mae: 1.9533, huber: 1.5617, swd: 3.7925, ept: 47.6652
      Epoch 3 composite train-obj: 1.245668
            No improvement (1.5422), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.9226, mae: 1.6141, huber: 1.2307, swd: 1.8138, ept: 66.5144
    Epoch [4/50], Val Losses: mse: 11.4422, mae: 1.8488, huber: 1.4786, swd: 2.2324, ept: 60.7076
    Epoch [4/50], Test Losses: mse: 10.0374, mae: 1.8405, huber: 1.4576, swd: 2.4363, ept: 50.4391
      Epoch 4 composite train-obj: 1.230665
            No improvement (1.4786), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.6234, mae: 1.5749, huber: 1.1943, swd: 1.6229, ept: 68.8831
    Epoch [5/50], Val Losses: mse: 11.4966, mae: 1.8592, huber: 1.4893, swd: 2.4988, ept: 61.4085
    Epoch [5/50], Test Losses: mse: 9.9333, mae: 1.8388, huber: 1.4557, swd: 2.5503, ept: 51.1698
      Epoch 5 composite train-obj: 1.194310
            No improvement (1.4893), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.3961, mae: 1.5398, huber: 1.1620, swd: 1.4919, ept: 70.6507
    Epoch [6/50], Val Losses: mse: 11.5430, mae: 1.8471, huber: 1.4776, swd: 2.2082, ept: 59.1822
    Epoch [6/50], Test Losses: mse: 9.8136, mae: 1.8158, huber: 1.4339, swd: 2.1393, ept: 51.1554
      Epoch 6 composite train-obj: 1.162018
            No improvement (1.4776), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.2397, mae: 1.5176, huber: 1.1415, swd: 1.4025, ept: 71.7990
    Epoch [7/50], Val Losses: mse: 11.7099, mae: 1.8481, huber: 1.4794, swd: 2.0468, ept: 60.7383
    Epoch [7/50], Test Losses: mse: 9.7888, mae: 1.8133, huber: 1.4316, swd: 1.9170, ept: 52.0538
      Epoch 7 composite train-obj: 1.141536
    Epoch [7/50], Test Losses: mse: 11.2906, mae: 1.9167, huber: 1.5292, swd: 2.1099, ept: 47.5890
    Best round's Test MSE: 11.2907, MAE: 1.9168, SWD: 2.1102
    Best round's Validation MSE: 10.9395, MAE: 1.8456, SWD: 1.5054
    Best round's Test verification MSE : 11.2906, MAE: 1.9167, SWD: 2.1099
    Time taken: 17.16 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 16.1953, mae: 2.2739, huber: 1.8673, swd: 7.4617, ept: 45.1619
    Epoch [1/50], Val Losses: mse: 10.8915, mae: 1.8465, huber: 1.4701, swd: 2.7672, ept: 61.2299
    Epoch [1/50], Test Losses: mse: 14.2505, mae: 2.0802, huber: 1.6885, swd: 3.8467, ept: 46.6197
      Epoch 1 composite train-obj: 1.867252
            Val objective improved inf → 1.4701, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.6245, mae: 1.6744, huber: 1.2873, swd: 2.0111, ept: 64.2920
    Epoch [2/50], Val Losses: mse: 10.8013, mae: 1.8200, huber: 1.4479, swd: 2.0127, ept: 58.1678
    Epoch [2/50], Test Losses: mse: 10.8036, mae: 1.8865, huber: 1.5000, swd: 2.3620, ept: 48.7698
      Epoch 2 composite train-obj: 1.287309
            Val objective improved 1.4701 → 1.4479, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.9943, mae: 1.6225, huber: 1.2382, swd: 1.8197, ept: 66.5268
    Epoch [3/50], Val Losses: mse: 11.1998, mae: 1.8387, huber: 1.4657, swd: 1.7888, ept: 55.9389
    Epoch [3/50], Test Losses: mse: 10.2153, mae: 1.8538, huber: 1.4681, swd: 2.0101, ept: 49.3433
      Epoch 3 composite train-obj: 1.238167
            No improvement (1.4657), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.6603, mae: 1.5810, huber: 1.1995, swd: 1.6451, ept: 68.9485
    Epoch [4/50], Val Losses: mse: 11.1236, mae: 1.8184, huber: 1.4493, swd: 2.0470, ept: 59.5555
    Epoch [4/50], Test Losses: mse: 9.9027, mae: 1.8266, huber: 1.4437, swd: 2.0719, ept: 51.3066
      Epoch 4 composite train-obj: 1.199462
            No improvement (1.4493), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.4610, mae: 1.5515, huber: 1.1726, swd: 1.5477, ept: 70.6614
    Epoch [5/50], Val Losses: mse: 11.5668, mae: 1.8713, huber: 1.5016, swd: 2.8687, ept: 60.6055
    Epoch [5/50], Test Losses: mse: 9.8120, mae: 1.8317, huber: 1.4492, swd: 2.6128, ept: 52.6202
      Epoch 5 composite train-obj: 1.172552
            No improvement (1.5016), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.3381, mae: 1.5335, huber: 1.1559, swd: 1.4787, ept: 71.8405
    Epoch [6/50], Val Losses: mse: 11.1477, mae: 1.8250, huber: 1.4571, swd: 2.5766, ept: 62.2959
    Epoch [6/50], Test Losses: mse: 9.7058, mae: 1.8103, huber: 1.4289, swd: 2.2936, ept: 52.8739
      Epoch 6 composite train-obj: 1.155891
            No improvement (1.4571), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.1705, mae: 1.5082, huber: 1.1324, swd: 1.3858, ept: 73.0602
    Epoch [7/50], Val Losses: mse: 11.4893, mae: 1.8438, huber: 1.4751, swd: 2.4829, ept: 61.8927
    Epoch [7/50], Test Losses: mse: 9.6706, mae: 1.8081, huber: 1.4271, swd: 2.1375, ept: 53.4601
      Epoch 7 composite train-obj: 1.132418
    Epoch [7/50], Test Losses: mse: 10.8039, mae: 1.8865, huber: 1.5000, swd: 2.3618, ept: 48.7282
    Best round's Test MSE: 10.8036, MAE: 1.8865, SWD: 2.3620
    Best round's Validation MSE: 10.8013, MAE: 1.8200, SWD: 2.0127
    Best round's Test verification MSE : 10.8039, MAE: 1.8865, SWD: 2.3618
    Time taken: 17.26 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.3844, mae: 2.3571, huber: 1.9488, swd: 7.5579, ept: 43.2456
    Epoch [1/50], Val Losses: mse: 10.9770, mae: 1.8187, huber: 1.4408, swd: 1.8074, ept: 58.6390
    Epoch [1/50], Test Losses: mse: 15.8539, mae: 2.1245, huber: 1.7344, swd: 3.1949, ept: 47.1515
      Epoch 1 composite train-obj: 1.948845
            Val objective improved inf → 1.4408, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.9150, mae: 1.6949, huber: 1.3074, swd: 1.9443, ept: 63.4042
    Epoch [2/50], Val Losses: mse: 10.8453, mae: 1.8513, huber: 1.4743, swd: 1.4482, ept: 54.3588
    Epoch [2/50], Test Losses: mse: 11.1397, mae: 1.9177, huber: 1.5293, swd: 2.0191, ept: 47.6212
      Epoch 2 composite train-obj: 1.307395
            No improvement (1.4743), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.0222, mae: 1.6274, huber: 1.2426, swd: 1.6418, ept: 65.7001
    Epoch [3/50], Val Losses: mse: 11.2609, mae: 1.8802, huber: 1.5062, swd: 2.6099, ept: 58.1785
    Epoch [3/50], Test Losses: mse: 10.5055, mae: 1.9072, huber: 1.5189, swd: 3.0898, ept: 48.9346
      Epoch 3 composite train-obj: 1.242620
            No improvement (1.5062), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.6582, mae: 1.5832, huber: 1.2013, swd: 1.4688, ept: 68.0971
    Epoch [4/50], Val Losses: mse: 11.1816, mae: 1.8305, huber: 1.4596, swd: 1.7923, ept: 57.8046
    Epoch [4/50], Test Losses: mse: 10.1094, mae: 1.8503, huber: 1.4659, swd: 2.0540, ept: 50.1264
      Epoch 4 composite train-obj: 1.201339
            No improvement (1.4596), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.4728, mae: 1.5533, huber: 1.1745, swd: 1.3651, ept: 70.2164
    Epoch [5/50], Val Losses: mse: 11.5062, mae: 1.8920, huber: 1.5198, swd: 2.7743, ept: 60.5264
    Epoch [5/50], Test Losses: mse: 10.0364, mae: 1.8662, huber: 1.4812, swd: 2.8416, ept: 50.8726
      Epoch 5 composite train-obj: 1.174520
            No improvement (1.5198), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.3178, mae: 1.5283, huber: 1.1520, swd: 1.3132, ept: 72.0630
    Epoch [6/50], Val Losses: mse: 11.5217, mae: 1.8661, huber: 1.4959, swd: 2.3959, ept: 60.0923
    Epoch [6/50], Test Losses: mse: 9.8329, mae: 1.8329, huber: 1.4503, swd: 2.4362, ept: 52.2777
      Epoch 6 composite train-obj: 1.151974
    Epoch [6/50], Test Losses: mse: 15.8534, mae: 2.1245, huber: 1.7343, swd: 3.1950, ept: 47.1136
    Best round's Test MSE: 15.8539, MAE: 2.1245, SWD: 3.1949
    Best round's Validation MSE: 10.9770, MAE: 1.8187, SWD: 1.8074
    Best round's Test verification MSE : 15.8534, MAE: 2.1245, SWD: 3.1950
    Time taken: 14.40 seconds
    
    ==================================================
    Experiment Summary (ACL_etth1_seq336_pred196_20250510_1544)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.6494 ± 2.2747
      mae: 1.9759 ± 0.1058
      huber: 1.5878 ± 0.1043
      swd: 2.5557 ± 0.4635
      ept: 47.8442 ± 0.6809
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.9059 ± 0.0756
      mae: 1.8281 ± 0.0124
      huber: 1.4529 ± 0.0124
      swd: 1.7752 ± 0.2083
      ept: 57.3368 ± 1.5205
      count: 10.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 48.88 seconds
    
    Experiment complete: ACL_etth1_seq336_pred196_20250510_1544
    Model: ACL
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['etth1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth1: tensor([7.0675, 2.0423, 6.8268, 1.8092, 1.1645, 0.5995, 8.5667],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 91
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 91
    Validation Batches: 9
    Test Batches: 22
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.0745, mae: 2.3652, huber: 1.9550, swd: 7.3538, ept: 55.2020
    Epoch [1/50], Val Losses: mse: 11.1840, mae: 1.8687, huber: 1.4895, swd: 2.8686, ept: 78.8522
    Epoch [1/50], Test Losses: mse: 16.4924, mae: 2.2579, huber: 1.8590, swd: 4.3812, ept: 63.2543
      Epoch 1 composite train-obj: 1.955028
            Val objective improved inf → 1.4895, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.2622, mae: 1.7541, huber: 1.3616, swd: 2.0719, ept: 81.3206
    Epoch [2/50], Val Losses: mse: 10.6886, mae: 1.8208, huber: 1.4480, swd: 1.9588, ept: 76.5808
    Epoch [2/50], Test Losses: mse: 11.4533, mae: 1.9884, huber: 1.5962, swd: 2.8018, ept: 66.3984
      Epoch 2 composite train-obj: 1.361581
            Val objective improved 1.4895 → 1.4480, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.3551, mae: 1.6891, huber: 1.2990, swd: 1.7853, ept: 84.3611
    Epoch [3/50], Val Losses: mse: 10.8538, mae: 1.8360, huber: 1.4598, swd: 1.6874, ept: 66.9480
    Epoch [3/50], Test Losses: mse: 10.7523, mae: 1.9559, huber: 1.5628, swd: 2.2299, ept: 64.7550
      Epoch 3 composite train-obj: 1.299021
            No improvement (1.4598), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.1368, mae: 1.6642, huber: 1.2758, swd: 1.7010, ept: 86.6075
    Epoch [4/50], Val Losses: mse: 11.3011, mae: 1.9439, huber: 1.5529, swd: 1.5670, ept: 57.8026
    Epoch [4/50], Test Losses: mse: 11.4084, mae: 2.0533, huber: 1.6540, swd: 2.0843, ept: 54.7271
      Epoch 4 composite train-obj: 1.275775
            No improvement (1.5529), counter 2/5
    Epoch [5/50], Train Losses: mse: 7.1124, mae: 1.6576, huber: 1.2703, swd: 1.7375, ept: 86.8479
    Epoch [5/50], Val Losses: mse: 10.8407, mae: 1.8162, huber: 1.4435, swd: 1.7428, ept: 70.9318
    Epoch [5/50], Test Losses: mse: 10.1688, mae: 1.9020, huber: 1.5120, swd: 1.9028, ept: 68.0563
      Epoch 5 composite train-obj: 1.270270
            Val objective improved 1.4480 → 1.4435, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.8138, mae: 1.6184, huber: 1.2336, swd: 1.5574, ept: 91.0821
    Epoch [6/50], Val Losses: mse: 11.9560, mae: 1.9839, huber: 1.6028, swd: 3.4856, ept: 77.8282
    Epoch [6/50], Test Losses: mse: 10.6942, mae: 2.0293, huber: 1.6311, swd: 3.7688, ept: 65.1825
      Epoch 6 composite train-obj: 1.233563
            No improvement (1.6028), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.6962, mae: 1.5997, huber: 1.2164, swd: 1.4951, ept: 90.7957
    Epoch [7/50], Val Losses: mse: 11.6119, mae: 1.9228, huber: 1.5462, swd: 2.9778, ept: 75.6407
    Epoch [7/50], Test Losses: mse: 10.3268, mae: 1.9660, huber: 1.5706, swd: 3.2027, ept: 66.3847
      Epoch 7 composite train-obj: 1.216428
            No improvement (1.5462), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.5747, mae: 1.5793, huber: 1.1978, swd: 1.4267, ept: 92.2455
    Epoch [8/50], Val Losses: mse: 11.1872, mae: 1.8448, huber: 1.4745, swd: 2.3329, ept: 75.7616
    Epoch [8/50], Test Losses: mse: 10.0803, mae: 1.9052, huber: 1.5157, swd: 2.4140, ept: 68.2214
      Epoch 8 composite train-obj: 1.197824
            No improvement (1.4745), counter 3/5
    Epoch [9/50], Train Losses: mse: 6.5445, mae: 1.5730, huber: 1.1923, swd: 1.4440, ept: 92.7137
    Epoch [9/50], Val Losses: mse: 11.9469, mae: 1.9382, huber: 1.5631, swd: 2.8390, ept: 77.3691
    Epoch [9/50], Test Losses: mse: 10.2901, mae: 1.9538, huber: 1.5618, swd: 2.8563, ept: 67.0360
      Epoch 9 composite train-obj: 1.192292
            No improvement (1.5631), counter 4/5
    Epoch [10/50], Train Losses: mse: 6.5007, mae: 1.5653, huber: 1.1849, swd: 1.3960, ept: 93.7003
    Epoch [10/50], Val Losses: mse: 11.3888, mae: 1.8629, huber: 1.4925, swd: 2.4327, ept: 76.6641
    Epoch [10/50], Test Losses: mse: 9.9670, mae: 1.8809, huber: 1.4934, swd: 2.1207, ept: 69.9285
      Epoch 10 composite train-obj: 1.184884
    Epoch [10/50], Test Losses: mse: 10.1686, mae: 1.9019, huber: 1.5119, swd: 1.9025, ept: 68.0464
    Best round's Test MSE: 10.1688, MAE: 1.9020, SWD: 1.9028
    Best round's Validation MSE: 10.8407, MAE: 1.8162, SWD: 1.7428
    Best round's Test verification MSE : 10.1686, MAE: 1.9019, SWD: 1.9025
    Time taken: 24.00 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.3863, mae: 2.3789, huber: 1.9684, swd: 7.9307, ept: 54.2819
    Epoch [1/50], Val Losses: mse: 10.8148, mae: 1.8162, huber: 1.4391, swd: 1.7565, ept: 77.3389
    Epoch [1/50], Test Losses: mse: 15.4960, mae: 2.1665, huber: 1.7723, swd: 2.9926, ept: 64.5643
      Epoch 1 composite train-obj: 1.968417
            Val objective improved inf → 1.4391, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.1614, mae: 1.7538, huber: 1.3608, swd: 2.0856, ept: 80.9479
    Epoch [2/50], Val Losses: mse: 10.7729, mae: 1.8259, huber: 1.4528, swd: 1.9817, ept: 78.3394
    Epoch [2/50], Test Losses: mse: 11.3298, mae: 1.9865, huber: 1.5934, swd: 2.7755, ept: 66.5467
      Epoch 2 composite train-obj: 1.360794
            No improvement (1.4528), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.3756, mae: 1.6947, huber: 1.3042, swd: 1.8691, ept: 83.8547
    Epoch [3/50], Val Losses: mse: 10.9636, mae: 1.8311, huber: 1.4588, swd: 2.1296, ept: 74.8922
    Epoch [3/50], Test Losses: mse: 10.5581, mae: 1.9411, huber: 1.5496, swd: 2.5587, ept: 67.2165
      Epoch 3 composite train-obj: 1.304242
            No improvement (1.4588), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.0758, mae: 1.6604, huber: 1.2718, swd: 1.7017, ept: 85.8452
    Epoch [4/50], Val Losses: mse: 12.2713, mae: 2.0760, huber: 1.6745, swd: 1.8386, ept: 49.8220
    Epoch [4/50], Test Losses: mse: 12.3008, mae: 2.1744, huber: 1.7694, swd: 2.7601, ept: 45.1231
      Epoch 4 composite train-obj: 1.271764
            No improvement (1.6745), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.4912, mae: 1.7019, huber: 1.3124, swd: 2.0886, ept: 83.7430
    Epoch [5/50], Val Losses: mse: 11.0290, mae: 1.8294, huber: 1.4585, swd: 2.2512, ept: 78.0750
    Epoch [5/50], Test Losses: mse: 10.1630, mae: 1.9186, huber: 1.5282, swd: 2.4982, ept: 68.5482
      Epoch 5 composite train-obj: 1.312356
            No improvement (1.4585), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.8674, mae: 1.6279, huber: 1.2425, swd: 1.5787, ept: 89.5915
    Epoch [6/50], Val Losses: mse: 11.5770, mae: 1.9438, huber: 1.5619, swd: 3.3701, ept: 75.7438
    Epoch [6/50], Test Losses: mse: 10.5569, mae: 2.0032, huber: 1.6050, swd: 3.5259, ept: 65.6012
      Epoch 6 composite train-obj: 1.242525
    Epoch [6/50], Test Losses: mse: 15.4961, mae: 2.1665, huber: 1.7723, swd: 2.9929, ept: 64.5767
    Best round's Test MSE: 15.4960, MAE: 2.1665, SWD: 2.9926
    Best round's Validation MSE: 10.8148, MAE: 1.8162, SWD: 1.7565
    Best round's Test verification MSE : 15.4961, MAE: 2.1665, SWD: 2.9929
    Time taken: 14.23 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.5340, mae: 2.3895, huber: 1.9790, swd: 7.9826, ept: 54.5500
    Epoch [1/50], Val Losses: mse: 10.7077, mae: 1.8015, huber: 1.4248, swd: 2.2509, ept: 79.1131
    Epoch [1/50], Test Losses: mse: 15.9970, mae: 2.1956, huber: 1.8004, swd: 3.8872, ept: 64.6947
      Epoch 1 composite train-obj: 1.979005
            Val objective improved inf → 1.4248, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.2121, mae: 1.7563, huber: 1.3634, swd: 2.0732, ept: 80.6808
    Epoch [2/50], Val Losses: mse: 10.5963, mae: 1.8348, huber: 1.4608, swd: 2.4575, ept: 79.4808
    Epoch [2/50], Test Losses: mse: 11.5621, mae: 2.0237, huber: 1.6284, swd: 3.5872, ept: 65.3220
      Epoch 2 composite train-obj: 1.363444
            No improvement (1.4608), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.3822, mae: 1.6951, huber: 1.3046, swd: 1.7809, ept: 83.9229
    Epoch [3/50], Val Losses: mse: 10.7481, mae: 1.8359, huber: 1.4616, swd: 2.2444, ept: 78.5167
    Epoch [3/50], Test Losses: mse: 10.8227, mae: 1.9811, huber: 1.5864, swd: 3.0352, ept: 65.8062
      Epoch 3 composite train-obj: 1.304645
            No improvement (1.4616), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.1527, mae: 1.6666, huber: 1.2780, swd: 1.6636, ept: 85.2662
    Epoch [4/50], Val Losses: mse: 11.3767, mae: 1.9533, huber: 1.5725, swd: 3.4705, ept: 76.5776
    Epoch [4/50], Test Losses: mse: 11.2396, mae: 2.0743, huber: 1.6747, swd: 4.2993, ept: 62.6698
      Epoch 4 composite train-obj: 1.278009
            No improvement (1.5725), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.1061, mae: 1.6584, huber: 1.2710, swd: 1.7156, ept: 86.1702
    Epoch [5/50], Val Losses: mse: 11.5647, mae: 1.9353, huber: 1.5534, swd: 2.8209, ept: 74.4951
    Epoch [5/50], Test Losses: mse: 10.5298, mae: 2.0003, huber: 1.6012, swd: 3.3047, ept: 64.8602
      Epoch 5 composite train-obj: 1.270970
            No improvement (1.5534), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.8759, mae: 1.6270, huber: 1.2420, swd: 1.5532, ept: 89.1793
    Epoch [6/50], Val Losses: mse: 11.4715, mae: 1.9165, huber: 1.5399, swd: 2.9591, ept: 78.1829
    Epoch [6/50], Test Losses: mse: 10.4711, mae: 1.9790, huber: 1.5855, swd: 3.4450, ept: 67.3361
      Epoch 6 composite train-obj: 1.242046
    Epoch [6/50], Test Losses: mse: 15.9966, mae: 2.1956, huber: 1.8004, swd: 3.8871, ept: 64.7007
    Best round's Test MSE: 15.9970, MAE: 2.1956, SWD: 3.8872
    Best round's Validation MSE: 10.7077, MAE: 1.8015, SWD: 2.2509
    Best round's Test verification MSE : 15.9966, MAE: 2.1956, SWD: 3.8871
    Time taken: 13.98 seconds
    
    ==================================================
    Experiment Summary (ACL_etth1_seq336_pred336_20250510_1545)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 13.8873 ± 2.6373
      mae: 2.0880 ± 0.1321
      huber: 1.6949 ± 0.1298
      swd: 2.9276 ± 0.8115
      ept: 65.7718 ± 1.6163
      count: 9.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.7877 ± 0.0576
      mae: 1.8113 ± 0.0069
      huber: 1.4358 ± 0.0080
      swd: 1.9167 ± 0.2363
      ept: 75.7946 ± 3.5140
      count: 9.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 52.29 seconds
    
    Experiment complete: ACL_etth1_seq336_pred336_20250510_1545
    Model: ACL
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['etth1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    global_std.shape: torch.Size([7])
    Global Std for etth1: tensor([7.0675, 2.0423, 6.8268, 1.8092, 1.1645, 0.5995, 8.5667],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 88
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 88
    Validation Batches: 6
    Test Batches: 19
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.7722, mae: 2.4806, huber: 2.0637, swd: 7.8700, ept: 65.8692
    Epoch [1/50], Val Losses: mse: 11.2337, mae: 1.8749, huber: 1.4938, swd: 2.0483, ept: 103.0102
    Epoch [1/50], Test Losses: mse: 17.6119, mae: 2.3802, huber: 1.9734, swd: 3.6108, ept: 94.6179
      Epoch 1 composite train-obj: 2.063682
            Val objective improved inf → 1.4938, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.1597, mae: 1.8921, huber: 1.4897, swd: 2.4185, ept: 98.1859
    Epoch [2/50], Val Losses: mse: 11.6941, mae: 1.9696, huber: 1.5930, swd: 2.9360, ept: 108.7678
    Epoch [2/50], Test Losses: mse: 12.1890, mae: 2.1558, huber: 1.7492, swd: 3.8077, ept: 100.9414
      Epoch 2 composite train-obj: 1.489720
            No improvement (1.5930), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.9777, mae: 1.8036, huber: 1.4039, swd: 2.0229, ept: 105.4015
    Epoch [3/50], Val Losses: mse: 12.5968, mae: 2.0676, huber: 1.6857, swd: 3.5610, ept: 111.3776
    Epoch [3/50], Test Losses: mse: 11.6527, mae: 2.1604, huber: 1.7521, swd: 4.0644, ept: 99.4896
      Epoch 3 composite train-obj: 1.403873
            No improvement (1.6857), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.8536, mae: 1.7895, huber: 1.3910, swd: 1.9544, ept: 103.5563
    Epoch [4/50], Val Losses: mse: 13.5934, mae: 2.1260, huber: 1.7439, swd: 2.9037, ept: 73.7287
    Epoch [4/50], Test Losses: mse: 10.9065, mae: 2.0655, huber: 1.6616, swd: 2.4225, ept: 98.3746
      Epoch 4 composite train-obj: 1.390975
            No improvement (1.7439), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.5531, mae: 1.7489, huber: 1.3527, swd: 1.7677, ept: 109.7188
    Epoch [5/50], Val Losses: mse: 14.1229, mae: 2.1944, huber: 1.8129, swd: 3.8565, ept: 79.1254
    Epoch [5/50], Test Losses: mse: 10.8929, mae: 2.0825, huber: 1.6788, swd: 3.1476, ept: 104.8552
      Epoch 5 composite train-obj: 1.352676
            No improvement (1.8129), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.3958, mae: 1.7246, huber: 1.3300, swd: 1.7191, ept: 112.5640
    Epoch [6/50], Val Losses: mse: 13.9900, mae: 2.1928, huber: 1.8063, swd: 3.8882, ept: 87.6880
    Epoch [6/50], Test Losses: mse: 11.0370, mae: 2.1214, huber: 1.7133, swd: 3.6399, ept: 104.0992
      Epoch 6 composite train-obj: 1.329959
    Epoch [6/50], Test Losses: mse: 17.6102, mae: 2.3800, huber: 1.9732, swd: 3.6111, ept: 94.6722
    Best round's Test MSE: 17.6119, MAE: 2.3802, SWD: 3.6108
    Best round's Validation MSE: 11.2337, MAE: 1.8749, SWD: 2.0483
    Best round's Test verification MSE : 17.6102, MAE: 2.3800, SWD: 3.6111
    Time taken: 13.90 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.6984, mae: 2.4601, huber: 2.0445, swd: 7.2014, ept: 67.6999
    Epoch [1/50], Val Losses: mse: 11.5564, mae: 1.9349, huber: 1.5539, swd: 3.1411, ept: 130.8851
    Epoch [1/50], Test Losses: mse: 17.7573, mae: 2.4314, huber: 2.0230, swd: 5.2757, ept: 95.4347
      Epoch 1 composite train-obj: 2.044512
            Val objective improved inf → 1.5539, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.9555, mae: 1.8680, huber: 1.4666, swd: 2.1646, ept: 100.5290
    Epoch [2/50], Val Losses: mse: 11.5072, mae: 1.9773, huber: 1.5965, swd: 1.8787, ept: 75.7364
    Epoch [2/50], Test Losses: mse: 12.4148, mae: 2.1671, huber: 1.7619, swd: 2.8803, ept: 88.2353
      Epoch 2 composite train-obj: 1.466598
            No improvement (1.5965), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.9909, mae: 1.8001, huber: 1.4010, swd: 1.9151, ept: 105.6817
    Epoch [3/50], Val Losses: mse: 12.6257, mae: 2.0641, huber: 1.6824, swd: 2.5225, ept: 71.7232
    Epoch [3/50], Test Losses: mse: 11.3613, mae: 2.0988, huber: 1.6955, swd: 2.7212, ept: 97.1577
      Epoch 3 composite train-obj: 1.400996
            No improvement (1.6824), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.7182, mae: 1.7692, huber: 1.3714, swd: 1.7736, ept: 108.4897
    Epoch [4/50], Val Losses: mse: 12.9356, mae: 2.0672, huber: 1.6884, swd: 2.6148, ept: 74.4987
    Epoch [4/50], Test Losses: mse: 10.8012, mae: 2.0433, huber: 1.6422, swd: 2.5069, ept: 107.4876
      Epoch 4 composite train-obj: 1.371405
            No improvement (1.6884), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.5603, mae: 1.7470, huber: 1.3512, swd: 1.7245, ept: 110.3150
    Epoch [5/50], Val Losses: mse: 13.7317, mae: 2.1326, huber: 1.7512, swd: 2.5743, ept: 73.6672
    Epoch [5/50], Test Losses: mse: 10.9408, mae: 2.0774, huber: 1.6742, swd: 2.3470, ept: 98.4854
      Epoch 5 composite train-obj: 1.351209
            No improvement (1.7512), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.6075, mae: 1.7499, huber: 1.3547, swd: 1.7997, ept: 108.7190
    Epoch [6/50], Val Losses: mse: 13.8291, mae: 2.1476, huber: 1.7673, swd: 3.1673, ept: 77.3090
    Epoch [6/50], Test Losses: mse: 10.6820, mae: 2.0516, huber: 1.6492, swd: 2.7581, ept: 106.3765
      Epoch 6 composite train-obj: 1.354664
    Epoch [6/50], Test Losses: mse: 17.7571, mae: 2.4314, huber: 2.0230, swd: 5.2764, ept: 95.4792
    Best round's Test MSE: 17.7573, MAE: 2.4314, SWD: 5.2757
    Best round's Validation MSE: 11.5564, MAE: 1.9349, SWD: 3.1411
    Best round's Test verification MSE : 17.7571, MAE: 2.4314, SWD: 5.2764
    Time taken: 18.41 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 17.7047, mae: 2.4640, huber: 2.0481, swd: 7.7244, ept: 68.0102
    Epoch [1/50], Val Losses: mse: 11.4911, mae: 1.8877, huber: 1.5059, swd: 2.1363, ept: 104.0358
    Epoch [1/50], Test Losses: mse: 18.0818, mae: 2.4176, huber: 2.0095, swd: 3.9641, ept: 90.9227
      Epoch 1 composite train-obj: 2.048146
            Val objective improved inf → 1.5059, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.0734, mae: 1.8815, huber: 1.4798, swd: 2.3951, ept: 99.7948
    Epoch [2/50], Val Losses: mse: 11.2564, mae: 1.9210, huber: 1.5455, swd: 2.1931, ept: 94.4958
    Epoch [2/50], Test Losses: mse: 12.1449, mae: 2.1431, huber: 1.7378, swd: 3.0899, ept: 99.2983
      Epoch 2 composite train-obj: 1.479817
            No improvement (1.5455), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.9781, mae: 1.8002, huber: 1.4010, swd: 2.0031, ept: 104.1703
    Epoch [3/50], Val Losses: mse: 12.5315, mae: 2.0871, huber: 1.6999, swd: 3.5803, ept: 110.8293
    Epoch [3/50], Test Losses: mse: 11.8571, mae: 2.1933, huber: 1.7813, swd: 4.1961, ept: 98.8822
      Epoch 3 composite train-obj: 1.401040
            No improvement (1.6999), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.7827, mae: 1.7789, huber: 1.3808, swd: 1.9567, ept: 105.1891
    Epoch [4/50], Val Losses: mse: 13.2037, mae: 2.0917, huber: 1.7119, swd: 3.1013, ept: 79.5695
    Epoch [4/50], Test Losses: mse: 11.0938, mae: 2.0926, huber: 1.6888, swd: 3.0220, ept: 105.7412
      Epoch 4 composite train-obj: 1.380805
            No improvement (1.7119), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.6891, mae: 1.7594, huber: 1.3630, swd: 1.9058, ept: 107.8215
    Epoch [5/50], Val Losses: mse: 13.3138, mae: 2.1419, huber: 1.7536, swd: 3.7154, ept: 97.3869
    Epoch [5/50], Test Losses: mse: 11.2228, mae: 2.1438, huber: 1.7326, swd: 3.8664, ept: 97.1788
      Epoch 5 composite train-obj: 1.363012
            No improvement (1.7536), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.4632, mae: 1.7316, huber: 1.3370, swd: 1.8364, ept: 111.6299
    Epoch [6/50], Val Losses: mse: 13.8474, mae: 2.1708, huber: 1.7890, swd: 3.8995, ept: 81.7450
    Epoch [6/50], Test Losses: mse: 10.9988, mae: 2.0973, huber: 1.6943, swd: 3.4378, ept: 108.3345
      Epoch 6 composite train-obj: 1.336966
    Epoch [6/50], Test Losses: mse: 18.0820, mae: 2.4176, huber: 2.0096, swd: 3.9647, ept: 90.7947
    Best round's Test MSE: 18.0818, MAE: 2.4176, SWD: 3.9641
    Best round's Validation MSE: 11.4911, MAE: 1.8877, SWD: 2.1363
    Best round's Test verification MSE : 18.0820, MAE: 2.4176, SWD: 3.9647
    Time taken: 23.71 seconds
    
    ==================================================
    Experiment Summary (ACL_etth1_seq336_pred720_20250510_1546)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 17.8170 ± 0.1964
      mae: 2.4097 ± 0.0216
      huber: 2.0019 ± 0.0209
      swd: 4.2835 ± 0.7162
      ept: 93.6584 ± 1.9630
      count: 6.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 11.4271 ± 0.1393
      mae: 1.8992 ± 0.0258
      huber: 1.5179 ± 0.0260
      swd: 2.4419 ± 0.4957
      ept: 112.6437 ± 12.9054
      count: 6.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 56.13 seconds
    
    Experiment complete: ACL_etth1_seq336_pred720_20250510_1546
    Model: ACL
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### Timemixer

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 11
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.0394, mae: 1.6638, huber: 1.2853, swd: 1.9024, target_std: 6.4056
    Epoch [1/50], Val Losses: mse: 7.6343, mae: 1.4468, huber: 1.0906, swd: 0.9178, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.0119, mae: 1.7374, huber: 1.3706, swd: 1.7793, target_std: 4.7659
      Epoch 1 composite train-obj: 1.285268
            Val objective improved inf → 1.0906, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0128, mae: 1.4433, huber: 1.0780, swd: 1.5266, target_std: 6.4060
    Epoch [2/50], Val Losses: mse: 7.5162, mae: 1.4237, huber: 1.0702, swd: 1.0179, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 9.9739, mae: 1.7227, huber: 1.3568, swd: 1.9098, target_std: 4.7659
      Epoch 2 composite train-obj: 1.077973
            Val objective improved 1.0906 → 1.0702, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.8058, mae: 1.4110, huber: 1.0478, swd: 1.4596, target_std: 6.4058
    Epoch [3/50], Val Losses: mse: 7.6479, mae: 1.4348, huber: 1.0806, swd: 0.9639, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.0208, mae: 1.7133, huber: 1.3480, swd: 1.7293, target_std: 4.7659
      Epoch 3 composite train-obj: 1.047804
            No improvement (1.0806), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5956, mae: 1.3832, huber: 1.0210, swd: 1.3735, target_std: 6.4060
    Epoch [4/50], Val Losses: mse: 7.5577, mae: 1.4319, huber: 1.0784, swd: 1.0378, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 9.9334, mae: 1.7096, huber: 1.3441, swd: 1.7492, target_std: 4.7659
      Epoch 4 composite train-obj: 1.021039
            No improvement (1.0784), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3312, mae: 1.3463, huber: 0.9859, swd: 1.2663, target_std: 6.4059
    Epoch [5/50], Val Losses: mse: 8.0557, mae: 1.4936, huber: 1.1372, swd: 1.3126, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.1161, mae: 1.7315, huber: 1.3637, swd: 1.8071, target_std: 4.7659
      Epoch 5 composite train-obj: 0.985928
            No improvement (1.1372), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.0417, mae: 1.3044, huber: 0.9458, swd: 1.1229, target_std: 6.4054
    Epoch [6/50], Val Losses: mse: 8.6310, mae: 1.5426, huber: 1.1858, swd: 1.5542, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.3050, mae: 1.7522, huber: 1.3843, swd: 2.0504, target_std: 4.7659
      Epoch 6 composite train-obj: 0.945758
            No improvement (1.1858), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.7331, mae: 1.2589, huber: 0.9024, swd: 0.9726, target_std: 6.4061
    Epoch [7/50], Val Losses: mse: 8.6333, mae: 1.5456, huber: 1.1878, swd: 1.4449, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.3633, mae: 1.7692, huber: 1.3999, swd: 1.9655, target_std: 4.7659
      Epoch 7 composite train-obj: 0.902365
    Epoch [7/50], Test Losses: mse: 9.9739, mae: 1.7227, huber: 1.3568, swd: 1.9098, target_std: 4.7659
    Best round's Test MSE: 9.9739, MAE: 1.7227, SWD: 1.9098
    Best round's Validation MSE: 7.5162, MAE: 1.4237
    Best round's Test verification MSE : 9.9739, MAE: 1.7227, SWD: 1.9098
    Time taken: 39.42 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4779, mae: 1.6442, huber: 1.2660, swd: 1.7376, target_std: 6.4060
    Epoch [1/50], Val Losses: mse: 7.6661, mae: 1.4507, huber: 1.0950, swd: 0.9780, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.1071, mae: 1.7527, huber: 1.3840, swd: 1.9013, target_std: 4.7659
      Epoch 1 composite train-obj: 1.266000
            Val objective improved inf → 1.0950, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9763, mae: 1.4407, huber: 1.0755, swd: 1.4432, target_std: 6.4057
    Epoch [2/50], Val Losses: mse: 7.6436, mae: 1.4487, huber: 1.0944, swd: 1.0766, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.0956, mae: 1.7319, huber: 1.3636, swd: 1.7752, target_std: 4.7659
      Epoch 2 composite train-obj: 1.075549
            Val objective improved 1.0950 → 1.0944, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.5799, mae: 1.3821, huber: 1.0206, swd: 1.3086, target_std: 6.4059
    Epoch [3/50], Val Losses: mse: 8.0445, mae: 1.5081, huber: 1.1516, swd: 1.4379, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 9.9186, mae: 1.7321, huber: 1.3632, swd: 1.9625, target_std: 4.7659
      Epoch 3 composite train-obj: 1.020594
            No improvement (1.1516), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1273, mae: 1.3207, huber: 0.9618, swd: 1.1086, target_std: 6.4060
    Epoch [4/50], Val Losses: mse: 8.2630, mae: 1.5244, huber: 1.1672, swd: 1.5047, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.4959, mae: 1.7790, huber: 1.4095, swd: 2.0599, target_std: 4.7659
      Epoch 4 composite train-obj: 0.961778
            No improvement (1.1672), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.6655, mae: 1.2548, huber: 0.8983, swd: 0.8877, target_std: 6.4058
    Epoch [5/50], Val Losses: mse: 8.1628, mae: 1.5068, huber: 1.1493, swd: 1.1949, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.7449, mae: 1.8025, huber: 1.4323, swd: 2.0170, target_std: 4.7659
      Epoch 5 composite train-obj: 0.898337
            No improvement (1.1493), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.2405, mae: 1.1895, huber: 0.8362, swd: 0.7293, target_std: 6.4058
    Epoch [6/50], Val Losses: mse: 8.7389, mae: 1.5793, huber: 1.2185, swd: 1.3874, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.8944, mae: 1.8303, huber: 1.4582, swd: 2.1548, target_std: 4.7659
      Epoch 6 composite train-obj: 0.836244
            No improvement (1.2185), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.9298, mae: 1.1403, huber: 0.7896, swd: 0.6344, target_std: 6.4057
    Epoch [7/50], Val Losses: mse: 9.2208, mae: 1.6308, huber: 1.2675, swd: 1.6496, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.9046, mae: 1.8499, huber: 1.4751, swd: 2.1553, target_std: 4.7659
      Epoch 7 composite train-obj: 0.789593
    Epoch [7/50], Test Losses: mse: 10.0956, mae: 1.7319, huber: 1.3636, swd: 1.7752, target_std: 4.7659
    Best round's Test MSE: 10.0956, MAE: 1.7319, SWD: 1.7752
    Best round's Validation MSE: 7.6436, MAE: 1.4487
    Best round's Test verification MSE : 10.0956, MAE: 1.7319, SWD: 1.7752
    Time taken: 39.95 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2572, mae: 1.7079, huber: 1.3280, swd: 1.6258, target_std: 6.4058
    Epoch [1/50], Val Losses: mse: 7.6812, mae: 1.4556, huber: 1.0999, swd: 0.9862, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.0303, mae: 1.7431, huber: 1.3758, swd: 1.7328, target_std: 4.7659
      Epoch 1 composite train-obj: 1.327977
            Val objective improved inf → 1.0999, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0510, mae: 1.4528, huber: 1.0872, swd: 1.4362, target_std: 6.4056
    Epoch [2/50], Val Losses: mse: 7.6811, mae: 1.4442, huber: 1.0904, swd: 0.9990, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 9.8222, mae: 1.7116, huber: 1.3459, swd: 1.7370, target_std: 4.7659
      Epoch 2 composite train-obj: 1.087193
            Val objective improved 1.0999 → 1.0904, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.8329, mae: 1.4173, huber: 1.0543, swd: 1.3748, target_std: 6.4058
    Epoch [3/50], Val Losses: mse: 7.5621, mae: 1.4407, huber: 1.0861, swd: 1.0466, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 9.8984, mae: 1.7117, huber: 1.3460, swd: 1.7015, target_std: 4.7659
      Epoch 3 composite train-obj: 1.054284
            Val objective improved 1.0904 → 1.0861, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.5972, mae: 1.3843, huber: 1.0229, swd: 1.2842, target_std: 6.4058
    Epoch [4/50], Val Losses: mse: 7.7804, mae: 1.4545, huber: 1.1007, swd: 0.9458, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.0445, mae: 1.7161, huber: 1.3506, swd: 1.6049, target_std: 4.7659
      Epoch 4 composite train-obj: 1.022864
            No improvement (1.1007), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.3100, mae: 1.3434, huber: 0.9839, swd: 1.1630, target_std: 6.4056
    Epoch [5/50], Val Losses: mse: 7.8602, mae: 1.4777, huber: 1.1226, swd: 1.1486, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.1892, mae: 1.7415, huber: 1.3759, swd: 1.8343, target_std: 4.7659
      Epoch 5 composite train-obj: 0.983938
            No improvement (1.1226), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.9784, mae: 1.2972, huber: 0.9396, swd: 1.0204, target_std: 6.4058
    Epoch [6/50], Val Losses: mse: 8.2557, mae: 1.5375, huber: 1.1797, swd: 1.5730, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.6166, mae: 1.8122, huber: 1.4418, swd: 2.2650, target_std: 4.7659
      Epoch 6 composite train-obj: 0.939612
            No improvement (1.1797), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.6155, mae: 1.2443, huber: 0.8889, swd: 0.8693, target_std: 6.4055
    Epoch [7/50], Val Losses: mse: 8.5981, mae: 1.5557, huber: 1.1977, swd: 1.3732, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.6729, mae: 1.8060, huber: 1.4361, swd: 1.9261, target_std: 4.7659
      Epoch 7 composite train-obj: 0.888919
            No improvement (1.1977), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.3017, mae: 1.1973, huber: 0.8439, swd: 0.7470, target_std: 6.4057
    Epoch [8/50], Val Losses: mse: 8.3314, mae: 1.5451, huber: 1.1862, swd: 1.2551, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.4254, mae: 1.7955, huber: 1.4257, swd: 1.9648, target_std: 4.7659
      Epoch 8 composite train-obj: 0.843859
    Epoch [8/50], Test Losses: mse: 9.8984, mae: 1.7117, huber: 1.3460, swd: 1.7015, target_std: 4.7659
    Best round's Test MSE: 9.8984, MAE: 1.7117, SWD: 1.7015
    Best round's Validation MSE: 7.5621, MAE: 1.4407
    Best round's Test verification MSE : 9.8984, MAE: 1.7117, SWD: 1.7015
    Time taken: 46.44 seconds
    
    ==================================================
    Experiment Summary (TimeMixer_etth1_seq336_pred96_20250503_2017)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.9893 ± 0.0812
      mae: 1.7221 ± 0.0083
      huber: 1.3555 ± 0.0073
      swd: 1.7955 ± 0.0863
      target_std: 4.7659 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.5739 ± 0.0527
      mae: 1.4377 ± 0.0104
      huber: 1.0836 ± 0.0101
      swd: 1.0470 ± 0.0240
      target_std: 4.4109 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 125.90 seconds
    
    Experiment complete: TimeMixer_etth1_seq336_pred96_20250503_2017
    Model: TimeMixer
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.0477, mae: 1.7323, huber: 1.3475, swd: 1.8656, target_std: 6.3995
    Epoch [1/50], Val Losses: mse: 9.4845, mae: 1.6501, huber: 1.2866, swd: 1.3216, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.3573, mae: 1.8401, huber: 1.4629, swd: 1.9446, target_std: 4.7741
      Epoch 1 composite train-obj: 1.347531
            Val objective improved inf → 1.2866, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.7129, mae: 1.5620, huber: 1.1875, swd: 1.5934, target_std: 6.3874
    Epoch [2/50], Val Losses: mse: 9.5895, mae: 1.6398, huber: 1.2772, swd: 1.4225, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.2512, mae: 1.8151, huber: 1.4383, swd: 1.9069, target_std: 4.7741
      Epoch 2 composite train-obj: 1.187546
            Val objective improved 1.2866 → 1.2772, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3388, mae: 1.5139, huber: 1.1415, swd: 1.4533, target_std: 6.3912
    Epoch [3/50], Val Losses: mse: 10.6985, mae: 1.7536, huber: 1.3869, swd: 1.9217, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.4024, mae: 1.8351, huber: 1.4568, swd: 2.0627, target_std: 4.7741
      Epoch 3 composite train-obj: 1.141473
            No improvement (1.3869), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8817, mae: 1.4533, huber: 1.0834, swd: 1.2472, target_std: 6.3954
    Epoch [4/50], Val Losses: mse: 10.9354, mae: 1.7988, huber: 1.4301, swd: 2.2005, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.5660, mae: 1.8693, huber: 1.4897, swd: 2.2261, target_std: 4.7741
      Epoch 4 composite train-obj: 1.083365
            No improvement (1.4301), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4016, mae: 1.3866, huber: 1.0192, swd: 1.0264, target_std: 6.3946
    Epoch [5/50], Val Losses: mse: 11.4727, mae: 1.8016, huber: 1.4340, swd: 1.5716, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.8656, mae: 1.8810, huber: 1.5016, swd: 1.7171, target_std: 4.7741
      Epoch 5 composite train-obj: 1.019207
            No improvement (1.4340), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.9925, mae: 1.3273, huber: 0.9619, swd: 0.8560, target_std: 6.3951
    Epoch [6/50], Val Losses: mse: 12.9594, mae: 1.9362, huber: 1.5643, swd: 2.2414, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 11.0878, mae: 1.9197, huber: 1.5371, swd: 2.0758, target_std: 4.7741
      Epoch 6 composite train-obj: 0.961924
            No improvement (1.5643), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.6295, mae: 1.2768, huber: 0.9131, swd: 0.7343, target_std: 6.4030
    Epoch [7/50], Val Losses: mse: 12.2628, mae: 1.8819, huber: 1.5105, swd: 1.8548, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 11.1956, mae: 1.9339, huber: 1.5511, swd: 2.0469, target_std: 4.7741
      Epoch 7 composite train-obj: 0.913125
    Epoch [7/50], Test Losses: mse: 10.2512, mae: 1.8151, huber: 1.4383, swd: 1.9069, target_std: 4.7741
    Best round's Test MSE: 10.2512, MAE: 1.8151, SWD: 1.9069
    Best round's Validation MSE: 9.5895, MAE: 1.6398
    Best round's Test verification MSE : 10.2512, MAE: 1.8151, SWD: 1.9069
    Time taken: 42.23 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1074, mae: 1.7297, huber: 1.3447, swd: 1.7799, target_std: 6.3969
    Epoch [1/50], Val Losses: mse: 9.8237, mae: 1.6636, huber: 1.3003, swd: 1.2795, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.3825, mae: 1.8265, huber: 1.4498, swd: 1.7317, target_std: 4.7741
      Epoch 1 composite train-obj: 1.344699
            Val objective improved inf → 1.3003, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6249, mae: 1.5531, huber: 1.1787, swd: 1.5712, target_std: 6.3980
    Epoch [2/50], Val Losses: mse: 9.3401, mae: 1.6299, huber: 1.2671, swd: 1.4141, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.2095, mae: 1.8200, huber: 1.4422, swd: 1.8586, target_std: 4.7741
      Epoch 2 composite train-obj: 1.178670
            Val objective improved 1.3003 → 1.2671, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.1928, mae: 1.5004, huber: 1.1283, swd: 1.4091, target_std: 6.4013
    Epoch [3/50], Val Losses: mse: 9.8287, mae: 1.6723, huber: 1.3072, swd: 1.3920, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.4216, mae: 1.8480, huber: 1.4678, swd: 1.6636, target_std: 4.7741
      Epoch 3 composite train-obj: 1.128266
            No improvement (1.3072), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.7133, mae: 1.4374, huber: 1.0675, swd: 1.1668, target_std: 6.3973
    Epoch [4/50], Val Losses: mse: 10.9749, mae: 1.7658, huber: 1.3983, swd: 1.7169, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.6496, mae: 1.8668, huber: 1.4857, swd: 1.7702, target_std: 4.7741
      Epoch 4 composite train-obj: 1.067532
            No improvement (1.3983), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.2560, mae: 1.3739, huber: 1.0064, swd: 0.9465, target_std: 6.3941
    Epoch [5/50], Val Losses: mse: 10.9244, mae: 1.7967, huber: 1.4261, swd: 2.0639, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 11.0694, mae: 1.9135, huber: 1.5307, swd: 2.1447, target_std: 4.7741
      Epoch 5 composite train-obj: 1.006428
            No improvement (1.4261), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8531, mae: 1.3164, huber: 0.9513, swd: 0.7951, target_std: 6.3959
    Epoch [6/50], Val Losses: mse: 11.6577, mae: 1.8368, huber: 1.4643, swd: 1.6349, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 11.2081, mae: 1.9049, huber: 1.5233, swd: 1.6064, target_std: 4.7741
      Epoch 6 composite train-obj: 0.951328
            No improvement (1.4643), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.5316, mae: 1.2674, huber: 0.9043, swd: 0.6803, target_std: 6.3938
    Epoch [7/50], Val Losses: mse: 11.3586, mae: 1.8526, huber: 1.4781, swd: 2.2268, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 11.5222, mae: 1.9647, huber: 1.5792, swd: 2.1995, target_std: 4.7741
      Epoch 7 composite train-obj: 0.904298
    Epoch [7/50], Test Losses: mse: 10.2095, mae: 1.8200, huber: 1.4422, swd: 1.8586, target_std: 4.7741
    Best round's Test MSE: 10.2095, MAE: 1.8200, SWD: 1.8586
    Best round's Validation MSE: 9.3401, MAE: 1.6299
    Best round's Test verification MSE : 10.2095, MAE: 1.8200, SWD: 1.8586
    Time taken: 40.54 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.0809, mae: 1.7331, huber: 1.3485, swd: 1.7327, target_std: 6.3999
    Epoch [1/50], Val Losses: mse: 9.6415, mae: 1.6502, huber: 1.2869, swd: 1.2598, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.2537, mae: 1.8180, huber: 1.4418, swd: 1.6766, target_std: 4.7741
      Epoch 1 composite train-obj: 1.348549
            Val objective improved inf → 1.2869, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6295, mae: 1.5543, huber: 1.1799, swd: 1.4005, target_std: 6.3984
    Epoch [2/50], Val Losses: mse: 9.9193, mae: 1.6811, huber: 1.3175, swd: 1.5280, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.3824, mae: 1.8374, huber: 1.4597, swd: 1.9270, target_std: 4.7741
      Epoch 2 composite train-obj: 1.179880
            No improvement (1.3175), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.1870, mae: 1.4944, huber: 1.1231, swd: 1.2627, target_std: 6.3968
    Epoch [3/50], Val Losses: mse: 10.0022, mae: 1.6907, huber: 1.3256, swd: 1.4915, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.5854, mae: 1.8592, huber: 1.4807, swd: 1.9635, target_std: 4.7741
      Epoch 3 composite train-obj: 1.123141
            No improvement (1.3256), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.7501, mae: 1.4356, huber: 1.0668, swd: 1.0818, target_std: 6.3943
    Epoch [4/50], Val Losses: mse: 10.3234, mae: 1.7184, huber: 1.3530, swd: 1.3744, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.8324, mae: 1.8733, huber: 1.4949, swd: 1.7196, target_std: 4.7741
      Epoch 4 composite train-obj: 1.066804
            No improvement (1.3530), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.2829, mae: 1.3697, huber: 1.0037, swd: 0.8929, target_std: 6.3913
    Epoch [5/50], Val Losses: mse: 11.0692, mae: 1.8005, huber: 1.4332, swd: 1.8404, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 11.0053, mae: 1.9329, huber: 1.5515, swd: 2.2536, target_std: 4.7741
      Epoch 5 composite train-obj: 1.003658
            No improvement (1.4332), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.9147, mae: 1.3193, huber: 0.9549, swd: 0.7768, target_std: 6.3962
    Epoch [6/50], Val Losses: mse: 11.1981, mae: 1.7986, huber: 1.4300, swd: 1.4436, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.9672, mae: 1.9090, huber: 1.5273, swd: 1.7968, target_std: 4.7741
      Epoch 6 composite train-obj: 0.954865
    Epoch [6/50], Test Losses: mse: 10.2537, mae: 1.8180, huber: 1.4418, swd: 1.6766, target_std: 4.7741
    Best round's Test MSE: 10.2537, MAE: 1.8180, SWD: 1.6766
    Best round's Validation MSE: 9.6415, MAE: 1.6502
    Best round's Test verification MSE : 10.2537, MAE: 1.8180, SWD: 1.6766
    Time taken: 34.46 seconds
    
    ==================================================
    Experiment Summary (TimeMixer_etth1_seq336_pred196_20250503_2019)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2381 ± 0.0203
      mae: 1.8177 ± 0.0020
      huber: 1.4407 ± 0.0018
      swd: 1.8140 ± 0.0992
      target_std: 4.7741 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.5237 ± 0.1316
      mae: 1.6400 ± 0.0083
      huber: 1.2770 ± 0.0081
      swd: 1.3655 ± 0.0748
      target_std: 4.3900 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 117.33 seconds
    
    Experiment complete: TimeMixer_etth1_seq336_pred196_20250503_2019
    Model: TimeMixer
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 91
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 91
    Validation Batches: 9
    Test Batches: 22
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.7395, mae: 1.8439, huber: 1.4533, swd: 2.0934, target_std: 6.3694
    Epoch [1/50], Val Losses: mse: 9.5970, mae: 1.6517, huber: 1.2874, swd: 0.9414, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 10.6859, mae: 1.9386, huber: 1.5547, swd: 1.4336, target_std: 4.8164
      Epoch 1 composite train-obj: 1.453251
            Val objective improved inf → 1.2874, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1823, mae: 1.6522, huber: 1.2711, swd: 1.6508, target_std: 6.3529
    Epoch [2/50], Val Losses: mse: 9.6906, mae: 1.6477, huber: 1.2850, swd: 1.4678, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 10.5457, mae: 1.9260, huber: 1.5409, swd: 2.0618, target_std: 4.8164
      Epoch 2 composite train-obj: 1.271135
            Val objective improved 1.2874 → 1.2850, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.8470, mae: 1.6094, huber: 1.2297, swd: 1.5382, target_std: 6.3713
    Epoch [3/50], Val Losses: mse: 9.6321, mae: 1.6440, huber: 1.2790, swd: 0.8498, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 10.8273, mae: 1.9340, huber: 1.5494, swd: 1.4397, target_std: 4.8164
      Epoch 3 composite train-obj: 1.229728
            Val objective improved 1.2850 → 1.2790, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.5658, mae: 1.5743, huber: 1.1956, swd: 1.3995, target_std: 6.3841
    Epoch [4/50], Val Losses: mse: 9.6398, mae: 1.6615, huber: 1.2959, swd: 1.2956, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 10.7932, mae: 1.9309, huber: 1.5450, swd: 1.7704, target_std: 4.8164
      Epoch 4 composite train-obj: 1.195563
            No improvement (1.2959), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.1444, mae: 1.5172, huber: 1.1406, swd: 1.1838, target_std: 6.3703
    Epoch [5/50], Val Losses: mse: 9.9826, mae: 1.6971, huber: 1.3297, swd: 1.1139, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.1472, mae: 1.9587, huber: 1.5725, swd: 1.3864, target_std: 4.8164
      Epoch 5 composite train-obj: 1.140608
            No improvement (1.3297), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.7740, mae: 1.4675, huber: 1.0922, swd: 1.0057, target_std: 6.3607
    Epoch [6/50], Val Losses: mse: 10.4470, mae: 1.7721, huber: 1.4021, swd: 1.9210, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.5372, mae: 2.0294, huber: 1.6392, swd: 2.5348, target_std: 4.8164
      Epoch 6 composite train-obj: 1.092222
            No improvement (1.4021), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.5051, mae: 1.4303, huber: 1.0566, swd: 0.9121, target_std: 6.3633
    Epoch [7/50], Val Losses: mse: 11.9551, mae: 1.8172, huber: 1.4473, swd: 1.2893, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.4961, mae: 1.9797, huber: 1.5908, swd: 1.5448, target_std: 4.8164
      Epoch 7 composite train-obj: 1.056585
            No improvement (1.4473), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.2291, mae: 1.3912, huber: 1.0189, swd: 0.7957, target_std: 6.3641
    Epoch [8/50], Val Losses: mse: 12.6866, mae: 1.9644, huber: 1.5883, swd: 2.4622, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 12.5190, mae: 2.1556, huber: 1.7596, swd: 3.0262, target_std: 4.8164
      Epoch 8 composite train-obj: 1.018874
    Epoch [8/50], Test Losses: mse: 10.8273, mae: 1.9340, huber: 1.5494, swd: 1.4397, target_std: 4.8164
    Best round's Test MSE: 10.8273, MAE: 1.9340, SWD: 1.4397
    Best round's Validation MSE: 9.6321, MAE: 1.6440
    Best round's Test verification MSE : 10.8273, MAE: 1.9340, SWD: 1.4397
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3692, mae: 1.8871, huber: 1.4935, swd: 1.9541, target_std: 6.3750
    Epoch [1/50], Val Losses: mse: 9.5280, mae: 1.6525, huber: 1.2879, swd: 1.1774, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 10.8514, mae: 1.9447, huber: 1.5607, swd: 1.8166, target_std: 4.8164
      Epoch 1 composite train-obj: 1.493496
            Val objective improved inf → 1.2879, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.2286, mae: 1.6624, huber: 1.2796, swd: 1.6730, target_std: 6.3611
    Epoch [2/50], Val Losses: mse: 9.0215, mae: 1.5969, huber: 1.2327, swd: 0.9078, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 10.7731, mae: 1.9206, huber: 1.5370, swd: 1.5486, target_std: 4.8164
      Epoch 2 composite train-obj: 1.279552
            Val objective improved 1.2879 → 1.2327, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.8790, mae: 1.6193, huber: 1.2381, swd: 1.5610, target_std: 6.3999
    Epoch [3/50], Val Losses: mse: 10.2138, mae: 1.6851, huber: 1.3189, swd: 1.3845, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 10.6351, mae: 1.9135, huber: 1.5278, swd: 1.6577, target_std: 4.8164
      Epoch 3 composite train-obj: 1.238091
            No improvement (1.3189), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.5494, mae: 1.5777, huber: 1.1978, swd: 1.4060, target_std: 6.3717
    Epoch [4/50], Val Losses: mse: 10.5967, mae: 1.7256, huber: 1.3574, swd: 1.5469, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 10.7656, mae: 1.9291, huber: 1.5425, swd: 1.8198, target_std: 4.8164
      Epoch 4 composite train-obj: 1.197822
            No improvement (1.3574), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.1370, mae: 1.5213, huber: 1.1432, swd: 1.1758, target_std: 6.3772
    Epoch [5/50], Val Losses: mse: 11.4182, mae: 1.7884, huber: 1.4145, swd: 1.4838, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.1104, mae: 1.9557, huber: 1.5650, swd: 1.6056, target_std: 4.8164
      Epoch 5 composite train-obj: 1.143249
            No improvement (1.4145), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.7249, mae: 1.4640, huber: 1.0879, swd: 0.9689, target_std: 6.3866
    Epoch [6/50], Val Losses: mse: 11.4013, mae: 1.8539, huber: 1.4759, swd: 2.1474, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.7648, mae: 2.0727, huber: 1.6768, swd: 2.4995, target_std: 4.8164
      Epoch 6 composite train-obj: 1.087875
            No improvement (1.4759), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4185, mae: 1.4191, huber: 1.0451, swd: 0.8386, target_std: 6.3521
    Epoch [7/50], Val Losses: mse: 11.9786, mae: 1.8288, huber: 1.4546, swd: 1.4911, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.4115, mae: 1.9844, huber: 1.5933, swd: 1.6169, target_std: 4.8164
      Epoch 7 composite train-obj: 1.045073
    Epoch [7/50], Test Losses: mse: 10.7731, mae: 1.9206, huber: 1.5370, swd: 1.5486, target_std: 4.8164
    Best round's Test MSE: 10.7731, MAE: 1.9206, SWD: 1.5486
    Best round's Validation MSE: 9.0215, MAE: 1.5969
    Best round's Test verification MSE : 10.7731, MAE: 1.9206, SWD: 1.5486
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.8073, mae: 1.8312, huber: 1.4399, swd: 1.8427, target_std: 6.3752
    Epoch [1/50], Val Losses: mse: 9.5071, mae: 1.6411, huber: 1.2786, swd: 1.3018, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 10.7210, mae: 1.9499, huber: 1.5644, swd: 2.0653, target_std: 4.8164
      Epoch 1 composite train-obj: 1.439948
            Val objective improved inf → 1.2786, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1745, mae: 1.6580, huber: 1.2758, swd: 1.6218, target_std: 6.3732
    Epoch [2/50], Val Losses: mse: 10.1154, mae: 1.6679, huber: 1.3024, swd: 0.8831, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 10.7592, mae: 1.9313, huber: 1.5471, swd: 1.2755, target_std: 4.8164
      Epoch 2 composite train-obj: 1.275843
            No improvement (1.3024), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.8134, mae: 1.6125, huber: 1.2319, swd: 1.4806, target_std: 6.3661
    Epoch [3/50], Val Losses: mse: 10.1122, mae: 1.6820, huber: 1.3140, swd: 1.1380, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 10.8150, mae: 1.9287, huber: 1.5440, swd: 1.2455, target_std: 4.8164
      Epoch 3 composite train-obj: 1.231912
            No improvement (1.3140), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.4547, mae: 1.5655, huber: 1.1863, swd: 1.2970, target_std: 6.3545
    Epoch [4/50], Val Losses: mse: 10.6381, mae: 1.7725, huber: 1.4010, swd: 1.8920, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 10.9306, mae: 1.9450, huber: 1.5570, swd: 1.7953, target_std: 4.8164
      Epoch 4 composite train-obj: 1.186281
            No improvement (1.4010), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.9665, mae: 1.5024, huber: 1.1248, swd: 1.0912, target_std: 6.3726
    Epoch [5/50], Val Losses: mse: 12.8818, mae: 1.9129, huber: 1.5372, swd: 1.7992, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.4494, mae: 1.9945, huber: 1.6045, swd: 1.9020, target_std: 4.8164
      Epoch 5 composite train-obj: 1.124786
            No improvement (1.5372), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.5794, mae: 1.4459, huber: 1.0705, swd: 0.9329, target_std: 6.3746
    Epoch [6/50], Val Losses: mse: 11.7588, mae: 1.8117, huber: 1.4398, swd: 1.3835, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.3275, mae: 1.9779, huber: 1.5891, swd: 1.4840, target_std: 4.8164
      Epoch 6 composite train-obj: 1.070488
    Epoch [6/50], Test Losses: mse: 10.7210, mae: 1.9499, huber: 1.5644, swd: 2.0653, target_std: 4.8164
    Best round's Test MSE: 10.7210, MAE: 1.9499, SWD: 2.0653
    Best round's Validation MSE: 9.5071, MAE: 1.6411
    Best round's Test verification MSE : 10.7210, MAE: 1.9499, SWD: 2.0653
    
    ==================================================
    Experiment Summary (TimeMixer_etth1_seq336_pred336_20250501_1150)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.7738 ± 0.0434
      mae: 1.9348 ± 0.0120
      huber: 1.5503 ± 0.0112
      swd: 1.6845 ± 0.2729
      target_std: 4.8164 ± 0.0000
      count: 9.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.3869 ± 0.2634
      mae: 1.6273 ± 0.0216
      huber: 1.2634 ± 0.0217
      swd: 1.0198 ± 0.2008
      target_std: 4.3610 ± 0.0000
      count: 9.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_etth1_seq336_pred336_20250501_1150
    Model: TimeMixer
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 88
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 88
    Validation Batches: 6
    Test Batches: 19
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4252, mae: 2.0376, huber: 1.6332, swd: 2.5871, target_std: 6.2839
    Epoch [1/50], Val Losses: mse: 10.0053, mae: 1.7366, huber: 1.3683, swd: 1.3308, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.1711, mae: 2.2027, huber: 1.8022, swd: 2.8585, target_std: 4.8721
      Epoch 1 composite train-obj: 1.633150
            Val objective improved inf → 1.3683, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.4565, mae: 1.8526, huber: 1.4557, swd: 2.2034, target_std: 6.2837
    Epoch [2/50], Val Losses: mse: 10.0582, mae: 1.7362, huber: 1.3659, swd: 1.6400, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 12.3884, mae: 2.2340, huber: 1.8309, swd: 3.3341, target_std: 4.8721
      Epoch 2 composite train-obj: 1.455696
            Val objective improved 1.3683 → 1.3659, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.0753, mae: 1.8015, huber: 1.4072, swd: 2.0099, target_std: 6.2933
    Epoch [3/50], Val Losses: mse: 11.9814, mae: 1.8789, huber: 1.5057, swd: 1.8007, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.1592, mae: 2.1774, huber: 1.7746, swd: 2.4003, target_std: 4.8721
      Epoch 3 composite train-obj: 1.407165
            No improvement (1.5057), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.6263, mae: 1.7507, huber: 1.3577, swd: 1.7596, target_std: 6.3131
    Epoch [4/50], Val Losses: mse: 11.0432, mae: 1.8145, huber: 1.4434, swd: 1.7793, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 11.6518, mae: 2.1274, huber: 1.7257, swd: 2.2524, target_std: 4.8721
      Epoch 4 composite train-obj: 1.357713
            No improvement (1.4434), counter 2/5
    Epoch [5/50], Train Losses: mse: 7.2936, mae: 1.7078, huber: 1.3156, swd: 1.5756, target_std: 6.3133
    Epoch [5/50], Val Losses: mse: 13.9989, mae: 2.0419, huber: 1.6605, swd: 2.0872, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.6998, mae: 2.2184, huber: 1.8118, swd: 2.3865, target_std: 4.8721
      Epoch 5 composite train-obj: 1.315586
            No improvement (1.6605), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.9516, mae: 1.6634, huber: 1.2725, swd: 1.3792, target_std: 6.2797
    Epoch [6/50], Val Losses: mse: 10.4786, mae: 1.8148, huber: 1.4358, swd: 1.6748, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.6169, mae: 2.2270, huber: 1.8198, swd: 2.8814, target_std: 4.8721
      Epoch 6 composite train-obj: 1.272535
            No improvement (1.4358), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.6588, mae: 1.6224, huber: 1.2330, swd: 1.2340, target_std: 6.3007
    Epoch [7/50], Val Losses: mse: 13.2951, mae: 1.9636, huber: 1.5827, swd: 1.4685, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.4110, mae: 2.1622, huber: 1.7559, swd: 2.0277, target_std: 4.8721
      Epoch 7 composite train-obj: 1.232976
    Epoch [7/50], Test Losses: mse: 12.3884, mae: 2.2340, huber: 1.8309, swd: 3.3341, target_std: 4.8721
    Best round's Test MSE: 12.3884, MAE: 2.2340, SWD: 3.3341
    Best round's Validation MSE: 10.0582, MAE: 1.7362
    Best round's Test verification MSE : 12.3884, MAE: 2.2340, SWD: 3.3341
    Time taken: 44.38 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9186, mae: 2.0041, huber: 1.6009, swd: 2.3922, target_std: 6.2974
    Epoch [1/50], Val Losses: mse: 10.0674, mae: 1.7163, huber: 1.3494, swd: 0.9672, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.0218, mae: 2.1799, huber: 1.7802, swd: 2.4405, target_std: 4.8721
      Epoch 1 composite train-obj: 1.600898
            Val objective improved inf → 1.3494, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.4984, mae: 1.8554, huber: 1.4589, swd: 2.0943, target_std: 6.2871
    Epoch [2/50], Val Losses: mse: 10.2806, mae: 1.6952, huber: 1.3276, swd: 0.8751, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 11.8889, mae: 2.1488, huber: 1.7490, swd: 2.1862, target_std: 4.8721
      Epoch 2 composite train-obj: 1.458891
            Val objective improved 1.3494 → 1.3276, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.0849, mae: 1.8064, huber: 1.4113, swd: 1.8926, target_std: 6.2852
    Epoch [3/50], Val Losses: mse: 11.6999, mae: 1.8683, huber: 1.4961, swd: 1.8574, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.2350, mae: 2.2150, huber: 1.8102, swd: 2.7012, target_std: 4.8721
      Epoch 3 composite train-obj: 1.411288
            No improvement (1.4961), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.6873, mae: 1.7544, huber: 1.3607, swd: 1.6608, target_std: 6.2887
    Epoch [4/50], Val Losses: mse: 21.5684, mae: 2.4698, huber: 2.0911, swd: 2.6580, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.3871, mae: 2.2394, huber: 1.8316, swd: 2.7133, target_std: 4.8721
      Epoch 4 composite train-obj: 1.360695
            No improvement (2.0911), counter 2/5
    Epoch [5/50], Train Losses: mse: 7.1565, mae: 1.6866, huber: 1.2949, swd: 1.3950, target_std: 6.2757
    Epoch [5/50], Val Losses: mse: 21.1504, mae: 2.5413, huber: 2.1577, swd: 3.3345, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.9245, mae: 2.3193, huber: 1.9098, swd: 3.5912, target_std: 4.8721
      Epoch 5 composite train-obj: 1.294931
            No improvement (2.1577), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.7077, mae: 1.6267, huber: 1.2376, swd: 1.1792, target_std: 6.2852
    Epoch [6/50], Val Losses: mse: 21.3863, mae: 2.5437, huber: 2.1570, swd: 2.8115, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 13.0647, mae: 2.3045, huber: 1.8937, swd: 3.0065, target_std: 4.8721
      Epoch 6 composite train-obj: 1.237608
            No improvement (2.1570), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.2592, mae: 1.5635, huber: 1.1769, swd: 0.9889, target_std: 6.2916
    Epoch [7/50], Val Losses: mse: 18.7514, mae: 2.3692, huber: 1.9829, swd: 2.2456, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.9246, mae: 2.2611, huber: 1.8508, swd: 2.5220, target_std: 4.8721
      Epoch 7 composite train-obj: 1.176886
    Epoch [7/50], Test Losses: mse: 11.8889, mae: 2.1488, huber: 1.7490, swd: 2.1862, target_std: 4.8721
    Best round's Test MSE: 11.8889, MAE: 2.1488, SWD: 2.1862
    Best round's Validation MSE: 10.2806, MAE: 1.6952
    Best round's Test verification MSE : 11.8889, MAE: 2.1488, SWD: 2.1862
    Time taken: 44.58 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8902, mae: 2.0035, huber: 1.6009, swd: 2.7127, target_std: 6.2980
    Epoch [1/50], Val Losses: mse: 11.0844, mae: 1.7646, huber: 1.3962, swd: 0.7058, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.3389, mae: 2.1817, huber: 1.7825, swd: 2.2198, target_std: 4.8721
      Epoch 1 composite train-obj: 1.600907
            Val objective improved inf → 1.3962, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.3416, mae: 1.8375, huber: 1.4419, swd: 2.2631, target_std: 6.2902
    Epoch [2/50], Val Losses: mse: 10.6793, mae: 1.7374, huber: 1.3684, swd: 0.9803, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 11.8881, mae: 2.1518, huber: 1.7506, swd: 2.1221, target_std: 4.8721
      Epoch 2 composite train-obj: 1.441929
            Val objective improved 1.3962 → 1.3684, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.7438, mae: 1.7666, huber: 1.3728, swd: 1.9789, target_std: 6.2961
    Epoch [3/50], Val Losses: mse: 11.6573, mae: 1.8605, huber: 1.4870, swd: 1.8431, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.1998, mae: 2.1795, huber: 1.7748, swd: 2.3800, target_std: 4.8721
      Epoch 3 composite train-obj: 1.372754
            No improvement (1.4870), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.1925, mae: 1.6978, huber: 1.3047, swd: 1.6252, target_std: 6.3097
    Epoch [4/50], Val Losses: mse: 14.0385, mae: 2.0498, huber: 1.6683, swd: 2.2129, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.8807, mae: 2.2214, huber: 1.8144, swd: 2.4243, target_std: 4.8721
      Epoch 4 composite train-obj: 1.304668
            No improvement (1.6683), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.6051, mae: 1.6193, huber: 1.2293, swd: 1.2791, target_std: 6.3131
    Epoch [5/50], Val Losses: mse: 16.5510, mae: 2.2810, huber: 1.8917, swd: 3.1084, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 14.0600, mae: 2.3440, huber: 1.9327, swd: 3.0628, target_std: 4.8721
      Epoch 5 composite train-obj: 1.229285
            No improvement (1.8917), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.3128, mae: 1.5782, huber: 1.1901, swd: 1.1391, target_std: 6.2739
    Epoch [6/50], Val Losses: mse: 16.2659, mae: 2.2366, huber: 1.8483, swd: 2.8409, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 14.3197, mae: 2.3470, huber: 1.9365, swd: 3.0957, target_std: 4.8721
      Epoch 6 composite train-obj: 1.190096
            No improvement (1.8483), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.9910, mae: 1.5296, huber: 1.1437, swd: 1.0059, target_std: 6.2742
    Epoch [7/50], Val Losses: mse: 16.5103, mae: 2.3066, huber: 1.9186, swd: 3.7639, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 13.1752, mae: 2.2779, huber: 1.8672, swd: 2.9330, target_std: 4.8721
      Epoch 7 composite train-obj: 1.143695
    Epoch [7/50], Test Losses: mse: 11.8881, mae: 2.1518, huber: 1.7506, swd: 2.1221, target_std: 4.8721
    Best round's Test MSE: 11.8881, MAE: 2.1518, SWD: 2.1221
    Best round's Validation MSE: 10.6793, MAE: 1.7374
    Best round's Test verification MSE : 11.8881, MAE: 2.1518, SWD: 2.1221
    Time taken: 44.64 seconds
    
    ==================================================
    Experiment Summary (TimeMixer_etth1_seq336_pred720_20250503_2021)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.0551 ± 0.2356
      mae: 2.1782 ± 0.0395
      huber: 1.7768 ± 0.0382
      swd: 2.5475 ± 0.5568
      target_std: 4.8721 ± 0.0000
      count: 6.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.3394 ± 0.2570
      mae: 1.7230 ± 0.0196
      huber: 1.3540 ± 0.0186
      swd: 1.1651 ± 0.3385
      target_std: 4.3728 ± 0.0000
      count: 6.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 133.67 seconds
    
    Experiment complete: TimeMixer_etth1_seq336_pred720_20250503_2021
    Model: TimeMixer
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### PatchTST

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 11
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.3435, mae: 1.7255, huber: 1.3440, swd: 1.8367, target_std: 6.4054
    Epoch [1/50], Val Losses: mse: 7.5741, mae: 1.4676, huber: 1.1094, swd: 1.4128, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.2306, mae: 1.7888, huber: 1.4182, swd: 2.7141, target_std: 4.7659
      Epoch 1 composite train-obj: 1.343987
            Val objective improved inf → 1.1094, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.8644, mae: 1.5518, huber: 1.1787, swd: 1.6185, target_std: 6.4057
    Epoch [2/50], Val Losses: mse: 7.8430, mae: 1.4877, huber: 1.1283, swd: 1.0611, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.0862, mae: 1.7455, huber: 1.3767, swd: 1.7193, target_std: 4.7659
      Epoch 2 composite train-obj: 1.178744
            No improvement (1.1283), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6246, mae: 1.5182, huber: 1.1466, swd: 1.5440, target_std: 6.4060
    Epoch [3/50], Val Losses: mse: 7.3253, mae: 1.4417, huber: 1.0833, swd: 1.1249, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.0389, mae: 1.7651, huber: 1.3937, swd: 2.2102, target_std: 4.7659
      Epoch 3 composite train-obj: 1.146649
            Val objective improved 1.1094 → 1.0833, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.3962, mae: 1.4915, huber: 1.1205, swd: 1.4560, target_std: 6.4054
    Epoch [4/50], Val Losses: mse: 7.9346, mae: 1.5020, huber: 1.1430, swd: 1.3914, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.0240, mae: 1.7689, huber: 1.3981, swd: 2.2051, target_std: 4.7659
      Epoch 4 composite train-obj: 1.120475
            No improvement (1.1430), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.1371, mae: 1.4594, huber: 1.0893, swd: 1.3475, target_std: 6.4059
    Epoch [5/50], Val Losses: mse: 7.9462, mae: 1.5038, huber: 1.1455, swd: 1.3666, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 9.7359, mae: 1.7518, huber: 1.3805, swd: 2.1605, target_std: 4.7659
      Epoch 5 composite train-obj: 1.089319
            No improvement (1.1455), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.9163, mae: 1.4321, huber: 1.0628, swd: 1.2448, target_std: 6.4057
    Epoch [6/50], Val Losses: mse: 7.9890, mae: 1.5134, huber: 1.1543, swd: 1.3239, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 9.8509, mae: 1.7608, huber: 1.3885, swd: 2.2419, target_std: 4.7659
      Epoch 6 composite train-obj: 1.062769
            No improvement (1.1543), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.7042, mae: 1.4027, huber: 1.0343, swd: 1.1482, target_std: 6.4056
    Epoch [7/50], Val Losses: mse: 8.0713, mae: 1.5282, huber: 1.1685, swd: 1.4973, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 9.7797, mae: 1.7533, huber: 1.3811, swd: 2.2152, target_std: 4.7659
      Epoch 7 composite train-obj: 1.034306
            No improvement (1.1685), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.5520, mae: 1.3805, huber: 1.0130, swd: 1.0821, target_std: 6.4057
    Epoch [8/50], Val Losses: mse: 8.9800, mae: 1.5931, huber: 1.2288, swd: 1.4879, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.1681, mae: 1.7726, huber: 1.4000, swd: 2.0750, target_std: 4.7659
      Epoch 8 composite train-obj: 1.013047
    Epoch [8/50], Test Losses: mse: 10.0389, mae: 1.7651, huber: 1.3937, swd: 2.2102, target_std: 4.7659
    Best round's Test MSE: 10.0389, MAE: 1.7651, SWD: 2.2102
    Best round's Validation MSE: 7.3253, MAE: 1.4417
    Best round's Test verification MSE : 10.0389, MAE: 1.7651, SWD: 2.2102
    Time taken: 32.88 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2861, mae: 1.7203, huber: 1.3388, swd: 1.7491, target_std: 6.4053
    Epoch [1/50], Val Losses: mse: 7.6732, mae: 1.4917, huber: 1.1315, swd: 1.4061, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.2531, mae: 1.8059, huber: 1.4339, swd: 2.5505, target_std: 4.7659
      Epoch 1 composite train-obj: 1.338826
            Val objective improved inf → 1.1315, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.8512, mae: 1.5531, huber: 1.1796, swd: 1.5449, target_std: 6.4057
    Epoch [2/50], Val Losses: mse: 7.4972, mae: 1.4634, huber: 1.1046, swd: 1.1128, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 9.9100, mae: 1.7606, huber: 1.3887, swd: 2.0386, target_std: 4.7659
      Epoch 2 composite train-obj: 1.179556
            Val objective improved 1.1315 → 1.1046, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.5811, mae: 1.5178, huber: 1.1452, swd: 1.4603, target_std: 6.4054
    Epoch [3/50], Val Losses: mse: 7.7195, mae: 1.4968, huber: 1.1373, swd: 1.2996, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 9.8926, mae: 1.7540, huber: 1.3831, swd: 2.0484, target_std: 4.7659
      Epoch 3 composite train-obj: 1.145162
            No improvement (1.1373), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.3344, mae: 1.4875, huber: 1.1157, swd: 1.3604, target_std: 6.4062
    Epoch [4/50], Val Losses: mse: 8.2842, mae: 1.5647, huber: 1.2042, swd: 1.9163, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.0289, mae: 1.7853, huber: 1.4118, swd: 2.4161, target_std: 4.7659
      Epoch 4 composite train-obj: 1.115663
            No improvement (1.2042), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.0758, mae: 1.4549, huber: 1.0840, swd: 1.2508, target_std: 6.4056
    Epoch [5/50], Val Losses: mse: 8.6506, mae: 1.5718, huber: 1.2117, swd: 1.7640, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 9.9435, mae: 1.7629, huber: 1.3901, swd: 1.9865, target_std: 4.7659
      Epoch 5 composite train-obj: 1.084041
            No improvement (1.2117), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.8135, mae: 1.4225, huber: 1.0527, swd: 1.1439, target_std: 6.4056
    Epoch [6/50], Val Losses: mse: 9.2334, mae: 1.6109, huber: 1.2511, swd: 1.8302, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.0796, mae: 1.7724, huber: 1.3990, swd: 1.9645, target_std: 4.7659
      Epoch 6 composite train-obj: 1.052691
            No improvement (1.2511), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.5954, mae: 1.3910, huber: 1.0224, swd: 1.0514, target_std: 6.4059
    Epoch [7/50], Val Losses: mse: 9.4514, mae: 1.6428, huber: 1.2801, swd: 2.3152, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.2598, mae: 1.8123, huber: 1.4348, swd: 2.4594, target_std: 4.7659
      Epoch 7 composite train-obj: 1.022416
    Epoch [7/50], Test Losses: mse: 9.9100, mae: 1.7606, huber: 1.3887, swd: 2.0386, target_std: 4.7659
    Best round's Test MSE: 9.9100, MAE: 1.7606, SWD: 2.0386
    Best round's Validation MSE: 7.4972, MAE: 1.4634
    Best round's Test verification MSE : 9.9100, MAE: 1.7606, SWD: 2.0386
    Time taken: 28.68 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2408, mae: 1.7133, huber: 1.3326, swd: 1.6839, target_std: 6.4058
    Epoch [1/50], Val Losses: mse: 7.8424, mae: 1.4797, huber: 1.1230, swd: 1.1318, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.1269, mae: 1.7753, huber: 1.4058, swd: 2.0087, target_std: 4.7659
      Epoch 1 composite train-obj: 1.332590
            Val objective improved inf → 1.1230, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.8667, mae: 1.5530, huber: 1.1797, swd: 1.5010, target_std: 6.4056
    Epoch [2/50], Val Losses: mse: 7.7136, mae: 1.4675, huber: 1.1098, swd: 0.9706, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.0906, mae: 1.7451, huber: 1.3770, swd: 1.6742, target_std: 4.7659
      Epoch 2 composite train-obj: 1.179705
            Val objective improved 1.1230 → 1.1098, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.6011, mae: 1.5195, huber: 1.1473, swd: 1.4328, target_std: 6.4059
    Epoch [3/50], Val Losses: mse: 7.3417, mae: 1.4274, huber: 1.0695, swd: 0.8847, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.1944, mae: 1.7652, huber: 1.3945, swd: 1.8774, target_std: 4.7659
      Epoch 3 composite train-obj: 1.147290
            Val objective improved 1.1098 → 1.0695, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.3595, mae: 1.4896, huber: 1.1180, swd: 1.3309, target_std: 6.4061
    Epoch [4/50], Val Losses: mse: 7.7582, mae: 1.4928, huber: 1.1337, swd: 1.1081, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.1258, mae: 1.7696, huber: 1.3995, swd: 1.9575, target_std: 4.7659
      Epoch 4 composite train-obj: 1.117986
            No improvement (1.1337), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.1252, mae: 1.4589, huber: 1.0883, swd: 1.2362, target_std: 6.4058
    Epoch [5/50], Val Losses: mse: 7.4757, mae: 1.4458, huber: 1.0877, swd: 1.2233, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.2022, mae: 1.7837, huber: 1.4104, swd: 2.3613, target_std: 4.7659
      Epoch 5 composite train-obj: 1.088326
            No improvement (1.0877), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.9073, mae: 1.4298, huber: 1.0601, swd: 1.1357, target_std: 6.4056
    Epoch [6/50], Val Losses: mse: 7.7022, mae: 1.4847, huber: 1.1252, swd: 1.2662, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 9.8842, mae: 1.7652, huber: 1.3914, swd: 2.1748, target_std: 4.7659
      Epoch 6 composite train-obj: 1.060145
            No improvement (1.1252), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.6741, mae: 1.3974, huber: 1.0291, swd: 1.0369, target_std: 6.4057
    Epoch [7/50], Val Losses: mse: 8.1328, mae: 1.5330, huber: 1.1718, swd: 1.4416, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.1647, mae: 1.7811, huber: 1.4072, swd: 1.9949, target_std: 4.7659
      Epoch 7 composite train-obj: 1.029091
            No improvement (1.1718), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.5021, mae: 1.3746, huber: 1.0072, swd: 0.9885, target_std: 6.4054
    Epoch [8/50], Val Losses: mse: 7.8158, mae: 1.4860, huber: 1.1267, swd: 1.3802, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.3570, mae: 1.8087, huber: 1.4329, swd: 2.6431, target_std: 4.7659
      Epoch 8 composite train-obj: 1.007198
    Epoch [8/50], Test Losses: mse: 10.1944, mae: 1.7652, huber: 1.3945, swd: 1.8774, target_std: 4.7659
    Best round's Test MSE: 10.1944, MAE: 1.7652, SWD: 1.8774
    Best round's Validation MSE: 7.3417, MAE: 1.4274
    Best round's Test verification MSE : 10.1944, MAE: 1.7652, SWD: 1.8774
    Time taken: 32.78 seconds
    
    ==================================================
    Experiment Summary (PatchTST_etth1_seq336_pred96_20250503_2040)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.0478 ± 0.1163
      mae: 1.7636 ± 0.0022
      huber: 1.3923 ± 0.0026
      swd: 2.0421 ± 0.1359
      target_std: 4.7659 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.3881 ± 0.0775
      mae: 1.4442 ± 0.0148
      huber: 1.0858 ± 0.0144
      swd: 1.0408 ± 0.1105
      target_std: 4.4109 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 94.41 seconds
    
    Experiment complete: PatchTST_etth1_seq336_pred96_20250503_2040
    Model: PatchTST
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.9224, mae: 1.8155, huber: 1.4280, swd: 1.9050, target_std: 6.4028
    Epoch [1/50], Val Losses: mse: 9.1417, mae: 1.6567, huber: 1.2895, swd: 1.4649, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.7250, mae: 1.8919, huber: 1.5131, swd: 2.3102, target_std: 4.7741
      Epoch 1 composite train-obj: 1.428043
            Val objective improved inf → 1.2895, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.5680, mae: 1.6659, huber: 1.2847, swd: 1.7272, target_std: 6.3908
    Epoch [2/50], Val Losses: mse: 9.1519, mae: 1.6369, huber: 1.2731, swd: 1.5884, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.5132, mae: 1.8760, huber: 1.4970, swd: 2.4843, target_std: 4.7741
      Epoch 2 composite train-obj: 1.284722
            Val objective improved 1.2895 → 1.2731, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2764, mae: 1.6287, huber: 1.2487, swd: 1.6278, target_std: 6.3909
    Epoch [3/50], Val Losses: mse: 9.4455, mae: 1.6842, huber: 1.3160, swd: 1.8073, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.5150, mae: 1.8967, huber: 1.5146, swd: 2.5670, target_std: 4.7741
      Epoch 3 composite train-obj: 1.248737
            No improvement (1.3160), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.9407, mae: 1.5932, huber: 1.2135, swd: 1.4926, target_std: 6.3993
    Epoch [4/50], Val Losses: mse: 9.7420, mae: 1.6762, huber: 1.3087, swd: 1.1136, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.3854, mae: 1.8544, huber: 1.4733, swd: 1.7272, target_std: 4.7741
      Epoch 4 composite train-obj: 1.213508
            No improvement (1.3087), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.6482, mae: 1.5575, huber: 1.1786, swd: 1.3385, target_std: 6.3910
    Epoch [5/50], Val Losses: mse: 10.0556, mae: 1.7112, huber: 1.3453, swd: 1.3045, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.2514, mae: 1.8553, huber: 1.4732, swd: 1.6755, target_std: 4.7741
      Epoch 5 composite train-obj: 1.178627
            No improvement (1.3453), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.3952, mae: 1.5241, huber: 1.1465, swd: 1.2354, target_std: 6.3928
    Epoch [6/50], Val Losses: mse: 13.1204, mae: 1.8720, huber: 1.5023, swd: 1.4555, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.8315, mae: 1.8637, huber: 1.4816, swd: 1.6137, target_std: 4.7741
      Epoch 6 composite train-obj: 1.146451
            No improvement (1.5023), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.1844, mae: 1.4966, huber: 1.1198, swd: 1.1469, target_std: 6.3988
    Epoch [7/50], Val Losses: mse: 10.8000, mae: 1.7826, huber: 1.4130, swd: 1.9378, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.3493, mae: 1.8773, huber: 1.4929, swd: 2.4743, target_std: 4.7741
      Epoch 7 composite train-obj: 1.119779
    Epoch [7/50], Test Losses: mse: 10.5132, mae: 1.8760, huber: 1.4970, swd: 2.4843, target_std: 4.7741
    Best round's Test MSE: 10.5132, MAE: 1.8760, SWD: 2.4843
    Best round's Validation MSE: 9.1519, MAE: 1.6369
    Best round's Test verification MSE : 10.5132, MAE: 1.8760, SWD: 2.4843
    Time taken: 29.04 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.9350, mae: 1.8143, huber: 1.4267, swd: 1.8780, target_std: 6.3915
    Epoch [1/50], Val Losses: mse: 9.1817, mae: 1.6505, huber: 1.2839, swd: 1.3936, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 11.0296, mae: 1.9218, huber: 1.5410, swd: 2.2582, target_std: 4.7741
      Epoch 1 composite train-obj: 1.426719
            Val objective improved inf → 1.2839, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.5446, mae: 1.6646, huber: 1.2822, swd: 1.6846, target_std: 6.3983
    Epoch [2/50], Val Losses: mse: 8.9137, mae: 1.6287, huber: 1.2608, swd: 1.2859, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.6102, mae: 1.8739, huber: 1.4928, swd: 1.9741, target_std: 4.7741
      Epoch 2 composite train-obj: 1.282156
            Val objective improved 1.2839 → 1.2608, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.1348, mae: 1.6171, huber: 1.2356, swd: 1.5419, target_std: 6.3954
    Epoch [3/50], Val Losses: mse: 9.7979, mae: 1.7158, huber: 1.3478, swd: 1.9059, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.3764, mae: 1.8785, huber: 1.4953, swd: 2.3371, target_std: 4.7741
      Epoch 3 composite train-obj: 1.235578
            No improvement (1.3478), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.8354, mae: 1.5823, huber: 1.2018, swd: 1.4105, target_std: 6.3894
    Epoch [4/50], Val Losses: mse: 10.5895, mae: 1.7779, huber: 1.4051, swd: 1.9760, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.5682, mae: 1.9105, huber: 1.5216, swd: 2.1544, target_std: 4.7741
      Epoch 4 composite train-obj: 1.201805
            No improvement (1.4051), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.5394, mae: 1.5461, huber: 1.1664, swd: 1.2768, target_std: 6.3958
    Epoch [5/50], Val Losses: mse: 10.7103, mae: 1.7781, huber: 1.4070, swd: 1.9705, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.3855, mae: 1.8850, huber: 1.4989, swd: 2.1699, target_std: 4.7741
      Epoch 5 composite train-obj: 1.166431
            No improvement (1.4070), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.2174, mae: 1.5047, huber: 1.1266, swd: 1.1242, target_std: 6.4024
    Epoch [6/50], Val Losses: mse: 10.7150, mae: 1.7812, huber: 1.4078, swd: 1.9912, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.3100, mae: 1.8886, huber: 1.5012, swd: 2.3225, target_std: 4.7741
      Epoch 6 composite train-obj: 1.126551
            No improvement (1.4078), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.0275, mae: 1.4789, huber: 1.1016, swd: 1.0496, target_std: 6.3898
    Epoch [7/50], Val Losses: mse: 13.8921, mae: 1.9233, huber: 1.5477, swd: 1.5809, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.8875, mae: 1.9219, huber: 1.5321, swd: 2.0071, target_std: 4.7741
      Epoch 7 composite train-obj: 1.101643
    Epoch [7/50], Test Losses: mse: 10.6102, mae: 1.8739, huber: 1.4928, swd: 1.9741, target_std: 4.7741
    Best round's Test MSE: 10.6102, MAE: 1.8739, SWD: 1.9741
    Best round's Validation MSE: 8.9137, MAE: 1.6287
    Best round's Test verification MSE : 10.6102, MAE: 1.8739, SWD: 1.9741
    Time taken: 28.92 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.9056, mae: 1.8101, huber: 1.4233, swd: 1.6752, target_std: 6.3940
    Epoch [1/50], Val Losses: mse: 9.6654, mae: 1.6799, huber: 1.3165, swd: 1.6022, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.6506, mae: 1.9021, huber: 1.5221, swd: 2.1602, target_std: 4.7741
      Epoch 1 composite train-obj: 1.423290
            Val objective improved inf → 1.3165, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.5689, mae: 1.6684, huber: 1.2869, swd: 1.5317, target_std: 6.3965
    Epoch [2/50], Val Losses: mse: 9.6144, mae: 1.6780, huber: 1.3125, swd: 1.5977, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.4077, mae: 1.8831, huber: 1.5025, swd: 2.1358, target_std: 4.7741
      Epoch 2 composite train-obj: 1.286881
            Val objective improved 1.3165 → 1.3125, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2069, mae: 1.6252, huber: 1.2448, swd: 1.4207, target_std: 6.3958
    Epoch [3/50], Val Losses: mse: 9.5083, mae: 1.6674, huber: 1.3025, swd: 1.4572, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.4693, mae: 1.8821, huber: 1.4999, swd: 2.0638, target_std: 4.7741
      Epoch 3 composite train-obj: 1.244807
            Val objective improved 1.3125 → 1.3025, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.8918, mae: 1.5894, huber: 1.2093, swd: 1.3030, target_std: 6.3941
    Epoch [4/50], Val Losses: mse: 9.6140, mae: 1.6743, huber: 1.3097, swd: 1.7577, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.4429, mae: 1.8895, huber: 1.5080, swd: 2.4448, target_std: 4.7741
      Epoch 4 composite train-obj: 1.209334
            No improvement (1.3097), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.5719, mae: 1.5476, huber: 1.1689, swd: 1.1690, target_std: 6.3954
    Epoch [5/50], Val Losses: mse: 9.3602, mae: 1.6700, huber: 1.3037, swd: 1.7986, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.5774, mae: 1.9066, huber: 1.5227, swd: 2.7521, target_std: 4.7741
      Epoch 5 composite train-obj: 1.168889
            No improvement (1.3037), counter 2/5
    Epoch [6/50], Train Losses: mse: 6.3558, mae: 1.5195, huber: 1.1416, swd: 1.0772, target_std: 6.3927
    Epoch [6/50], Val Losses: mse: 10.0399, mae: 1.7463, huber: 1.3749, swd: 2.0363, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.8770, mae: 1.9388, huber: 1.5533, swd: 2.9200, target_std: 4.7741
      Epoch 6 composite train-obj: 1.141619
            No improvement (1.3749), counter 3/5
    Epoch [7/50], Train Losses: mse: 6.1758, mae: 1.4956, huber: 1.1186, swd: 1.0377, target_std: 6.3995
    Epoch [7/50], Val Losses: mse: 9.7353, mae: 1.6839, huber: 1.3151, swd: 1.1862, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.3969, mae: 1.8541, huber: 1.4732, swd: 1.8355, target_std: 4.7741
      Epoch 7 composite train-obj: 1.118640
            No improvement (1.3151), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.9428, mae: 1.4618, huber: 1.0864, swd: 0.9260, target_std: 6.3919
    Epoch [8/50], Val Losses: mse: 10.5268, mae: 1.7449, huber: 1.3753, swd: 1.6479, target_std: 4.3900
    Epoch [8/50], Test Losses: mse: 10.7036, mae: 1.9065, huber: 1.5213, swd: 2.2998, target_std: 4.7741
      Epoch 8 composite train-obj: 1.086387
    Epoch [8/50], Test Losses: mse: 10.4693, mae: 1.8821, huber: 1.4999, swd: 2.0638, target_std: 4.7741
    Best round's Test MSE: 10.4693, MAE: 1.8821, SWD: 2.0638
    Best round's Validation MSE: 9.5083, MAE: 1.6674
    Best round's Test verification MSE : 10.4693, MAE: 1.8821, SWD: 2.0638
    Time taken: 32.89 seconds
    
    ==================================================
    Experiment Summary (PatchTST_etth1_seq336_pred196_20250503_2038)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5309 ± 0.0588
      mae: 1.8774 ± 0.0035
      huber: 1.4966 ± 0.0029
      swd: 2.1741 ± 0.2224
      target_std: 4.7741 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.1913 ± 0.2443
      mae: 1.6443 ± 0.0166
      huber: 1.2788 ± 0.0175
      swd: 1.4438 ± 0.1238
      target_std: 4.3900 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 90.91 seconds
    
    Experiment complete: PatchTST_etth1_seq336_pred196_20250503_2038
    Model: PatchTST
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 91
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 91
    Validation Batches: 9
    Test Batches: 22
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4874, mae: 1.9058, huber: 1.5123, swd: 1.9389, target_std: 6.3677
    Epoch [1/50], Val Losses: mse: 9.2299, mae: 1.6823, huber: 1.3112, swd: 0.7866, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 12.8451, mae: 2.1430, huber: 1.7524, swd: 1.5713, target_std: 4.8164
      Epoch 1 composite train-obj: 1.512274
            Val objective improved inf → 1.3112, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.1931, mae: 1.7734, huber: 1.3840, swd: 1.8185, target_std: 6.3853
    Epoch [2/50], Val Losses: mse: 9.4904, mae: 1.7293, huber: 1.3533, swd: 1.2924, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.1880, mae: 2.0010, huber: 1.6119, swd: 2.1520, target_std: 4.8164
      Epoch 2 composite train-obj: 1.383999
            No improvement (1.3533), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.7546, mae: 1.7254, huber: 1.3359, swd: 1.6449, target_std: 6.3578
    Epoch [3/50], Val Losses: mse: 9.6265, mae: 1.7233, huber: 1.3502, swd: 1.3569, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 10.9140, mae: 1.9897, huber: 1.5984, swd: 2.1812, target_std: 4.8164
      Epoch 3 composite train-obj: 1.335879
            No improvement (1.3502), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.2886, mae: 1.6689, huber: 1.2810, swd: 1.4703, target_std: 6.3830
    Epoch [4/50], Val Losses: mse: 10.9471, mae: 1.7875, huber: 1.4117, swd: 1.1850, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.4331, mae: 2.0106, huber: 1.6140, swd: 1.6883, target_std: 4.8164
      Epoch 4 composite train-obj: 1.281034
            No improvement (1.4117), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.9774, mae: 1.6283, huber: 1.2418, swd: 1.3135, target_std: 6.3623
    Epoch [5/50], Val Losses: mse: 9.0949, mae: 1.6875, huber: 1.3144, swd: 1.0747, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.3277, mae: 2.0030, huber: 1.6096, swd: 1.8141, target_std: 4.8164
      Epoch 5 composite train-obj: 1.241791
            No improvement (1.3144), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.7548, mae: 1.5995, huber: 1.2139, swd: 1.2239, target_std: 6.4163
    Epoch [6/50], Val Losses: mse: 8.8337, mae: 1.6472, huber: 1.2772, swd: 1.4442, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.2406, mae: 1.9791, huber: 1.5871, swd: 2.2268, target_std: 4.8164
      Epoch 6 composite train-obj: 1.213940
            Val objective improved 1.3112 → 1.2772, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.6255, mae: 1.5815, huber: 1.1961, swd: 1.1631, target_std: 6.3734
    Epoch [7/50], Val Losses: mse: 8.6988, mae: 1.6505, huber: 1.2793, swd: 1.4151, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.3964, mae: 2.0157, huber: 1.6202, swd: 2.3567, target_std: 4.8164
      Epoch 7 composite train-obj: 1.196142
            No improvement (1.2793), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.3732, mae: 1.5475, huber: 1.1638, swd: 1.0571, target_std: 6.3775
    Epoch [8/50], Val Losses: mse: 9.7101, mae: 1.7173, huber: 1.3453, swd: 1.2799, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 11.0830, mae: 2.0018, huber: 1.6061, swd: 2.0482, target_std: 4.8164
      Epoch 8 composite train-obj: 1.163775
            No improvement (1.3453), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.1803, mae: 1.5169, huber: 1.1346, swd: 0.9927, target_std: 6.3714
    Epoch [9/50], Val Losses: mse: 9.4239, mae: 1.7322, huber: 1.3606, swd: 1.7768, target_std: 4.3610
    Epoch [9/50], Test Losses: mse: 11.0257, mae: 2.0176, huber: 1.6208, swd: 2.6635, target_std: 4.8164
      Epoch 9 composite train-obj: 1.134643
            No improvement (1.3606), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.0479, mae: 1.4950, huber: 1.1141, swd: 0.9458, target_std: 6.3703
    Epoch [10/50], Val Losses: mse: 9.3443, mae: 1.7408, huber: 1.3662, swd: 1.6489, target_std: 4.3610
    Epoch [10/50], Test Losses: mse: 11.4175, mae: 2.0379, huber: 1.6416, swd: 2.7742, target_std: 4.8164
      Epoch 10 composite train-obj: 1.114146
            No improvement (1.3662), counter 4/5
    Epoch [11/50], Train Losses: mse: 5.9225, mae: 1.4744, huber: 1.0944, swd: 0.8933, target_std: 6.3723
    Epoch [11/50], Val Losses: mse: 10.9173, mae: 1.8099, huber: 1.4358, swd: 1.4376, target_std: 4.3610
    Epoch [11/50], Test Losses: mse: 11.2292, mae: 2.0227, huber: 1.6248, swd: 2.1815, target_std: 4.8164
      Epoch 11 composite train-obj: 1.094386
    Epoch [11/50], Test Losses: mse: 11.2406, mae: 1.9791, huber: 1.5871, swd: 2.2268, target_std: 4.8164
    Best round's Test MSE: 11.2406, MAE: 1.9791, SWD: 2.2268
    Best round's Validation MSE: 8.8337, MAE: 1.6472
    Best round's Test verification MSE : 11.2406, MAE: 1.9791, SWD: 2.2268
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4229, mae: 1.8993, huber: 1.5060, swd: 1.9886, target_std: 6.4006
    Epoch [1/50], Val Losses: mse: 10.2017, mae: 1.7912, huber: 1.4142, swd: 1.4309, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 12.1046, mae: 2.0991, huber: 1.7072, swd: 2.0766, target_std: 4.8164
      Epoch 1 composite train-obj: 1.505986
            Val objective improved inf → 1.4142, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.0757, mae: 1.7598, huber: 1.3703, swd: 1.7587, target_std: 6.3895
    Epoch [2/50], Val Losses: mse: 9.3354, mae: 1.7006, huber: 1.3279, swd: 1.1449, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.5627, mae: 2.0537, huber: 1.6599, swd: 2.0201, target_std: 4.8164
      Epoch 2 composite train-obj: 1.370306
            Val objective improved 1.4142 → 1.3279, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.5767, mae: 1.7005, huber: 1.3120, swd: 1.5428, target_std: 6.3628
    Epoch [3/50], Val Losses: mse: 9.5578, mae: 1.7213, huber: 1.3489, swd: 1.2415, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 11.1743, mae: 2.0122, huber: 1.6172, swd: 1.8778, target_std: 4.8164
      Epoch 3 composite train-obj: 1.311971
            No improvement (1.3489), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.2168, mae: 1.6555, huber: 1.2682, swd: 1.3884, target_std: 6.3661
    Epoch [4/50], Val Losses: mse: 9.7160, mae: 1.7540, huber: 1.3811, swd: 1.6823, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.3748, mae: 2.0497, huber: 1.6508, swd: 2.3040, target_std: 4.8164
      Epoch 4 composite train-obj: 1.268187
            No improvement (1.3811), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.9529, mae: 1.6220, huber: 1.2358, swd: 1.2859, target_std: 6.3954
    Epoch [5/50], Val Losses: mse: 10.5710, mae: 1.7954, huber: 1.4195, swd: 1.5201, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 10.8722, mae: 1.9779, huber: 1.5835, swd: 1.8361, target_std: 4.8164
      Epoch 5 composite train-obj: 1.235824
            No improvement (1.4195), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.6783, mae: 1.5840, huber: 1.1994, swd: 1.1669, target_std: 6.3667
    Epoch [6/50], Val Losses: mse: 10.5701, mae: 1.7991, huber: 1.4247, swd: 1.8873, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.1438, mae: 2.0254, huber: 1.6283, swd: 2.3128, target_std: 4.8164
      Epoch 6 composite train-obj: 1.199380
            No improvement (1.4247), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.4573, mae: 1.5559, huber: 1.1722, swd: 1.0632, target_std: 6.4068
    Epoch [7/50], Val Losses: mse: 10.9552, mae: 1.8136, huber: 1.4366, swd: 1.4241, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.3322, mae: 2.0144, huber: 1.6161, swd: 1.7146, target_std: 4.8164
      Epoch 7 composite train-obj: 1.172192
    Epoch [7/50], Test Losses: mse: 11.5627, mae: 2.0537, huber: 1.6599, swd: 2.0201, target_std: 4.8164
    Best round's Test MSE: 11.5627, MAE: 2.0537, SWD: 2.0201
    Best round's Validation MSE: 9.3354, MAE: 1.7006
    Best round's Test verification MSE : 11.5627, MAE: 2.0537, SWD: 2.0201
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.5126, mae: 1.9065, huber: 1.5136, swd: 1.8962, target_std: 6.3562
    Epoch [1/50], Val Losses: mse: 8.8019, mae: 1.6374, huber: 1.2699, swd: 1.4754, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 12.9164, mae: 2.1912, huber: 1.7950, swd: 2.8886, target_std: 4.8164
      Epoch 1 composite train-obj: 1.513607
            Val objective improved inf → 1.2699, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.3795, mae: 1.7923, huber: 1.4031, swd: 1.8414, target_std: 6.3697
    Epoch [2/50], Val Losses: mse: 9.0119, mae: 1.6364, huber: 1.2722, swd: 0.8200, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.0846, mae: 1.9870, huber: 1.5997, swd: 1.5480, target_std: 4.8164
      Epoch 2 composite train-obj: 1.403148
            No improvement (1.2722), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.9288, mae: 1.7401, huber: 1.3525, swd: 1.6835, target_std: 6.3625
    Epoch [3/50], Val Losses: mse: 9.8407, mae: 1.7319, huber: 1.3584, swd: 1.2873, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 11.5347, mae: 2.0392, huber: 1.6469, swd: 2.0821, target_std: 4.8164
      Epoch 3 composite train-obj: 1.352460
            No improvement (1.3584), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.5119, mae: 1.6947, huber: 1.3072, swd: 1.5233, target_std: 6.3780
    Epoch [4/50], Val Losses: mse: 9.0631, mae: 1.6736, huber: 1.3035, swd: 1.5152, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.4156, mae: 2.0431, huber: 1.6505, swd: 2.5427, target_std: 4.8164
      Epoch 4 composite train-obj: 1.307191
            No improvement (1.3035), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.2863, mae: 1.6647, huber: 1.2777, swd: 1.4051, target_std: 6.3799
    Epoch [5/50], Val Losses: mse: 8.9468, mae: 1.6332, huber: 1.2668, swd: 1.0663, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.3500, mae: 1.9924, huber: 1.6018, swd: 1.9194, target_std: 4.8164
      Epoch 5 composite train-obj: 1.277688
            Val objective improved 1.2699 → 1.2668, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.9076, mae: 1.6154, huber: 1.2304, swd: 1.2538, target_std: 6.3717
    Epoch [6/50], Val Losses: mse: 9.1118, mae: 1.6765, huber: 1.3058, swd: 1.5583, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.9977, mae: 2.1255, huber: 1.7249, swd: 2.7664, target_std: 4.8164
      Epoch 6 composite train-obj: 1.230427
            No improvement (1.3058), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.7231, mae: 1.5939, huber: 1.2090, swd: 1.1597, target_std: 6.3601
    Epoch [7/50], Val Losses: mse: 9.9873, mae: 1.7046, huber: 1.3360, swd: 1.1704, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.4696, mae: 2.0192, huber: 1.6260, swd: 1.9266, target_std: 4.8164
      Epoch 7 composite train-obj: 1.209002
            No improvement (1.3360), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.5295, mae: 1.5634, huber: 1.1801, swd: 1.0668, target_std: 6.3686
    Epoch [8/50], Val Losses: mse: 10.5639, mae: 1.7444, huber: 1.3750, swd: 1.1559, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 11.7513, mae: 2.0481, huber: 1.6509, swd: 1.9394, target_std: 4.8164
      Epoch 8 composite train-obj: 1.180109
            No improvement (1.3750), counter 3/5
    Epoch [9/50], Train Losses: mse: 6.4050, mae: 1.5474, huber: 1.1645, swd: 1.0161, target_std: 6.3661
    Epoch [9/50], Val Losses: mse: 10.3026, mae: 1.7181, huber: 1.3500, swd: 1.1132, target_std: 4.3610
    Epoch [9/50], Test Losses: mse: 12.1174, mae: 2.0973, huber: 1.6989, swd: 2.3077, target_std: 4.8164
      Epoch 9 composite train-obj: 1.164455
            No improvement (1.3500), counter 4/5
    Epoch [10/50], Train Losses: mse: 6.2527, mae: 1.5279, huber: 1.1454, swd: 0.9874, target_std: 6.3545
    Epoch [10/50], Val Losses: mse: 11.4585, mae: 1.8028, huber: 1.4310, swd: 1.2400, target_std: 4.3610
    Epoch [10/50], Test Losses: mse: 11.6701, mae: 2.0049, huber: 1.6132, swd: 1.9454, target_std: 4.8164
      Epoch 10 composite train-obj: 1.145438
    Epoch [10/50], Test Losses: mse: 11.3500, mae: 1.9924, huber: 1.6018, swd: 1.9194, target_std: 4.8164
    Best round's Test MSE: 11.3500, MAE: 1.9924, SWD: 1.9194
    Best round's Validation MSE: 8.9468, MAE: 1.6332
    Best round's Test verification MSE : 11.3500, MAE: 1.9924, SWD: 1.9194
    
    ==================================================
    Experiment Summary (PatchTST_etth1_seq336_pred336_20250501_1148)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.3845 ± 0.1337
      mae: 2.0084 ± 0.0325
      huber: 1.6163 ± 0.0314
      swd: 2.0555 ± 0.1280
      target_std: 4.8164 ± 0.0000
      count: 9.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.0386 ± 0.2149
      mae: 1.6603 ± 0.0290
      huber: 1.2906 ± 0.0267
      swd: 1.2185 ± 0.1628
      target_std: 4.3610 ± 0.0000
      count: 9.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_etth1_seq336_pred336_20250501_1148
    Model: PatchTST
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['etth1']['channels'],
    enc_in=data_mgr.datasets['etth1']['channels'],
    dec_in=data_mgr.datasets['etth1']['channels'],
    c_out=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 88
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 88
    Validation Batches: 6
    Test Batches: 19
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.8853, mae: 2.0934, huber: 1.6882, swd: 2.5292, target_std: 6.2901
    Epoch [1/50], Val Losses: mse: 11.5257, mae: 1.9480, huber: 1.5728, swd: 2.5312, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 14.4731, mae: 2.4619, huber: 2.0527, swd: 4.3674, target_std: 4.8721
      Epoch 1 composite train-obj: 1.688158
            Val objective improved inf → 1.5728, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.4813, mae: 1.9563, huber: 1.5535, swd: 2.3537, target_std: 6.3000
    Epoch [2/50], Val Losses: mse: 10.1831, mae: 1.8163, huber: 1.4366, swd: 1.2639, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 12.7963, mae: 2.2964, huber: 1.8857, swd: 3.0132, target_std: 4.8721
      Epoch 2 composite train-obj: 1.553487
            Val objective improved 1.5728 → 1.4366, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.8787, mae: 1.8885, huber: 1.4865, swd: 2.0576, target_std: 6.2770
    Epoch [3/50], Val Losses: mse: 9.8367, mae: 1.7738, huber: 1.3971, swd: 0.9798, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.7573, mae: 2.2564, huber: 1.8467, swd: 2.2990, target_std: 4.8721
      Epoch 3 composite train-obj: 1.486542
            Val objective improved 1.4366 → 1.3971, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 8.3766, mae: 1.8294, huber: 1.4286, swd: 1.7693, target_std: 6.2792
    Epoch [4/50], Val Losses: mse: 11.2846, mae: 1.8640, huber: 1.4884, swd: 1.5677, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.1844, mae: 2.2352, huber: 1.8229, swd: 2.7573, target_std: 4.8721
      Epoch 4 composite train-obj: 1.428558
            No improvement (1.4884), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.8731, mae: 1.7649, huber: 1.3661, swd: 1.5023, target_std: 6.2902
    Epoch [5/50], Val Losses: mse: 12.1528, mae: 1.9789, huber: 1.5969, swd: 2.1205, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.0746, mae: 2.2400, huber: 1.8247, swd: 2.7724, target_std: 4.8721
      Epoch 5 composite train-obj: 1.366138
            No improvement (1.5969), counter 2/5
    Epoch [6/50], Train Losses: mse: 7.5840, mae: 1.7275, huber: 1.3298, swd: 1.3603, target_std: 6.2846
    Epoch [6/50], Val Losses: mse: 13.7334, mae: 2.0612, huber: 1.6804, swd: 2.3147, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.8177, mae: 2.3219, huber: 1.9060, swd: 3.3428, target_std: 4.8721
      Epoch 6 composite train-obj: 1.329813
            No improvement (1.6804), counter 3/5
    Epoch [7/50], Train Losses: mse: 7.3380, mae: 1.6929, huber: 1.2971, swd: 1.2526, target_std: 6.2861
    Epoch [7/50], Val Losses: mse: 12.3182, mae: 1.9611, huber: 1.5817, swd: 2.2222, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 13.0016, mae: 2.3652, huber: 1.9459, swd: 3.9622, target_std: 4.8721
      Epoch 7 composite train-obj: 1.297052
            No improvement (1.5817), counter 4/5
    Epoch [8/50], Train Losses: mse: 7.3009, mae: 1.6915, huber: 1.2952, swd: 1.2554, target_std: 6.3116
    Epoch [8/50], Val Losses: mse: 15.1312, mae: 2.1114, huber: 1.7267, swd: 1.8496, target_std: 4.3728
    Epoch [8/50], Test Losses: mse: 12.5564, mae: 2.2313, huber: 1.8182, swd: 2.0593, target_std: 4.8721
      Epoch 8 composite train-obj: 1.295233
    Epoch [8/50], Test Losses: mse: 12.7573, mae: 2.2564, huber: 1.8467, swd: 2.2990, target_std: 4.8721
    Best round's Test MSE: 12.7573, MAE: 2.2564, SWD: 2.2990
    Best round's Validation MSE: 9.8367, MAE: 1.7738
    Best round's Test verification MSE : 12.7573, MAE: 2.2564, SWD: 2.2990
    Time taken: 32.61 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.7984, mae: 2.0831, huber: 1.6779, swd: 2.3553, target_std: 6.2760
    Epoch [1/50], Val Losses: mse: 10.3720, mae: 1.7944, huber: 1.4238, swd: 1.1878, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.6403, mae: 2.2686, huber: 1.8621, swd: 2.3996, target_std: 4.8721
      Epoch 1 composite train-obj: 1.677874
            Val objective improved inf → 1.4238, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.2748, mae: 1.9336, huber: 1.5309, swd: 2.0668, target_std: 6.2922
    Epoch [2/50], Val Losses: mse: 13.7669, mae: 2.0844, huber: 1.7020, swd: 2.1790, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 13.7151, mae: 2.4180, huber: 2.0032, swd: 3.4215, target_std: 4.8721
      Epoch 2 composite train-obj: 1.530863
            No improvement (1.7020), counter 1/5
    Epoch [3/50], Train Losses: mse: 8.6267, mae: 1.8599, huber: 1.4581, swd: 1.7949, target_std: 6.2792
    Epoch [3/50], Val Losses: mse: 13.7496, mae: 2.1092, huber: 1.7221, swd: 2.0180, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 13.1208, mae: 2.3668, huber: 1.9482, swd: 3.3012, target_std: 4.8721
      Epoch 3 composite train-obj: 1.458135
            No improvement (1.7221), counter 2/5
    Epoch [4/50], Train Losses: mse: 8.0863, mae: 1.7966, huber: 1.3962, swd: 1.5346, target_std: 6.3176
    Epoch [4/50], Val Losses: mse: 12.4361, mae: 1.9129, huber: 1.5337, swd: 0.8964, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 13.3184, mae: 2.3627, huber: 1.9438, swd: 2.8930, target_std: 4.8721
      Epoch 4 composite train-obj: 1.396219
            No improvement (1.5337), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.8434, mae: 1.7649, huber: 1.3658, swd: 1.4221, target_std: 6.2782
    Epoch [5/50], Val Losses: mse: 12.2051, mae: 1.9071, huber: 1.5338, swd: 1.6068, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.1970, mae: 2.2588, huber: 1.8441, swd: 2.7684, target_std: 4.8721
      Epoch 5 composite train-obj: 1.365841
            No improvement (1.5338), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.4384, mae: 1.7089, huber: 1.3122, swd: 1.2308, target_std: 6.2813
    Epoch [6/50], Val Losses: mse: 12.5876, mae: 2.0029, huber: 1.6214, swd: 2.0110, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.9467, mae: 2.3588, huber: 1.9397, swd: 3.3711, target_std: 4.8721
      Epoch 6 composite train-obj: 1.312237
    Epoch [6/50], Test Losses: mse: 12.6403, mae: 2.2686, huber: 1.8621, swd: 2.3996, target_std: 4.8721
    Best round's Test MSE: 12.6403, MAE: 2.2686, SWD: 2.3996
    Best round's Validation MSE: 10.3720, MAE: 1.7944
    Best round's Test verification MSE : 12.6403, MAE: 2.2686, SWD: 2.3996
    Time taken: 24.49 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.8085, mae: 2.0842, huber: 1.6796, swd: 2.6389, target_std: 6.2970
    Epoch [1/50], Val Losses: mse: 10.3526, mae: 1.7812, huber: 1.4104, swd: 1.4595, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 13.4661, mae: 2.3654, huber: 1.9564, swd: 3.1606, target_std: 4.8721
      Epoch 1 composite train-obj: 1.679583
            Val objective improved inf → 1.4104, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.3632, mae: 1.9424, huber: 1.5407, swd: 2.3515, target_std: 6.2937
    Epoch [2/50], Val Losses: mse: 10.2673, mae: 1.7329, huber: 1.3638, swd: 0.6957, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 13.2750, mae: 2.3014, huber: 1.8898, swd: 2.3556, target_std: 4.8721
      Epoch 2 composite train-obj: 1.540716
            Val objective improved 1.4104 → 1.3638, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.8832, mae: 1.8906, huber: 1.4891, swd: 2.0882, target_std: 6.2739
    Epoch [3/50], Val Losses: mse: 12.8769, mae: 1.9579, huber: 1.5827, swd: 1.6527, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.4300, mae: 2.2127, huber: 1.8009, swd: 2.3215, target_std: 4.8721
      Epoch 3 composite train-obj: 1.489107
            No improvement (1.5827), counter 1/5
    Epoch [4/50], Train Losses: mse: 8.3161, mae: 1.8264, huber: 1.4259, swd: 1.8246, target_std: 6.3002
    Epoch [4/50], Val Losses: mse: 13.1005, mae: 1.8707, huber: 1.5008, swd: 0.7863, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 13.3089, mae: 2.2749, huber: 1.8620, swd: 2.4475, target_std: 4.8721
      Epoch 4 composite train-obj: 1.425924
            No improvement (1.5008), counter 2/5
    Epoch [5/50], Train Losses: mse: 8.0247, mae: 1.7877, huber: 1.3884, swd: 1.6550, target_std: 6.2927
    Epoch [5/50], Val Losses: mse: 12.3529, mae: 1.8702, huber: 1.4987, swd: 1.0503, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 11.9837, mae: 2.1784, huber: 1.7677, swd: 2.0284, target_std: 4.8721
      Epoch 5 composite train-obj: 1.388444
            No improvement (1.4987), counter 3/5
    Epoch [6/50], Train Losses: mse: 7.6811, mae: 1.7387, huber: 1.3416, swd: 1.4487, target_std: 6.2921
    Epoch [6/50], Val Losses: mse: 12.9535, mae: 1.9768, huber: 1.6022, swd: 2.1605, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.7927, mae: 2.3001, huber: 1.8874, swd: 3.0390, target_std: 4.8721
      Epoch 6 composite train-obj: 1.341632
            No improvement (1.6022), counter 4/5
    Epoch [7/50], Train Losses: mse: 7.5495, mae: 1.7223, huber: 1.3258, swd: 1.4084, target_std: 6.3008
    Epoch [7/50], Val Losses: mse: 13.6321, mae: 1.9612, huber: 1.5897, swd: 1.6159, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.4434, mae: 2.2368, huber: 1.8232, swd: 2.4324, target_std: 4.8721
      Epoch 7 composite train-obj: 1.325759
    Epoch [7/50], Test Losses: mse: 13.2750, mae: 2.3014, huber: 1.8898, swd: 2.3556, target_std: 4.8721
    Best round's Test MSE: 13.2750, MAE: 2.3014, SWD: 2.3556
    Best round's Validation MSE: 10.2673, MAE: 1.7329
    Best round's Test verification MSE : 13.2750, MAE: 2.3014, SWD: 2.3556
    Time taken: 28.71 seconds
    
    ==================================================
    Experiment Summary (PatchTST_etth1_seq336_pred720_20250503_2041)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.8908 ± 0.2758
      mae: 2.2755 ± 0.0190
      huber: 1.8662 ± 0.0178
      swd: 2.3514 ± 0.0412
      target_std: 4.8721 ± 0.0000
      count: 6.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.1587 ± 0.2317
      mae: 1.7670 ± 0.0255
      huber: 1.3949 ± 0.0246
      swd: 0.9544 ± 0.2017
      target_std: 4.3728 ± 0.0000
      count: 6.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 85.92 seconds
    
    Experiment complete: PatchTST_etth1_seq336_pred720_20250503_2041
    Model: PatchTST
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### pred=96


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 11
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.3469, mae: 1.8650, huber: 1.4774, swd: 2.3097, target_std: 6.4055
    Epoch [1/50], Val Losses: mse: 8.4995, mae: 1.5798, huber: 1.2159, swd: 1.1629, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.4647, mae: 1.8189, huber: 1.4432, swd: 1.7388, target_std: 4.7659
      Epoch 1 composite train-obj: 1.477375
            Val objective improved inf → 1.2159, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2537, mae: 1.4868, huber: 1.1188, swd: 1.6284, target_std: 6.4055
    Epoch [2/50], Val Losses: mse: 7.8887, mae: 1.4939, huber: 1.1351, swd: 1.0212, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.2123, mae: 1.7610, huber: 1.3890, swd: 1.6513, target_std: 4.7659
      Epoch 2 composite train-obj: 1.118795
            Val objective improved 1.2159 → 1.1351, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0296, mae: 1.4476, huber: 1.0827, swd: 1.5720, target_std: 6.4060
    Epoch [3/50], Val Losses: mse: 7.6122, mae: 1.4577, huber: 1.1016, swd: 0.9780, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.1297, mae: 1.7373, huber: 1.3680, swd: 1.6650, target_std: 4.7659
      Epoch 3 composite train-obj: 1.082706
            Val objective improved 1.1351 → 1.1016, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.9468, mae: 1.4311, huber: 1.0680, swd: 1.5457, target_std: 6.4057
    Epoch [4/50], Val Losses: mse: 7.5753, mae: 1.4502, huber: 1.0946, swd: 0.9142, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.0867, mae: 1.7259, huber: 1.3568, swd: 1.5663, target_std: 4.7659
      Epoch 4 composite train-obj: 1.067959
            Val objective improved 1.1016 → 1.0946, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.9216, mae: 1.4257, huber: 1.0632, swd: 1.5434, target_std: 6.4059
    Epoch [5/50], Val Losses: mse: 7.6574, mae: 1.4631, huber: 1.1073, swd: 1.0382, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.1137, mae: 1.7267, huber: 1.3580, swd: 1.6096, target_std: 4.7659
      Epoch 5 composite train-obj: 1.063170
            No improvement (1.1073), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.8733, mae: 1.4165, huber: 1.0546, swd: 1.5247, target_std: 6.4059
    Epoch [6/50], Val Losses: mse: 7.4892, mae: 1.4384, huber: 1.0834, swd: 1.0281, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.1289, mae: 1.7265, huber: 1.3589, swd: 1.7106, target_std: 4.7659
      Epoch 6 composite train-obj: 1.054580
            Val objective improved 1.0946 → 1.0834, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 5.8777, mae: 1.4170, huber: 1.0552, swd: 1.5367, target_std: 6.4061
    Epoch [7/50], Val Losses: mse: 7.7852, mae: 1.4782, huber: 1.1223, swd: 1.3198, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.0241, mae: 1.7130, huber: 1.3443, swd: 1.7037, target_std: 4.7659
      Epoch 7 composite train-obj: 1.055154
            No improvement (1.1223), counter 1/5
    Epoch [8/50], Train Losses: mse: 5.8594, mae: 1.4123, huber: 1.0507, swd: 1.5290, target_std: 6.4056
    Epoch [8/50], Val Losses: mse: 7.4975, mae: 1.4370, huber: 1.0831, swd: 1.0519, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.0180, mae: 1.7078, huber: 1.3410, swd: 1.6250, target_std: 4.7659
      Epoch 8 composite train-obj: 1.050742
            Val objective improved 1.0834 → 1.0831, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 5.8695, mae: 1.4125, huber: 1.0512, swd: 1.5346, target_std: 6.4058
    Epoch [9/50], Val Losses: mse: 7.5401, mae: 1.4464, huber: 1.0918, swd: 1.0889, target_std: 4.4109
    Epoch [9/50], Test Losses: mse: 10.0394, mae: 1.7116, huber: 1.3440, swd: 1.6157, target_std: 4.7659
      Epoch 9 composite train-obj: 1.051215
            No improvement (1.0918), counter 1/5
    Epoch [10/50], Train Losses: mse: 5.8417, mae: 1.4081, huber: 1.0471, swd: 1.5306, target_std: 6.4058
    Epoch [10/50], Val Losses: mse: 7.5056, mae: 1.4417, huber: 1.0862, swd: 1.1002, target_std: 4.4109
    Epoch [10/50], Test Losses: mse: 10.0242, mae: 1.7111, huber: 1.3435, swd: 1.6787, target_std: 4.7659
      Epoch 10 composite train-obj: 1.047077
            No improvement (1.0862), counter 2/5
    Epoch [11/50], Train Losses: mse: 5.8716, mae: 1.4117, huber: 1.0505, swd: 1.5470, target_std: 6.4060
    Epoch [11/50], Val Losses: mse: 7.5696, mae: 1.4407, huber: 1.0866, swd: 0.9942, target_std: 4.4109
    Epoch [11/50], Test Losses: mse: 10.0389, mae: 1.7058, huber: 1.3388, swd: 1.5611, target_std: 4.7659
      Epoch 11 composite train-obj: 1.050479
            No improvement (1.0866), counter 3/5
    Epoch [12/50], Train Losses: mse: 5.8255, mae: 1.4053, huber: 1.0443, swd: 1.5110, target_std: 6.4053
    Epoch [12/50], Val Losses: mse: 7.3533, mae: 1.4193, huber: 1.0638, swd: 0.8682, target_std: 4.4109
    Epoch [12/50], Test Losses: mse: 10.1164, mae: 1.7160, huber: 1.3471, swd: 1.5671, target_std: 4.7659
      Epoch 12 composite train-obj: 1.044330
            Val objective improved 1.0831 → 1.0638, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 5.8313, mae: 1.4060, huber: 1.0450, swd: 1.5165, target_std: 6.4055
    Epoch [13/50], Val Losses: mse: 7.5029, mae: 1.4431, huber: 1.0877, swd: 1.0123, target_std: 4.4109
    Epoch [13/50], Test Losses: mse: 10.0621, mae: 1.7100, huber: 1.3429, swd: 1.5782, target_std: 4.7659
      Epoch 13 composite train-obj: 1.045030
            No improvement (1.0877), counter 1/5
    Epoch [14/50], Train Losses: mse: 5.8190, mae: 1.4034, huber: 1.0427, swd: 1.5115, target_std: 6.4054
    Epoch [14/50], Val Losses: mse: 7.4300, mae: 1.4306, huber: 1.0764, swd: 0.9981, target_std: 4.4109
    Epoch [14/50], Test Losses: mse: 10.0188, mae: 1.7051, huber: 1.3384, swd: 1.6759, target_std: 4.7659
      Epoch 14 composite train-obj: 1.042690
            No improvement (1.0764), counter 2/5
    Epoch [15/50], Train Losses: mse: 5.8095, mae: 1.4018, huber: 1.0411, swd: 1.5070, target_std: 6.4057
    Epoch [15/50], Val Losses: mse: 7.3638, mae: 1.4281, huber: 1.0731, swd: 1.0706, target_std: 4.4109
    Epoch [15/50], Test Losses: mse: 10.0581, mae: 1.7129, huber: 1.3460, swd: 1.7397, target_std: 4.7659
      Epoch 15 composite train-obj: 1.041069
            No improvement (1.0731), counter 3/5
    Epoch [16/50], Train Losses: mse: 5.8290, mae: 1.4062, huber: 1.0451, swd: 1.5295, target_std: 6.4060
    Epoch [16/50], Val Losses: mse: 7.4180, mae: 1.4247, huber: 1.0718, swd: 0.9591, target_std: 4.4109
    Epoch [16/50], Test Losses: mse: 10.0991, mae: 1.7121, huber: 1.3446, swd: 1.6277, target_std: 4.7659
      Epoch 16 composite train-obj: 1.045116
            No improvement (1.0718), counter 4/5
    Epoch [17/50], Train Losses: mse: 5.8248, mae: 1.4037, huber: 1.0431, swd: 1.5238, target_std: 6.4057
    Epoch [17/50], Val Losses: mse: 7.4381, mae: 1.4270, huber: 1.0732, swd: 0.9638, target_std: 4.4109
    Epoch [17/50], Test Losses: mse: 10.0127, mae: 1.7045, huber: 1.3369, swd: 1.5910, target_std: 4.7659
      Epoch 17 composite train-obj: 1.043052
    Epoch [17/50], Test Losses: mse: 10.1164, mae: 1.7160, huber: 1.3471, swd: 1.5671, target_std: 4.7659
    Best round's Test MSE: 10.1164, MAE: 1.7160, SWD: 1.5671
    Best round's Validation MSE: 7.3533, MAE: 1.4193
    Best round's Test verification MSE : 10.1164, MAE: 1.7160, SWD: 1.5671
    Time taken: 21.15 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.3390, mae: 1.8647, huber: 1.4774, swd: 2.2782, target_std: 6.4057
    Epoch [1/50], Val Losses: mse: 8.6615, mae: 1.5972, huber: 1.2329, swd: 1.1309, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.5293, mae: 1.8286, huber: 1.4528, swd: 1.6686, target_std: 4.7659
      Epoch 1 composite train-obj: 1.477408
            Val objective improved inf → 1.2329, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2764, mae: 1.4909, huber: 1.1226, swd: 1.5678, target_std: 6.4059
    Epoch [2/50], Val Losses: mse: 7.9095, mae: 1.4926, huber: 1.1344, swd: 0.8769, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.2618, mae: 1.7623, huber: 1.3912, swd: 1.5284, target_std: 4.7659
      Epoch 2 composite train-obj: 1.122622
            Val objective improved 1.2329 → 1.1344, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0583, mae: 1.4506, huber: 1.0859, swd: 1.5148, target_std: 6.4058
    Epoch [3/50], Val Losses: mse: 7.7205, mae: 1.4694, huber: 1.1127, swd: 0.9805, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.1350, mae: 1.7395, huber: 1.3700, swd: 1.5780, target_std: 4.7659
      Epoch 3 composite train-obj: 1.085869
            Val objective improved 1.1344 → 1.1127, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.9645, mae: 1.4337, huber: 1.0703, swd: 1.4881, target_std: 6.4058
    Epoch [4/50], Val Losses: mse: 7.6673, mae: 1.4632, huber: 1.1072, swd: 1.0335, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.1533, mae: 1.7360, huber: 1.3671, swd: 1.5999, target_std: 4.7659
      Epoch 4 composite train-obj: 1.070347
            Val objective improved 1.1127 → 1.1072, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.9121, mae: 1.4233, huber: 1.0609, swd: 1.4700, target_std: 6.4053
    Epoch [5/50], Val Losses: mse: 7.4911, mae: 1.4403, huber: 1.0843, swd: 0.8998, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.1109, mae: 1.7224, huber: 1.3550, swd: 1.5523, target_std: 4.7659
      Epoch 5 composite train-obj: 1.060948
            Val objective improved 1.1072 → 1.0843, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.8827, mae: 1.4181, huber: 1.0560, swd: 1.4601, target_std: 6.4056
    Epoch [6/50], Val Losses: mse: 7.6186, mae: 1.4566, huber: 1.1012, swd: 1.1365, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.0542, mae: 1.7167, huber: 1.3491, swd: 1.6208, target_std: 4.7659
      Epoch 6 composite train-obj: 1.055985
            No improvement (1.1012), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.8750, mae: 1.4159, huber: 1.0541, swd: 1.4645, target_std: 6.4063
    Epoch [7/50], Val Losses: mse: 7.4852, mae: 1.4413, huber: 1.0866, swd: 1.0097, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.0454, mae: 1.7148, huber: 1.3476, swd: 1.6127, target_std: 4.7659
      Epoch 7 composite train-obj: 1.054140
            No improvement (1.0866), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.8722, mae: 1.4141, huber: 1.0527, swd: 1.4679, target_std: 6.4059
    Epoch [8/50], Val Losses: mse: 7.5468, mae: 1.4459, huber: 1.0913, swd: 1.0541, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.0230, mae: 1.7108, huber: 1.3441, swd: 1.5955, target_std: 4.7659
      Epoch 8 composite train-obj: 1.052673
            No improvement (1.0913), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.8543, mae: 1.4108, huber: 1.0495, swd: 1.4641, target_std: 6.4059
    Epoch [9/50], Val Losses: mse: 7.4322, mae: 1.4264, huber: 1.0717, swd: 0.8350, target_std: 4.4109
    Epoch [9/50], Test Losses: mse: 10.1312, mae: 1.7209, huber: 1.3525, swd: 1.4625, target_std: 4.7659
      Epoch 9 composite train-obj: 1.049540
            Val objective improved 1.0843 → 1.0717, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 5.8513, mae: 1.4106, huber: 1.0493, swd: 1.4564, target_std: 6.4056
    Epoch [10/50], Val Losses: mse: 7.4874, mae: 1.4348, huber: 1.0801, swd: 0.9593, target_std: 4.4109
    Epoch [10/50], Test Losses: mse: 10.0236, mae: 1.7071, huber: 1.3404, swd: 1.5509, target_std: 4.7659
      Epoch 10 composite train-obj: 1.049270
            No improvement (1.0801), counter 1/5
    Epoch [11/50], Train Losses: mse: 5.8555, mae: 1.4097, huber: 1.0486, swd: 1.4686, target_std: 6.4059
    Epoch [11/50], Val Losses: mse: 7.4946, mae: 1.4355, huber: 1.0814, swd: 1.0215, target_std: 4.4109
    Epoch [11/50], Test Losses: mse: 10.0311, mae: 1.7094, huber: 1.3411, swd: 1.5352, target_std: 4.7659
      Epoch 11 composite train-obj: 1.048571
            No improvement (1.0814), counter 2/5
    Epoch [12/50], Train Losses: mse: 5.8466, mae: 1.4082, huber: 1.0471, swd: 1.4543, target_std: 6.4057
    Epoch [12/50], Val Losses: mse: 7.4568, mae: 1.4316, huber: 1.0776, swd: 0.9508, target_std: 4.4109
    Epoch [12/50], Test Losses: mse: 10.0387, mae: 1.7111, huber: 1.3435, swd: 1.5121, target_std: 4.7659
      Epoch 12 composite train-obj: 1.047142
            No improvement (1.0776), counter 3/5
    Epoch [13/50], Train Losses: mse: 5.8397, mae: 1.4074, huber: 1.0464, swd: 1.4543, target_std: 6.4058
    Epoch [13/50], Val Losses: mse: 7.5116, mae: 1.4337, huber: 1.0801, swd: 1.0137, target_std: 4.4109
    Epoch [13/50], Test Losses: mse: 9.9936, mae: 1.6965, huber: 1.3306, swd: 1.4931, target_std: 4.7659
      Epoch 13 composite train-obj: 1.046358
            No improvement (1.0801), counter 4/5
    Epoch [14/50], Train Losses: mse: 5.8114, mae: 1.4027, huber: 1.0421, swd: 1.4485, target_std: 6.4057
    Epoch [14/50], Val Losses: mse: 7.5119, mae: 1.4393, huber: 1.0848, swd: 1.1095, target_std: 4.4109
    Epoch [14/50], Test Losses: mse: 9.9749, mae: 1.7034, huber: 1.3358, swd: 1.6334, target_std: 4.7659
      Epoch 14 composite train-obj: 1.042135
    Epoch [14/50], Test Losses: mse: 10.1312, mae: 1.7209, huber: 1.3525, swd: 1.4625, target_std: 4.7659
    Best round's Test MSE: 10.1312, MAE: 1.7209, SWD: 1.4625
    Best round's Validation MSE: 7.4322, MAE: 1.4264
    Best round's Test verification MSE : 10.1312, MAE: 1.7209, SWD: 1.4625
    Time taken: 18.31 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4602, mae: 1.8661, huber: 1.4793, swd: 2.1446, target_std: 6.4059
    Epoch [1/50], Val Losses: mse: 8.6149, mae: 1.5870, huber: 1.2233, swd: 1.1186, target_std: 4.4109
    Epoch [1/50], Test Losses: mse: 10.5468, mae: 1.8278, huber: 1.4519, swd: 1.6407, target_std: 4.7659
      Epoch 1 composite train-obj: 1.479273
            Val objective improved inf → 1.2233, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2754, mae: 1.4899, huber: 1.1219, swd: 1.5014, target_std: 6.4055
    Epoch [2/50], Val Losses: mse: 7.9014, mae: 1.4950, huber: 1.1357, swd: 0.9055, target_std: 4.4109
    Epoch [2/50], Test Losses: mse: 10.2793, mae: 1.7689, huber: 1.3964, swd: 1.5562, target_std: 4.7659
      Epoch 2 composite train-obj: 1.121855
            Val objective improved 1.2233 → 1.1357, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0399, mae: 1.4495, huber: 1.0847, swd: 1.4499, target_std: 6.4052
    Epoch [3/50], Val Losses: mse: 7.7478, mae: 1.4693, huber: 1.1125, swd: 0.8855, target_std: 4.4109
    Epoch [3/50], Test Losses: mse: 10.2136, mae: 1.7415, huber: 1.3726, swd: 1.4838, target_std: 4.7659
      Epoch 3 composite train-obj: 1.084667
            Val objective improved 1.1357 → 1.1125, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.9687, mae: 1.4342, huber: 1.0709, swd: 1.4264, target_std: 6.4053
    Epoch [4/50], Val Losses: mse: 7.5972, mae: 1.4567, huber: 1.1003, swd: 0.9826, target_std: 4.4109
    Epoch [4/50], Test Losses: mse: 10.1350, mae: 1.7312, huber: 1.3620, swd: 1.6072, target_std: 4.7659
      Epoch 4 composite train-obj: 1.070923
            Val objective improved 1.1125 → 1.1003, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.9048, mae: 1.4234, huber: 1.0608, swd: 1.4112, target_std: 6.4058
    Epoch [5/50], Val Losses: mse: 7.6331, mae: 1.4589, huber: 1.1033, swd: 1.0167, target_std: 4.4109
    Epoch [5/50], Test Losses: mse: 10.1040, mae: 1.7227, huber: 1.3539, swd: 1.5384, target_std: 4.7659
      Epoch 5 composite train-obj: 1.060819
            No improvement (1.1033), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.9197, mae: 1.4231, huber: 1.0608, swd: 1.4249, target_std: 6.4061
    Epoch [6/50], Val Losses: mse: 7.4772, mae: 1.4341, huber: 1.0794, swd: 0.8906, target_std: 4.4109
    Epoch [6/50], Test Losses: mse: 10.1423, mae: 1.7235, huber: 1.3557, swd: 1.5123, target_std: 4.7659
      Epoch 6 composite train-obj: 1.060848
            Val objective improved 1.1003 → 1.0794, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 5.8701, mae: 1.4153, huber: 1.0535, swd: 1.4063, target_std: 6.4058
    Epoch [7/50], Val Losses: mse: 7.4925, mae: 1.4357, huber: 1.0808, swd: 0.9488, target_std: 4.4109
    Epoch [7/50], Test Losses: mse: 10.0619, mae: 1.7129, huber: 1.3458, swd: 1.5310, target_std: 4.7659
      Epoch 7 composite train-obj: 1.053520
            No improvement (1.0808), counter 1/5
    Epoch [8/50], Train Losses: mse: 5.8706, mae: 1.4141, huber: 1.0526, swd: 1.4123, target_std: 6.4056
    Epoch [8/50], Val Losses: mse: 7.4355, mae: 1.4309, huber: 1.0758, swd: 0.8897, target_std: 4.4109
    Epoch [8/50], Test Losses: mse: 10.0808, mae: 1.7154, huber: 1.3476, swd: 1.5170, target_std: 4.7659
      Epoch 8 composite train-obj: 1.052586
            Val objective improved 1.0794 → 1.0758, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 5.8503, mae: 1.4104, huber: 1.0490, swd: 1.3942, target_std: 6.4055
    Epoch [9/50], Val Losses: mse: 7.5352, mae: 1.4508, huber: 1.0951, swd: 1.1291, target_std: 4.4109
    Epoch [9/50], Test Losses: mse: 10.0746, mae: 1.7193, huber: 1.3517, swd: 1.6700, target_std: 4.7659
      Epoch 9 composite train-obj: 1.048987
            No improvement (1.0951), counter 1/5
    Epoch [10/50], Train Losses: mse: 5.8500, mae: 1.4102, huber: 1.0489, swd: 1.3997, target_std: 6.4056
    Epoch [10/50], Val Losses: mse: 7.5578, mae: 1.4564, huber: 1.1004, swd: 1.1123, target_std: 4.4109
    Epoch [10/50], Test Losses: mse: 10.0947, mae: 1.7218, huber: 1.3542, swd: 1.6968, target_std: 4.7659
      Epoch 10 composite train-obj: 1.048949
            No improvement (1.1004), counter 2/5
    Epoch [11/50], Train Losses: mse: 5.8508, mae: 1.4101, huber: 1.0488, swd: 1.4095, target_std: 6.4054
    Epoch [11/50], Val Losses: mse: 7.4470, mae: 1.4347, huber: 1.0789, swd: 0.9931, target_std: 4.4109
    Epoch [11/50], Test Losses: mse: 10.0692, mae: 1.7154, huber: 1.3476, swd: 1.5633, target_std: 4.7659
      Epoch 11 composite train-obj: 1.048802
            No improvement (1.0789), counter 3/5
    Epoch [12/50], Train Losses: mse: 5.8334, mae: 1.4061, huber: 1.0452, swd: 1.3982, target_std: 6.4055
    Epoch [12/50], Val Losses: mse: 7.4133, mae: 1.4207, huber: 1.0668, swd: 0.8287, target_std: 4.4109
    Epoch [12/50], Test Losses: mse: 10.1298, mae: 1.7116, huber: 1.3445, swd: 1.4871, target_std: 4.7659
      Epoch 12 composite train-obj: 1.045197
            Val objective improved 1.0758 → 1.0668, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 5.8340, mae: 1.4070, huber: 1.0461, swd: 1.3984, target_std: 6.4055
    Epoch [13/50], Val Losses: mse: 7.3857, mae: 1.4225, huber: 1.0684, swd: 0.8966, target_std: 4.4109
    Epoch [13/50], Test Losses: mse: 10.0493, mae: 1.7061, huber: 1.3388, swd: 1.5101, target_std: 4.7659
      Epoch 13 composite train-obj: 1.046077
            No improvement (1.0684), counter 1/5
    Epoch [14/50], Train Losses: mse: 5.8297, mae: 1.4053, huber: 1.0445, swd: 1.3994, target_std: 6.4056
    Epoch [14/50], Val Losses: mse: 7.5861, mae: 1.4417, huber: 1.0871, swd: 1.0275, target_std: 4.4109
    Epoch [14/50], Test Losses: mse: 10.0798, mae: 1.7044, huber: 1.3373, swd: 1.4861, target_std: 4.7659
      Epoch 14 composite train-obj: 1.044485
            No improvement (1.0871), counter 2/5
    Epoch [15/50], Train Losses: mse: 5.8395, mae: 1.4056, huber: 1.0448, swd: 1.4072, target_std: 6.4060
    Epoch [15/50], Val Losses: mse: 7.3944, mae: 1.4232, huber: 1.0685, swd: 0.8402, target_std: 4.4109
    Epoch [15/50], Test Losses: mse: 10.0942, mae: 1.7140, huber: 1.3471, swd: 1.4992, target_std: 4.7659
      Epoch 15 composite train-obj: 1.044774
            No improvement (1.0685), counter 3/5
    Epoch [16/50], Train Losses: mse: 5.8279, mae: 1.4060, huber: 1.0448, swd: 1.3947, target_std: 6.4056
    Epoch [16/50], Val Losses: mse: 7.3983, mae: 1.4231, huber: 1.0689, swd: 0.8240, target_std: 4.4109
    Epoch [16/50], Test Losses: mse: 10.0534, mae: 1.7058, huber: 1.3391, swd: 1.4506, target_std: 4.7659
      Epoch 16 composite train-obj: 1.044795
            No improvement (1.0689), counter 4/5
    Epoch [17/50], Train Losses: mse: 5.8153, mae: 1.4032, huber: 1.0425, swd: 1.3920, target_std: 6.4058
    Epoch [17/50], Val Losses: mse: 7.4150, mae: 1.4306, huber: 1.0754, swd: 0.9919, target_std: 4.4109
    Epoch [17/50], Test Losses: mse: 10.0133, mae: 1.7030, huber: 1.3371, swd: 1.5387, target_std: 4.7659
      Epoch 17 composite train-obj: 1.042454
    Epoch [17/50], Test Losses: mse: 10.1298, mae: 1.7116, huber: 1.3445, swd: 1.4871, target_std: 4.7659
    Best round's Test MSE: 10.1298, MAE: 1.7116, SWD: 1.4871
    Best round's Validation MSE: 7.4133, MAE: 1.4207
    Best round's Test verification MSE : 10.1298, MAE: 1.7116, SWD: 1.4871
    Time taken: 22.17 seconds
    
    ==================================================
    Experiment Summary (DLinear_etth1_seq336_pred96_20250503_1955)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.1258 ± 0.0067
      mae: 1.7161 ± 0.0038
      huber: 1.3480 ± 0.0033
      swd: 1.5056 ± 0.0446
      target_std: 4.7659 ± 0.0000
      count: 11.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.3996 ± 0.0336
      mae: 1.4221 ± 0.0030
      huber: 1.0674 ± 0.0033
      swd: 0.8440 ± 0.0173
      target_std: 4.4109 ± 0.0000
      count: 11.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 61.67 seconds
    
    Experiment complete: DLinear_etth1_seq336_pred96_20250503_1955
    Model: DLinear
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 92
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 92
    Validation Batches: 10
    Test Batches: 24
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.0549, mae: 1.9507, huber: 1.5580, swd: 2.3285, target_std: 6.3954
    Epoch [1/50], Val Losses: mse: 10.2483, mae: 1.7456, huber: 1.3753, swd: 1.4115, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.8520, mae: 1.9130, huber: 1.5282, swd: 1.7112, target_std: 4.7741
      Epoch 1 composite train-obj: 1.558044
            Val objective improved inf → 1.3753, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9386, mae: 1.5990, huber: 1.2219, swd: 1.6812, target_std: 6.3953
    Epoch [2/50], Val Losses: mse: 9.7811, mae: 1.6772, huber: 1.3119, swd: 1.2949, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.5718, mae: 1.8507, huber: 1.4700, swd: 1.5911, target_std: 4.7741
      Epoch 2 composite train-obj: 1.221937
            Val objective improved 1.3753 → 1.3119, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7514, mae: 1.5663, huber: 1.1918, swd: 1.6400, target_std: 6.3929
    Epoch [3/50], Val Losses: mse: 9.5097, mae: 1.6530, huber: 1.2880, swd: 1.2453, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.5361, mae: 1.8382, huber: 1.4585, swd: 1.6073, target_std: 4.7741
      Epoch 3 composite train-obj: 1.191807
            Val objective improved 1.3119 → 1.2880, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.6596, mae: 1.5519, huber: 1.1783, swd: 1.6088, target_std: 6.4043
    Epoch [4/50], Val Losses: mse: 9.3531, mae: 1.6444, huber: 1.2785, swd: 1.3007, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.6116, mae: 1.8491, huber: 1.4701, swd: 1.8540, target_std: 4.7741
      Epoch 4 composite train-obj: 1.178319
            Val objective improved 1.2880 → 1.2785, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.6576, mae: 1.5488, huber: 1.1757, swd: 1.6253, target_std: 6.3932
    Epoch [5/50], Val Losses: mse: 9.2582, mae: 1.6269, huber: 1.2625, swd: 1.1545, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.5686, mae: 1.8321, huber: 1.4533, swd: 1.6178, target_std: 4.7741
      Epoch 5 composite train-obj: 1.175745
            Val objective improved 1.2785 → 1.2625, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.6345, mae: 1.5438, huber: 1.1710, swd: 1.6283, target_std: 6.3977
    Epoch [6/50], Val Losses: mse: 9.2471, mae: 1.6234, huber: 1.2599, swd: 1.2263, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.5548, mae: 1.8283, huber: 1.4494, swd: 1.7064, target_std: 4.7741
      Epoch 6 composite train-obj: 1.171034
            Val objective improved 1.2625 → 1.2599, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.6263, mae: 1.5425, huber: 1.1699, swd: 1.6328, target_std: 6.3943
    Epoch [7/50], Val Losses: mse: 9.2842, mae: 1.6336, huber: 1.2691, swd: 1.2487, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.5861, mae: 1.8305, huber: 1.4518, swd: 1.6716, target_std: 4.7741
      Epoch 7 composite train-obj: 1.169864
            No improvement (1.2691), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.5892, mae: 1.5370, huber: 1.1646, swd: 1.5949, target_std: 6.3875
    Epoch [8/50], Val Losses: mse: 9.5568, mae: 1.6573, huber: 1.2926, swd: 1.4423, target_std: 4.3900
    Epoch [8/50], Test Losses: mse: 10.4683, mae: 1.8226, huber: 1.4418, swd: 1.6674, target_std: 4.7741
      Epoch 8 composite train-obj: 1.164626
            No improvement (1.2926), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.5494, mae: 1.5320, huber: 1.1598, swd: 1.5940, target_std: 6.3887
    Epoch [9/50], Val Losses: mse: 9.3769, mae: 1.6310, huber: 1.2677, swd: 1.3057, target_std: 4.3900
    Epoch [9/50], Test Losses: mse: 10.4542, mae: 1.8188, huber: 1.4380, swd: 1.6582, target_std: 4.7741
      Epoch 9 composite train-obj: 1.159812
            No improvement (1.2677), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.5707, mae: 1.5315, huber: 1.1598, swd: 1.6048, target_std: 6.3974
    Epoch [10/50], Val Losses: mse: 9.3887, mae: 1.6354, huber: 1.2724, swd: 1.3748, target_std: 4.3900
    Epoch [10/50], Test Losses: mse: 10.4284, mae: 1.8096, huber: 1.4321, swd: 1.5970, target_std: 4.7741
      Epoch 10 composite train-obj: 1.159783
            No improvement (1.2724), counter 4/5
    Epoch [11/50], Train Losses: mse: 6.5481, mae: 1.5282, huber: 1.1565, swd: 1.5993, target_std: 6.3948
    Epoch [11/50], Val Losses: mse: 9.2854, mae: 1.6213, huber: 1.2583, swd: 1.2453, target_std: 4.3900
    Epoch [11/50], Test Losses: mse: 10.4665, mae: 1.8096, huber: 1.4325, swd: 1.5820, target_std: 4.7741
      Epoch 11 composite train-obj: 1.156537
            Val objective improved 1.2599 → 1.2583, saving checkpoint.
    Epoch [12/50], Train Losses: mse: 6.5565, mae: 1.5307, huber: 1.1588, swd: 1.6021, target_std: 6.3934
    Epoch [12/50], Val Losses: mse: 9.1566, mae: 1.6155, huber: 1.2512, swd: 1.0932, target_std: 4.3900
    Epoch [12/50], Test Losses: mse: 10.6116, mae: 1.8351, huber: 1.4513, swd: 1.5118, target_std: 4.7741
      Epoch 12 composite train-obj: 1.158802
            Val objective improved 1.2583 → 1.2512, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 6.5457, mae: 1.5290, huber: 1.1569, swd: 1.5969, target_std: 6.3984
    Epoch [13/50], Val Losses: mse: 9.2849, mae: 1.6246, huber: 1.2610, swd: 1.2497, target_std: 4.3900
    Epoch [13/50], Test Losses: mse: 10.4504, mae: 1.8115, huber: 1.4324, swd: 1.5634, target_std: 4.7741
      Epoch 13 composite train-obj: 1.156859
            No improvement (1.2610), counter 1/5
    Epoch [14/50], Train Losses: mse: 6.5216, mae: 1.5240, huber: 1.1527, swd: 1.5846, target_std: 6.3946
    Epoch [14/50], Val Losses: mse: 9.4382, mae: 1.6330, huber: 1.2704, swd: 1.3200, target_std: 4.3900
    Epoch [14/50], Test Losses: mse: 10.4145, mae: 1.8036, huber: 1.4267, swd: 1.5636, target_std: 4.7741
      Epoch 14 composite train-obj: 1.152699
            No improvement (1.2704), counter 2/5
    Epoch [15/50], Train Losses: mse: 6.5094, mae: 1.5232, huber: 1.1518, swd: 1.5812, target_std: 6.3958
    Epoch [15/50], Val Losses: mse: 9.4038, mae: 1.6373, huber: 1.2733, swd: 1.3459, target_std: 4.3900
    Epoch [15/50], Test Losses: mse: 10.4874, mae: 1.8170, huber: 1.4395, swd: 1.6631, target_std: 4.7741
      Epoch 15 composite train-obj: 1.151843
            No improvement (1.2733), counter 3/5
    Epoch [16/50], Train Losses: mse: 6.5632, mae: 1.5306, huber: 1.1590, swd: 1.6175, target_std: 6.3906
    Epoch [16/50], Val Losses: mse: 9.5785, mae: 1.6601, huber: 1.2945, swd: 1.4841, target_std: 4.3900
    Epoch [16/50], Test Losses: mse: 10.3871, mae: 1.8107, huber: 1.4321, swd: 1.6484, target_std: 4.7741
      Epoch 16 composite train-obj: 1.159000
            No improvement (1.2945), counter 4/5
    Epoch [17/50], Train Losses: mse: 6.5478, mae: 1.5267, huber: 1.1553, swd: 1.5893, target_std: 6.3898
    Epoch [17/50], Val Losses: mse: 9.3092, mae: 1.6293, huber: 1.2659, swd: 1.2798, target_std: 4.3900
    Epoch [17/50], Test Losses: mse: 10.4814, mae: 1.8117, huber: 1.4358, swd: 1.5868, target_std: 4.7741
      Epoch 17 composite train-obj: 1.155328
    Epoch [17/50], Test Losses: mse: 10.6116, mae: 1.8351, huber: 1.4513, swd: 1.5118, target_std: 4.7741
    Best round's Test MSE: 10.6116, MAE: 1.8351, SWD: 1.5118
    Best round's Validation MSE: 9.1566, MAE: 1.6155
    Best round's Test verification MSE : 10.6116, MAE: 1.8351, SWD: 1.5118
    Time taken: 23.08 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.1770, mae: 1.9532, huber: 1.5602, swd: 2.3262, target_std: 6.3879
    Epoch [1/50], Val Losses: mse: 10.0291, mae: 1.7239, huber: 1.3541, swd: 1.2784, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.8600, mae: 1.9073, huber: 1.5244, swd: 1.7002, target_std: 4.7741
      Epoch 1 composite train-obj: 1.560152
            Val objective improved inf → 1.3541, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9307, mae: 1.5984, huber: 1.2213, swd: 1.6625, target_std: 6.3904
    Epoch [2/50], Val Losses: mse: 9.5900, mae: 1.6591, huber: 1.2937, swd: 1.1532, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.5942, mae: 1.8526, huber: 1.4709, swd: 1.5443, target_std: 4.7741
      Epoch 2 composite train-obj: 1.221320
            Val objective improved 1.3541 → 1.2937, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7399, mae: 1.5655, huber: 1.1909, swd: 1.6317, target_std: 6.3971
    Epoch [3/50], Val Losses: mse: 9.6885, mae: 1.6645, huber: 1.2996, swd: 1.1911, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.5303, mae: 1.8385, huber: 1.4569, swd: 1.4249, target_std: 4.7741
      Epoch 3 composite train-obj: 1.190887
            No improvement (1.2996), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.6610, mae: 1.5518, huber: 1.1783, swd: 1.6076, target_std: 6.4010
    Epoch [4/50], Val Losses: mse: 9.4113, mae: 1.6411, huber: 1.2775, swd: 1.1172, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.5620, mae: 1.8302, huber: 1.4514, swd: 1.4300, target_std: 4.7741
      Epoch 4 composite train-obj: 1.178333
            Val objective improved 1.2937 → 1.2775, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.6478, mae: 1.5470, huber: 1.1741, swd: 1.6102, target_std: 6.3927
    Epoch [5/50], Val Losses: mse: 9.4288, mae: 1.6388, huber: 1.2749, swd: 1.2038, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.5450, mae: 1.8317, huber: 1.4515, swd: 1.4972, target_std: 4.7741
      Epoch 5 composite train-obj: 1.174099
            Val objective improved 1.2775 → 1.2749, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.6484, mae: 1.5444, huber: 1.1717, swd: 1.6277, target_std: 6.3898
    Epoch [6/50], Val Losses: mse: 9.4409, mae: 1.6395, huber: 1.2761, swd: 1.3088, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.5188, mae: 1.8236, huber: 1.4444, swd: 1.4902, target_std: 4.7741
      Epoch 6 composite train-obj: 1.171706
            No improvement (1.2761), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.6071, mae: 1.5391, huber: 1.1668, swd: 1.6029, target_std: 6.3868
    Epoch [7/50], Val Losses: mse: 9.5520, mae: 1.6460, huber: 1.2826, swd: 1.3254, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.4275, mae: 1.8143, huber: 1.4354, swd: 1.5047, target_std: 4.7741
      Epoch 7 composite train-obj: 1.166772
            No improvement (1.2826), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.5775, mae: 1.5354, huber: 1.1632, swd: 1.5927, target_std: 6.3982
    Epoch [8/50], Val Losses: mse: 9.4876, mae: 1.6423, huber: 1.2791, swd: 1.3811, target_std: 4.3900
    Epoch [8/50], Test Losses: mse: 10.4507, mae: 1.8115, huber: 1.4340, swd: 1.5467, target_std: 4.7741
      Epoch 8 composite train-obj: 1.163241
            No improvement (1.2791), counter 3/5
    Epoch [9/50], Train Losses: mse: 6.5565, mae: 1.5318, huber: 1.1596, swd: 1.5880, target_std: 6.3897
    Epoch [9/50], Val Losses: mse: 9.2933, mae: 1.6171, huber: 1.2548, swd: 1.1457, target_std: 4.3900
    Epoch [9/50], Test Losses: mse: 10.5036, mae: 1.8183, huber: 1.4399, swd: 1.4713, target_std: 4.7741
      Epoch 9 composite train-obj: 1.159601
            Val objective improved 1.2749 → 1.2548, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 6.5750, mae: 1.5327, huber: 1.1610, swd: 1.5842, target_std: 6.3884
    Epoch [10/50], Val Losses: mse: 9.2910, mae: 1.6263, huber: 1.2628, swd: 1.3093, target_std: 4.3900
    Epoch [10/50], Test Losses: mse: 10.4814, mae: 1.8148, huber: 1.4364, swd: 1.5713, target_std: 4.7741
      Epoch 10 composite train-obj: 1.161021
            No improvement (1.2628), counter 1/5
    Epoch [11/50], Train Losses: mse: 6.5548, mae: 1.5297, huber: 1.1580, swd: 1.5833, target_std: 6.4006
    Epoch [11/50], Val Losses: mse: 9.4740, mae: 1.6395, huber: 1.2773, swd: 1.4228, target_std: 4.3900
    Epoch [11/50], Test Losses: mse: 10.4144, mae: 1.8071, huber: 1.4307, swd: 1.5505, target_std: 4.7741
      Epoch 11 composite train-obj: 1.158009
            No improvement (1.2773), counter 2/5
    Epoch [12/50], Train Losses: mse: 6.5437, mae: 1.5276, huber: 1.1561, swd: 1.5862, target_std: 6.3911
    Epoch [12/50], Val Losses: mse: 9.3541, mae: 1.6305, huber: 1.2670, swd: 1.2883, target_std: 4.3900
    Epoch [12/50], Test Losses: mse: 10.4623, mae: 1.8134, huber: 1.4348, swd: 1.5196, target_std: 4.7741
      Epoch 12 composite train-obj: 1.156146
            No improvement (1.2670), counter 3/5
    Epoch [13/50], Train Losses: mse: 6.5655, mae: 1.5303, huber: 1.1585, swd: 1.5749, target_std: 6.3927
    Epoch [13/50], Val Losses: mse: 9.5734, mae: 1.6539, huber: 1.2903, swd: 1.5748, target_std: 4.3900
    Epoch [13/50], Test Losses: mse: 10.3916, mae: 1.8046, huber: 1.4281, swd: 1.6042, target_std: 4.7741
      Epoch 13 composite train-obj: 1.158508
            No improvement (1.2903), counter 4/5
    Epoch [14/50], Train Losses: mse: 6.5215, mae: 1.5260, huber: 1.1543, swd: 1.5785, target_std: 6.3974
    Epoch [14/50], Val Losses: mse: 9.2767, mae: 1.6250, huber: 1.2618, swd: 1.2516, target_std: 4.3900
    Epoch [14/50], Test Losses: mse: 10.5115, mae: 1.8250, huber: 1.4434, swd: 1.5269, target_std: 4.7741
      Epoch 14 composite train-obj: 1.154323
    Epoch [14/50], Test Losses: mse: 10.5036, mae: 1.8183, huber: 1.4399, swd: 1.4713, target_std: 4.7741
    Best round's Test MSE: 10.5036, MAE: 1.8183, SWD: 1.4713
    Best round's Validation MSE: 9.2933, MAE: 1.6171
    Best round's Test verification MSE : 10.5036, MAE: 1.8183, SWD: 1.4713
    Time taken: 19.09 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.1144, mae: 1.9488, huber: 1.5559, swd: 2.0131, target_std: 6.3981
    Epoch [1/50], Val Losses: mse: 10.2538, mae: 1.7379, huber: 1.3690, swd: 1.1813, target_std: 4.3900
    Epoch [1/50], Test Losses: mse: 10.8128, mae: 1.9010, huber: 1.5169, swd: 1.4391, target_std: 4.7741
      Epoch 1 composite train-obj: 1.555866
            Val objective improved inf → 1.3690, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9160, mae: 1.5967, huber: 1.2196, swd: 1.4930, target_std: 6.3955
    Epoch [2/50], Val Losses: mse: 9.8625, mae: 1.6962, huber: 1.3290, swd: 1.3059, target_std: 4.3900
    Epoch [2/50], Test Losses: mse: 10.5752, mae: 1.8546, huber: 1.4732, swd: 1.5603, target_std: 4.7741
      Epoch 2 composite train-obj: 1.219557
            Val objective improved 1.3690 → 1.3290, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7275, mae: 1.5653, huber: 1.1906, swd: 1.4680, target_std: 6.3938
    Epoch [3/50], Val Losses: mse: 9.4688, mae: 1.6527, huber: 1.2874, swd: 1.1159, target_std: 4.3900
    Epoch [3/50], Test Losses: mse: 10.6038, mae: 1.8496, huber: 1.4694, swd: 1.5714, target_std: 4.7741
      Epoch 3 composite train-obj: 1.190627
            Val objective improved 1.3290 → 1.2874, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.6751, mae: 1.5534, huber: 1.1800, swd: 1.4593, target_std: 6.3950
    Epoch [4/50], Val Losses: mse: 9.7532, mae: 1.6739, huber: 1.3086, swd: 1.4122, target_std: 4.3900
    Epoch [4/50], Test Losses: mse: 10.4958, mae: 1.8303, huber: 1.4522, swd: 1.6128, target_std: 4.7741
      Epoch 4 composite train-obj: 1.180008
            No improvement (1.3086), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.6131, mae: 1.5432, huber: 1.1705, swd: 1.4466, target_std: 6.3989
    Epoch [5/50], Val Losses: mse: 9.4931, mae: 1.6404, huber: 1.2766, swd: 1.1317, target_std: 4.3900
    Epoch [5/50], Test Losses: mse: 10.5156, mae: 1.8230, huber: 1.4445, swd: 1.4438, target_std: 4.7741
      Epoch 5 composite train-obj: 1.170533
            Val objective improved 1.2874 → 1.2766, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.6070, mae: 1.5407, huber: 1.1683, swd: 1.4436, target_std: 6.3975
    Epoch [6/50], Val Losses: mse: 9.4547, mae: 1.6431, huber: 1.2789, swd: 1.1723, target_std: 4.3900
    Epoch [6/50], Test Losses: mse: 10.4710, mae: 1.8208, huber: 1.4413, swd: 1.4278, target_std: 4.7741
      Epoch 6 composite train-obj: 1.168325
            No improvement (1.2789), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.6095, mae: 1.5384, huber: 1.1662, swd: 1.4495, target_std: 6.3970
    Epoch [7/50], Val Losses: mse: 9.5183, mae: 1.6427, huber: 1.2789, swd: 1.1998, target_std: 4.3900
    Epoch [7/50], Test Losses: mse: 10.4367, mae: 1.8098, huber: 1.4326, swd: 1.4233, target_std: 4.7741
      Epoch 7 composite train-obj: 1.166198
            No improvement (1.2789), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.5924, mae: 1.5359, huber: 1.1639, swd: 1.4454, target_std: 6.3937
    Epoch [8/50], Val Losses: mse: 9.7930, mae: 1.6682, huber: 1.3051, swd: 1.3583, target_std: 4.3900
    Epoch [8/50], Test Losses: mse: 10.4156, mae: 1.8108, huber: 1.4321, swd: 1.4622, target_std: 4.7741
      Epoch 8 composite train-obj: 1.163878
            No improvement (1.3051), counter 3/5
    Epoch [9/50], Train Losses: mse: 6.5586, mae: 1.5316, huber: 1.1598, swd: 1.4236, target_std: 6.3943
    Epoch [9/50], Val Losses: mse: 9.3963, mae: 1.6308, huber: 1.2680, swd: 1.1589, target_std: 4.3900
    Epoch [9/50], Test Losses: mse: 10.4486, mae: 1.8133, huber: 1.4342, swd: 1.4477, target_std: 4.7741
      Epoch 9 composite train-obj: 1.159764
            Val objective improved 1.2766 → 1.2680, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 6.5505, mae: 1.5312, huber: 1.1592, swd: 1.4269, target_std: 6.3962
    Epoch [10/50], Val Losses: mse: 9.2445, mae: 1.6254, huber: 1.2608, swd: 1.2257, target_std: 4.3900
    Epoch [10/50], Test Losses: mse: 10.4988, mae: 1.8155, huber: 1.4393, swd: 1.5913, target_std: 4.7741
      Epoch 10 composite train-obj: 1.159221
            Val objective improved 1.2680 → 1.2608, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 6.5577, mae: 1.5302, huber: 1.1584, swd: 1.4279, target_std: 6.3921
    Epoch [11/50], Val Losses: mse: 9.4327, mae: 1.6425, huber: 1.2780, swd: 1.3110, target_std: 4.3900
    Epoch [11/50], Test Losses: mse: 10.4353, mae: 1.8159, huber: 1.4372, swd: 1.6081, target_std: 4.7741
      Epoch 11 composite train-obj: 1.158353
            No improvement (1.2780), counter 1/5
    Epoch [12/50], Train Losses: mse: 6.5333, mae: 1.5278, huber: 1.1562, swd: 1.4283, target_std: 6.4063
    Epoch [12/50], Val Losses: mse: 9.5169, mae: 1.6443, huber: 1.2810, swd: 1.2460, target_std: 4.3900
    Epoch [12/50], Test Losses: mse: 10.4277, mae: 1.8113, huber: 1.4334, swd: 1.4749, target_std: 4.7741
      Epoch 12 composite train-obj: 1.156192
            No improvement (1.2810), counter 2/5
    Epoch [13/50], Train Losses: mse: 6.5557, mae: 1.5280, huber: 1.1568, swd: 1.4254, target_std: 6.3935
    Epoch [13/50], Val Losses: mse: 9.3542, mae: 1.6323, huber: 1.2694, swd: 1.3525, target_std: 4.3900
    Epoch [13/50], Test Losses: mse: 10.4367, mae: 1.8109, huber: 1.4328, swd: 1.6047, target_std: 4.7741
      Epoch 13 composite train-obj: 1.156770
            No improvement (1.2694), counter 3/5
    Epoch [14/50], Train Losses: mse: 6.5435, mae: 1.5275, huber: 1.1558, swd: 1.4246, target_std: 6.4030
    Epoch [14/50], Val Losses: mse: 9.4588, mae: 1.6369, huber: 1.2736, swd: 1.2227, target_std: 4.3900
    Epoch [14/50], Test Losses: mse: 10.4860, mae: 1.8184, huber: 1.4388, swd: 1.4872, target_std: 4.7741
      Epoch 14 composite train-obj: 1.155820
            No improvement (1.2736), counter 4/5
    Epoch [15/50], Train Losses: mse: 6.5400, mae: 1.5273, huber: 1.1552, swd: 1.4291, target_std: 6.3898
    Epoch [15/50], Val Losses: mse: 9.3425, mae: 1.6279, huber: 1.2646, swd: 1.1401, target_std: 4.3900
    Epoch [15/50], Test Losses: mse: 10.4821, mae: 1.8157, huber: 1.4357, swd: 1.4266, target_std: 4.7741
      Epoch 15 composite train-obj: 1.155225
    Epoch [15/50], Test Losses: mse: 10.4988, mae: 1.8155, huber: 1.4393, swd: 1.5913, target_std: 4.7741
    Best round's Test MSE: 10.4988, MAE: 1.8155, SWD: 1.5913
    Best round's Validation MSE: 9.2445, MAE: 1.6254
    Best round's Test verification MSE : 10.4988, MAE: 1.8155, SWD: 1.5913
    Time taken: 20.21 seconds
    
    ==================================================
    Experiment Summary (DLinear_etth1_seq336_pred196_20250503_1956)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5380 ± 0.0521
      mae: 1.8230 ± 0.0086
      huber: 1.4435 ± 0.0055
      swd: 1.5248 ± 0.0498
      target_std: 4.7741 ± 0.0000
      count: 10.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.2315 ± 0.0566
      mae: 1.6193 ± 0.0043
      huber: 1.2556 ± 0.0040
      swd: 1.1549 ± 0.0545
      target_std: 4.3900 ± 0.0000
      count: 10.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 62.42 seconds
    
    Experiment complete: DLinear_etth1_seq336_pred196_20250503_1956
    Model: DLinear
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 91
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 91
    Validation Batches: 9
    Test Batches: 22
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.2378, mae: 2.0078, huber: 1.6099, swd: 2.3177, target_std: 6.3685
    Epoch [1/50], Val Losses: mse: 10.0096, mae: 1.7306, huber: 1.3576, swd: 1.2833, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 11.4898, mae: 2.0416, huber: 1.6428, swd: 1.8463, target_std: 4.8164
      Epoch 1 composite train-obj: 1.609938
            Val objective improved inf → 1.3576, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.4747, mae: 1.6918, huber: 1.3070, swd: 1.7258, target_std: 6.3662
    Epoch [2/50], Val Losses: mse: 9.8530, mae: 1.6917, huber: 1.3233, swd: 1.2686, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.1527, mae: 1.9801, huber: 1.5900, swd: 1.7992, target_std: 4.8164
      Epoch 2 composite train-obj: 1.307026
            Val objective improved 1.3576 → 1.3233, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2778, mae: 1.6624, huber: 1.2798, swd: 1.7069, target_std: 6.3876
    Epoch [3/50], Val Losses: mse: 9.6022, mae: 1.6590, huber: 1.2908, swd: 0.8603, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 11.2932, mae: 1.9811, huber: 1.5914, swd: 1.5740, target_std: 4.8164
      Epoch 3 composite train-obj: 1.279844
            Val objective improved 1.3233 → 1.2908, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.2709, mae: 1.6575, huber: 1.2756, swd: 1.6932, target_std: 6.3700
    Epoch [4/50], Val Losses: mse: 9.8634, mae: 1.7341, huber: 1.3574, swd: 1.5276, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.4277, mae: 2.0327, huber: 1.6371, swd: 2.2080, target_std: 4.8164
      Epoch 4 composite train-obj: 1.275575
            No improvement (1.3574), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.2334, mae: 1.6537, huber: 1.2710, swd: 1.7023, target_std: 6.3685
    Epoch [5/50], Val Losses: mse: 9.6916, mae: 1.6823, huber: 1.3124, swd: 1.3575, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.0763, mae: 1.9609, huber: 1.5703, swd: 1.8462, target_std: 4.8164
      Epoch 5 composite train-obj: 1.271018
            No improvement (1.3124), counter 2/5
    Epoch [6/50], Train Losses: mse: 7.1392, mae: 1.6371, huber: 1.2565, swd: 1.6678, target_std: 6.3718
    Epoch [6/50], Val Losses: mse: 9.6380, mae: 1.6622, huber: 1.2937, swd: 1.1536, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.0248, mae: 1.9475, huber: 1.5588, swd: 1.6519, target_std: 4.8164
      Epoch 6 composite train-obj: 1.256463
            No improvement (1.2937), counter 3/5
    Epoch [7/50], Train Losses: mse: 7.1479, mae: 1.6338, huber: 1.2540, swd: 1.6859, target_std: 6.3859
    Epoch [7/50], Val Losses: mse: 9.7695, mae: 1.6720, huber: 1.3042, swd: 1.1736, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.0480, mae: 1.9452, huber: 1.5583, swd: 1.6318, target_std: 4.8164
      Epoch 7 composite train-obj: 1.254001
            No improvement (1.3042), counter 4/5
    Epoch [8/50], Train Losses: mse: 7.1050, mae: 1.6319, huber: 1.2515, swd: 1.6641, target_std: 6.3702
    Epoch [8/50], Val Losses: mse: 9.9070, mae: 1.7006, huber: 1.3290, swd: 1.4825, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 11.0335, mae: 1.9603, huber: 1.5659, swd: 1.8328, target_std: 4.8164
      Epoch 8 composite train-obj: 1.251477
    Epoch [8/50], Test Losses: mse: 11.2932, mae: 1.9811, huber: 1.5914, swd: 1.5740, target_std: 4.8164
    Best round's Test MSE: 11.2932, MAE: 1.9811, SWD: 1.5740
    Best round's Validation MSE: 9.6022, MAE: 1.6590
    Best round's Test verification MSE : 11.2932, MAE: 1.9811, SWD: 1.5740
    Time taken: 11.59 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.5150, mae: 2.0254, huber: 1.6270, swd: 2.3963, target_std: 6.3928
    Epoch [1/50], Val Losses: mse: 9.8413, mae: 1.7130, huber: 1.3414, swd: 1.1204, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 11.6597, mae: 2.0445, huber: 1.6515, swd: 1.8105, target_std: 4.8164
      Epoch 1 composite train-obj: 1.627023
            Val objective improved inf → 1.3414, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.4892, mae: 1.6942, huber: 1.3096, swd: 1.7648, target_std: 6.3825
    Epoch [2/50], Val Losses: mse: 9.5732, mae: 1.6651, huber: 1.2969, swd: 0.9775, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.3018, mae: 1.9904, huber: 1.6001, swd: 1.7126, target_std: 4.8164
      Epoch 2 composite train-obj: 1.309578
            Val objective improved 1.3414 → 1.2969, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2942, mae: 1.6648, huber: 1.2818, swd: 1.7239, target_std: 6.3704
    Epoch [3/50], Val Losses: mse: 9.5639, mae: 1.6650, huber: 1.2961, swd: 1.2684, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 11.1635, mae: 1.9800, huber: 1.5847, swd: 1.8639, target_std: 4.8164
      Epoch 3 composite train-obj: 1.281830
            Val objective improved 1.2969 → 1.2961, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.1749, mae: 1.6459, huber: 1.2644, swd: 1.7059, target_std: 6.3695
    Epoch [4/50], Val Losses: mse: 10.0091, mae: 1.7020, huber: 1.3322, swd: 1.3230, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.0897, mae: 1.9669, huber: 1.5759, swd: 1.7763, target_std: 4.8164
      Epoch 4 composite train-obj: 1.264440
            No improvement (1.3322), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.1855, mae: 1.6442, huber: 1.2632, swd: 1.7022, target_std: 6.3894
    Epoch [5/50], Val Losses: mse: 9.4279, mae: 1.6423, huber: 1.2739, swd: 0.9556, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.2078, mae: 1.9715, huber: 1.5771, swd: 1.5725, target_std: 4.8164
      Epoch 5 composite train-obj: 1.263163
            Val objective improved 1.2961 → 1.2739, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 7.1931, mae: 1.6432, huber: 1.2623, swd: 1.7267, target_std: 6.3795
    Epoch [6/50], Val Losses: mse: 9.7107, mae: 1.6667, huber: 1.2992, swd: 1.1433, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.0562, mae: 1.9495, huber: 1.5605, swd: 1.6330, target_std: 4.8164
      Epoch 6 composite train-obj: 1.262252
            No improvement (1.2992), counter 1/5
    Epoch [7/50], Train Losses: mse: 7.1457, mae: 1.6362, huber: 1.2555, swd: 1.6919, target_std: 6.3725
    Epoch [7/50], Val Losses: mse: 9.4089, mae: 1.6432, huber: 1.2752, swd: 1.0076, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.2040, mae: 1.9677, huber: 1.5726, swd: 1.6170, target_std: 4.8164
      Epoch 7 composite train-obj: 1.255454
            No improvement (1.2752), counter 2/5
    Epoch [8/50], Train Losses: mse: 7.1440, mae: 1.6333, huber: 1.2529, swd: 1.7053, target_std: 6.3681
    Epoch [8/50], Val Losses: mse: 9.6476, mae: 1.6484, huber: 1.2831, swd: 1.0590, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 10.9430, mae: 1.9284, huber: 1.5417, swd: 1.4932, target_std: 4.8164
      Epoch 8 composite train-obj: 1.252920
            No improvement (1.2831), counter 3/5
    Epoch [9/50], Train Losses: mse: 7.0517, mae: 1.6237, huber: 1.2438, swd: 1.6768, target_std: 6.3830
    Epoch [9/50], Val Losses: mse: 9.6194, mae: 1.6621, huber: 1.2922, swd: 1.0480, target_std: 4.3610
    Epoch [9/50], Test Losses: mse: 11.1231, mae: 1.9619, huber: 1.5704, swd: 1.6769, target_std: 4.8164
      Epoch 9 composite train-obj: 1.243834
            No improvement (1.2922), counter 4/5
    Epoch [10/50], Train Losses: mse: 7.1251, mae: 1.6340, huber: 1.2531, swd: 1.7094, target_std: 6.3550
    Epoch [10/50], Val Losses: mse: 9.6312, mae: 1.6687, huber: 1.2988, swd: 1.3196, target_std: 4.3610
    Epoch [10/50], Test Losses: mse: 11.0787, mae: 1.9633, huber: 1.5685, swd: 1.8195, target_std: 4.8164
      Epoch 10 composite train-obj: 1.253146
    Epoch [10/50], Test Losses: mse: 11.2078, mae: 1.9715, huber: 1.5771, swd: 1.5725, target_std: 4.8164
    Best round's Test MSE: 11.2078, MAE: 1.9715, SWD: 1.5725
    Best round's Validation MSE: 9.4279, MAE: 1.6423
    Best round's Test verification MSE : 11.2078, MAE: 1.9715, SWD: 1.5725
    Time taken: 12.40 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 11.5903, mae: 2.0214, huber: 1.6235, swd: 2.3345, target_std: 6.3594
    Epoch [1/50], Val Losses: mse: 9.7707, mae: 1.7030, huber: 1.3323, swd: 1.0724, target_std: 4.3610
    Epoch [1/50], Test Losses: mse: 11.6525, mae: 2.0475, huber: 1.6532, swd: 1.9099, target_std: 4.8164
      Epoch 1 composite train-obj: 1.623511
            Val objective improved inf → 1.3323, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.4742, mae: 1.6895, huber: 1.3054, swd: 1.6995, target_std: 6.3615
    Epoch [2/50], Val Losses: mse: 9.6868, mae: 1.6726, huber: 1.3043, swd: 1.0875, target_std: 4.3610
    Epoch [2/50], Test Losses: mse: 11.1923, mae: 1.9749, huber: 1.5846, swd: 1.7112, target_std: 4.8164
      Epoch 2 composite train-obj: 1.305392
            Val objective improved 1.3323 → 1.3043, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2743, mae: 1.6604, huber: 1.2778, swd: 1.6565, target_std: 6.3714
    Epoch [3/50], Val Losses: mse: 9.7991, mae: 1.6916, huber: 1.3205, swd: 1.1920, target_std: 4.3610
    Epoch [3/50], Test Losses: mse: 11.2783, mae: 1.9884, huber: 1.6000, swd: 1.8791, target_std: 4.8164
      Epoch 3 composite train-obj: 1.277780
            No improvement (1.3205), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.2213, mae: 1.6533, huber: 1.2709, swd: 1.6537, target_std: 6.3906
    Epoch [4/50], Val Losses: mse: 9.5655, mae: 1.6592, huber: 1.2907, swd: 1.0057, target_std: 4.3610
    Epoch [4/50], Test Losses: mse: 11.3135, mae: 1.9847, huber: 1.5922, swd: 1.7342, target_std: 4.8164
      Epoch 4 composite train-obj: 1.270913
            Val objective improved 1.3043 → 1.2907, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 7.1757, mae: 1.6417, huber: 1.2608, swd: 1.6359, target_std: 6.3687
    Epoch [5/50], Val Losses: mse: 9.5344, mae: 1.6475, huber: 1.2812, swd: 1.0823, target_std: 4.3610
    Epoch [5/50], Test Losses: mse: 11.1023, mae: 1.9551, huber: 1.5653, swd: 1.7559, target_std: 4.8164
      Epoch 5 composite train-obj: 1.260810
            Val objective improved 1.2907 → 1.2812, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 7.1223, mae: 1.6339, huber: 1.2536, swd: 1.6262, target_std: 6.3604
    Epoch [6/50], Val Losses: mse: 9.4945, mae: 1.6478, huber: 1.2807, swd: 1.2171, target_std: 4.3610
    Epoch [6/50], Test Losses: mse: 11.0993, mae: 1.9590, huber: 1.5661, swd: 1.8213, target_std: 4.8164
      Epoch 6 composite train-obj: 1.253588
            Val objective improved 1.2812 → 1.2807, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 7.1602, mae: 1.6375, huber: 1.2568, swd: 1.6478, target_std: 6.3978
    Epoch [7/50], Val Losses: mse: 9.6677, mae: 1.7007, huber: 1.3269, swd: 1.3006, target_std: 4.3610
    Epoch [7/50], Test Losses: mse: 11.6862, mae: 2.0453, huber: 1.6517, swd: 2.2296, target_std: 4.8164
      Epoch 7 composite train-obj: 1.256846
            No improvement (1.3269), counter 1/5
    Epoch [8/50], Train Losses: mse: 7.2816, mae: 1.6522, huber: 1.2704, swd: 1.7219, target_std: 6.3805
    Epoch [8/50], Val Losses: mse: 9.2900, mae: 1.6218, huber: 1.2557, swd: 0.9511, target_std: 4.3610
    Epoch [8/50], Test Losses: mse: 11.1978, mae: 1.9597, huber: 1.5686, swd: 1.7089, target_std: 4.8164
      Epoch 8 composite train-obj: 1.270380
            Val objective improved 1.2807 → 1.2557, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 7.1385, mae: 1.6349, huber: 1.2544, swd: 1.6410, target_std: 6.3868
    Epoch [9/50], Val Losses: mse: 9.4443, mae: 1.6424, huber: 1.2760, swd: 1.1461, target_std: 4.3610
    Epoch [9/50], Test Losses: mse: 11.1965, mae: 1.9548, huber: 1.5687, swd: 1.8704, target_std: 4.8164
      Epoch 9 composite train-obj: 1.254382
            No improvement (1.2760), counter 1/5
    Epoch [10/50], Train Losses: mse: 7.1055, mae: 1.6301, huber: 1.2501, swd: 1.6008, target_std: 6.3654
    Epoch [10/50], Val Losses: mse: 9.8922, mae: 1.6909, huber: 1.3226, swd: 1.4656, target_std: 4.3610
    Epoch [10/50], Test Losses: mse: 10.9673, mae: 1.9410, huber: 1.5518, swd: 1.7831, target_std: 4.8164
      Epoch 10 composite train-obj: 1.250098
            No improvement (1.3226), counter 2/5
    Epoch [11/50], Train Losses: mse: 7.1340, mae: 1.6332, huber: 1.2532, swd: 1.6407, target_std: 6.3977
    Epoch [11/50], Val Losses: mse: 9.4559, mae: 1.6411, huber: 1.2737, swd: 1.0279, target_std: 4.3610
    Epoch [11/50], Test Losses: mse: 11.1729, mae: 1.9576, huber: 1.5676, swd: 1.6611, target_std: 4.8164
      Epoch 11 composite train-obj: 1.253239
            No improvement (1.2737), counter 3/5
    Epoch [12/50], Train Losses: mse: 7.0799, mae: 1.6241, huber: 1.2445, swd: 1.5944, target_std: 6.3657
    Epoch [12/50], Val Losses: mse: 9.4893, mae: 1.6565, huber: 1.2868, swd: 1.2328, target_std: 4.3610
    Epoch [12/50], Test Losses: mse: 11.0524, mae: 1.9472, huber: 1.5595, swd: 1.7886, target_std: 4.8164
      Epoch 12 composite train-obj: 1.244463
            No improvement (1.2868), counter 4/5
    Epoch [13/50], Train Losses: mse: 7.1157, mae: 1.6262, huber: 1.2467, swd: 1.6126, target_std: 6.3580
    Epoch [13/50], Val Losses: mse: 9.5478, mae: 1.6846, huber: 1.3110, swd: 1.3686, target_std: 4.3610
    Epoch [13/50], Test Losses: mse: 11.1599, mae: 1.9724, huber: 1.5791, swd: 2.0043, target_std: 4.8164
      Epoch 13 composite train-obj: 1.246693
    Epoch [13/50], Test Losses: mse: 11.1978, mae: 1.9597, huber: 1.5686, swd: 1.7089, target_std: 4.8164
    Best round's Test MSE: 11.1978, MAE: 1.9597, SWD: 1.7089
    Best round's Validation MSE: 9.2900, MAE: 1.6218
    Best round's Test verification MSE : 11.1978, MAE: 1.9597, SWD: 1.7089
    Time taken: 15.97 seconds
    
    ==================================================
    Experiment Summary (DLinear_etth1_seq336_pred336_20250503_1954)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.2329 ± 0.0428
      mae: 1.9708 ± 0.0088
      huber: 1.5790 ± 0.0094
      swd: 1.6184 ± 0.0640
      target_std: 4.8164 ± 0.0000
      count: 9.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.4401 ± 0.1277
      mae: 1.6410 ± 0.0152
      huber: 1.2735 ± 0.0143
      swd: 0.9223 ± 0.0439
      target_std: 4.3610 ± 0.0000
      count: 9.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 40.02 seconds
    
    Experiment complete: DLinear_etth1_seq336_pred336_20250503_1954
    Model: DLinear
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['etth1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('etth1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([12194, 7])
    Shape of validation data: torch.Size([1742, 7])
    Shape of testing data: torch.Size([3484, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([3484, 7]), torch.Size([3484, 7])
    Number of batches in train_loader: 88
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: etth1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 88
    Validation Batches: 6
    Test Batches: 19
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 12.7148, mae: 2.1840, huber: 1.7744, swd: 2.8599, target_std: 6.2855
    Epoch [1/50], Val Losses: mse: 10.1200, mae: 1.7773, huber: 1.4024, swd: 1.3431, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 13.0057, mae: 2.2852, huber: 1.8715, swd: 2.6697, target_std: 4.8721
      Epoch 1 composite train-obj: 1.774387
            Val objective improved inf → 1.4024, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.6018, mae: 1.8651, huber: 1.4668, swd: 2.2380, target_std: 6.2914
    Epoch [2/50], Val Losses: mse: 9.7999, mae: 1.7300, huber: 1.3564, swd: 1.2097, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 12.5019, mae: 2.2187, huber: 1.8056, swd: 2.4112, target_std: 4.8721
      Epoch 2 composite train-obj: 1.466775
            Val objective improved 1.4024 → 1.3564, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.3884, mae: 1.8345, huber: 1.4384, swd: 2.1988, target_std: 6.2967
    Epoch [3/50], Val Losses: mse: 10.4234, mae: 1.8066, huber: 1.4306, swd: 1.6344, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.9251, mae: 2.2737, huber: 1.8633, swd: 3.0259, target_std: 4.8721
      Epoch 3 composite train-obj: 1.438379
            No improvement (1.4306), counter 1/5
    Epoch [4/50], Train Losses: mse: 8.4492, mae: 1.8371, huber: 1.4412, swd: 2.2260, target_std: 6.2942
    Epoch [4/50], Val Losses: mse: 9.9930, mae: 1.7427, huber: 1.3698, swd: 1.3501, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.5512, mae: 2.2041, huber: 1.7986, swd: 2.4954, target_std: 4.8721
      Epoch 4 composite train-obj: 1.441209
            No improvement (1.3698), counter 2/5
    Epoch [5/50], Train Losses: mse: 8.2814, mae: 1.8169, huber: 1.4221, swd: 2.1655, target_std: 6.2915
    Epoch [5/50], Val Losses: mse: 10.5818, mae: 1.8291, huber: 1.4495, swd: 1.8296, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.5930, mae: 2.2222, huber: 1.8177, swd: 2.8741, target_std: 4.8721
      Epoch 5 composite train-obj: 1.422088
            No improvement (1.4495), counter 3/5
    Epoch [6/50], Train Losses: mse: 8.2856, mae: 1.8161, huber: 1.4211, swd: 2.1793, target_std: 6.2857
    Epoch [6/50], Val Losses: mse: 9.9348, mae: 1.7418, huber: 1.3689, swd: 1.2830, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.4705, mae: 2.1982, huber: 1.7905, swd: 2.4753, target_std: 4.8721
      Epoch 6 composite train-obj: 1.421068
            No improvement (1.3689), counter 4/5
    Epoch [7/50], Train Losses: mse: 8.2112, mae: 1.8044, huber: 1.4106, swd: 2.1236, target_std: 6.2913
    Epoch [7/50], Val Losses: mse: 10.3143, mae: 1.7782, huber: 1.4027, swd: 1.5490, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.6101, mae: 2.2149, huber: 1.8086, swd: 2.7043, target_std: 4.8721
      Epoch 7 composite train-obj: 1.410642
    Epoch [7/50], Test Losses: mse: 12.5019, mae: 2.2187, huber: 1.8056, swd: 2.4112, target_std: 4.8721
    Best round's Test MSE: 12.5019, MAE: 2.2187, SWD: 2.4112
    Best round's Validation MSE: 9.7999, MAE: 1.7300
    Best round's Test verification MSE : 12.5019, MAE: 2.2187, SWD: 2.4112
    Time taken: 8.69 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 12.3750, mae: 2.1724, huber: 1.7628, swd: 2.5977, target_std: 6.2913
    Epoch [1/50], Val Losses: mse: 10.4711, mae: 1.8435, huber: 1.4597, swd: 1.3793, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.9537, mae: 2.2919, huber: 1.8747, swd: 2.5819, target_std: 4.8721
      Epoch 1 composite train-obj: 1.762804
            Val objective improved inf → 1.4597, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.5628, mae: 1.8642, huber: 1.4652, swd: 2.0690, target_std: 6.2851
    Epoch [2/50], Val Losses: mse: 10.1681, mae: 1.7721, huber: 1.3972, swd: 1.2587, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 12.9777, mae: 2.2757, huber: 1.8645, swd: 2.7500, target_std: 4.8721
      Epoch 2 composite train-obj: 1.465154
            Val objective improved 1.4597 → 1.3972, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.4606, mae: 1.8438, huber: 1.4469, swd: 2.0971, target_std: 6.3107
    Epoch [3/50], Val Losses: mse: 10.0912, mae: 1.7548, huber: 1.3814, swd: 1.0692, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.6359, mae: 2.2205, huber: 1.8163, swd: 2.3422, target_std: 4.8721
      Epoch 3 composite train-obj: 1.446903
            Val objective improved 1.3972 → 1.3814, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 8.3221, mae: 1.8246, huber: 1.4287, swd: 2.0316, target_std: 6.2845
    Epoch [4/50], Val Losses: mse: 9.6371, mae: 1.7234, huber: 1.3450, swd: 1.1050, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.5134, mae: 2.2102, huber: 1.7962, swd: 2.4323, target_std: 4.8721
      Epoch 4 composite train-obj: 1.428670
            Val objective improved 1.3814 → 1.3450, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 8.2841, mae: 1.8156, huber: 1.4208, swd: 2.0506, target_std: 6.3076
    Epoch [5/50], Val Losses: mse: 9.4776, mae: 1.6764, huber: 1.3094, swd: 0.8021, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.2262, mae: 2.1617, huber: 1.7542, swd: 1.8590, target_std: 4.8721
      Epoch 5 composite train-obj: 1.420778
            Val objective improved 1.3450 → 1.3094, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 8.3366, mae: 1.8187, huber: 1.4244, swd: 2.0793, target_std: 6.2855
    Epoch [6/50], Val Losses: mse: 10.1903, mae: 1.7513, huber: 1.3781, swd: 1.1977, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.2251, mae: 2.1657, huber: 1.7578, swd: 2.1752, target_std: 4.8721
      Epoch 6 composite train-obj: 1.424428
            No improvement (1.3781), counter 1/5
    Epoch [7/50], Train Losses: mse: 8.1717, mae: 1.7994, huber: 1.4060, swd: 1.9819, target_std: 6.2864
    Epoch [7/50], Val Losses: mse: 10.3223, mae: 1.7772, huber: 1.4034, swd: 1.5099, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.2528, mae: 2.1639, huber: 1.7632, swd: 2.3843, target_std: 4.8721
      Epoch 7 composite train-obj: 1.405984
            No improvement (1.4034), counter 2/5
    Epoch [8/50], Train Losses: mse: 8.1576, mae: 1.7946, huber: 1.4020, swd: 1.9848, target_std: 6.2883
    Epoch [8/50], Val Losses: mse: 10.2270, mae: 1.7568, huber: 1.3842, swd: 1.3120, target_std: 4.3728
    Epoch [8/50], Test Losses: mse: 12.2551, mae: 2.1684, huber: 1.7635, swd: 2.2014, target_std: 4.8721
      Epoch 8 composite train-obj: 1.401976
            No improvement (1.3842), counter 3/5
    Epoch [9/50], Train Losses: mse: 8.1658, mae: 1.7963, huber: 1.4034, swd: 1.9781, target_std: 6.2817
    Epoch [9/50], Val Losses: mse: 9.4228, mae: 1.6809, huber: 1.3115, swd: 0.9627, target_std: 4.3728
    Epoch [9/50], Test Losses: mse: 12.2013, mae: 2.1555, huber: 1.7483, swd: 2.0468, target_std: 4.8721
      Epoch 9 composite train-obj: 1.403417
            No improvement (1.3115), counter 4/5
    Epoch [10/50], Train Losses: mse: 8.1466, mae: 1.7943, huber: 1.4015, swd: 1.9560, target_std: 6.2849
    Epoch [10/50], Val Losses: mse: 10.0313, mae: 1.7589, huber: 1.3857, swd: 1.3833, target_std: 4.3728
    Epoch [10/50], Test Losses: mse: 12.2691, mae: 2.1767, huber: 1.7710, swd: 2.3143, target_std: 4.8721
      Epoch 10 composite train-obj: 1.401473
    Epoch [10/50], Test Losses: mse: 12.2262, mae: 2.1617, huber: 1.7542, swd: 1.8590, target_std: 4.8721
    Best round's Test MSE: 12.2262, MAE: 2.1617, SWD: 1.8590
    Best round's Validation MSE: 9.4776, MAE: 1.6764
    Best round's Test verification MSE : 12.2262, MAE: 2.1617, SWD: 1.8590
    Time taken: 13.27 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 12.4049, mae: 2.1725, huber: 1.7629, swd: 2.8958, target_std: 6.3092
    Epoch [1/50], Val Losses: mse: 10.3813, mae: 1.7953, huber: 1.4207, swd: 1.3330, target_std: 4.3728
    Epoch [1/50], Test Losses: mse: 12.8930, mae: 2.2682, huber: 1.8592, swd: 2.6046, target_std: 4.8721
      Epoch 1 composite train-obj: 1.762864
            Val objective improved inf → 1.4207, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 8.6084, mae: 1.8650, huber: 1.4668, swd: 2.3014, target_std: 6.2760
    Epoch [2/50], Val Losses: mse: 10.2385, mae: 1.7576, huber: 1.3867, swd: 1.4000, target_std: 4.3728
    Epoch [2/50], Test Losses: mse: 12.6100, mae: 2.2262, huber: 1.8179, swd: 2.7004, target_std: 4.8721
      Epoch 2 composite train-obj: 1.466776
            Val objective improved 1.4207 → 1.3867, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 8.3904, mae: 1.8355, huber: 1.4392, swd: 2.2664, target_std: 6.2825
    Epoch [3/50], Val Losses: mse: 10.5522, mae: 1.8735, huber: 1.4855, swd: 1.7639, target_std: 4.3728
    Epoch [3/50], Test Losses: mse: 12.6755, mae: 2.2495, huber: 1.8378, swd: 2.9188, target_std: 4.8721
      Epoch 3 composite train-obj: 1.439216
            No improvement (1.4855), counter 1/5
    Epoch [4/50], Train Losses: mse: 8.2906, mae: 1.8222, huber: 1.4262, swd: 2.2510, target_std: 6.2770
    Epoch [4/50], Val Losses: mse: 9.8530, mae: 1.7392, huber: 1.3627, swd: 1.3204, target_std: 4.3728
    Epoch [4/50], Test Losses: mse: 12.3837, mae: 2.1944, huber: 1.7838, swd: 2.4778, target_std: 4.8721
      Epoch 4 composite train-obj: 1.426173
            Val objective improved 1.3867 → 1.3627, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 8.2187, mae: 1.8082, huber: 1.4137, swd: 2.2119, target_std: 6.2946
    Epoch [5/50], Val Losses: mse: 9.6551, mae: 1.7173, huber: 1.3429, swd: 1.2336, target_std: 4.3728
    Epoch [5/50], Test Losses: mse: 12.7633, mae: 2.2341, huber: 1.8250, swd: 2.8533, target_std: 4.8721
      Epoch 5 composite train-obj: 1.413748
            Val objective improved 1.3627 → 1.3429, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 8.3060, mae: 1.8156, huber: 1.4213, swd: 2.2725, target_std: 6.2910
    Epoch [6/50], Val Losses: mse: 9.7573, mae: 1.7281, huber: 1.3523, swd: 1.2702, target_std: 4.3728
    Epoch [6/50], Test Losses: mse: 12.3511, mae: 2.1896, huber: 1.7763, swd: 2.4015, target_std: 4.8721
      Epoch 6 composite train-obj: 1.421348
            No improvement (1.3523), counter 1/5
    Epoch [7/50], Train Losses: mse: 8.2025, mae: 1.8038, huber: 1.4098, swd: 2.1958, target_std: 6.2809
    Epoch [7/50], Val Losses: mse: 10.1016, mae: 1.7990, huber: 1.4178, swd: 1.7573, target_std: 4.3728
    Epoch [7/50], Test Losses: mse: 12.4431, mae: 2.2134, huber: 1.8006, swd: 2.7651, target_std: 4.8721
      Epoch 7 composite train-obj: 1.409754
            No improvement (1.4178), counter 2/5
    Epoch [8/50], Train Losses: mse: 8.1825, mae: 1.8018, huber: 1.4080, swd: 2.1838, target_std: 6.2777
    Epoch [8/50], Val Losses: mse: 10.4078, mae: 1.7967, huber: 1.4219, swd: 1.7151, target_std: 4.3728
    Epoch [8/50], Test Losses: mse: 12.3977, mae: 2.1874, huber: 1.7838, swd: 2.6661, target_std: 4.8721
      Epoch 8 composite train-obj: 1.408022
            No improvement (1.4219), counter 3/5
    Epoch [9/50], Train Losses: mse: 8.1498, mae: 1.7939, huber: 1.4012, swd: 2.1598, target_std: 6.2728
    Epoch [9/50], Val Losses: mse: 9.8551, mae: 1.7210, huber: 1.3512, swd: 1.3352, target_std: 4.3728
    Epoch [9/50], Test Losses: mse: 12.1495, mae: 2.1498, huber: 1.7442, swd: 2.3483, target_std: 4.8721
      Epoch 9 composite train-obj: 1.401176
            No improvement (1.3512), counter 4/5
    Epoch [10/50], Train Losses: mse: 8.1117, mae: 1.7888, huber: 1.3965, swd: 2.1547, target_std: 6.2886
    Epoch [10/50], Val Losses: mse: 9.6637, mae: 1.7284, huber: 1.3511, swd: 1.2519, target_std: 4.3728
    Epoch [10/50], Test Losses: mse: 12.3126, mae: 2.1674, huber: 1.7618, swd: 2.4772, target_std: 4.8721
      Epoch 10 composite train-obj: 1.396534
    Epoch [10/50], Test Losses: mse: 12.7633, mae: 2.2341, huber: 1.8250, swd: 2.8533, target_std: 4.8721
    Best round's Test MSE: 12.7633, MAE: 2.2341, SWD: 2.8533
    Best round's Validation MSE: 9.6551, MAE: 1.7173
    Best round's Test verification MSE : 12.7633, MAE: 2.2341, SWD: 2.8533
    Time taken: 14.64 seconds
    
    ==================================================
    Experiment Summary (DLinear_etth1_seq336_pred720_20250503_1957)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.4971 ± 0.2193
      mae: 2.2048 ± 0.0311
      huber: 1.7949 ± 0.0299
      swd: 2.3745 ± 0.4067
      target_std: 4.8721 ± 0.0000
      count: 6.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.6442 ± 0.1318
      mae: 1.7079 ± 0.0229
      huber: 1.3362 ± 0.0197
      swd: 1.0818 ± 0.1980
      target_std: 4.3728 ± 0.0000
      count: 6.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 36.73 seconds
    
    Experiment complete: DLinear_etth1_seq336_pred720_20250503_1957
    Model: DLinear
    Dataset: etth1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    




