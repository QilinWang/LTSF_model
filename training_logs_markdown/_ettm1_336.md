# data


```python
%load_ext autoreload
%autoreload 2
import importlib
from importlib import reload  
  
import monotonic
import utils
from train import execute_model_evaluation
from train_config import FlatACLConfig
import train_config
import data_manager
from data_manager import DatasetManager
import metrics
from dataclasses import replace

reload(utils)
reload(monotonic)
reload(train_config)


%load_ext autoreload
%autoreload 2
# Initialize the data manager
data_mgr = DatasetManager(device='cuda')

# Load a synthetic dataset
data_mgr.load_csv('ettm1', './ettm1.csv')
# SCALE = False
# trajectory = utils.generate_trajectory('lorenz',steps=52200, dt=1e-2) 
# trajectory = utils.generate_hyperchaotic_rossler(steps=12000, dt=1e-3)
# trajectory_2 = utils.generate_henon(steps=52000) 
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    
    ==================================================
    Dataset: ettm1 (csv)
    ==================================================
    Shape: torch.Size([69680, 7])
    Channels: 7
    Length: 69680
    Source: ./ettm1.csv
    
    Sample data (first 2 rows):
    tensor([[ 5.8270,  2.0090,  1.5990,  0.4620,  4.2030,  1.3400, 30.5310],
            [ 5.7600,  2.0760,  1.4920,  0.4260,  4.2640,  1.4010, 30.4600]])
    ==================================================
    




    <data_manager.DatasetManager at 0x17e1684b560>



# Seq=336

### EigenACL


#### 336-96

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5921, mae: 1.5222, huber: 1.1507, swd: 3.2411, ept: 59.4323
    Epoch [1/50], Val Losses: mse: 6.3484, mae: 1.3687, huber: 1.0136, swd: 1.7832, ept: 63.5799
    Epoch [1/50], Test Losses: mse: 7.8562, mae: 1.5428, huber: 1.1785, swd: 2.0886, ept: 52.5251
      Epoch 1 composite train-obj: 1.150681
            Val objective improved inf → 1.0136, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3237, mae: 1.2053, huber: 0.8534, swd: 1.3985, ept: 69.5255
    Epoch [2/50], Val Losses: mse: 5.6756, mae: 1.2452, huber: 0.9002, swd: 1.2836, ept: 70.4240
    Epoch [2/50], Test Losses: mse: 7.4857, mae: 1.4514, huber: 1.0971, swd: 1.8155, ept: 57.7881
      Epoch 2 composite train-obj: 0.853409
            Val objective improved 1.0136 → 0.9002, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.0314, mae: 1.1512, huber: 0.8046, swd: 1.2742, ept: 71.5465
    Epoch [3/50], Val Losses: mse: 5.5839, mae: 1.2360, huber: 0.8918, swd: 1.2896, ept: 70.2062
    Epoch [3/50], Test Losses: mse: 7.5053, mae: 1.4462, huber: 1.0924, swd: 1.8285, ept: 58.6287
      Epoch 3 composite train-obj: 0.804580
            Val objective improved 0.9002 → 0.8918, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.8546, mae: 1.1232, huber: 0.7790, swd: 1.2215, ept: 72.5197
    Epoch [4/50], Val Losses: mse: 5.8874, mae: 1.2570, huber: 0.9121, swd: 1.2422, ept: 71.1436
    Epoch [4/50], Test Losses: mse: 7.7812, mae: 1.4370, huber: 1.0851, swd: 1.6761, ept: 60.4324
      Epoch 4 composite train-obj: 0.778980
            No improvement (0.9121), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.6894, mae: 1.0968, huber: 0.7549, swd: 1.1626, ept: 73.2440
    Epoch [5/50], Val Losses: mse: 5.7953, mae: 1.2561, huber: 0.9103, swd: 1.1567, ept: 71.2585
    Epoch [5/50], Test Losses: mse: 7.7038, mae: 1.4412, huber: 1.0887, swd: 1.6860, ept: 60.6754
      Epoch 5 composite train-obj: 0.754876
            No improvement (0.9103), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.5108, mae: 1.0722, huber: 0.7319, swd: 1.1055, ept: 73.9407
    Epoch [6/50], Val Losses: mse: 5.7130, mae: 1.2523, huber: 0.9075, swd: 1.1941, ept: 71.2473
    Epoch [6/50], Test Losses: mse: 7.9464, mae: 1.4520, huber: 1.0993, swd: 1.7070, ept: 60.5110
      Epoch 6 composite train-obj: 0.731927
            No improvement (0.9075), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.3274, mae: 1.0443, huber: 0.7061, swd: 1.0288, ept: 74.4896
    Epoch [7/50], Val Losses: mse: 5.7460, mae: 1.2485, huber: 0.9043, swd: 1.1842, ept: 71.6048
    Epoch [7/50], Test Losses: mse: 7.9619, mae: 1.4583, huber: 1.1060, swd: 1.7753, ept: 60.2867
      Epoch 7 composite train-obj: 0.706074
            No improvement (0.9043), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.1700, mae: 1.0247, huber: 0.6876, swd: 0.9936, ept: 75.0429
    Epoch [8/50], Val Losses: mse: 5.8757, mae: 1.2702, huber: 0.9263, swd: 1.3679, ept: 72.1208
    Epoch [8/50], Test Losses: mse: 8.2784, mae: 1.4808, huber: 1.1284, swd: 1.9695, ept: 60.5139
      Epoch 8 composite train-obj: 0.687587
    Epoch [8/50], Test Losses: mse: 7.5056, mae: 1.4462, huber: 1.0924, swd: 1.8286, ept: 58.6351
    Best round's Test MSE: 7.5053, MAE: 1.4462, SWD: 1.8285
    Best round's Validation MSE: 5.5839, MAE: 1.2360, SWD: 1.2896
    Best round's Test verification MSE : 7.5056, MAE: 1.4462, SWD: 1.8286
    Time taken: 86.01 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3979, mae: 1.4949, huber: 1.1251, swd: 3.0571, ept: 60.6614
    Epoch [1/50], Val Losses: mse: 6.1892, mae: 1.3484, huber: 0.9931, swd: 1.7629, ept: 64.8151
    Epoch [1/50], Test Losses: mse: 7.8408, mae: 1.5370, huber: 1.1723, swd: 2.2264, ept: 53.7126
      Epoch 1 composite train-obj: 1.125123
            Val objective improved inf → 0.9931, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.2355, mae: 1.1914, huber: 0.8401, swd: 1.3333, ept: 69.8672
    Epoch [2/50], Val Losses: mse: 5.7713, mae: 1.2374, huber: 0.8928, swd: 1.1449, ept: 70.2433
    Epoch [2/50], Test Losses: mse: 7.5189, mae: 1.4387, huber: 1.0834, swd: 1.5770, ept: 58.2085
      Epoch 2 composite train-obj: 0.840137
            Val objective improved 0.9931 → 0.8928, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9415, mae: 1.1375, huber: 0.7917, swd: 1.2161, ept: 71.5881
    Epoch [3/50], Val Losses: mse: 5.7072, mae: 1.2283, huber: 0.8841, swd: 1.0519, ept: 70.8173
    Epoch [3/50], Test Losses: mse: 7.5462, mae: 1.4294, huber: 1.0755, swd: 1.5347, ept: 59.4201
      Epoch 3 composite train-obj: 0.791714
            Val objective improved 0.8928 → 0.8841, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.7661, mae: 1.1082, huber: 0.7652, swd: 1.1514, ept: 72.5814
    Epoch [4/50], Val Losses: mse: 5.6468, mae: 1.2264, huber: 0.8847, swd: 1.0850, ept: 70.9367
    Epoch [4/50], Test Losses: mse: 7.4993, mae: 1.4155, huber: 1.0649, swd: 1.5932, ept: 60.1431
      Epoch 4 composite train-obj: 0.765222
            No improvement (0.8847), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.6064, mae: 1.0826, huber: 0.7419, swd: 1.0966, ept: 73.3569
    Epoch [5/50], Val Losses: mse: 5.5779, mae: 1.2370, huber: 0.8939, swd: 1.1895, ept: 71.2535
    Epoch [5/50], Test Losses: mse: 7.7754, mae: 1.4421, huber: 1.0901, swd: 1.7867, ept: 60.1285
      Epoch 5 composite train-obj: 0.741900
            No improvement (0.8939), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.4386, mae: 1.0584, huber: 0.7196, swd: 1.0427, ept: 74.0375
    Epoch [6/50], Val Losses: mse: 5.6839, mae: 1.2463, huber: 0.9033, swd: 1.2289, ept: 70.9370
    Epoch [6/50], Test Losses: mse: 8.0466, mae: 1.4605, huber: 1.1082, swd: 1.9002, ept: 59.8386
      Epoch 6 composite train-obj: 0.719555
            No improvement (0.9033), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.2864, mae: 1.0375, huber: 0.6999, swd: 0.9934, ept: 74.4718
    Epoch [7/50], Val Losses: mse: 5.8219, mae: 1.2493, huber: 0.9065, swd: 1.2365, ept: 71.6203
    Epoch [7/50], Test Losses: mse: 7.9775, mae: 1.4511, huber: 1.1001, swd: 1.8880, ept: 60.4692
      Epoch 7 composite train-obj: 0.699889
            No improvement (0.9065), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.1286, mae: 1.0153, huber: 0.6792, swd: 0.9476, ept: 74.9385
    Epoch [8/50], Val Losses: mse: 5.8388, mae: 1.2539, huber: 0.9099, swd: 1.2367, ept: 71.9163
    Epoch [8/50], Test Losses: mse: 8.1620, mae: 1.4593, huber: 1.1079, swd: 1.8316, ept: 60.5626
      Epoch 8 composite train-obj: 0.679224
    Epoch [8/50], Test Losses: mse: 7.5463, mae: 1.4294, huber: 1.0755, swd: 1.5348, ept: 59.4214
    Best round's Test MSE: 7.5462, MAE: 1.4294, SWD: 1.5347
    Best round's Validation MSE: 5.7072, MAE: 1.2283, SWD: 1.0519
    Best round's Test verification MSE : 7.5463, MAE: 1.4294, SWD: 1.5348
    Time taken: 104.59 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.6943, mae: 1.5053, huber: 1.1367, swd: 3.1271, ept: 60.9157
    Epoch [1/50], Val Losses: mse: 5.9114, mae: 1.2721, huber: 0.9250, swd: 1.1107, ept: 69.2582
    Epoch [1/50], Test Losses: mse: 7.5054, mae: 1.4537, huber: 1.0980, swd: 1.4963, ept: 57.3426
      Epoch 1 composite train-obj: 1.136681
            Val objective improved inf → 0.9250, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1586, mae: 1.1742, huber: 0.8257, swd: 1.2008, ept: 70.6855
    Epoch [2/50], Val Losses: mse: 5.6326, mae: 1.2384, huber: 0.8948, swd: 1.2205, ept: 70.7544
    Epoch [2/50], Test Losses: mse: 7.2536, mae: 1.4238, huber: 1.0716, swd: 1.6712, ept: 59.1291
      Epoch 2 composite train-obj: 0.825714
            Val objective improved 0.9250 → 0.8948, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9397, mae: 1.1349, huber: 0.7902, swd: 1.1309, ept: 72.0156
    Epoch [3/50], Val Losses: mse: 5.6516, mae: 1.2385, huber: 0.8953, swd: 1.1948, ept: 71.0572
    Epoch [3/50], Test Losses: mse: 7.5539, mae: 1.4343, huber: 1.0822, swd: 1.6528, ept: 59.7987
      Epoch 3 composite train-obj: 0.790216
            No improvement (0.8953), counter 1/5
    Epoch [4/50], Train Losses: mse: 3.7661, mae: 1.1064, huber: 0.7642, swd: 1.0788, ept: 72.8443
    Epoch [4/50], Val Losses: mse: 5.6505, mae: 1.2580, huber: 0.9070, swd: 0.9874, ept: 69.8837
    Epoch [4/50], Test Losses: mse: 7.5079, mae: 1.4368, huber: 1.0802, swd: 1.4071, ept: 60.2031
      Epoch 4 composite train-obj: 0.764207
            No improvement (0.9070), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.6273, mae: 1.0854, huber: 0.7449, swd: 1.0451, ept: 73.5294
    Epoch [5/50], Val Losses: mse: 5.7086, mae: 1.2469, huber: 0.9033, swd: 1.1426, ept: 71.3779
    Epoch [5/50], Test Losses: mse: 7.6212, mae: 1.4325, huber: 1.0803, swd: 1.6824, ept: 60.4929
      Epoch 5 composite train-obj: 0.744947
            No improvement (0.9033), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.4485, mae: 1.0578, huber: 0.7195, swd: 0.9814, ept: 74.1770
    Epoch [6/50], Val Losses: mse: 5.4715, mae: 1.2241, huber: 0.8819, swd: 1.1476, ept: 71.7961
    Epoch [6/50], Test Losses: mse: 7.6532, mae: 1.4418, huber: 1.0888, swd: 1.7592, ept: 60.6282
      Epoch 6 composite train-obj: 0.719497
            Val objective improved 0.8948 → 0.8819, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 3.2680, mae: 1.0320, huber: 0.6954, swd: 0.9216, ept: 74.7105
    Epoch [7/50], Val Losses: mse: 5.5677, mae: 1.2304, huber: 0.8882, swd: 1.0692, ept: 71.8535
    Epoch [7/50], Test Losses: mse: 7.9727, mae: 1.4354, huber: 1.0861, swd: 1.6331, ept: 60.6355
      Epoch 7 composite train-obj: 0.695401
            No improvement (0.8882), counter 1/5
    Epoch [8/50], Train Losses: mse: 3.1287, mae: 1.0144, huber: 0.6788, swd: 0.8936, ept: 75.1624
    Epoch [8/50], Val Losses: mse: 5.8602, mae: 1.2698, huber: 0.9254, swd: 1.2060, ept: 71.1019
    Epoch [8/50], Test Losses: mse: 8.1170, mae: 1.4609, huber: 1.1097, swd: 1.7286, ept: 60.6943
      Epoch 8 composite train-obj: 0.678767
            No improvement (0.9254), counter 2/5
    Epoch [9/50], Train Losses: mse: 2.9649, mae: 0.9928, huber: 0.6584, swd: 0.8505, ept: 75.6302
    Epoch [9/50], Val Losses: mse: 6.1194, mae: 1.2881, huber: 0.9436, swd: 1.2724, ept: 71.7954
    Epoch [9/50], Test Losses: mse: 8.3625, mae: 1.4771, huber: 1.1255, swd: 1.7629, ept: 61.0074
      Epoch 9 composite train-obj: 0.658359
            No improvement (0.9436), counter 3/5
    Epoch [10/50], Train Losses: mse: 2.7712, mae: 0.9638, huber: 0.6314, swd: 0.7852, ept: 76.1077
    Epoch [10/50], Val Losses: mse: 6.3591, mae: 1.3153, huber: 0.9696, swd: 1.2400, ept: 71.3625
    Epoch [10/50], Test Losses: mse: 8.4971, mae: 1.4802, huber: 1.1294, swd: 1.6506, ept: 60.6874
      Epoch 10 composite train-obj: 0.631358
            No improvement (0.9696), counter 4/5
    Epoch [11/50], Train Losses: mse: 2.6041, mae: 0.9382, huber: 0.6075, swd: 0.7296, ept: 76.4893
    Epoch [11/50], Val Losses: mse: 6.2977, mae: 1.3098, huber: 0.9634, swd: 1.3819, ept: 72.1058
    Epoch [11/50], Test Losses: mse: 8.6033, mae: 1.5065, huber: 1.1539, swd: 1.9235, ept: 60.5770
      Epoch 11 composite train-obj: 0.607513
    Epoch [11/50], Test Losses: mse: 7.6531, mae: 1.4418, huber: 1.0888, swd: 1.7588, ept: 60.6249
    Best round's Test MSE: 7.6532, MAE: 1.4418, SWD: 1.7592
    Best round's Validation MSE: 5.4715, MAE: 1.2241, SWD: 1.1476
    Best round's Test verification MSE : 7.6531, MAE: 1.4418, SWD: 1.7588
    Time taken: 118.76 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred96_20250512_1420)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5682 ± 0.0624
      mae: 1.4391 ± 0.0071
      huber: 1.0856 ± 0.0073
      swd: 1.7074 ± 0.1254
      ept: 59.5590 ± 0.8222
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.5875 ± 0.0963
      mae: 1.2295 ± 0.0050
      huber: 0.8860 ± 0.0043
      swd: 1.1630 ± 0.0977
      ept: 70.9399 ± 0.6548
      count: 52.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 310.47 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred96_20250512_1420
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### ablate threshold


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5283, mae: 1.5132, huber: 1.1422, swd: 3.1959, ept: 59.7674
    Epoch [1/50], Val Losses: mse: 6.3116, mae: 1.3622, huber: 1.0076, swd: 1.7655, ept: 63.8519
    Epoch [1/50], Test Losses: mse: 7.8864, mae: 1.5444, huber: 1.1801, swd: 2.1187, ept: 52.5710
      Epoch 1 composite train-obj: 1.142247
            Val objective improved inf → 1.0076, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3096, mae: 1.2031, huber: 0.8513, swd: 1.3915, ept: 69.6461
    Epoch [2/50], Val Losses: mse: 5.7846, mae: 1.2603, huber: 0.9130, swd: 1.1941, ept: 69.9281
    Epoch [2/50], Test Losses: mse: 7.5711, mae: 1.4631, huber: 1.1064, swd: 1.7079, ept: 57.8335
      Epoch 2 composite train-obj: 0.851334
            Val objective improved 1.0076 → 0.9130, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.0250, mae: 1.1506, huber: 0.8040, swd: 1.2752, ept: 71.5850
    Epoch [3/50], Val Losses: mse: 5.6419, mae: 1.2382, huber: 0.8947, swd: 1.2435, ept: 70.6528
    Epoch [3/50], Test Losses: mse: 7.6386, mae: 1.4526, huber: 1.0992, swd: 1.7848, ept: 59.0017
      Epoch 3 composite train-obj: 0.804008
            Val objective improved 0.9130 → 0.8947, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.8241, mae: 1.1176, huber: 0.7740, swd: 1.2081, ept: 72.6013
    Epoch [4/50], Val Losses: mse: 5.8881, mae: 1.2657, huber: 0.9180, swd: 1.2199, ept: 70.5936
    Epoch [4/50], Test Losses: mse: 7.8169, mae: 1.4676, huber: 1.1111, swd: 1.7494, ept: 59.8421
      Epoch 4 composite train-obj: 0.773978
            No improvement (0.9180), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.6521, mae: 1.0917, huber: 0.7501, swd: 1.1517, ept: 73.2970
    Epoch [5/50], Val Losses: mse: 5.8568, mae: 1.2597, huber: 0.9141, swd: 1.2607, ept: 71.2176
    Epoch [5/50], Test Losses: mse: 7.8525, mae: 1.4603, huber: 1.1061, swd: 1.8400, ept: 60.4047
      Epoch 5 composite train-obj: 0.750112
            No improvement (0.9141), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.4771, mae: 1.0694, huber: 0.7291, swd: 1.0960, ept: 73.9140
    Epoch [6/50], Val Losses: mse: 5.7012, mae: 1.2375, huber: 0.8941, swd: 1.1528, ept: 71.2943
    Epoch [6/50], Test Losses: mse: 7.9200, mae: 1.4432, huber: 1.0909, swd: 1.6461, ept: 60.6867
      Epoch 6 composite train-obj: 0.729103
            Val objective improved 0.8947 → 0.8941, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 3.2627, mae: 1.0365, huber: 0.6987, swd: 1.0114, ept: 74.5320
    Epoch [7/50], Val Losses: mse: 5.6901, mae: 1.2350, huber: 0.8922, swd: 1.1597, ept: 72.2936
    Epoch [7/50], Test Losses: mse: 8.0195, mae: 1.4497, huber: 1.0986, swd: 1.6989, ept: 61.0274
      Epoch 7 composite train-obj: 0.698678
            Val objective improved 0.8941 → 0.8922, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 3.1323, mae: 1.0229, huber: 0.6855, swd: 0.9948, ept: 75.0027
    Epoch [8/50], Val Losses: mse: 5.8404, mae: 1.2645, huber: 0.9194, swd: 1.2758, ept: 71.7118
    Epoch [8/50], Test Losses: mse: 8.1564, mae: 1.4719, huber: 1.1194, swd: 1.7941, ept: 60.7043
      Epoch 8 composite train-obj: 0.685488
            No improvement (0.9194), counter 1/5
    Epoch [9/50], Train Losses: mse: 2.9126, mae: 0.9914, huber: 0.6560, swd: 0.9196, ept: 75.5744
    Epoch [9/50], Val Losses: mse: 6.1964, mae: 1.3007, huber: 0.9544, swd: 1.3311, ept: 71.4779
    Epoch [9/50], Test Losses: mse: 8.1271, mae: 1.4609, huber: 1.1092, swd: 1.7269, ept: 61.0368
      Epoch 9 composite train-obj: 0.655973
            No improvement (0.9544), counter 2/5
    Epoch [10/50], Train Losses: mse: 2.7481, mae: 0.9695, huber: 0.6353, swd: 0.8733, ept: 75.9143
    Epoch [10/50], Val Losses: mse: 6.4542, mae: 1.3047, huber: 0.9582, swd: 1.3157, ept: 71.9277
    Epoch [10/50], Test Losses: mse: 8.5852, mae: 1.4907, huber: 1.1373, swd: 1.7769, ept: 60.7407
      Epoch 10 composite train-obj: 0.635312
            No improvement (0.9582), counter 3/5
    Epoch [11/50], Train Losses: mse: 2.5461, mae: 0.9391, huber: 0.6071, swd: 0.8005, ept: 76.4014
    Epoch [11/50], Val Losses: mse: 6.5160, mae: 1.3182, huber: 0.9718, swd: 1.4328, ept: 70.9095
    Epoch [11/50], Test Losses: mse: 8.5948, mae: 1.4949, huber: 1.1419, swd: 1.8165, ept: 60.3793
      Epoch 11 composite train-obj: 0.607122
            No improvement (0.9718), counter 4/5
    Epoch [12/50], Train Losses: mse: 2.3894, mae: 0.9171, huber: 0.5864, swd: 0.7465, ept: 76.7801
    Epoch [12/50], Val Losses: mse: 6.8049, mae: 1.3522, huber: 1.0021, swd: 1.4425, ept: 71.1674
    Epoch [12/50], Test Losses: mse: 8.5697, mae: 1.5020, huber: 1.1469, swd: 1.8093, ept: 61.0409
      Epoch 12 composite train-obj: 0.586367
    Epoch [12/50], Test Losses: mse: 8.0187, mae: 1.4497, huber: 1.0986, swd: 1.6988, ept: 61.0225
    Best round's Test MSE: 8.0195, MAE: 1.4497, SWD: 1.6989
    Best round's Validation MSE: 5.6901, MAE: 1.2350, SWD: 1.1597
    Best round's Test verification MSE : 8.0187, MAE: 1.4497, SWD: 1.6988
    Time taken: 125.04 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4496, mae: 1.5017, huber: 1.1316, swd: 3.0873, ept: 60.4607
    Epoch [1/50], Val Losses: mse: 6.1255, mae: 1.3257, huber: 0.9740, swd: 1.6703, ept: 66.2320
    Epoch [1/50], Test Losses: mse: 7.8223, mae: 1.5200, huber: 1.1581, swd: 2.1308, ept: 54.4750
      Epoch 1 composite train-obj: 1.131568
            Val objective improved inf → 0.9740, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.2480, mae: 1.1938, huber: 0.8420, swd: 1.3302, ept: 69.6684
    Epoch [2/50], Val Losses: mse: 5.7372, mae: 1.2401, huber: 0.8954, swd: 1.2048, ept: 69.9203
    Epoch [2/50], Test Losses: mse: 7.4662, mae: 1.4394, huber: 1.0847, swd: 1.6789, ept: 57.8480
      Epoch 2 composite train-obj: 0.842032
            Val objective improved 0.9740 → 0.8954, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9914, mae: 1.1457, huber: 0.7990, swd: 1.2432, ept: 71.3357
    Epoch [3/50], Val Losses: mse: 5.7497, mae: 1.2379, huber: 0.8943, swd: 1.1168, ept: 70.4286
    Epoch [3/50], Test Losses: mse: 7.6108, mae: 1.4384, huber: 1.0848, swd: 1.6634, ept: 58.9664
      Epoch 3 composite train-obj: 0.799030
            Val objective improved 0.8954 → 0.8943, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.8191, mae: 1.1152, huber: 0.7715, swd: 1.1734, ept: 72.3364
    Epoch [4/50], Val Losses: mse: 5.6608, mae: 1.2301, huber: 0.8873, swd: 1.0545, ept: 70.3121
    Epoch [4/50], Test Losses: mse: 7.6296, mae: 1.4276, huber: 1.0755, swd: 1.5630, ept: 59.3743
      Epoch 4 composite train-obj: 0.771479
            Val objective improved 0.8943 → 0.8873, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.6558, mae: 1.0891, huber: 0.7477, swd: 1.1140, ept: 73.0684
    Epoch [5/50], Val Losses: mse: 5.6519, mae: 1.2427, huber: 0.8988, swd: 1.2314, ept: 70.7977
    Epoch [5/50], Test Losses: mse: 7.7488, mae: 1.4480, huber: 1.0949, swd: 1.7843, ept: 59.1948
      Epoch 5 composite train-obj: 0.747695
            No improvement (0.8988), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.4802, mae: 1.0637, huber: 0.7243, swd: 1.0580, ept: 73.7302
    Epoch [6/50], Val Losses: mse: 5.7103, mae: 1.2505, huber: 0.9063, swd: 1.1854, ept: 71.0194
    Epoch [6/50], Test Losses: mse: 8.1383, mae: 1.4670, huber: 1.1139, swd: 1.7811, ept: 59.7325
      Epoch 6 composite train-obj: 0.724253
            No improvement (0.9063), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.3284, mae: 1.0429, huber: 0.7047, swd: 1.0082, ept: 74.2115
    Epoch [7/50], Val Losses: mse: 5.7484, mae: 1.2557, huber: 0.9112, swd: 1.3003, ept: 71.0834
    Epoch [7/50], Test Losses: mse: 8.3178, mae: 1.4797, huber: 1.1273, swd: 1.9263, ept: 59.6901
      Epoch 7 composite train-obj: 0.704718
            No improvement (0.9112), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.1811, mae: 1.0234, huber: 0.6865, swd: 0.9676, ept: 74.6838
    Epoch [8/50], Val Losses: mse: 5.9552, mae: 1.2765, huber: 0.9319, swd: 1.4233, ept: 71.0203
    Epoch [8/50], Test Losses: mse: 8.2334, mae: 1.4726, huber: 1.1204, swd: 1.9325, ept: 59.7944
      Epoch 8 composite train-obj: 0.686482
            No improvement (0.9319), counter 4/5
    Epoch [9/50], Train Losses: mse: 2.9961, mae: 0.9965, huber: 0.6614, swd: 0.9012, ept: 75.1372
    Epoch [9/50], Val Losses: mse: 6.1558, mae: 1.3049, huber: 0.9585, swd: 1.5445, ept: 70.2447
    Epoch [9/50], Test Losses: mse: 8.5817, mae: 1.5128, huber: 1.1591, swd: 2.1058, ept: 59.2659
      Epoch 9 composite train-obj: 0.661359
    Epoch [9/50], Test Losses: mse: 7.6292, mae: 1.4276, huber: 1.0755, swd: 1.5628, ept: 59.3758
    Best round's Test MSE: 7.6296, MAE: 1.4276, SWD: 1.5630
    Best round's Validation MSE: 5.6608, MAE: 1.2301, SWD: 1.0545
    Best round's Test verification MSE : 7.6292, MAE: 1.4276, SWD: 1.5628
    Time taken: 95.22 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.7038, mae: 1.5073, huber: 1.1385, swd: 3.1334, ept: 60.9433
    Epoch [1/50], Val Losses: mse: 5.9265, mae: 1.2769, huber: 0.9289, swd: 1.1089, ept: 69.3271
    Epoch [1/50], Test Losses: mse: 7.5374, mae: 1.4577, huber: 1.1010, swd: 1.4980, ept: 57.4715
      Epoch 1 composite train-obj: 1.138493
            Val objective improved inf → 0.9289, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1545, mae: 1.1738, huber: 0.8252, swd: 1.1988, ept: 70.7477
    Epoch [2/50], Val Losses: mse: 5.6548, mae: 1.2381, huber: 0.8950, swd: 1.2320, ept: 70.7352
    Epoch [2/50], Test Losses: mse: 7.2527, mae: 1.4231, huber: 1.0710, swd: 1.6828, ept: 59.3190
      Epoch 2 composite train-obj: 0.825176
            Val objective improved 0.9289 → 0.8950, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9260, mae: 1.1334, huber: 0.7887, swd: 1.1237, ept: 72.0913
    Epoch [3/50], Val Losses: mse: 5.6456, mae: 1.2474, huber: 0.9036, swd: 1.2825, ept: 70.8409
    Epoch [3/50], Test Losses: mse: 7.5827, mae: 1.4425, huber: 1.0902, swd: 1.7668, ept: 59.3350
      Epoch 3 composite train-obj: 0.788674
            No improvement (0.9036), counter 1/5
    Epoch [4/50], Train Losses: mse: 3.7362, mae: 1.1017, huber: 0.7597, swd: 1.0612, ept: 73.0116
    Epoch [4/50], Val Losses: mse: 5.6311, mae: 1.2551, huber: 0.9068, swd: 1.0124, ept: 70.3828
    Epoch [4/50], Test Losses: mse: 7.5717, mae: 1.4366, huber: 1.0814, swd: 1.4517, ept: 60.5918
      Epoch 4 composite train-obj: 0.759709
            No improvement (0.9068), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.5961, mae: 1.0808, huber: 0.7406, swd: 1.0260, ept: 73.6216
    Epoch [5/50], Val Losses: mse: 5.6659, mae: 1.2473, huber: 0.9037, swd: 1.1279, ept: 71.6156
    Epoch [5/50], Test Losses: mse: 7.6714, mae: 1.4296, huber: 1.0782, swd: 1.6252, ept: 60.9578
      Epoch 5 composite train-obj: 0.740586
            No improvement (0.9037), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.4232, mae: 1.0547, huber: 0.7166, swd: 0.9712, ept: 74.2313
    Epoch [6/50], Val Losses: mse: 5.5204, mae: 1.2517, huber: 0.9074, swd: 1.3043, ept: 72.0281
    Epoch [6/50], Test Losses: mse: 7.8068, mae: 1.4621, huber: 1.1082, swd: 1.8605, ept: 60.5830
      Epoch 6 composite train-obj: 0.716554
            No improvement (0.9074), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.2544, mae: 1.0295, huber: 0.6932, swd: 0.9142, ept: 74.7130
    Epoch [7/50], Val Losses: mse: 5.7240, mae: 1.2472, huber: 0.9045, swd: 1.0930, ept: 71.3114
    Epoch [7/50], Test Losses: mse: 8.0004, mae: 1.4437, huber: 1.0937, swd: 1.5885, ept: 60.3800
      Epoch 7 composite train-obj: 0.693155
    Epoch [7/50], Test Losses: mse: 7.2528, mae: 1.4231, huber: 1.0710, swd: 1.6831, ept: 59.3169
    Best round's Test MSE: 7.2527, MAE: 1.4231, SWD: 1.6828
    Best round's Validation MSE: 5.6548, MAE: 1.2381, SWD: 1.2320
    Best round's Test verification MSE : 7.2528, MAE: 1.4231, SWD: 1.6831
    Time taken: 73.71 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred96_20250512_1426)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.6340 ± 0.3130
      mae: 1.4335 ± 0.0116
      huber: 1.0817 ± 0.0121
      swd: 1.6482 ± 0.0606
      ept: 59.9069 ± 0.7926
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.6686 ± 0.0155
      mae: 1.2344 ± 0.0033
      huber: 0.8915 ± 0.0032
      swd: 1.1488 ± 0.0729
      ept: 71.1136 ± 0.8521
      count: 52.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 294.04 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred96_20250512_1426
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### ab: use (8,4) rotations


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_336_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0782, mae: 1.4608, huber: 1.0950, swd: 3.0517, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 6.0198, mae: 1.2855, huber: 0.9393, swd: 1.3657, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.4992, mae: 1.4445, huber: 1.0914, swd: 1.6723, target_std: 4.7623
      Epoch 1 composite train-obj: 1.094958
            Val objective improved inf → 0.9393, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1229, mae: 1.1623, huber: 0.8159, swd: 1.3058, target_std: 6.5014
    Epoch [2/50], Val Losses: mse: 5.6116, mae: 1.2263, huber: 0.8840, swd: 1.2102, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.4465, mae: 1.4284, huber: 1.0765, swd: 1.7098, target_std: 4.7623
      Epoch 2 composite train-obj: 0.815872
            Val objective improved 0.9393 → 0.8840, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.8974, mae: 1.1239, huber: 0.7813, swd: 1.2330, target_std: 6.5013
    Epoch [3/50], Val Losses: mse: 5.5158, mae: 1.2253, huber: 0.8830, swd: 1.2872, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.4322, mae: 1.4189, huber: 1.0676, swd: 1.7677, target_std: 4.7623
      Epoch 3 composite train-obj: 0.781259
            Val objective improved 0.8840 → 0.8830, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.6983, mae: 1.0902, huber: 0.7506, swd: 1.1507, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 5.5235, mae: 1.2208, huber: 0.8785, swd: 1.1447, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.5438, mae: 1.4230, huber: 1.0716, swd: 1.7015, target_std: 4.7623
      Epoch 4 composite train-obj: 0.750592
            Val objective improved 0.8830 → 0.8785, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.5403, mae: 1.0658, huber: 0.7283, swd: 1.0974, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.4393, mae: 1.2174, huber: 0.8775, swd: 1.1654, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.7648, mae: 1.4305, huber: 1.0814, swd: 1.7409, target_std: 4.7623
      Epoch 5 composite train-obj: 0.728259
            Val objective improved 0.8785 → 0.8775, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 3.4177, mae: 1.0493, huber: 0.7129, swd: 1.0668, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 5.6515, mae: 1.2344, huber: 0.8899, swd: 1.1887, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 7.9535, mae: 1.4440, huber: 1.0912, swd: 1.7701, target_std: 4.7623
      Epoch 6 composite train-obj: 0.712946
            No improvement (0.8899), counter 1/5
    Epoch [7/50], Train Losses: mse: 3.2473, mae: 1.0236, huber: 0.6892, swd: 1.0105, target_std: 6.5010
    Epoch [7/50], Val Losses: mse: 5.7534, mae: 1.2566, huber: 0.9130, swd: 1.1619, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 8.1475, mae: 1.4523, huber: 1.1021, swd: 1.6929, target_std: 4.7623
      Epoch 7 composite train-obj: 0.689220
            No improvement (0.9130), counter 2/5
    Epoch [8/50], Train Losses: mse: 3.1064, mae: 1.0034, huber: 0.6704, swd: 0.9700, target_std: 6.5017
    Epoch [8/50], Val Losses: mse: 5.8631, mae: 1.2694, huber: 0.9243, swd: 1.3242, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 8.3149, mae: 1.4680, huber: 1.1160, swd: 1.8594, target_std: 4.7623
      Epoch 8 composite train-obj: 0.670385
            No improvement (0.9243), counter 3/5
    Epoch [9/50], Train Losses: mse: 2.9857, mae: 0.9862, huber: 0.6542, swd: 0.9350, target_std: 6.5014
    Epoch [9/50], Val Losses: mse: 5.7982, mae: 1.2606, huber: 0.9175, swd: 1.3120, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 8.3409, mae: 1.4741, huber: 1.1238, swd: 1.8912, target_std: 4.7623
      Epoch 9 composite train-obj: 0.654234
            No improvement (0.9175), counter 4/5
    Epoch [10/50], Train Losses: mse: 2.8118, mae: 0.9595, huber: 0.6294, swd: 0.8763, target_std: 6.5012
    Epoch [10/50], Val Losses: mse: 6.0519, mae: 1.2840, huber: 0.9385, swd: 1.3648, target_std: 4.2993
    Epoch [10/50], Test Losses: mse: 8.3523, mae: 1.4816, huber: 1.1283, swd: 1.8885, target_std: 4.7623
      Epoch 10 composite train-obj: 0.629413
    Epoch [10/50], Test Losses: mse: 7.7648, mae: 1.4305, huber: 1.0814, swd: 1.7408, target_std: 4.7623
    Best round's Test MSE: 7.7648, MAE: 1.4305, SWD: 1.7409
    Best round's Validation MSE: 5.4393, MAE: 1.2174
    Best round's Test verification MSE : 7.7648, MAE: 1.4305, SWD: 1.7408
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.1356, mae: 1.4640, huber: 1.0974, swd: 3.0565, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 5.8357, mae: 1.2708, huber: 0.9250, swd: 1.4061, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.5329, mae: 1.4694, huber: 1.1152, swd: 1.9801, target_std: 4.7623
      Epoch 1 composite train-obj: 1.097397
            Val objective improved inf → 0.9250, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0860, mae: 1.1580, huber: 0.8118, swd: 1.2684, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 5.6567, mae: 1.2310, huber: 0.8874, swd: 1.1701, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.3223, mae: 1.4156, huber: 1.0638, swd: 1.6331, target_std: 4.7623
      Epoch 2 composite train-obj: 0.811772
            Val objective improved 0.9250 → 0.8874, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9064, mae: 1.1254, huber: 0.7824, swd: 1.2192, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 5.5565, mae: 1.2244, huber: 0.8833, swd: 1.2370, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.2364, mae: 1.4013, huber: 1.0520, swd: 1.7006, target_std: 4.7623
      Epoch 3 composite train-obj: 0.782396
            Val objective improved 0.8874 → 0.8833, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.7133, mae: 1.0932, huber: 0.7529, swd: 1.1408, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 5.5528, mae: 1.2149, huber: 0.8745, swd: 1.1636, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.3120, mae: 1.4052, huber: 1.0554, swd: 1.6948, target_std: 4.7623
      Epoch 4 composite train-obj: 0.752858
            Val objective improved 0.8833 → 0.8745, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.5346, mae: 1.0655, huber: 0.7274, swd: 1.0847, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.5017, mae: 1.2288, huber: 0.8841, swd: 1.1015, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.6641, mae: 1.4190, huber: 1.0682, swd: 1.6900, target_std: 4.7623
      Epoch 5 composite train-obj: 0.727419
            No improvement (0.8841), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.4124, mae: 1.0504, huber: 0.7132, swd: 1.0552, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 5.6424, mae: 1.2362, huber: 0.8935, swd: 1.1339, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 7.9721, mae: 1.4253, huber: 1.0765, swd: 1.6441, target_std: 4.7623
      Epoch 6 composite train-obj: 0.713181
            No improvement (0.8935), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.2061, mae: 1.0207, huber: 0.6855, swd: 0.9895, target_std: 6.5009
    Epoch [7/50], Val Losses: mse: 5.5850, mae: 1.2299, huber: 0.8879, swd: 1.2140, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 7.9999, mae: 1.4368, huber: 1.0884, swd: 1.7845, target_std: 4.7623
      Epoch 7 composite train-obj: 0.685519
            No improvement (0.8879), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.0378, mae: 0.9978, huber: 0.6642, swd: 0.9456, target_std: 6.5008
    Epoch [8/50], Val Losses: mse: 5.8853, mae: 1.2693, huber: 0.9257, swd: 1.4179, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 8.3183, mae: 1.4635, huber: 1.1141, swd: 1.9599, target_std: 4.7623
      Epoch 8 composite train-obj: 0.664218
            No improvement (0.9257), counter 4/5
    Epoch [9/50], Train Losses: mse: 2.8398, mae: 0.9664, huber: 0.6351, swd: 0.8650, target_std: 6.5012
    Epoch [9/50], Val Losses: mse: 5.8706, mae: 1.2607, huber: 0.9180, swd: 1.4241, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 8.2598, mae: 1.4840, huber: 1.1320, swd: 2.1279, target_std: 4.7623
      Epoch 9 composite train-obj: 0.635131
    Epoch [9/50], Test Losses: mse: 7.3119, mae: 1.4052, huber: 1.0554, swd: 1.6947, target_std: 4.7623
    Best round's Test MSE: 7.3120, MAE: 1.4052, SWD: 1.6948
    Best round's Validation MSE: 5.5528, MAE: 1.2149
    Best round's Test verification MSE : 7.3119, MAE: 1.4052, SWD: 1.6947
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.9376, mae: 1.4540, huber: 1.0876, swd: 2.7293, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 5.9149, mae: 1.2692, huber: 0.9246, swd: 1.2521, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.5121, mae: 1.4474, huber: 1.0954, swd: 1.6228, target_std: 4.7623
      Epoch 1 composite train-obj: 1.087603
            Val objective improved inf → 0.9246, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.2300, mae: 1.1827, huber: 0.8343, swd: 1.2684, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 5.7713, mae: 1.2556, huber: 0.9062, swd: 1.0912, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.4930, mae: 1.4435, huber: 1.0873, swd: 1.5147, target_std: 4.7623
      Epoch 2 composite train-obj: 0.834314
            Val objective improved 0.9246 → 0.9062, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9985, mae: 1.1430, huber: 0.7982, swd: 1.1882, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 5.5585, mae: 1.2276, huber: 0.8837, swd: 1.1024, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.5046, mae: 1.4336, huber: 1.0807, swd: 1.5752, target_std: 4.7623
      Epoch 3 composite train-obj: 0.798228
            Val objective improved 0.9062 → 0.8837, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.8095, mae: 1.1115, huber: 0.7693, swd: 1.1184, target_std: 6.5009
    Epoch [4/50], Val Losses: mse: 5.5178, mae: 1.2348, huber: 0.8917, swd: 1.1559, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.6327, mae: 1.4415, huber: 1.0898, swd: 1.6979, target_std: 4.7623
      Epoch 4 composite train-obj: 0.769347
            No improvement (0.8917), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.6227, mae: 1.0813, huber: 0.7416, swd: 1.0478, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.4840, mae: 1.2217, huber: 0.8785, swd: 1.0789, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.6663, mae: 1.4167, huber: 1.0676, swd: 1.6133, target_std: 4.7623
      Epoch 5 composite train-obj: 0.741625
            Val objective improved 0.8837 → 0.8785, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 3.4614, mae: 1.0576, huber: 0.7198, swd: 1.0047, target_std: 6.5014
    Epoch [6/50], Val Losses: mse: 5.6665, mae: 1.2406, huber: 0.8966, swd: 1.1845, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.0734, mae: 1.4509, huber: 1.1003, swd: 1.7293, target_std: 4.7623
      Epoch 6 composite train-obj: 0.719803
            No improvement (0.8966), counter 1/5
    Epoch [7/50], Train Losses: mse: 3.3108, mae: 1.0367, huber: 0.7002, swd: 0.9587, target_std: 6.5014
    Epoch [7/50], Val Losses: mse: 5.5852, mae: 1.2420, huber: 0.8991, swd: 1.2184, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 7.9951, mae: 1.4491, huber: 1.0989, swd: 1.7578, target_std: 4.7623
      Epoch 7 composite train-obj: 0.700218
            No improvement (0.8991), counter 2/5
    Epoch [8/50], Train Losses: mse: 3.1372, mae: 1.0125, huber: 0.6777, swd: 0.9137, target_std: 6.5015
    Epoch [8/50], Val Losses: mse: 5.8343, mae: 1.2751, huber: 0.9302, swd: 1.2917, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 8.4331, mae: 1.4715, huber: 1.1220, swd: 1.7513, target_std: 4.7623
      Epoch 8 composite train-obj: 0.677688
            No improvement (0.9302), counter 3/5
    Epoch [9/50], Train Losses: mse: 2.9472, mae: 0.9848, huber: 0.6519, swd: 0.8500, target_std: 6.5010
    Epoch [9/50], Val Losses: mse: 5.9317, mae: 1.2890, huber: 0.9404, swd: 1.3252, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 8.4086, mae: 1.4866, huber: 1.1330, swd: 1.8086, target_std: 4.7623
      Epoch 9 composite train-obj: 0.651893
            No improvement (0.9404), counter 4/5
    Epoch [10/50], Train Losses: mse: 2.7947, mae: 0.9650, huber: 0.6332, swd: 0.8155, target_std: 6.5012
    Epoch [10/50], Val Losses: mse: 5.8779, mae: 1.2722, huber: 0.9265, swd: 1.2910, target_std: 4.2993
    Epoch [10/50], Test Losses: mse: 8.5023, mae: 1.4878, huber: 1.1354, swd: 1.8129, target_std: 4.7623
      Epoch 10 composite train-obj: 0.633175
    Epoch [10/50], Test Losses: mse: 7.6661, mae: 1.4167, huber: 1.0677, swd: 1.6132, target_std: 4.7623
    Best round's Test MSE: 7.6663, MAE: 1.4167, SWD: 1.6133
    Best round's Validation MSE: 5.4840, MAE: 1.2217
    Best round's Test verification MSE : 7.6661, MAE: 1.4167, SWD: 1.6132
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred96_20250429_1723)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5811 ± 0.1944
      mae: 1.4175 ± 0.0104
      huber: 1.0681 ± 0.0106
      swd: 1.6830 ± 0.0527
      target_std: 4.7623 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.4920 ± 0.0467
      mae: 1.2180 ± 0.0028
      huber: 0.8768 ± 0.0017
      swd: 1.1360 ± 0.0404
      target_std: 4.2993 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred96_20250429_1723
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 336-196


##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.8287, mae: 1.6592, huber: 1.2808, swd: 3.5161, ept: 93.4859
    Epoch [1/50], Val Losses: mse: 7.2678, mae: 1.4613, huber: 1.1022, swd: 1.5938, ept: 103.7057
    Epoch [1/50], Test Losses: mse: 9.5167, mae: 1.6907, huber: 1.3201, swd: 2.2777, ept: 80.2625
      Epoch 1 composite train-obj: 1.280781
            Val objective improved inf → 1.1022, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.3098, mae: 1.3483, huber: 0.9867, swd: 1.6000, ept: 110.2166
    Epoch [2/50], Val Losses: mse: 6.8850, mae: 1.3861, huber: 1.0340, swd: 1.2933, ept: 110.5202
    Epoch [2/50], Test Losses: mse: 8.8346, mae: 1.5999, huber: 1.2366, swd: 1.8836, ept: 85.9667
      Epoch 2 composite train-obj: 0.986703
            Val objective improved 1.1022 → 1.0340, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.0710, mae: 1.3057, huber: 0.9484, swd: 1.5094, ept: 114.6783
    Epoch [3/50], Val Losses: mse: 6.9883, mae: 1.3984, huber: 1.0466, swd: 1.4848, ept: 111.7608
    Epoch [3/50], Test Losses: mse: 8.9649, mae: 1.6088, huber: 1.2456, swd: 2.0943, ept: 88.0178
      Epoch 3 composite train-obj: 0.948435
            No improvement (1.0466), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.8439, mae: 1.2675, huber: 0.9135, swd: 1.3993, ept: 117.6676
    Epoch [4/50], Val Losses: mse: 7.0260, mae: 1.3960, huber: 1.0422, swd: 1.2387, ept: 113.8679
    Epoch [4/50], Test Losses: mse: 8.9475, mae: 1.5879, huber: 1.2245, swd: 1.7416, ept: 91.1592
      Epoch 4 composite train-obj: 0.913512
            No improvement (1.0422), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.7456, mae: 1.2543, huber: 0.9013, swd: 1.3857, ept: 118.9780
    Epoch [5/50], Val Losses: mse: 6.8939, mae: 1.3904, huber: 1.0376, swd: 1.4148, ept: 116.1868
    Epoch [5/50], Test Losses: mse: 9.1065, mae: 1.6055, huber: 1.2423, swd: 2.0602, ept: 91.4465
      Epoch 5 composite train-obj: 0.901332
            No improvement (1.0376), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.5669, mae: 1.2290, huber: 0.8778, swd: 1.3113, ept: 120.5472
    Epoch [6/50], Val Losses: mse: 7.1124, mae: 1.4222, huber: 1.0692, swd: 1.5820, ept: 114.6369
    Epoch [6/50], Test Losses: mse: 9.1825, mae: 1.6118, huber: 1.2485, swd: 2.1456, ept: 90.2972
      Epoch 6 composite train-obj: 0.877827
            No improvement (1.0692), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.3868, mae: 1.2034, huber: 0.8536, swd: 1.2289, ept: 121.9517
    Epoch [7/50], Val Losses: mse: 7.0565, mae: 1.3982, huber: 1.0461, swd: 1.3369, ept: 116.0763
    Epoch [7/50], Test Losses: mse: 9.3795, mae: 1.6049, huber: 1.2428, swd: 1.8735, ept: 93.0884
      Epoch 7 composite train-obj: 0.853647
    Epoch [7/50], Test Losses: mse: 8.8348, mae: 1.5999, huber: 1.2366, swd: 1.8840, ept: 85.9743
    Best round's Test MSE: 8.8346, MAE: 1.5999, SWD: 1.8836
    Best round's Validation MSE: 6.8850, MAE: 1.3861, SWD: 1.2933
    Best round's Test verification MSE : 8.8348, MAE: 1.5999, SWD: 1.8840
    Time taken: 73.05 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.3181, mae: 1.6122, huber: 1.2360, swd: 3.3882, ept: 96.3476
    Epoch [1/50], Val Losses: mse: 6.9949, mae: 1.4218, huber: 1.0662, swd: 1.4409, ept: 108.0605
    Epoch [1/50], Test Losses: mse: 9.1698, mae: 1.6448, huber: 1.2783, swd: 2.0647, ept: 84.1916
      Epoch 1 composite train-obj: 1.236038
            Val objective improved inf → 1.0662, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.2072, mae: 1.3292, huber: 0.9698, swd: 1.6029, ept: 112.4935
    Epoch [2/50], Val Losses: mse: 6.8326, mae: 1.3832, huber: 1.0317, swd: 1.3685, ept: 112.3249
    Epoch [2/50], Test Losses: mse: 8.7827, mae: 1.5841, huber: 1.2224, swd: 1.8415, ept: 88.5542
      Epoch 2 composite train-obj: 0.969777
            Val objective improved 1.0662 → 1.0317, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.9478, mae: 1.2830, huber: 0.9280, swd: 1.4765, ept: 116.7838
    Epoch [3/50], Val Losses: mse: 6.7576, mae: 1.3801, huber: 1.0285, swd: 1.4327, ept: 112.0075
    Epoch [3/50], Test Losses: mse: 8.7727, mae: 1.5848, huber: 1.2221, swd: 1.9626, ept: 88.8775
      Epoch 3 composite train-obj: 0.927995
            Val objective improved 1.0317 → 1.0285, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.8079, mae: 1.2613, huber: 0.9081, swd: 1.4281, ept: 118.7288
    Epoch [4/50], Val Losses: mse: 6.8739, mae: 1.3987, huber: 1.0441, swd: 1.3853, ept: 114.6313
    Epoch [4/50], Test Losses: mse: 8.8491, mae: 1.5818, huber: 1.2195, swd: 1.8649, ept: 91.6906
      Epoch 4 composite train-obj: 0.908064
            No improvement (1.0441), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.6557, mae: 1.2377, huber: 0.8863, swd: 1.3611, ept: 120.3480
    Epoch [5/50], Val Losses: mse: 6.8450, mae: 1.3891, huber: 1.0379, swd: 1.4937, ept: 116.7233
    Epoch [5/50], Test Losses: mse: 8.9731, mae: 1.5944, huber: 1.2324, swd: 2.1216, ept: 92.1457
      Epoch 5 composite train-obj: 0.886275
            No improvement (1.0379), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.5159, mae: 1.2187, huber: 0.8684, swd: 1.3108, ept: 121.5216
    Epoch [6/50], Val Losses: mse: 7.1593, mae: 1.4339, huber: 1.0805, swd: 1.6486, ept: 116.1040
    Epoch [6/50], Test Losses: mse: 9.1493, mae: 1.5905, huber: 1.2296, swd: 2.0070, ept: 93.6881
      Epoch 6 composite train-obj: 0.868443
            No improvement (1.0805), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.3478, mae: 1.1954, huber: 0.8464, swd: 1.2397, ept: 122.7300
    Epoch [7/50], Val Losses: mse: 7.2727, mae: 1.4393, huber: 1.0857, swd: 1.5380, ept: 115.4511
    Epoch [7/50], Test Losses: mse: 9.2730, mae: 1.6050, huber: 1.2436, swd: 1.9774, ept: 92.5819
      Epoch 7 composite train-obj: 0.846388
            No improvement (1.0857), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.1589, mae: 1.1696, huber: 0.8220, swd: 1.1576, ept: 123.8736
    Epoch [8/50], Val Losses: mse: 7.7495, mae: 1.5092, huber: 1.1512, swd: 1.9041, ept: 115.3139
    Epoch [8/50], Test Losses: mse: 9.5354, mae: 1.6418, huber: 1.2760, swd: 2.1363, ept: 93.4285
      Epoch 8 composite train-obj: 0.822012
    Epoch [8/50], Test Losses: mse: 8.7723, mae: 1.5848, huber: 1.2220, swd: 1.9625, ept: 88.8626
    Best round's Test MSE: 8.7727, MAE: 1.5848, SWD: 1.9626
    Best round's Validation MSE: 6.7576, MAE: 1.3801, SWD: 1.4327
    Best round's Test verification MSE : 8.7723, MAE: 1.5848, SWD: 1.9625
    Time taken: 87.43 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.8932, mae: 1.6488, huber: 1.2722, swd: 3.3834, ept: 95.0761
    Epoch [1/50], Val Losses: mse: 6.9699, mae: 1.4211, huber: 1.0656, swd: 1.3206, ept: 107.5109
    Epoch [1/50], Test Losses: mse: 9.1948, mae: 1.6423, huber: 1.2770, swd: 1.8709, ept: 83.2361
      Epoch 1 composite train-obj: 1.272203
            Val objective improved inf → 1.0656, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.2462, mae: 1.3318, huber: 0.9726, swd: 1.4106, ept: 112.7463
    Epoch [2/50], Val Losses: mse: 6.9383, mae: 1.3985, huber: 1.0471, swd: 1.3780, ept: 112.3472
    Epoch [2/50], Test Losses: mse: 8.7923, mae: 1.5985, huber: 1.2358, swd: 1.8703, ept: 87.9895
      Epoch 2 composite train-obj: 0.972613
            Val objective improved 1.0656 → 1.0471, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.0098, mae: 1.2923, huber: 0.9365, swd: 1.3324, ept: 116.4722
    Epoch [3/50], Val Losses: mse: 6.8456, mae: 1.3887, huber: 1.0318, swd: 1.1889, ept: 112.4192
    Epoch [3/50], Test Losses: mse: 9.0590, mae: 1.6148, huber: 1.2483, swd: 1.7596, ept: 89.5311
      Epoch 3 composite train-obj: 0.936520
            Val objective improved 1.0471 → 1.0318, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.8411, mae: 1.2672, huber: 0.9133, swd: 1.2791, ept: 118.2969
    Epoch [4/50], Val Losses: mse: 7.0628, mae: 1.4195, huber: 1.0666, swd: 1.4676, ept: 113.2777
    Epoch [4/50], Test Losses: mse: 8.9296, mae: 1.6101, huber: 1.2471, swd: 2.0031, ept: 90.1557
      Epoch 4 composite train-obj: 0.913287
            No improvement (1.0666), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.6537, mae: 1.2407, huber: 0.8886, swd: 1.2126, ept: 120.0192
    Epoch [5/50], Val Losses: mse: 6.9941, mae: 1.4099, huber: 1.0567, swd: 1.4357, ept: 114.7339
    Epoch [5/50], Test Losses: mse: 9.1258, mae: 1.6094, huber: 1.2462, swd: 1.9828, ept: 91.2101
      Epoch 5 composite train-obj: 0.888638
            No improvement (1.0567), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.4782, mae: 1.2186, huber: 0.8677, swd: 1.1618, ept: 121.4168
    Epoch [6/50], Val Losses: mse: 7.0731, mae: 1.4083, huber: 1.0564, swd: 1.3460, ept: 115.9215
    Epoch [6/50], Test Losses: mse: 9.2717, mae: 1.6112, huber: 1.2485, swd: 1.8865, ept: 92.1777
      Epoch 6 composite train-obj: 0.867710
            No improvement (1.0564), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.2427, mae: 1.1891, huber: 0.8396, swd: 1.0808, ept: 122.7254
    Epoch [7/50], Val Losses: mse: 7.4548, mae: 1.4557, huber: 1.0994, swd: 1.5267, ept: 116.1984
    Epoch [7/50], Test Losses: mse: 9.8440, mae: 1.6495, huber: 1.2841, swd: 2.0113, ept: 92.4710
      Epoch 7 composite train-obj: 0.839645
            No improvement (1.0994), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.0104, mae: 1.1601, huber: 0.8120, swd: 1.0077, ept: 123.9170
    Epoch [8/50], Val Losses: mse: 7.3209, mae: 1.4437, huber: 1.0906, swd: 1.5596, ept: 115.1520
    Epoch [8/50], Test Losses: mse: 9.6594, mae: 1.6404, huber: 1.2774, swd: 2.0618, ept: 91.5230
      Epoch 8 composite train-obj: 0.811977
    Epoch [8/50], Test Losses: mse: 9.0591, mae: 1.6148, huber: 1.2484, swd: 1.7594, ept: 89.5298
    Best round's Test MSE: 9.0590, MAE: 1.6148, SWD: 1.7596
    Best round's Validation MSE: 6.8456, MAE: 1.3887, SWD: 1.1889
    Best round's Test verification MSE : 9.0591, MAE: 1.6148, SWD: 1.7594
    Time taken: 92.60 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred196_20250512_1430)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.8888 ± 0.1230
      mae: 1.5998 ± 0.0122
      huber: 1.2357 ± 0.0108
      swd: 1.8686 ± 0.0835
      ept: 88.1251 ± 1.5493
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.8294 ± 0.0533
      mae: 1.3850 ± 0.0036
      huber: 1.0314 ± 0.0022
      swd: 1.3050 ± 0.0999
      ept: 111.6489 ± 0.8157
      count: 51.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 253.15 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred196_20250512_1430
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_336_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    [autoreload of data_generator failed: Traceback (most recent call last):
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 283, in check
        superreload(m, reload, self.old_objects)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 508, in superreload
        update_generic(old_obj, new_obj)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 405, in update_generic
        update(a, b)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 357, in update_class
        if update_generic(old_obj, new_obj):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 405, in update_generic
        update(a, b)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 317, in update_function
        setattr(old, name, getattr(new, name))
    ValueError: __init__() requires a code object with 0 free vars, not 2147483648001
    ]
    

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1591, mae: 1.5934, huber: 1.2191, swd: 3.3392, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 6.8918, mae: 1.3901, huber: 1.0366, swd: 1.2781, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.0050, mae: 1.6052, huber: 1.2425, swd: 1.7612, target_std: 4.7534
      Epoch 1 composite train-obj: 1.219067
            Val objective improved inf → 1.0366, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1156, mae: 1.3065, huber: 0.9501, swd: 1.5016, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 7.1310, mae: 1.4184, huber: 1.0605, swd: 1.2954, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.2106, mae: 1.6215, huber: 1.2569, swd: 1.8071, target_std: 4.7534
      Epoch 2 composite train-obj: 0.950137
            No improvement (1.0605), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.9274, mae: 1.2751, huber: 0.9217, swd: 1.4524, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.7561, mae: 1.3748, huber: 1.0241, swd: 1.3800, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 8.8388, mae: 1.5781, huber: 1.2186, swd: 1.9283, target_std: 4.7534
      Epoch 3 composite train-obj: 0.921712
            Val objective improved 1.0366 → 1.0241, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.7626, mae: 1.2500, huber: 0.8985, swd: 1.3840, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 6.8615, mae: 1.3976, huber: 1.0473, swd: 1.5342, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 8.8985, mae: 1.5888, huber: 1.2295, swd: 2.1250, target_std: 4.7534
      Epoch 4 composite train-obj: 0.898541
            No improvement (1.0473), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.6029, mae: 1.2262, huber: 0.8765, swd: 1.3289, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.9744, mae: 1.4097, huber: 1.0566, swd: 1.6256, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.1076, mae: 1.6085, huber: 1.2455, swd: 2.1780, target_std: 4.7534
      Epoch 5 composite train-obj: 0.876470
            No improvement (1.0566), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.4465, mae: 1.2058, huber: 0.8571, swd: 1.2739, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 7.0723, mae: 1.4091, huber: 1.0580, swd: 1.5927, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.2710, mae: 1.6026, huber: 1.2420, swd: 2.1142, target_std: 4.7534
      Epoch 6 composite train-obj: 0.857114
            No improvement (1.0580), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.2900, mae: 1.1871, huber: 0.8392, swd: 1.2295, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 7.1743, mae: 1.4328, huber: 1.0808, swd: 1.6915, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.5003, mae: 1.6087, huber: 1.2489, swd: 2.0515, target_std: 4.7534
      Epoch 7 composite train-obj: 0.839174
            No improvement (1.0808), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.0740, mae: 1.1565, huber: 0.8105, swd: 1.1462, target_std: 6.5011
    Epoch [8/50], Val Losses: mse: 7.3427, mae: 1.4596, huber: 1.1055, swd: 1.8386, target_std: 4.2875
    Epoch [8/50], Test Losses: mse: 9.6842, mae: 1.6437, huber: 1.2808, swd: 2.3294, target_std: 4.7534
      Epoch 8 composite train-obj: 0.810456
    Epoch [8/50], Test Losses: mse: 8.8386, mae: 1.5781, huber: 1.2186, swd: 1.9283, target_std: 4.7534
    Best round's Test MSE: 8.8388, MAE: 1.5781, SWD: 1.9283
    Best round's Validation MSE: 6.7561, MAE: 1.3748
    Best round's Test verification MSE : 8.8386, MAE: 1.5781, SWD: 1.9283
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1713, mae: 1.5953, huber: 1.2210, swd: 3.4633, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 6.9735, mae: 1.4212, huber: 1.0669, swd: 1.5683, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 8.9586, mae: 1.6150, huber: 1.2531, swd: 2.0657, target_std: 4.7534
      Epoch 1 composite train-obj: 1.221023
            Val objective improved inf → 1.0669, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1867, mae: 1.3179, huber: 0.9608, swd: 1.5921, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 6.6878, mae: 1.3736, huber: 1.0211, swd: 1.4397, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 8.9007, mae: 1.6028, huber: 1.2402, swd: 2.1194, target_std: 4.7534
      Epoch 2 composite train-obj: 0.960789
            Val objective improved 1.0669 → 1.0211, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.9517, mae: 1.2773, huber: 0.9238, swd: 1.4869, target_std: 6.5012
    Epoch [3/50], Val Losses: mse: 6.7161, mae: 1.3523, huber: 1.0036, swd: 1.2553, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 8.7845, mae: 1.5683, huber: 1.2084, swd: 1.7509, target_std: 4.7534
      Epoch 3 composite train-obj: 0.923810
            Val objective improved 1.0211 → 1.0036, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.7663, mae: 1.2483, huber: 0.8971, swd: 1.4098, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.8207, mae: 1.3720, huber: 1.0225, swd: 1.4391, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 8.9036, mae: 1.5767, huber: 1.2166, swd: 1.9280, target_std: 4.7534
      Epoch 4 composite train-obj: 0.897108
            No improvement (1.0225), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.6077, mae: 1.2256, huber: 0.8759, swd: 1.3510, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.7215, mae: 1.3855, huber: 1.0347, swd: 1.6296, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.1166, mae: 1.5973, huber: 1.2369, swd: 2.1835, target_std: 4.7534
      Epoch 5 composite train-obj: 0.875897
            No improvement (1.0347), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.4974, mae: 1.2127, huber: 0.8637, swd: 1.3283, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 7.0374, mae: 1.4004, huber: 1.0496, swd: 1.6153, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.3381, mae: 1.6061, huber: 1.2454, swd: 2.1038, target_std: 4.7534
      Epoch 6 composite train-obj: 0.863725
            No improvement (1.0496), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.2903, mae: 1.1834, huber: 0.8361, swd: 1.2420, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 6.8909, mae: 1.3998, huber: 1.0488, swd: 1.6319, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.4754, mae: 1.6044, huber: 1.2448, swd: 2.0453, target_std: 4.7534
      Epoch 7 composite train-obj: 0.836091
            No improvement (1.0488), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.1071, mae: 1.1615, huber: 0.8152, swd: 1.1929, target_std: 6.5011
    Epoch [8/50], Val Losses: mse: 6.8787, mae: 1.4131, huber: 1.0605, swd: 1.7802, target_std: 4.2875
    Epoch [8/50], Test Losses: mse: 9.5372, mae: 1.6243, huber: 1.2629, swd: 2.1877, target_std: 4.7534
      Epoch 8 composite train-obj: 0.815183
    Epoch [8/50], Test Losses: mse: 8.7848, mae: 1.5682, huber: 1.2084, swd: 1.7509, target_std: 4.7534
    Best round's Test MSE: 8.7845, MAE: 1.5683, SWD: 1.7509
    Best round's Validation MSE: 6.7161, MAE: 1.3523
    Best round's Test verification MSE : 8.7848, MAE: 1.5682, SWD: 1.7509
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2159, mae: 1.6028, huber: 1.2281, swd: 3.0860, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 7.0960, mae: 1.4334, huber: 1.0787, swd: 1.4580, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 8.9909, mae: 1.6261, huber: 1.2630, swd: 1.9070, target_std: 4.7534
      Epoch 1 composite train-obj: 1.228100
            Val objective improved inf → 1.0787, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1766, mae: 1.3171, huber: 0.9598, swd: 1.3953, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.7245, mae: 1.3742, huber: 1.0238, swd: 1.3382, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 8.6999, mae: 1.5750, huber: 1.2146, swd: 1.8138, target_std: 4.7534
      Epoch 2 composite train-obj: 0.959759
            Val objective improved 1.0787 → 1.0238, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.9677, mae: 1.2815, huber: 0.9274, swd: 1.3201, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.8679, mae: 1.3907, huber: 1.0402, swd: 1.3717, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 8.8210, mae: 1.5863, huber: 1.2254, swd: 1.8883, target_std: 4.7534
      Epoch 3 composite train-obj: 0.927439
            No improvement (1.0402), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.7917, mae: 1.2547, huber: 0.9026, swd: 1.2592, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.9225, mae: 1.3858, huber: 1.0361, swd: 1.3173, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 8.7759, mae: 1.5806, huber: 1.2195, swd: 1.8198, target_std: 4.7534
      Epoch 4 composite train-obj: 0.902563
            No improvement (1.0361), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.6269, mae: 1.2328, huber: 0.8821, swd: 1.2083, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.7978, mae: 1.3792, huber: 1.0283, swd: 1.2999, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.1089, mae: 1.5884, huber: 1.2272, swd: 1.7773, target_std: 4.7534
      Epoch 5 composite train-obj: 0.882087
            No improvement (1.0283), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.4776, mae: 1.2127, huber: 0.8631, swd: 1.1613, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.8488, mae: 1.3978, huber: 1.0452, swd: 1.4410, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.3267, mae: 1.6183, huber: 1.2551, swd: 1.9847, target_std: 4.7534
      Epoch 6 composite train-obj: 0.863071
            No improvement (1.0452), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.2586, mae: 1.1826, huber: 0.8347, swd: 1.0853, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 7.1588, mae: 1.4327, huber: 1.0795, swd: 1.6283, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.6481, mae: 1.6420, huber: 1.2794, swd: 2.1821, target_std: 4.7534
      Epoch 7 composite train-obj: 0.834726
    Epoch [7/50], Test Losses: mse: 8.7004, mae: 1.5750, huber: 1.2146, swd: 1.8135, target_std: 4.7534
    Best round's Test MSE: 8.6999, MAE: 1.5750, SWD: 1.8138
    Best round's Validation MSE: 6.7245, MAE: 1.3742
    Best round's Test verification MSE : 8.7004, MAE: 1.5750, SWD: 1.8135
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred196_20250429_1759)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.7744 ± 0.0572
      mae: 1.5738 ± 0.0041
      huber: 1.2139 ± 0.0042
      swd: 1.8310 ± 0.0734
      target_std: 4.7534 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.7322 ± 0.0172
      mae: 1.3671 ± 0.0105
      huber: 1.0172 ± 0.0096
      swd: 1.3245 ± 0.0518
      target_std: 4.2875 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred196_20250429_1759
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 336-336 

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3162, mae: 1.7278, huber: 1.3452, swd: 3.3523, ept: 128.8043
    Epoch [1/50], Val Losses: mse: 8.6288, mae: 1.5933, huber: 1.2280, swd: 1.5577, ept: 141.6576
    Epoch [1/50], Test Losses: mse: 10.3636, mae: 1.7823, huber: 1.4070, swd: 2.0218, ept: 109.7072
      Epoch 1 composite train-obj: 1.345165
            Val objective improved inf → 1.2280, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9510, mae: 1.4431, huber: 1.0751, swd: 1.6534, ept: 152.0902
    Epoch [2/50], Val Losses: mse: 8.3009, mae: 1.5351, huber: 1.1768, swd: 1.4955, ept: 152.1699
    Epoch [2/50], Test Losses: mse: 10.0088, mae: 1.7288, huber: 1.3585, swd: 1.9623, ept: 118.0737
      Epoch 2 composite train-obj: 1.075148
            Val objective improved 1.2280 → 1.1768, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6678, mae: 1.3943, huber: 1.0311, swd: 1.5152, ept: 159.7791
    Epoch [3/50], Val Losses: mse: 8.4463, mae: 1.5711, huber: 1.2111, swd: 1.8624, ept: 155.5427
    Epoch [3/50], Test Losses: mse: 9.8966, mae: 1.7285, huber: 1.3583, swd: 2.2550, ept: 121.7871
      Epoch 3 composite train-obj: 1.031060
            No improvement (1.2111), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5107, mae: 1.3691, huber: 1.0079, swd: 1.4456, ept: 163.5733
    Epoch [4/50], Val Losses: mse: 8.3314, mae: 1.5669, huber: 1.2075, swd: 1.9445, ept: 153.8529
    Epoch [4/50], Test Losses: mse: 9.7659, mae: 1.7260, huber: 1.3558, swd: 2.2925, ept: 121.8142
      Epoch 4 composite train-obj: 1.007886
            No improvement (1.2075), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3821, mae: 1.3496, huber: 0.9900, swd: 1.3983, ept: 166.0237
    Epoch [5/50], Val Losses: mse: 8.8260, mae: 1.6163, huber: 1.2569, swd: 2.1501, ept: 155.6680
    Epoch [5/50], Test Losses: mse: 9.8641, mae: 1.7295, huber: 1.3600, swd: 2.2470, ept: 123.0563
      Epoch 5 composite train-obj: 0.989988
            No improvement (1.2569), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2126, mae: 1.3260, huber: 0.9680, swd: 1.3301, ept: 168.0291
    Epoch [6/50], Val Losses: mse: 9.0712, mae: 1.6268, huber: 1.2670, swd: 2.0366, ept: 156.7957
    Epoch [6/50], Test Losses: mse: 10.2806, mae: 1.7503, huber: 1.3793, swd: 2.0556, ept: 123.1180
      Epoch 6 composite train-obj: 0.967952
            No improvement (1.2670), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0547, mae: 1.3056, huber: 0.9487, swd: 1.2717, ept: 169.4753
    Epoch [7/50], Val Losses: mse: 9.2220, mae: 1.6542, huber: 1.2951, swd: 2.4350, ept: 158.7093
    Epoch [7/50], Test Losses: mse: 10.4395, mae: 1.7564, huber: 1.3870, swd: 2.3070, ept: 124.7925
      Epoch 7 composite train-obj: 0.948711
    Epoch [7/50], Test Losses: mse: 10.0083, mae: 1.7287, huber: 1.3585, swd: 1.9623, ept: 118.0540
    Best round's Test MSE: 10.0088, MAE: 1.7288, SWD: 1.9623
    Best round's Validation MSE: 8.3009, MAE: 1.5351, SWD: 1.4955
    Best round's Test verification MSE : 10.0083, MAE: 1.7287, SWD: 1.9623
    Time taken: 83.00 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3906, mae: 1.7247, huber: 1.3430, swd: 3.6732, ept: 129.1649
    Epoch [1/50], Val Losses: mse: 8.3450, mae: 1.5595, huber: 1.1970, swd: 1.5801, ept: 145.0523
    Epoch [1/50], Test Losses: mse: 10.1649, mae: 1.7614, huber: 1.3879, swd: 2.0859, ept: 111.0627
      Epoch 1 composite train-obj: 1.343007
            Val objective improved inf → 1.1970, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9079, mae: 1.4347, huber: 1.0682, swd: 1.7002, ept: 153.9447
    Epoch [2/50], Val Losses: mse: 8.1078, mae: 1.5256, huber: 1.1681, swd: 1.6940, ept: 152.5946
    Epoch [2/50], Test Losses: mse: 9.7259, mae: 1.7133, huber: 1.3437, swd: 2.1657, ept: 119.6202
      Epoch 2 composite train-obj: 1.068237
            Val objective improved 1.1970 → 1.1681, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6455, mae: 1.3906, huber: 1.0278, swd: 1.5657, ept: 160.8830
    Epoch [3/50], Val Losses: mse: 8.2377, mae: 1.5474, huber: 1.1892, swd: 1.8947, ept: 154.7723
    Epoch [3/50], Test Losses: mse: 9.7473, mae: 1.7125, huber: 1.3437, swd: 2.2904, ept: 121.1276
      Epoch 3 composite train-obj: 1.027794
            No improvement (1.1892), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5267, mae: 1.3727, huber: 1.0113, swd: 1.5348, ept: 163.5891
    Epoch [4/50], Val Losses: mse: 8.1223, mae: 1.5330, huber: 1.1754, swd: 1.7753, ept: 157.3211
    Epoch [4/50], Test Losses: mse: 9.7535, mae: 1.7096, huber: 1.3392, swd: 2.0901, ept: 123.4054
      Epoch 4 composite train-obj: 1.011332
            No improvement (1.1754), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3546, mae: 1.3475, huber: 0.9879, swd: 1.4575, ept: 166.1246
    Epoch [5/50], Val Losses: mse: 8.8452, mae: 1.6173, huber: 1.2544, swd: 2.0112, ept: 152.4681
    Epoch [5/50], Test Losses: mse: 10.0998, mae: 1.7418, huber: 1.3692, swd: 2.1018, ept: 122.0039
      Epoch 5 composite train-obj: 0.987866
            No improvement (1.2544), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2030, mae: 1.3258, huber: 0.9676, swd: 1.3994, ept: 168.2713
    Epoch [6/50], Val Losses: mse: 9.2072, mae: 1.6491, huber: 1.2891, swd: 2.3254, ept: 160.0954
    Epoch [6/50], Test Losses: mse: 10.0572, mae: 1.7405, huber: 1.3700, swd: 2.3821, ept: 124.5416
      Epoch 6 composite train-obj: 0.967620
            No improvement (1.2891), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0044, mae: 1.2999, huber: 0.9430, swd: 1.3111, ept: 169.9575
    Epoch [7/50], Val Losses: mse: 9.1966, mae: 1.6645, huber: 1.3041, swd: 2.5695, ept: 157.5898
    Epoch [7/50], Test Losses: mse: 10.3791, mae: 1.7685, huber: 1.3977, swd: 2.6788, ept: 123.6689
      Epoch 7 composite train-obj: 0.943031
    Epoch [7/50], Test Losses: mse: 9.7263, mae: 1.7134, huber: 1.3437, swd: 2.1658, ept: 119.6130
    Best round's Test MSE: 9.7259, MAE: 1.7133, SWD: 2.1657
    Best round's Validation MSE: 8.1078, MAE: 1.5256, SWD: 1.6940
    Best round's Test verification MSE : 9.7263, MAE: 1.7134, SWD: 2.1658
    Time taken: 74.31 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4735, mae: 1.7373, huber: 1.3549, swd: 3.5637, ept: 128.4622
    Epoch [1/50], Val Losses: mse: 8.3900, mae: 1.5686, huber: 1.2055, swd: 1.5967, ept: 141.9286
    Epoch [1/50], Test Losses: mse: 10.3639, mae: 1.7864, huber: 1.4120, swd: 2.3252, ept: 109.4834
      Epoch 1 composite train-obj: 1.354916
            Val objective improved inf → 1.2055, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9426, mae: 1.4399, huber: 1.0729, swd: 1.6170, ept: 153.8194
    Epoch [2/50], Val Losses: mse: 8.4824, mae: 1.5714, huber: 1.2059, swd: 1.4813, ept: 144.8817
    Epoch [2/50], Test Losses: mse: 10.1057, mae: 1.7481, huber: 1.3733, swd: 2.0072, ept: 116.4811
      Epoch 2 composite train-obj: 1.072862
            No improvement (1.2059), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6639, mae: 1.3935, huber: 1.0304, swd: 1.4987, ept: 160.7671
    Epoch [3/50], Val Losses: mse: 8.3646, mae: 1.5575, huber: 1.1990, swd: 1.7959, ept: 152.7591
    Epoch [3/50], Test Losses: mse: 9.8338, mae: 1.7196, huber: 1.3501, swd: 2.2872, ept: 120.9976
      Epoch 3 composite train-obj: 1.030352
            Val objective improved 1.2055 → 1.1990, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.5058, mae: 1.3683, huber: 1.0072, swd: 1.4343, ept: 164.0830
    Epoch [4/50], Val Losses: mse: 8.3939, mae: 1.5663, huber: 1.2072, swd: 1.7636, ept: 154.4788
    Epoch [4/50], Test Losses: mse: 9.8577, mae: 1.7179, huber: 1.3481, swd: 2.1938, ept: 122.3623
      Epoch 4 composite train-obj: 1.007174
            No improvement (1.2072), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.3518, mae: 1.3470, huber: 0.9874, swd: 1.3838, ept: 166.5241
    Epoch [5/50], Val Losses: mse: 8.5491, mae: 1.5730, huber: 1.2146, swd: 1.7760, ept: 156.3976
    Epoch [5/50], Test Losses: mse: 10.0725, mae: 1.7269, huber: 1.3571, swd: 2.1204, ept: 123.7189
      Epoch 5 composite train-obj: 0.987372
            No improvement (1.2146), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.1959, mae: 1.3263, huber: 0.9679, swd: 1.3317, ept: 168.1273
    Epoch [6/50], Val Losses: mse: 8.9060, mae: 1.6113, huber: 1.2533, swd: 2.0306, ept: 156.1782
    Epoch [6/50], Test Losses: mse: 10.3357, mae: 1.7501, huber: 1.3799, swd: 2.2435, ept: 123.8638
      Epoch 6 composite train-obj: 0.967881
            No improvement (1.2533), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.0015, mae: 1.2996, huber: 0.9427, swd: 1.2501, ept: 169.8972
    Epoch [7/50], Val Losses: mse: 8.9988, mae: 1.6166, huber: 1.2586, swd: 2.0934, ept: 159.9639
    Epoch [7/50], Test Losses: mse: 10.5941, mae: 1.7689, huber: 1.3985, swd: 2.3651, ept: 124.5505
      Epoch 7 composite train-obj: 0.942735
            No improvement (1.2586), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8093, mae: 1.2749, huber: 0.9192, swd: 1.1798, ept: 171.7046
    Epoch [8/50], Val Losses: mse: 9.0661, mae: 1.6384, huber: 1.2782, swd: 2.3179, ept: 155.4630
    Epoch [8/50], Test Losses: mse: 10.6590, mae: 1.7959, huber: 1.4230, swd: 2.6787, ept: 123.7681
      Epoch 8 composite train-obj: 0.919191
    Epoch [8/50], Test Losses: mse: 9.8339, mae: 1.7196, huber: 1.3501, swd: 2.2871, ept: 120.9825
    Best round's Test MSE: 9.8338, MAE: 1.7196, SWD: 2.2872
    Best round's Validation MSE: 8.3646, MAE: 1.5575, SWD: 1.7959
    Best round's Test verification MSE : 9.8339, MAE: 1.7196, SWD: 2.2871
    Time taken: 86.19 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250512_1435)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.8562 ± 0.1165
      mae: 1.7206 ± 0.0063
      huber: 1.3508 ± 0.0061
      swd: 2.1384 ± 0.1340
      ept: 119.5638 ± 1.1944
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.2578 ± 0.1092
      mae: 1.5394 ± 0.0134
      huber: 1.1813 ± 0.0130
      swd: 1.6618 ± 0.1247
      ept: 152.5079 ± 0.2483
      count: 50.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 243.59 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250512_1435
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

##### model I


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only',
    # single_magnitude_for_shift=True,
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False,
    

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3162, mae: 1.7278, huber: 1.3452, swd: 3.3523, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 8.6288, mae: 1.5933, huber: 1.2280, swd: 1.5577, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3636, mae: 1.7823, huber: 1.4070, swd: 2.0218, target_std: 4.7502
      Epoch 1 composite train-obj: 1.345165
            Val objective improved inf → 1.2280, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9510, mae: 1.4431, huber: 1.0751, swd: 1.6534, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 8.3009, mae: 1.5351, huber: 1.1768, swd: 1.4955, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.0088, mae: 1.7288, huber: 1.3585, swd: 1.9623, target_std: 4.7502
      Epoch 2 composite train-obj: 1.075148
            Val objective improved 1.2280 → 1.1768, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6678, mae: 1.3943, huber: 1.0311, swd: 1.5152, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.4463, mae: 1.5711, huber: 1.2111, swd: 1.8624, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.8966, mae: 1.7285, huber: 1.3583, swd: 2.2550, target_std: 4.7502
      Epoch 3 composite train-obj: 1.031060
            No improvement (1.2111), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5107, mae: 1.3691, huber: 1.0079, swd: 1.4456, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.3314, mae: 1.5669, huber: 1.2075, swd: 1.9445, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.7659, mae: 1.7260, huber: 1.3558, swd: 2.2925, target_std: 4.7502
      Epoch 4 composite train-obj: 1.007886
            No improvement (1.2075), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3821, mae: 1.3496, huber: 0.9900, swd: 1.3983, target_std: 6.5008
    Epoch [5/50], Val Losses: mse: 8.8260, mae: 1.6163, huber: 1.2569, swd: 2.1501, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 9.8641, mae: 1.7295, huber: 1.3600, swd: 2.2470, target_std: 4.7502
      Epoch 5 composite train-obj: 0.989988
            No improvement (1.2569), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2126, mae: 1.3260, huber: 0.9680, swd: 1.3301, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 9.0712, mae: 1.6268, huber: 1.2670, swd: 2.0366, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.2806, mae: 1.7503, huber: 1.3793, swd: 2.0556, target_std: 4.7502
      Epoch 6 composite train-obj: 0.967952
            No improvement (1.2670), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0547, mae: 1.3056, huber: 0.9487, swd: 1.2717, target_std: 6.5008
    Epoch [7/50], Val Losses: mse: 9.2220, mae: 1.6542, huber: 1.2951, swd: 2.4350, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.4395, mae: 1.7564, huber: 1.3870, swd: 2.3070, target_std: 4.7502
      Epoch 7 composite train-obj: 0.948711
    Epoch [7/50], Test Losses: mse: 10.0083, mae: 1.7287, huber: 1.3585, swd: 1.9623, target_std: 4.7502
    Best round's Test MSE: 10.0088, MAE: 1.7288, SWD: 1.9623
    Best round's Validation MSE: 8.3009, MAE: 1.5351, SWD: 1.4955
    Best round's Test verification MSE : 10.0083, MAE: 1.7287, SWD: 1.9623
    Time taken: 71.10 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3906, mae: 1.7247, huber: 1.3430, swd: 3.6732, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 8.3450, mae: 1.5595, huber: 1.1970, swd: 1.5801, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.1649, mae: 1.7614, huber: 1.3879, swd: 2.0859, target_std: 4.7502
      Epoch 1 composite train-obj: 1.343007
            Val objective improved inf → 1.1970, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9079, mae: 1.4347, huber: 1.0682, swd: 1.7002, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.1078, mae: 1.5256, huber: 1.1681, swd: 1.6940, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.7259, mae: 1.7133, huber: 1.3437, swd: 2.1657, target_std: 4.7502
      Epoch 2 composite train-obj: 1.068237
            Val objective improved 1.1970 → 1.1681, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6455, mae: 1.3906, huber: 1.0278, swd: 1.5657, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 8.2377, mae: 1.5474, huber: 1.1892, swd: 1.8947, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.7473, mae: 1.7125, huber: 1.3437, swd: 2.2904, target_std: 4.7502
      Epoch 3 composite train-obj: 1.027794
            No improvement (1.1892), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5267, mae: 1.3727, huber: 1.0113, swd: 1.5348, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.1223, mae: 1.5330, huber: 1.1754, swd: 1.7753, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.7535, mae: 1.7096, huber: 1.3392, swd: 2.0901, target_std: 4.7502
      Epoch 4 composite train-obj: 1.011332
            No improvement (1.1754), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3546, mae: 1.3475, huber: 0.9879, swd: 1.4575, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 8.8452, mae: 1.6173, huber: 1.2544, swd: 2.0112, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.0998, mae: 1.7418, huber: 1.3692, swd: 2.1018, target_std: 4.7502
      Epoch 5 composite train-obj: 0.987866
            No improvement (1.2544), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2030, mae: 1.3258, huber: 0.9676, swd: 1.3994, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 9.2072, mae: 1.6491, huber: 1.2891, swd: 2.3254, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.0572, mae: 1.7405, huber: 1.3700, swd: 2.3821, target_std: 4.7502
      Epoch 6 composite train-obj: 0.967620
            No improvement (1.2891), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0044, mae: 1.2999, huber: 0.9430, swd: 1.3111, target_std: 6.5013
    Epoch [7/50], Val Losses: mse: 9.1966, mae: 1.6645, huber: 1.3041, swd: 2.5695, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.3791, mae: 1.7685, huber: 1.3977, swd: 2.6788, target_std: 4.7502
      Epoch 7 composite train-obj: 0.943031
    Epoch [7/50], Test Losses: mse: 9.7263, mae: 1.7134, huber: 1.3437, swd: 2.1658, target_std: 4.7502
    Best round's Test MSE: 9.7259, MAE: 1.7133, SWD: 2.1657
    Best round's Validation MSE: 8.1078, MAE: 1.5256, SWD: 1.6940
    Best round's Test verification MSE : 9.7263, MAE: 1.7134, SWD: 2.1658
    Time taken: 72.21 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4735, mae: 1.7373, huber: 1.3549, swd: 3.5637, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 8.3900, mae: 1.5686, huber: 1.2055, swd: 1.5967, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3639, mae: 1.7864, huber: 1.4120, swd: 2.3252, target_std: 4.7502
      Epoch 1 composite train-obj: 1.354916
            Val objective improved inf → 1.2055, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9426, mae: 1.4399, huber: 1.0729, swd: 1.6170, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.4824, mae: 1.5714, huber: 1.2059, swd: 1.4813, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.1057, mae: 1.7481, huber: 1.3733, swd: 2.0072, target_std: 4.7502
      Epoch 2 composite train-obj: 1.072862
            No improvement (1.2059), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6639, mae: 1.3935, huber: 1.0304, swd: 1.4987, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.3646, mae: 1.5575, huber: 1.1990, swd: 1.7959, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.8338, mae: 1.7196, huber: 1.3501, swd: 2.2872, target_std: 4.7502
      Epoch 3 composite train-obj: 1.030352
            Val objective improved 1.2055 → 1.1990, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.5058, mae: 1.3683, huber: 1.0072, swd: 1.4343, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.3939, mae: 1.5663, huber: 1.2072, swd: 1.7636, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.8577, mae: 1.7179, huber: 1.3481, swd: 2.1938, target_std: 4.7502
      Epoch 4 composite train-obj: 1.007174
            No improvement (1.2072), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.3518, mae: 1.3470, huber: 0.9874, swd: 1.3838, target_std: 6.5010
    Epoch [5/50], Val Losses: mse: 8.5491, mae: 1.5730, huber: 1.2146, swd: 1.7760, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.0725, mae: 1.7269, huber: 1.3571, swd: 2.1204, target_std: 4.7502
      Epoch 5 composite train-obj: 0.987372
            No improvement (1.2146), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.1959, mae: 1.3263, huber: 0.9679, swd: 1.3317, target_std: 6.5013
    Epoch [6/50], Val Losses: mse: 8.9060, mae: 1.6113, huber: 1.2533, swd: 2.0306, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.3357, mae: 1.7501, huber: 1.3799, swd: 2.2435, target_std: 4.7502
      Epoch 6 composite train-obj: 0.967881
            No improvement (1.2533), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.0015, mae: 1.2996, huber: 0.9427, swd: 1.2501, target_std: 6.5013
    Epoch [7/50], Val Losses: mse: 8.9988, mae: 1.6166, huber: 1.2586, swd: 2.0934, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.5941, mae: 1.7689, huber: 1.3985, swd: 2.3651, target_std: 4.7502
      Epoch 7 composite train-obj: 0.942735
            No improvement (1.2586), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8093, mae: 1.2749, huber: 0.9192, swd: 1.1798, target_std: 6.5009
    Epoch [8/50], Val Losses: mse: 9.0661, mae: 1.6384, huber: 1.2782, swd: 2.3179, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.6590, mae: 1.7959, huber: 1.4230, swd: 2.6787, target_std: 4.7502
      Epoch 8 composite train-obj: 0.919191
    Epoch [8/50], Test Losses: mse: 9.8339, mae: 1.7196, huber: 1.3501, swd: 2.2871, target_std: 4.7502
    Best round's Test MSE: 9.8338, MAE: 1.7196, SWD: 2.2872
    Best round's Validation MSE: 8.3646, MAE: 1.5575, SWD: 1.7959
    Best round's Test verification MSE : 9.8339, MAE: 1.7196, SWD: 2.2871
    Time taken: 87.12 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250509_0302)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.8562 ± 0.1165
      mae: 1.7206 ± 0.0063
      huber: 1.3508 ± 0.0061
      swd: 2.1384 ± 0.1340
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.2578 ± 0.1092
      mae: 1.5394 ± 0.0134
      huber: 1.1813 ± 0.0130
      swd: 1.6618 ± 0.1247
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 230.51 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250509_0302
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### model II


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=True,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only',
    # single_magnitude_for_shift=True,
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=True,
    

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1648, mae: 1.6279, huber: 1.2529, swd: 2.5374, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 8.6214, mae: 1.5452, huber: 1.1853, swd: 1.2324, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.7615, mae: 1.7650, huber: 1.3967, swd: 1.7994, target_std: 4.7502
      Epoch 1 composite train-obj: 1.252850
            Val objective improved inf → 1.1853, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9023, mae: 1.4158, huber: 1.0518, swd: 1.5764, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 8.4763, mae: 1.5583, huber: 1.2010, swd: 1.7522, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.0904, mae: 1.7257, huber: 1.3582, swd: 2.1014, target_std: 4.7502
      Epoch 2 composite train-obj: 1.051804
            No improvement (1.2010), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6586, mae: 1.3786, huber: 1.0174, swd: 1.4648, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.8846, mae: 1.5929, huber: 1.2355, swd: 1.8797, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.1306, mae: 1.7247, huber: 1.3582, swd: 2.1156, target_std: 4.7502
      Epoch 3 composite train-obj: 1.017373
            No improvement (1.2355), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.4662, mae: 1.3517, huber: 0.9922, swd: 1.3780, target_std: 6.5009
    Epoch [4/50], Val Losses: mse: 9.1745, mae: 1.6355, huber: 1.2775, swd: 2.1683, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.2589, mae: 1.7418, huber: 1.3736, swd: 2.1213, target_std: 4.7502
      Epoch 4 composite train-obj: 0.992180
            No improvement (1.2775), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.2244, mae: 1.3192, huber: 0.9616, swd: 1.2696, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 9.1765, mae: 1.6413, huber: 1.2829, swd: 2.2577, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.4488, mae: 1.7667, huber: 1.3965, swd: 2.3267, target_std: 4.7502
      Epoch 5 composite train-obj: 0.961572
            No improvement (1.2829), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.9864, mae: 1.2910, huber: 0.9346, swd: 1.1826, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 8.8874, mae: 1.6150, huber: 1.2570, swd: 2.2093, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.7259, mae: 1.7820, huber: 1.4116, swd: 2.4251, target_std: 4.7502
      Epoch 6 composite train-obj: 0.934614
    Epoch [6/50], Test Losses: mse: 10.7614, mae: 1.7650, huber: 1.3967, swd: 1.7993, target_std: 4.7502
    Best round's Test MSE: 10.7615, MAE: 1.7650, SWD: 1.7994
    Best round's Validation MSE: 8.6214, MAE: 1.5452, SWD: 1.2324
    Best round's Test verification MSE : 10.7614, MAE: 1.7650, SWD: 1.7993
    Time taken: 61.20 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.9999, mae: 1.6123, huber: 1.2382, swd: 2.6216, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 8.3970, mae: 1.5273, huber: 1.1711, swd: 1.4946, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.4391, mae: 1.7387, huber: 1.3727, swd: 2.0603, target_std: 4.7502
      Epoch 1 composite train-obj: 1.238194
            Val objective improved inf → 1.1711, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8827, mae: 1.4127, huber: 1.0489, swd: 1.6233, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.8998, mae: 1.6052, huber: 1.2468, swd: 1.9903, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.2208, mae: 1.7332, huber: 1.3666, swd: 2.2522, target_std: 4.7502
      Epoch 2 composite train-obj: 1.048948
            No improvement (1.2468), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6684, mae: 1.3793, huber: 1.0182, swd: 1.5239, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 9.1905, mae: 1.6490, huber: 1.2895, swd: 2.3358, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.1008, mae: 1.7379, huber: 1.3692, swd: 2.3646, target_std: 4.7502
      Epoch 3 composite train-obj: 1.018184
            No improvement (1.2895), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.5215, mae: 1.3582, huber: 0.9986, swd: 1.4629, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 9.3113, mae: 1.6412, huber: 1.2826, swd: 2.1279, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.1878, mae: 1.7349, huber: 1.3663, swd: 2.1100, target_std: 4.7502
      Epoch 4 composite train-obj: 0.998559
            No improvement (1.2826), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.3443, mae: 1.3343, huber: 0.9761, swd: 1.3850, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 9.0702, mae: 1.6234, huber: 1.2648, swd: 2.0764, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.3074, mae: 1.7556, huber: 1.3854, swd: 2.2302, target_std: 4.7502
      Epoch 5 composite train-obj: 0.976082
            No improvement (1.2648), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.1101, mae: 1.3040, huber: 0.9473, swd: 1.2809, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 9.1282, mae: 1.6367, huber: 1.2782, swd: 2.2447, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.2637, mae: 1.7580, huber: 1.3871, swd: 2.3613, target_std: 4.7502
      Epoch 6 composite train-obj: 0.947332
    Epoch [6/50], Test Losses: mse: 10.4391, mae: 1.7387, huber: 1.3727, swd: 2.0603, target_std: 4.7502
    Best round's Test MSE: 10.4391, MAE: 1.7387, SWD: 2.0603
    Best round's Validation MSE: 8.3970, MAE: 1.5273, SWD: 1.4946
    Best round's Test verification MSE : 10.4391, MAE: 1.7387, SWD: 2.0603
    Time taken: 59.06 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.8324, mae: 1.6058, huber: 1.2319, swd: 2.5500, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 8.4110, mae: 1.5202, huber: 1.1638, swd: 1.3668, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3814, mae: 1.7293, huber: 1.3634, swd: 2.0113, target_std: 4.7502
      Epoch 1 composite train-obj: 1.231917
            Val objective improved inf → 1.1638, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8652, mae: 1.4089, huber: 1.0457, swd: 1.5399, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 9.0166, mae: 1.6181, huber: 1.2600, swd: 2.0591, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.2864, mae: 1.7326, huber: 1.3669, swd: 2.2839, target_std: 4.7502
      Epoch 2 composite train-obj: 1.045653
            No improvement (1.2600), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6728, mae: 1.3788, huber: 1.0178, swd: 1.4617, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 9.6881, mae: 1.6750, huber: 1.3148, swd: 2.2007, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.4277, mae: 1.7410, huber: 1.3735, swd: 2.1139, target_std: 4.7502
      Epoch 3 composite train-obj: 1.017820
            No improvement (1.3148), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.4885, mae: 1.3517, huber: 0.9925, swd: 1.3764, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 9.7635, mae: 1.6933, huber: 1.3347, swd: 2.5049, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.2950, mae: 1.7433, huber: 1.3757, swd: 2.3196, target_std: 4.7502
      Epoch 4 composite train-obj: 0.992548
            No improvement (1.3347), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.3166, mae: 1.3282, huber: 0.9704, swd: 1.3056, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 9.2239, mae: 1.6704, huber: 1.3083, swd: 2.3512, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.1339, mae: 1.7661, huber: 1.3934, swd: 2.5263, target_std: 4.7502
      Epoch 5 composite train-obj: 0.970360
            No improvement (1.3083), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.1206, mae: 1.3030, huber: 0.9465, swd: 1.2372, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 9.2656, mae: 1.6361, huber: 1.2767, swd: 2.0047, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.4151, mae: 1.7536, huber: 1.3826, swd: 2.2086, target_std: 4.7502
      Epoch 6 composite train-obj: 0.946526
    Epoch [6/50], Test Losses: mse: 10.3813, mae: 1.7292, huber: 1.3634, swd: 2.0112, target_std: 4.7502
    Best round's Test MSE: 10.3814, MAE: 1.7293, SWD: 2.0113
    Best round's Validation MSE: 8.4110, MAE: 1.5202, SWD: 1.3668
    Best round's Test verification MSE : 10.3813, MAE: 1.7292, SWD: 2.0112
    Time taken: 63.25 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250509_0259)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5273 ± 0.1672
      mae: 1.7443 ± 0.0151
      huber: 1.3776 ± 0.0140
      swd: 1.9570 ± 0.1132
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.4765 ± 0.1027
      mae: 1.5309 ± 0.0105
      huber: 1.1734 ± 0.0089
      swd: 1.3646 ± 0.1071
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 184.91 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250509_0259
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### model III


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 4,
    householder_reflects_data = 8,
    mixing_strategy='delay_only',
    # single_magnitude_for_shift=True,
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False,
    

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU,
                                              nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1518, mae: 1.7202, huber: 1.3378, swd: 3.3301, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 8.2471, mae: 1.5595, huber: 1.1966, swd: 1.7501, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3845, mae: 1.7932, huber: 1.4187, swd: 2.4308, target_std: 4.7502
      Epoch 1 composite train-obj: 1.337767
            Val objective improved inf → 1.1966, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9162, mae: 1.4355, huber: 1.0688, swd: 1.6231, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 8.4396, mae: 1.5937, huber: 1.2319, swd: 2.1651, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.7780, mae: 1.7424, huber: 1.3707, swd: 2.4729, target_std: 4.7502
      Epoch 2 composite train-obj: 1.068813
            No improvement (1.2319), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6640, mae: 1.3920, huber: 1.0292, swd: 1.5066, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 8.2139, mae: 1.5325, huber: 1.1744, swd: 1.5967, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.6696, mae: 1.7016, huber: 1.3328, swd: 1.9587, target_std: 4.7502
      Epoch 3 composite train-obj: 1.029191
            Val objective improved 1.1966 → 1.1744, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.5441, mae: 1.3734, huber: 1.0121, swd: 1.4761, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.3066, mae: 1.5465, huber: 1.1877, swd: 1.7003, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.8126, mae: 1.7089, huber: 1.3393, swd: 1.9672, target_std: 4.7502
      Epoch 4 composite train-obj: 1.012059
            No improvement (1.1877), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.3695, mae: 1.3490, huber: 0.9892, swd: 1.3919, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 8.6070, mae: 1.6005, huber: 1.2401, swd: 2.1145, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.0816, mae: 1.7422, huber: 1.3719, swd: 2.3271, target_std: 4.7502
      Epoch 5 composite train-obj: 0.989240
            No improvement (1.2401), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.2168, mae: 1.3270, huber: 0.9686, swd: 1.3387, target_std: 6.5009
    Epoch [6/50], Val Losses: mse: 9.2332, mae: 1.6564, huber: 1.2970, swd: 2.4428, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.4288, mae: 1.7597, huber: 1.3898, swd: 2.3953, target_std: 4.7502
      Epoch 6 composite train-obj: 0.968590
            No improvement (1.2970), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.0601, mae: 1.3076, huber: 0.9503, swd: 1.2945, target_std: 6.5010
    Epoch [7/50], Val Losses: mse: 9.6922, mae: 1.7048, huber: 1.3449, swd: 2.7288, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.5561, mae: 1.7606, huber: 1.3920, swd: 2.2891, target_std: 4.7502
      Epoch 7 composite train-obj: 0.950277
            No improvement (1.3449), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8286, mae: 1.2762, huber: 0.9205, swd: 1.1908, target_std: 6.5012
    Epoch [8/50], Val Losses: mse: 9.5094, mae: 1.6774, huber: 1.3176, swd: 2.5026, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.8562, mae: 1.7851, huber: 1.4154, swd: 2.4727, target_std: 4.7502
      Epoch 8 composite train-obj: 0.920525
    Epoch [8/50], Test Losses: mse: 9.6693, mae: 1.7015, huber: 1.3328, swd: 1.9586, target_std: 4.7502
    Best round's Test MSE: 9.6696, MAE: 1.7016, SWD: 1.9587
    Best round's Validation MSE: 8.2139, MAE: 1.5325, SWD: 1.5967
    Best round's Test verification MSE : 9.6693, MAE: 1.7015, SWD: 1.9586
    Time taken: 125.80 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.2077, mae: 1.7230, huber: 1.3407, swd: 3.5583, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 8.4034, mae: 1.5714, huber: 1.2082, swd: 1.6971, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3407, mae: 1.7935, huber: 1.4189, swd: 2.3852, target_std: 4.7502
      Epoch 1 composite train-obj: 1.340700
            Val objective improved inf → 1.2082, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8773, mae: 1.4296, huber: 1.0635, swd: 1.6507, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.2580, mae: 1.5334, huber: 1.1752, swd: 1.5866, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.7751, mae: 1.7075, huber: 1.3389, swd: 1.9453, target_std: 4.7502
      Epoch 2 composite train-obj: 1.063540
            Val objective improved 1.2082 → 1.1752, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6843, mae: 1.3965, huber: 1.0335, swd: 1.6072, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.3872, mae: 1.5411, huber: 1.1840, swd: 1.7611, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.8811, mae: 1.7252, huber: 1.3559, swd: 2.3130, target_std: 4.7502
      Epoch 3 composite train-obj: 1.033517
            No improvement (1.1840), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4778, mae: 1.3654, huber: 1.0045, swd: 1.4921, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 8.1744, mae: 1.5327, huber: 1.1763, swd: 1.7427, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.7608, mae: 1.6991, huber: 1.3309, swd: 2.0337, target_std: 4.7502
      Epoch 4 composite train-obj: 1.004515
            No improvement (1.1763), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3390, mae: 1.3452, huber: 0.9858, swd: 1.4433, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 8.5838, mae: 1.5727, huber: 1.2121, swd: 1.8659, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.1187, mae: 1.7295, huber: 1.3588, swd: 2.1899, target_std: 4.7502
      Epoch 5 composite train-obj: 0.985791
            No improvement (1.2121), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1911, mae: 1.3252, huber: 0.9669, swd: 1.3950, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 8.5587, mae: 1.5736, huber: 1.2148, swd: 1.8625, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.1518, mae: 1.7253, huber: 1.3557, swd: 2.0964, target_std: 4.7502
      Epoch 6 composite train-obj: 0.966950
            No improvement (1.2148), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0249, mae: 1.3031, huber: 0.9462, swd: 1.3290, target_std: 6.5009
    Epoch [7/50], Val Losses: mse: 8.6854, mae: 1.5834, huber: 1.2246, swd: 2.0186, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.3238, mae: 1.7442, huber: 1.3737, swd: 2.2377, target_std: 4.7502
      Epoch 7 composite train-obj: 0.946162
    Epoch [7/50], Test Losses: mse: 9.7752, mae: 1.7075, huber: 1.3389, swd: 1.9454, target_std: 4.7502
    Best round's Test MSE: 9.7751, MAE: 1.7075, SWD: 1.9453
    Best round's Validation MSE: 8.2580, MAE: 1.5334, SWD: 1.5866
    Best round's Test verification MSE : 9.7752, MAE: 1.7075, SWD: 1.9454
    Time taken: 93.29 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1072, mae: 1.7078, huber: 1.3265, swd: 3.4210, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 8.3898, mae: 1.5634, huber: 1.2020, swd: 1.6233, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.1845, mae: 1.7761, huber: 1.4034, swd: 2.3081, target_std: 4.7502
      Epoch 1 composite train-obj: 1.326508
            Val objective improved inf → 1.2020, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8824, mae: 1.4289, huber: 1.0632, swd: 1.5884, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.1967, mae: 1.5418, huber: 1.1836, swd: 1.7699, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.7548, mae: 1.7224, huber: 1.3532, swd: 2.3658, target_std: 4.7502
      Epoch 2 composite train-obj: 1.063175
            Val objective improved 1.2020 → 1.1836, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6454, mae: 1.3903, huber: 1.0277, swd: 1.4881, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 8.1817, mae: 1.5328, huber: 1.1751, swd: 1.6443, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.7707, mae: 1.7073, huber: 1.3387, swd: 2.1291, target_std: 4.7502
      Epoch 3 composite train-obj: 1.027655
            Val objective improved 1.1836 → 1.1751, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.5101, mae: 1.3696, huber: 1.0085, swd: 1.4454, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 8.3264, mae: 1.5508, huber: 1.1925, swd: 1.8121, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.9825, mae: 1.7239, huber: 1.3541, swd: 2.3556, target_std: 4.7502
      Epoch 4 composite train-obj: 1.008537
            No improvement (1.1925), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.3439, mae: 1.3455, huber: 0.9859, swd: 1.3809, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 8.6128, mae: 1.5939, huber: 1.2344, swd: 1.9457, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 9.9519, mae: 1.7286, huber: 1.3591, swd: 2.2850, target_std: 4.7502
      Epoch 5 composite train-obj: 0.985948
            No improvement (1.2344), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.1961, mae: 1.3260, huber: 0.9676, swd: 1.3245, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 8.8158, mae: 1.6085, huber: 1.2496, swd: 2.0632, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.2251, mae: 1.7434, huber: 1.3732, swd: 2.3989, target_std: 4.7502
      Epoch 6 composite train-obj: 0.967632
            No improvement (1.2496), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.0210, mae: 1.3031, huber: 0.9459, swd: 1.2554, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 9.3023, mae: 1.6646, huber: 1.3035, swd: 2.3320, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.5581, mae: 1.7725, huber: 1.4022, swd: 2.5352, target_std: 4.7502
      Epoch 7 composite train-obj: 0.945868
            No improvement (1.3035), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8769, mae: 1.2850, huber: 0.9286, swd: 1.2148, target_std: 6.5011
    Epoch [8/50], Val Losses: mse: 9.0545, mae: 1.6335, huber: 1.2738, swd: 2.1989, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.6216, mae: 1.7525, huber: 1.3827, swd: 2.2248, target_std: 4.7502
      Epoch 8 composite train-obj: 0.928627
    Epoch [8/50], Test Losses: mse: 9.7710, mae: 1.7073, huber: 1.3388, swd: 2.1290, target_std: 4.7502
    Best round's Test MSE: 9.7707, MAE: 1.7073, SWD: 2.1291
    Best round's Validation MSE: 8.1817, MAE: 1.5328, SWD: 1.6443
    Best round's Test verification MSE : 9.7710, MAE: 1.7073, SWD: 2.1290
    Time taken: 98.66 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250509_0306)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.7385 ± 0.0488
      mae: 1.7054 ± 0.0028
      huber: 1.3368 ± 0.0028
      swd: 2.0111 ± 0.0837
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.2179 ± 0.0313
      mae: 1.5329 ± 0.0004
      huber: 1.1749 ± 0.0003
      swd: 1.6092 ± 0.0251
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 317.85 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250509_0306
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_336_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1980, mae: 1.7196, huber: 1.3374, swd: 3.4891, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 8.2247, mae: 1.5374, huber: 1.1778, swd: 1.5112, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.2393, mae: 1.7633, huber: 1.3917, swd: 2.0907, target_std: 4.7502
      Epoch 1 composite train-obj: 1.337442
            Val objective improved inf → 1.1778, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8862, mae: 1.4271, huber: 1.0613, swd: 1.5994, target_std: 6.5013
    Epoch [2/50], Val Losses: mse: 8.1487, mae: 1.5354, huber: 1.1760, swd: 1.7487, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.7541, mae: 1.7301, huber: 1.3580, swd: 2.2214, target_std: 4.7502
      Epoch 2 composite train-obj: 1.061255
            Val objective improved 1.1778 → 1.1760, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.7109, mae: 1.3966, huber: 1.0338, swd: 1.5502, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.1387, mae: 1.5334, huber: 1.1762, swd: 1.7620, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.7063, mae: 1.7100, huber: 1.3409, swd: 2.2106, target_std: 4.7502
      Epoch 3 composite train-obj: 1.033835
            No improvement (1.1762), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4985, mae: 1.3641, huber: 1.0038, swd: 1.4509, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.2450, mae: 1.5606, huber: 1.2025, swd: 2.0361, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.8967, mae: 1.7376, huber: 1.3667, swd: 2.4704, target_std: 4.7502
      Epoch 4 composite train-obj: 1.003825
            No improvement (1.2025), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.3394, mae: 1.3419, huber: 0.9832, swd: 1.3979, target_std: 6.5010
    Epoch [5/50], Val Losses: mse: 8.2790, mae: 1.5465, huber: 1.1883, swd: 1.8314, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.0953, mae: 1.7480, huber: 1.3764, swd: 2.2665, target_std: 4.7502
      Epoch 5 composite train-obj: 0.983155
            No improvement (1.1883), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1822, mae: 1.3216, huber: 0.9641, swd: 1.3411, target_std: 6.5009
    Epoch [6/50], Val Losses: mse: 8.8364, mae: 1.6178, huber: 1.2574, swd: 2.2678, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.4654, mae: 1.7753, huber: 1.4039, swd: 2.4908, target_std: 4.7502
      Epoch 6 composite train-obj: 0.964099
            No improvement (1.2574), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.9631, mae: 1.2917, huber: 0.9358, swd: 1.2544, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 9.2060, mae: 1.6424, huber: 1.2822, swd: 2.1675, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.3815, mae: 1.7482, huber: 1.3787, swd: 2.0658, target_std: 4.7502
      Epoch 7 composite train-obj: 0.935795
    Epoch [7/50], Test Losses: mse: 9.7543, mae: 1.7301, huber: 1.3581, swd: 2.2216, target_std: 4.7502
    Best round's Test MSE: 9.7541, MAE: 1.7301, SWD: 2.2214
    Best round's Validation MSE: 8.1487, MAE: 1.5354
    Best round's Test verification MSE : 9.7543, MAE: 1.7301, SWD: 2.2216
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3567, mae: 1.7272, huber: 1.3450, swd: 3.6954, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 8.1600, mae: 1.5323, huber: 1.1722, swd: 1.5384, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3465, mae: 1.7670, huber: 1.3955, swd: 2.2456, target_std: 4.7502
      Epoch 1 composite train-obj: 1.344953
            Val objective improved inf → 1.1722, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9397, mae: 1.4341, huber: 1.0679, swd: 1.7045, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 8.1843, mae: 1.5335, huber: 1.1757, swd: 1.8200, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.8466, mae: 1.7227, huber: 1.3527, swd: 2.2718, target_std: 4.7502
      Epoch 2 composite train-obj: 1.067937
            No improvement (1.1757), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6345, mae: 1.3844, huber: 1.0222, swd: 1.5410, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 8.2132, mae: 1.5430, huber: 1.1849, swd: 1.8668, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.9408, mae: 1.7254, huber: 1.3554, swd: 2.2516, target_std: 4.7502
      Epoch 3 composite train-obj: 1.022227
            No improvement (1.1849), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.5271, mae: 1.3693, huber: 1.0084, swd: 1.5293, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.2343, mae: 1.5379, huber: 1.1814, swd: 1.7688, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 9.9935, mae: 1.7198, huber: 1.3510, swd: 2.1409, target_std: 4.7502
      Epoch 4 composite train-obj: 1.008417
            No improvement (1.1814), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.3449, mae: 1.3438, huber: 0.9847, swd: 1.4534, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 8.6189, mae: 1.5723, huber: 1.2149, swd: 1.8437, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.1583, mae: 1.7276, huber: 1.3589, swd: 2.0541, target_std: 4.7502
      Epoch 5 composite train-obj: 0.984750
            No improvement (1.2149), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.2182, mae: 1.3276, huber: 0.9695, swd: 1.4309, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 8.6750, mae: 1.5819, huber: 1.2224, swd: 1.9642, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.2797, mae: 1.7477, huber: 1.3747, swd: 2.2318, target_std: 4.7502
      Epoch 6 composite train-obj: 0.969524
    Epoch [6/50], Test Losses: mse: 10.3470, mae: 1.7670, huber: 1.3956, swd: 2.2461, target_std: 4.7502
    Best round's Test MSE: 10.3465, MAE: 1.7670, SWD: 2.2456
    Best round's Validation MSE: 8.1600, MAE: 1.5323
    Best round's Test verification MSE : 10.3470, MAE: 1.7670, SWD: 2.2461
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.3344, mae: 1.7230, huber: 1.3416, swd: 3.5285, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 8.3760, mae: 1.5735, huber: 1.2104, swd: 1.8345, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3841, mae: 1.7959, huber: 1.4214, swd: 2.6141, target_std: 4.7502
      Epoch 1 composite train-obj: 1.341609
            Val objective improved inf → 1.2104, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9596, mae: 1.4349, huber: 1.0691, swd: 1.6117, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.5611, mae: 1.5748, huber: 1.2141, swd: 1.7770, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.1399, mae: 1.7487, huber: 1.3778, swd: 2.2980, target_std: 4.7502
      Epoch 2 composite train-obj: 1.069109
            No improvement (1.2141), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6932, mae: 1.3931, huber: 1.0303, swd: 1.5011, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.8815, mae: 1.6262, huber: 1.2660, swd: 2.2070, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.1158, mae: 1.7490, huber: 1.3780, swd: 2.3537, target_std: 4.7502
      Epoch 3 composite train-obj: 1.030319
            No improvement (1.2660), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.4859, mae: 1.3623, huber: 1.0016, swd: 1.4191, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 9.7571, mae: 1.7366, huber: 1.3751, swd: 2.9891, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.3111, mae: 1.7841, huber: 1.4122, swd: 2.7282, target_std: 4.7502
      Epoch 4 composite train-obj: 1.001647
            No improvement (1.3751), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.3056, mae: 1.3362, huber: 0.9775, swd: 1.3554, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 9.3401, mae: 1.6690, huber: 1.3096, swd: 2.4361, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.2737, mae: 1.7585, huber: 1.3877, swd: 2.3653, target_std: 4.7502
      Epoch 5 composite train-obj: 0.977529
            No improvement (1.3096), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.1212, mae: 1.3107, huber: 0.9536, swd: 1.2887, target_std: 6.5008
    Epoch [6/50], Val Losses: mse: 9.4212, mae: 1.6706, huber: 1.3113, swd: 2.5873, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.9505, mae: 1.8042, huber: 1.4319, swd: 2.5415, target_std: 4.7502
      Epoch 6 composite train-obj: 0.953571
    Epoch [6/50], Test Losses: mse: 10.3836, mae: 1.7959, huber: 1.4214, swd: 2.6142, target_std: 4.7502
    Best round's Test MSE: 10.3841, MAE: 1.7959, SWD: 2.6141
    Best round's Validation MSE: 8.3760, MAE: 1.5735
    Best round's Test verification MSE : 10.3836, MAE: 1.7959, SWD: 2.6142
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250429_1835)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.1616 ± 0.2885
      mae: 1.7643 ± 0.0269
      huber: 1.3917 ± 0.0260
      swd: 2.3604 ± 0.1797
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.2282 ± 0.1046
      mae: 1.5471 ± 0.0187
      huber: 1.1862 ± 0.0172
      swd: 1.7072 ± 0.1244
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250429_1835
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_336_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9402, mae: 1.8071, huber: 1.4164, swd: 3.7249, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 8.4629, mae: 1.5860, huber: 1.2247, swd: 1.9920, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.4724, mae: 1.7896, huber: 1.4180, swd: 2.4979, target_std: 4.7502
      Epoch 1 composite train-obj: 1.416418
            Val objective improved inf → 1.2247, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0485, mae: 1.4533, huber: 1.0849, swd: 1.6828, target_std: 6.5013
    Epoch [2/50], Val Losses: mse: 8.3968, mae: 1.5875, huber: 1.2243, swd: 2.1705, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.1180, mae: 1.7770, huber: 1.4012, swd: 2.5169, target_std: 4.7502
      Epoch 2 composite train-obj: 1.084869
            Val objective improved 1.2247 → 1.2243, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.8184, mae: 1.4149, huber: 1.0503, swd: 1.6013, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.6551, mae: 1.5943, huber: 1.2347, swd: 2.3106, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.0075, mae: 1.7338, huber: 1.3630, swd: 2.3482, target_std: 4.7502
      Epoch 3 composite train-obj: 1.050336
            No improvement (1.2347), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5612, mae: 1.3763, huber: 1.0145, swd: 1.4698, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.9128, mae: 1.6398, huber: 1.2776, swd: 2.7007, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.2638, mae: 1.7689, huber: 1.3964, swd: 2.6966, target_std: 4.7502
      Epoch 4 composite train-obj: 1.014512
            No improvement (1.2776), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4067, mae: 1.3533, huber: 0.9931, swd: 1.4132, target_std: 6.5010
    Epoch [5/50], Val Losses: mse: 9.8656, mae: 1.6888, huber: 1.3279, swd: 2.9632, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.6376, mae: 1.7848, huber: 1.4127, swd: 2.4846, target_std: 4.7502
      Epoch 5 composite train-obj: 0.993101
            No improvement (1.3279), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2357, mae: 1.3303, huber: 0.9716, swd: 1.3547, target_std: 6.5009
    Epoch [6/50], Val Losses: mse: 10.8560, mae: 1.8017, huber: 1.4365, swd: 3.6875, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.2153, mae: 1.8518, huber: 1.4775, swd: 2.8535, target_std: 4.7502
      Epoch 6 composite train-obj: 0.971623
            No improvement (1.4365), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0162, mae: 1.2998, huber: 0.9428, swd: 1.2529, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 11.1291, mae: 1.7966, huber: 1.4356, swd: 3.5172, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 11.2780, mae: 1.8384, huber: 1.4658, swd: 2.6876, target_std: 4.7502
      Epoch 7 composite train-obj: 0.942799
    Epoch [7/50], Test Losses: mse: 10.1183, mae: 1.7770, huber: 1.4013, swd: 2.5172, target_std: 4.7502
    Best round's Test MSE: 10.1180, MAE: 1.7770, SWD: 2.5169
    Best round's Validation MSE: 8.3968, MAE: 1.5875
    Best round's Test verification MSE : 10.1183, MAE: 1.7770, SWD: 2.5172
    Time taken: 128.46 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.6413, mae: 1.7784, huber: 1.3889, swd: 3.7516, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 9.3340, mae: 1.6905, huber: 1.3180, swd: 1.9057, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 11.4673, mae: 1.9033, huber: 1.5223, swd: 2.4617, target_std: 4.7502
      Epoch 1 composite train-obj: 1.388906
            Val objective improved inf → 1.3180, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.1008, mae: 1.4606, huber: 1.0916, swd: 1.7564, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 8.3534, mae: 1.5582, huber: 1.1987, swd: 1.9226, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 9.9771, mae: 1.7313, huber: 1.3608, swd: 2.2780, target_std: 4.7502
      Epoch 2 composite train-obj: 1.091591
            Val objective improved 1.3180 → 1.1987, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.7545, mae: 1.4041, huber: 1.0400, swd: 1.5717, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 8.4213, mae: 1.5708, huber: 1.2106, swd: 2.0597, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.1387, mae: 1.7432, huber: 1.3724, swd: 2.3994, target_std: 4.7502
      Epoch 3 composite train-obj: 1.039979
            No improvement (1.2106), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.6371, mae: 1.3862, huber: 1.0238, swd: 1.5525, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 8.6833, mae: 1.5910, huber: 1.2321, swd: 2.1248, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.1928, mae: 1.7379, huber: 1.3684, swd: 2.3010, target_std: 4.7502
      Epoch 4 composite train-obj: 1.023796
            No improvement (1.2321), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4314, mae: 1.3565, huber: 0.9962, swd: 1.4530, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 9.1265, mae: 1.6283, huber: 1.2689, swd: 2.1939, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.1816, mae: 1.7292, huber: 1.3606, swd: 2.1293, target_std: 4.7502
      Epoch 5 composite train-obj: 0.996179
            No improvement (1.2689), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2906, mae: 1.3389, huber: 0.9795, swd: 1.4118, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 9.2737, mae: 1.6393, huber: 1.2788, swd: 2.3986, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.7331, mae: 1.7810, huber: 1.4094, swd: 2.5646, target_std: 4.7502
      Epoch 6 composite train-obj: 0.979509
            No improvement (1.2788), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.1154, mae: 1.3158, huber: 0.9579, swd: 1.3477, target_std: 6.5009
    Epoch [7/50], Val Losses: mse: 9.0314, mae: 1.6199, huber: 1.2594, swd: 2.2391, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.7781, mae: 1.7785, huber: 1.4059, swd: 2.4345, target_std: 4.7502
      Epoch 7 composite train-obj: 0.957872
    Epoch [7/50], Test Losses: mse: 9.9774, mae: 1.7314, huber: 1.3609, swd: 2.2785, target_std: 4.7502
    Best round's Test MSE: 9.9771, MAE: 1.7313, SWD: 2.2780
    Best round's Validation MSE: 8.3534, MAE: 1.5582
    Best round's Test verification MSE : 9.9774, MAE: 1.7314, SWD: 2.2785
    Time taken: 129.79 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.1197, mae: 1.8276, huber: 1.4344, swd: 3.8603, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 8.6342, mae: 1.6116, huber: 1.2465, swd: 2.0747, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.5816, mae: 1.8094, huber: 1.4341, swd: 2.7087, target_std: 4.7502
      Epoch 1 composite train-obj: 1.434433
            Val objective improved inf → 1.2465, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2355, mae: 1.5080, huber: 1.1308, swd: 1.8476, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 8.5306, mae: 1.5727, huber: 1.2129, swd: 1.8488, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.1145, mae: 1.7466, huber: 1.3767, swd: 2.2981, target_std: 4.7502
      Epoch 2 composite train-obj: 1.130848
            Val objective improved 1.2465 → 1.2129, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.8754, mae: 1.4333, huber: 1.0649, swd: 1.5943, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 8.5171, mae: 1.5871, huber: 1.2272, swd: 2.0442, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.0264, mae: 1.7345, huber: 1.3639, swd: 2.2618, target_std: 4.7502
      Epoch 3 composite train-obj: 1.064916
            No improvement (1.2272), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.6441, mae: 1.3922, huber: 1.0283, swd: 1.4842, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 8.7061, mae: 1.6169, huber: 1.2568, swd: 2.3080, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.1514, mae: 1.7503, huber: 1.3794, swd: 2.5159, target_std: 4.7502
      Epoch 4 composite train-obj: 1.028270
            No improvement (1.2568), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4550, mae: 1.3643, huber: 1.0025, swd: 1.4090, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 9.1212, mae: 1.6423, huber: 1.2823, swd: 2.3214, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.1771, mae: 1.7495, huber: 1.3788, swd: 2.3834, target_std: 4.7502
      Epoch 5 composite train-obj: 1.002540
            No improvement (1.2823), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.3001, mae: 1.3424, huber: 0.9821, swd: 1.3562, target_std: 6.5008
    Epoch [6/50], Val Losses: mse: 9.0930, mae: 1.6319, huber: 1.2724, swd: 2.2854, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.6514, mae: 1.7809, huber: 1.4083, swd: 2.4429, target_std: 4.7502
      Epoch 6 composite train-obj: 0.982131
            No improvement (1.2724), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0945, mae: 1.3148, huber: 0.9559, swd: 1.2713, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 9.5532, mae: 1.6621, huber: 1.3029, swd: 2.4182, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.9395, mae: 1.7929, huber: 1.4204, swd: 2.3528, target_std: 4.7502
      Epoch 7 composite train-obj: 0.955926
    Epoch [7/50], Test Losses: mse: 10.1148, mae: 1.7467, huber: 1.3768, swd: 2.2988, target_std: 4.7502
    Best round's Test MSE: 10.1145, MAE: 1.7466, SWD: 2.2981
    Best round's Validation MSE: 8.5306, MAE: 1.5727
    Best round's Test verification MSE : 10.1148, MAE: 1.7467, SWD: 2.2988
    Time taken: 196.11 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250502_2232)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.0699 ± 0.0656
      mae: 1.7516 ± 0.0190
      huber: 1.3796 ± 0.0166
      swd: 2.3644 ± 0.1082
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.4270 ± 0.0754
      mae: 1.5728 ± 0.0120
      huber: 1.2120 ± 0.0105
      swd: 1.9806 ± 0.1376
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 456.06 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250502_2232
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 336-720


##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9782, mae: 1.8280, huber: 1.4385, swd: 3.3959, ept: 186.3981
    Epoch [1/50], Val Losses: mse: 10.2265, mae: 1.7445, huber: 1.3766, swd: 2.1355, ept: 193.0685
    Epoch [1/50], Test Losses: mse: 11.1016, mae: 1.9015, huber: 1.5186, swd: 2.3992, ept: 175.2262
      Epoch 1 composite train-obj: 1.438493
            Val objective improved inf → 1.3766, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6654, mae: 1.5582, huber: 1.1816, swd: 1.6545, ept: 225.0446
    Epoch [2/50], Val Losses: mse: 10.3845, mae: 1.7547, huber: 1.3899, swd: 2.3910, ept: 203.3563
    Epoch [2/50], Test Losses: mse: 10.4675, mae: 1.8444, huber: 1.4652, swd: 2.3894, ept: 186.1216
      Epoch 2 composite train-obj: 1.181641
            No improvement (1.3899), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.3697, mae: 1.5141, huber: 1.1411, swd: 1.5269, ept: 237.6164
    Epoch [3/50], Val Losses: mse: 10.2865, mae: 1.7677, huber: 1.4018, swd: 2.5990, ept: 205.3351
    Epoch [3/50], Test Losses: mse: 10.3161, mae: 1.8395, huber: 1.4586, swd: 2.4125, ept: 191.7525
      Epoch 3 composite train-obj: 1.141067
            No improvement (1.4018), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.2470, mae: 1.4962, huber: 1.1246, swd: 1.4991, ept: 242.4009
    Epoch [4/50], Val Losses: mse: 10.3621, mae: 1.7605, huber: 1.3973, swd: 2.5007, ept: 205.3452
    Epoch [4/50], Test Losses: mse: 10.3996, mae: 1.8362, huber: 1.4561, swd: 2.2245, ept: 188.9173
      Epoch 4 composite train-obj: 1.124608
            No improvement (1.3973), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.0678, mae: 1.4704, huber: 1.1004, swd: 1.4101, ept: 246.7569
    Epoch [5/50], Val Losses: mse: 10.6647, mae: 1.8047, huber: 1.4403, swd: 2.8828, ept: 207.5477
    Epoch [5/50], Test Losses: mse: 10.6461, mae: 1.8575, huber: 1.4767, swd: 2.5248, ept: 185.3443
      Epoch 5 composite train-obj: 1.100442
            No improvement (1.4403), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.9211, mae: 1.4500, huber: 1.0811, swd: 1.3509, ept: 249.8640
    Epoch [6/50], Val Losses: mse: 9.9188, mae: 1.7379, huber: 1.3735, swd: 2.5225, ept: 208.4248
    Epoch [6/50], Test Losses: mse: 10.8513, mae: 1.8591, huber: 1.4775, swd: 2.3700, ept: 190.1697
      Epoch 6 composite train-obj: 1.081148
            Val objective improved 1.3766 → 1.3735, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 5.7515, mae: 1.4251, huber: 1.0576, swd: 1.2821, ept: 252.6389
    Epoch [7/50], Val Losses: mse: 10.4432, mae: 1.8021, huber: 1.4364, swd: 3.0169, ept: 212.8456
    Epoch [7/50], Test Losses: mse: 11.4542, mae: 1.9072, huber: 1.5242, swd: 2.7146, ept: 184.5431
      Epoch 7 composite train-obj: 1.057584
            No improvement (1.4364), counter 1/5
    Epoch [8/50], Train Losses: mse: 5.5833, mae: 1.3996, huber: 1.0337, swd: 1.2046, ept: 255.7080
    Epoch [8/50], Val Losses: mse: 10.8035, mae: 1.8305, huber: 1.4641, swd: 3.0919, ept: 212.2900
    Epoch [8/50], Test Losses: mse: 11.3965, mae: 1.9041, huber: 1.5203, swd: 2.5922, ept: 182.5983
      Epoch 8 composite train-obj: 1.033684
            No improvement (1.4641), counter 2/5
    Epoch [9/50], Train Losses: mse: 5.4250, mae: 1.3762, huber: 1.0115, swd: 1.1380, ept: 258.0783
    Epoch [9/50], Val Losses: mse: 10.9474, mae: 1.8551, huber: 1.4877, swd: 3.3042, ept: 212.7966
    Epoch [9/50], Test Losses: mse: 11.8711, mae: 1.9397, huber: 1.5552, swd: 2.8478, ept: 181.7585
      Epoch 9 composite train-obj: 1.011496
            No improvement (1.4877), counter 3/5
    Epoch [10/50], Train Losses: mse: 5.2586, mae: 1.3525, huber: 0.9891, swd: 1.0759, ept: 260.6578
    Epoch [10/50], Val Losses: mse: 11.0048, mae: 1.8458, huber: 1.4784, swd: 3.2018, ept: 206.6331
    Epoch [10/50], Test Losses: mse: 12.2836, mae: 1.9501, huber: 1.5657, swd: 2.5808, ept: 179.1082
      Epoch 10 composite train-obj: 0.989055
            No improvement (1.4784), counter 4/5
    Epoch [11/50], Train Losses: mse: 5.0153, mae: 1.3190, huber: 0.9571, swd: 0.9546, ept: 263.7967
    Epoch [11/50], Val Losses: mse: 10.4917, mae: 1.7962, huber: 1.4292, swd: 2.8852, ept: 215.0417
    Epoch [11/50], Test Losses: mse: 12.1944, mae: 1.9516, huber: 1.5679, swd: 2.7466, ept: 178.3602
      Epoch 11 composite train-obj: 0.957057
    Epoch [11/50], Test Losses: mse: 10.8511, mae: 1.8590, huber: 1.4775, swd: 2.3701, ept: 190.1868
    Best round's Test MSE: 10.8513, MAE: 1.8591, SWD: 2.3700
    Best round's Validation MSE: 9.9188, MAE: 1.7379, SWD: 2.5225
    Best round's Test verification MSE : 10.8511, MAE: 1.8590, SWD: 2.3701
    Time taken: 115.58 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8510, mae: 1.8140, huber: 1.4253, swd: 3.1840, ept: 188.9851
    Epoch [1/50], Val Losses: mse: 10.1727, mae: 1.7369, huber: 1.3694, swd: 1.8748, ept: 192.9479
    Epoch [1/50], Test Losses: mse: 10.9353, mae: 1.8857, huber: 1.5040, swd: 2.2403, ept: 174.6223
      Epoch 1 composite train-obj: 1.425336
            Val objective improved inf → 1.3694, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5816, mae: 1.5482, huber: 1.1721, swd: 1.5296, ept: 226.0979
    Epoch [2/50], Val Losses: mse: 10.1602, mae: 1.7217, huber: 1.3580, swd: 1.9273, ept: 202.4921
    Epoch [2/50], Test Losses: mse: 10.6302, mae: 1.8483, huber: 1.4686, swd: 2.1009, ept: 182.5183
      Epoch 2 composite train-obj: 1.172055
            Val objective improved 1.3694 → 1.3580, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3576, mae: 1.5144, huber: 1.1412, swd: 1.4508, ept: 236.1278
    Epoch [3/50], Val Losses: mse: 10.2493, mae: 1.7586, huber: 1.3926, swd: 2.3483, ept: 198.7191
    Epoch [3/50], Test Losses: mse: 10.5044, mae: 1.8617, huber: 1.4798, swd: 2.5236, ept: 186.6104
      Epoch 3 composite train-obj: 1.141194
            No improvement (1.3926), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.1780, mae: 1.4877, huber: 1.1165, swd: 1.3741, ept: 242.6375
    Epoch [4/50], Val Losses: mse: 10.5746, mae: 1.7972, huber: 1.4328, swd: 2.6213, ept: 210.3981
    Epoch [4/50], Test Losses: mse: 10.5751, mae: 1.8578, huber: 1.4771, swd: 2.5292, ept: 189.7346
      Epoch 4 composite train-obj: 1.116473
            No improvement (1.4328), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.0541, mae: 1.4691, huber: 1.0992, swd: 1.3394, ept: 246.5368
    Epoch [5/50], Val Losses: mse: 10.7679, mae: 1.7965, huber: 1.4338, swd: 2.4897, ept: 207.7703
    Epoch [5/50], Test Losses: mse: 10.7407, mae: 1.8580, huber: 1.4772, swd: 2.2660, ept: 185.9210
      Epoch 5 composite train-obj: 1.099165
            No improvement (1.4338), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.8793, mae: 1.4441, huber: 1.0756, swd: 1.2588, ept: 250.4690
    Epoch [6/50], Val Losses: mse: 10.5438, mae: 1.7769, huber: 1.4124, swd: 2.4064, ept: 205.7406
    Epoch [6/50], Test Losses: mse: 11.3362, mae: 1.8896, huber: 1.5065, swd: 2.2412, ept: 181.7735
      Epoch 6 composite train-obj: 1.075588
            No improvement (1.4124), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.7073, mae: 1.4184, huber: 1.0513, swd: 1.1932, ept: 253.3432
    Epoch [7/50], Val Losses: mse: 10.2645, mae: 1.7487, huber: 1.3859, swd: 2.2922, ept: 215.6978
    Epoch [7/50], Test Losses: mse: 11.2930, mae: 1.8970, huber: 1.5154, swd: 2.5448, ept: 183.8388
      Epoch 7 composite train-obj: 1.051346
    Epoch [7/50], Test Losses: mse: 10.6301, mae: 1.8483, huber: 1.4686, swd: 2.1008, ept: 182.5276
    Best round's Test MSE: 10.6302, MAE: 1.8483, SWD: 2.1009
    Best round's Validation MSE: 10.1602, MAE: 1.7217, SWD: 1.9273
    Best round's Test verification MSE : 10.6301, MAE: 1.8483, SWD: 2.1008
    Time taken: 73.93 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9560, mae: 1.8199, huber: 1.4311, swd: 3.4630, ept: 186.8614
    Epoch [1/50], Val Losses: mse: 10.3080, mae: 1.7575, huber: 1.3888, swd: 2.3081, ept: 190.6378
    Epoch [1/50], Test Losses: mse: 10.8052, mae: 1.8896, huber: 1.5067, swd: 2.5677, ept: 175.2668
      Epoch 1 composite train-obj: 1.431113
            Val objective improved inf → 1.3888, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5798, mae: 1.5475, huber: 1.1719, swd: 1.6741, ept: 227.1848
    Epoch [2/50], Val Losses: mse: 9.9904, mae: 1.7240, huber: 1.3598, swd: 2.3872, ept: 204.7931
    Epoch [2/50], Test Losses: mse: 10.3866, mae: 1.8410, huber: 1.4611, swd: 2.3786, ept: 188.7551
      Epoch 2 composite train-obj: 1.171924
            Val objective improved 1.3888 → 1.3598, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3520, mae: 1.5136, huber: 1.1407, swd: 1.5922, ept: 238.1961
    Epoch [3/50], Val Losses: mse: 10.3357, mae: 1.7841, huber: 1.4180, swd: 2.9148, ept: 207.5657
    Epoch [3/50], Test Losses: mse: 10.5686, mae: 1.8599, huber: 1.4784, swd: 2.6877, ept: 190.2441
      Epoch 3 composite train-obj: 1.140709
            No improvement (1.4180), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.1490, mae: 1.4841, huber: 1.1132, swd: 1.4923, ept: 244.6497
    Epoch [4/50], Val Losses: mse: 10.4841, mae: 1.7700, huber: 1.4074, swd: 2.6610, ept: 211.4751
    Epoch [4/50], Test Losses: mse: 10.6491, mae: 1.8471, huber: 1.4668, swd: 2.2068, ept: 187.3180
      Epoch 4 composite train-obj: 1.113160
            No improvement (1.4074), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.9948, mae: 1.4608, huber: 1.0914, swd: 1.4210, ept: 248.9380
    Epoch [5/50], Val Losses: mse: 10.7772, mae: 1.8316, huber: 1.4650, swd: 3.1625, ept: 208.2570
    Epoch [5/50], Test Losses: mse: 10.7456, mae: 1.8799, huber: 1.4972, swd: 2.8557, ept: 188.7947
      Epoch 5 composite train-obj: 1.091373
            No improvement (1.4650), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.8543, mae: 1.4409, huber: 1.0726, swd: 1.3732, ept: 251.3201
    Epoch [6/50], Val Losses: mse: 11.0465, mae: 1.8477, huber: 1.4831, swd: 3.1368, ept: 210.1530
    Epoch [6/50], Test Losses: mse: 10.7532, mae: 1.8604, huber: 1.4802, swd: 2.5237, ept: 187.8467
      Epoch 6 composite train-obj: 1.072600
            No improvement (1.4831), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.7149, mae: 1.4188, huber: 1.0519, swd: 1.3168, ept: 253.5966
    Epoch [7/50], Val Losses: mse: 10.6724, mae: 1.8320, huber: 1.4652, swd: 3.2216, ept: 211.8577
    Epoch [7/50], Test Losses: mse: 11.1268, mae: 1.8920, huber: 1.5099, swd: 2.8674, ept: 186.9642
      Epoch 7 composite train-obj: 1.051872
    Epoch [7/50], Test Losses: mse: 10.3864, mae: 1.8410, huber: 1.4610, swd: 2.3785, ept: 188.7672
    Best round's Test MSE: 10.3866, MAE: 1.8410, SWD: 2.3786
    Best round's Validation MSE: 9.9904, MAE: 1.7240, SWD: 2.3872
    Best round's Test verification MSE : 10.3864, MAE: 1.8410, SWD: 2.3785
    Time taken: 74.17 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred720_20250512_1439)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.6227 ± 0.1898
      mae: 1.8495 ± 0.0074
      huber: 1.4691 ± 0.0067
      swd: 2.2832 ± 0.1290
      ept: 187.1477 ± 3.3240
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.0231 ± 0.1012
      mae: 1.7279 ± 0.0072
      huber: 1.3637 ± 0.0069
      swd: 2.2790 ± 0.2548
      ept: 205.2367 ± 2.4423
      count: 47.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 263.78 seconds
    
    Experiment complete: ACL_ettm1_seq336_pred720_20250512_1439
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_336_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4437, mae: 1.8590, huber: 1.4686, swd: 3.8074, target_std: 6.4986
    Epoch [1/50], Val Losses: mse: 10.5871, mae: 1.8262, huber: 1.4524, swd: 2.9978, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.5019, mae: 1.9820, huber: 1.5948, swd: 3.3601, target_std: 4.7606
      Epoch 1 composite train-obj: 1.468559
            Val objective improved inf → 1.4524, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6981, mae: 1.5636, huber: 1.1866, swd: 1.6341, target_std: 6.4985
    Epoch [2/50], Val Losses: mse: 10.3485, mae: 1.7593, huber: 1.3937, swd: 2.3582, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.6884, mae: 1.8596, huber: 1.4799, swd: 2.2380, target_std: 4.7606
      Epoch 2 composite train-obj: 1.186594
            Val objective improved 1.4524 → 1.3937, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.4166, mae: 1.5190, huber: 1.1461, swd: 1.5328, target_std: 6.4986
    Epoch [3/50], Val Losses: mse: 10.0785, mae: 1.7482, huber: 1.3824, swd: 2.5361, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.5914, mae: 1.8581, huber: 1.4771, swd: 2.4235, target_std: 4.7606
      Epoch 3 composite train-obj: 1.146089
            Val objective improved 1.3937 → 1.3824, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.2864, mae: 1.5004, huber: 1.1288, swd: 1.5032, target_std: 6.4988
    Epoch [4/50], Val Losses: mse: 10.1787, mae: 1.7594, huber: 1.3946, swd: 2.5775, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 10.6549, mae: 1.8604, huber: 1.4788, swd: 2.3761, target_std: 4.7606
      Epoch 4 composite train-obj: 1.128825
            No improvement (1.3946), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.1156, mae: 1.4760, huber: 1.1060, swd: 1.4209, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 10.3446, mae: 1.7846, huber: 1.4195, swd: 2.8570, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 10.9296, mae: 1.8782, huber: 1.4964, swd: 2.5468, target_std: 4.7606
      Epoch 5 composite train-obj: 1.105953
            No improvement (1.4195), counter 2/5
    Epoch [6/50], Train Losses: mse: 6.0045, mae: 1.4597, huber: 1.0907, swd: 1.3930, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 10.4802, mae: 1.8187, huber: 1.4514, swd: 3.0488, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.0189, mae: 1.8948, huber: 1.5125, swd: 2.7644, target_std: 4.7606
      Epoch 6 composite train-obj: 1.090665
            No improvement (1.4514), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.8280, mae: 1.4332, huber: 1.0657, swd: 1.3088, target_std: 6.4986
    Epoch [7/50], Val Losses: mse: 10.5823, mae: 1.8083, huber: 1.4434, swd: 3.0223, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.4686, mae: 1.9130, huber: 1.5305, swd: 2.6647, target_std: 4.7606
      Epoch 7 composite train-obj: 1.065685
            No improvement (1.4434), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.7260, mae: 1.4165, huber: 1.0501, swd: 1.2804, target_std: 6.4985
    Epoch [8/50], Val Losses: mse: 11.0904, mae: 1.8627, huber: 1.4964, swd: 3.2765, target_std: 4.2736
    Epoch [8/50], Test Losses: mse: 11.4429, mae: 1.9180, huber: 1.5357, swd: 2.6643, target_std: 4.7606
      Epoch 8 composite train-obj: 1.050136
    Epoch [8/50], Test Losses: mse: 10.5912, mae: 1.8581, huber: 1.4770, swd: 2.4231, target_std: 4.7606
    Best round's Test MSE: 10.5914, MAE: 1.8581, SWD: 2.4235
    Best round's Validation MSE: 10.0785, MAE: 1.7482
    Best round's Test verification MSE : 10.5912, MAE: 1.8581, SWD: 2.4231
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4125, mae: 1.8555, huber: 1.4651, swd: 3.5466, target_std: 6.4985
    Epoch [1/50], Val Losses: mse: 10.6194, mae: 1.7947, huber: 1.4239, swd: 2.2504, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.2020, mae: 1.9314, huber: 1.5468, swd: 2.5689, target_std: 4.7606
      Epoch 1 composite train-obj: 1.465095
            Val objective improved inf → 1.4239, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.7189, mae: 1.5664, huber: 1.1894, swd: 1.5626, target_std: 6.4986
    Epoch [2/50], Val Losses: mse: 10.3685, mae: 1.7584, huber: 1.3931, swd: 2.1522, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.5666, mae: 1.8537, huber: 1.4735, swd: 2.2094, target_std: 4.7606
      Epoch 2 composite train-obj: 1.189435
            Val objective improved 1.4239 → 1.3931, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.4068, mae: 1.5178, huber: 1.1450, swd: 1.4440, target_std: 6.4985
    Epoch [3/50], Val Losses: mse: 10.3263, mae: 1.7726, huber: 1.4075, swd: 2.4392, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.6699, mae: 1.8688, huber: 1.4879, swd: 2.4804, target_std: 4.7606
      Epoch 3 composite train-obj: 1.144996
            No improvement (1.4075), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.2734, mae: 1.4972, huber: 1.1260, swd: 1.4153, target_std: 6.4985
    Epoch [4/50], Val Losses: mse: 11.0063, mae: 1.8641, huber: 1.4948, swd: 2.9446, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 10.6605, mae: 1.8930, huber: 1.5086, swd: 2.7686, target_std: 4.7606
      Epoch 4 composite train-obj: 1.126028
            No improvement (1.4948), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.1047, mae: 1.4726, huber: 1.1029, swd: 1.3491, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 10.9238, mae: 1.8321, huber: 1.4672, swd: 2.7924, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 10.9592, mae: 1.8781, huber: 1.4966, swd: 2.4772, target_std: 4.7606
      Epoch 5 composite train-obj: 1.102864
            No improvement (1.4672), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.9754, mae: 1.4536, huber: 1.0850, swd: 1.3091, target_std: 6.4987
    Epoch [6/50], Val Losses: mse: 11.4030, mae: 1.8628, huber: 1.4975, swd: 2.8991, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.0997, mae: 1.8962, huber: 1.5143, swd: 2.4402, target_std: 4.7606
      Epoch 6 composite train-obj: 1.085012
            No improvement (1.4975), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.8373, mae: 1.4318, huber: 1.0647, swd: 1.2586, target_std: 6.4986
    Epoch [7/50], Val Losses: mse: 10.9840, mae: 1.8397, huber: 1.4733, swd: 2.7822, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 10.8297, mae: 1.8783, huber: 1.4957, swd: 2.5521, target_std: 4.7606
      Epoch 7 composite train-obj: 1.064660
    Epoch [7/50], Test Losses: mse: 10.5667, mae: 1.8537, huber: 1.4735, swd: 2.2093, target_std: 4.7606
    Best round's Test MSE: 10.5666, MAE: 1.8537, SWD: 2.2094
    Best round's Validation MSE: 10.3685, MAE: 1.7584
    Best round's Test verification MSE : 10.5667, MAE: 1.8537, SWD: 2.2093
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.2305, mae: 1.8448, huber: 1.4544, swd: 3.6804, target_std: 6.4986
    Epoch [1/50], Val Losses: mse: 10.7622, mae: 1.7842, huber: 1.4153, swd: 1.8397, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.4093, mae: 1.9339, huber: 1.5513, swd: 2.0875, target_std: 4.7606
      Epoch 1 composite train-obj: 1.454435
            Val objective improved inf → 1.4153, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6308, mae: 1.5523, huber: 1.1762, swd: 1.6706, target_std: 6.4987
    Epoch [2/50], Val Losses: mse: 10.1107, mae: 1.7302, huber: 1.3655, swd: 2.2510, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.6139, mae: 1.8495, huber: 1.4696, swd: 2.1642, target_std: 4.7606
      Epoch 2 composite train-obj: 1.176242
            Val objective improved 1.4153 → 1.3655, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.3679, mae: 1.5127, huber: 1.1400, swd: 1.5613, target_std: 6.4986
    Epoch [3/50], Val Losses: mse: 10.3243, mae: 1.7470, huber: 1.3841, swd: 2.3653, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.5727, mae: 1.8466, huber: 1.4672, swd: 2.2381, target_std: 4.7606
      Epoch 3 composite train-obj: 1.140026
            No improvement (1.3841), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.2434, mae: 1.4937, huber: 1.1226, swd: 1.5295, target_std: 6.4985
    Epoch [4/50], Val Losses: mse: 10.3888, mae: 1.7736, huber: 1.4094, swd: 2.6784, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 10.5704, mae: 1.8535, huber: 1.4730, swd: 2.4861, target_std: 4.7606
      Epoch 4 composite train-obj: 1.122646
            No improvement (1.4094), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.0456, mae: 1.4662, huber: 1.0968, swd: 1.4298, target_std: 6.4986
    Epoch [5/50], Val Losses: mse: 10.3127, mae: 1.7826, huber: 1.4187, swd: 2.9299, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 10.6565, mae: 1.8564, huber: 1.4750, swd: 2.5699, target_std: 4.7606
      Epoch 5 composite train-obj: 1.096799
            No improvement (1.4187), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.9074, mae: 1.4463, huber: 1.0780, swd: 1.4015, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 10.5139, mae: 1.8110, huber: 1.4453, swd: 3.1479, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 10.8953, mae: 1.8900, huber: 1.5085, swd: 2.8996, target_std: 4.7606
      Epoch 6 composite train-obj: 1.078027
            No improvement (1.4453), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.7120, mae: 1.4167, huber: 1.0500, swd: 1.2962, target_std: 6.4987
    Epoch [7/50], Val Losses: mse: 10.4362, mae: 1.7851, huber: 1.4206, swd: 2.8418, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 10.9766, mae: 1.8895, huber: 1.5075, swd: 2.7464, target_std: 4.7606
      Epoch 7 composite train-obj: 1.050041
    Epoch [7/50], Test Losses: mse: 10.6142, mae: 1.8496, huber: 1.4696, swd: 2.1645, target_std: 4.7606
    Best round's Test MSE: 10.6139, MAE: 1.8495, SWD: 2.1642
    Best round's Validation MSE: 10.1107, MAE: 1.7302
    Best round's Test verification MSE : 10.6142, MAE: 1.8496, SWD: 2.1645
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred720_20250429_1840)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5907 ± 0.0193
      mae: 1.8538 ± 0.0035
      huber: 1.4734 ± 0.0031
      swd: 2.2657 ± 0.1131
      target_std: 4.7606 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.1859 ± 0.1298
      mae: 1.7456 ± 0.0117
      huber: 1.3804 ± 0.0114
      swd: 2.3131 ± 0.1628
      target_std: 4.2736 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred720_20250429_1840
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### TimeMixer


#### 336-96


```python
utils.reload_modules([utils])
cfg_time_mixer_336_96 = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_336_96 = execute_model_evaluation('ettm1', cfg_time_mixer_336_96, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.8393, mae: 1.2318, huber: 0.8857, swd: 1.4699, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 5.3056, mae: 1.1541, huber: 0.8196, swd: 0.9544, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.4871, mae: 1.3792, huber: 1.0369, swd: 1.4602, target_std: 4.7623
      Epoch 1 composite train-obj: 0.885731
            Val objective improved inf → 0.8196, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0726, mae: 1.1271, huber: 0.7890, swd: 1.2681, target_std: 6.5008
    Epoch [2/50], Val Losses: mse: 5.4502, mae: 1.1814, huber: 0.8457, swd: 0.8920, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.5540, mae: 1.3714, huber: 1.0307, swd: 1.3140, target_std: 4.7623
      Epoch 2 composite train-obj: 0.789002
            No improvement (0.8457), counter 1/5
    Epoch [3/50], Train Losses: mse: 3.8542, mae: 1.0949, huber: 0.7588, swd: 1.1928, target_std: 6.5014
    Epoch [3/50], Val Losses: mse: 5.2349, mae: 1.1698, huber: 0.8339, swd: 0.8872, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.3928, mae: 1.3706, huber: 1.0277, swd: 1.3915, target_std: 4.7623
      Epoch 3 composite train-obj: 0.758842
            No improvement (0.8339), counter 2/5
    Epoch [4/50], Train Losses: mse: 3.6188, mae: 1.0620, huber: 0.7281, swd: 1.1155, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 5.2746, mae: 1.1789, huber: 0.8416, swd: 0.9292, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.5979, mae: 1.4011, huber: 1.0556, swd: 1.5258, target_std: 4.7623
      Epoch 4 composite train-obj: 0.728095
            No improvement (0.8416), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.3555, mae: 1.0270, huber: 0.6949, swd: 1.0331, target_std: 6.5014
    Epoch [5/50], Val Losses: mse: 5.4555, mae: 1.2105, huber: 0.8711, swd: 0.8977, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.7195, mae: 1.3986, huber: 1.0533, swd: 1.3795, target_std: 4.7623
      Epoch 5 composite train-obj: 0.694919
            No improvement (0.8711), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.0242, mae: 0.9814, huber: 0.6517, swd: 0.9171, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 5.5575, mae: 1.2207, huber: 0.8804, swd: 1.0440, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.1443, mae: 1.4607, huber: 1.1105, swd: 1.8272, target_std: 4.7623
      Epoch 6 composite train-obj: 0.651663
    Epoch [6/50], Test Losses: mse: 7.4871, mae: 1.3792, huber: 1.0369, swd: 1.4602, target_std: 4.7623
    Best round's Test MSE: 7.4871, MAE: 1.3792, SWD: 1.4602
    Best round's Validation MSE: 5.3056, MAE: 1.1541
    Best round's Test verification MSE : 7.4871, MAE: 1.3792, SWD: 1.4602
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.7265, mae: 1.2240, huber: 0.8784, swd: 1.4171, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 5.1391, mae: 1.1477, huber: 0.8131, swd: 0.9152, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.3561, mae: 1.3814, huber: 1.0380, swd: 1.5486, target_std: 4.7623
      Epoch 1 composite train-obj: 0.878437
            Val objective improved inf → 0.8131, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.9333, mae: 1.1039, huber: 0.7679, swd: 1.1999, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 5.1644, mae: 1.1550, huber: 0.8202, swd: 0.9225, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.2032, mae: 1.3693, huber: 1.0247, swd: 1.5149, target_std: 4.7623
      Epoch 2 composite train-obj: 0.767869
            No improvement (0.8202), counter 1/5
    Epoch [3/50], Train Losses: mse: 3.5943, mae: 1.0551, huber: 0.7222, swd: 1.0871, target_std: 6.5015
    Epoch [3/50], Val Losses: mse: 5.3024, mae: 1.1832, huber: 0.8464, swd: 0.9494, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.6736, mae: 1.4159, huber: 1.0695, swd: 1.6521, target_std: 4.7623
      Epoch 3 composite train-obj: 0.722208
            No improvement (0.8464), counter 2/5
    Epoch [4/50], Train Losses: mse: 3.1648, mae: 0.9974, huber: 0.6670, swd: 0.9347, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 5.4442, mae: 1.2174, huber: 0.8772, swd: 0.9826, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 8.1629, mae: 1.4502, huber: 1.1016, swd: 1.6993, target_std: 4.7623
      Epoch 4 composite train-obj: 0.666951
            No improvement (0.8772), counter 3/5
    Epoch [5/50], Train Losses: mse: 2.6858, mae: 0.9296, huber: 0.6022, swd: 0.7542, target_std: 6.5014
    Epoch [5/50], Val Losses: mse: 5.8526, mae: 1.2660, huber: 0.9227, swd: 1.0231, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 8.4648, mae: 1.4736, huber: 1.1237, swd: 1.7259, target_std: 4.7623
      Epoch 5 composite train-obj: 0.602211
            No improvement (0.9227), counter 4/5
    Epoch [6/50], Train Losses: mse: 2.2665, mae: 0.8654, huber: 0.5419, swd: 0.6006, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.2042, mae: 1.2995, huber: 0.9533, swd: 1.0877, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.4943, mae: 1.4946, huber: 1.1421, swd: 1.8568, target_std: 4.7623
      Epoch 6 composite train-obj: 0.541916
    Epoch [6/50], Test Losses: mse: 7.3561, mae: 1.3814, huber: 1.0380, swd: 1.5486, target_std: 4.7623
    Best round's Test MSE: 7.3561, MAE: 1.3814, SWD: 1.5486
    Best round's Validation MSE: 5.1391, MAE: 1.1477
    Best round's Test verification MSE : 7.3561, MAE: 1.3814, SWD: 1.5486
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.9440, mae: 1.2440, huber: 0.8979, swd: 1.3460, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 5.3060, mae: 1.1621, huber: 0.8267, swd: 0.9070, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.6067, mae: 1.3880, huber: 1.0467, swd: 1.3904, target_std: 4.7623
      Epoch 1 composite train-obj: 0.897875
            Val objective improved inf → 0.8267, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1108, mae: 1.1305, huber: 0.7927, swd: 1.1811, target_std: 6.5013
    Epoch [2/50], Val Losses: mse: 5.1987, mae: 1.1530, huber: 0.8189, swd: 0.8410, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.2827, mae: 1.3711, huber: 1.0285, swd: 1.3539, target_std: 4.7623
      Epoch 2 composite train-obj: 0.792702
            Val objective improved 0.8267 → 0.8189, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.8620, mae: 1.0940, huber: 0.7585, swd: 1.0958, target_std: 6.5016
    Epoch [3/50], Val Losses: mse: 5.2520, mae: 1.1722, huber: 0.8361, swd: 0.9612, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.4413, mae: 1.3945, huber: 1.0506, swd: 1.5452, target_std: 4.7623
      Epoch 3 composite train-obj: 0.758461
            No improvement (0.8361), counter 1/5
    Epoch [4/50], Train Losses: mse: 3.5651, mae: 1.0545, huber: 0.7212, swd: 1.0100, target_std: 6.5016
    Epoch [4/50], Val Losses: mse: 5.4123, mae: 1.2033, huber: 0.8649, swd: 0.8536, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.7853, mae: 1.4089, huber: 1.0635, swd: 1.4193, target_std: 4.7623
      Epoch 4 composite train-obj: 0.721197
            No improvement (0.8649), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.1762, mae: 1.0031, huber: 0.6720, swd: 0.8831, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 5.4586, mae: 1.2169, huber: 0.8767, swd: 0.9986, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 8.0427, mae: 1.4488, huber: 1.1004, swd: 1.6313, target_std: 4.7623
      Epoch 5 composite train-obj: 0.672047
            No improvement (0.8767), counter 3/5
    Epoch [6/50], Train Losses: mse: 2.7639, mae: 0.9463, huber: 0.6178, swd: 0.7473, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 5.7430, mae: 1.2466, huber: 0.9052, swd: 0.8914, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.3046, mae: 1.4595, huber: 1.1105, swd: 1.4728, target_std: 4.7623
      Epoch 6 composite train-obj: 0.617817
            No improvement (0.9052), counter 4/5
    Epoch [7/50], Train Losses: mse: 2.3730, mae: 0.8879, huber: 0.5628, swd: 0.6068, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 6.0175, mae: 1.2802, huber: 0.9358, swd: 0.9560, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 8.6672, mae: 1.4883, huber: 1.1380, swd: 1.5869, target_std: 4.7623
      Epoch 7 composite train-obj: 0.562798
    Epoch [7/50], Test Losses: mse: 7.2827, mae: 1.3711, huber: 1.0285, swd: 1.3539, target_std: 4.7623
    Best round's Test MSE: 7.2827, MAE: 1.3711, SWD: 1.3539
    Best round's Validation MSE: 5.1987, MAE: 1.1530
    Best round's Test verification MSE : 7.2827, MAE: 1.3711, SWD: 1.3539
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq336_pred96_20250429_1806)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.3753 ± 0.0846
      mae: 1.3772 ± 0.0045
      huber: 1.0345 ± 0.0043
      swd: 1.4542 ± 0.0796
      target_std: 4.7623 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.2145 ± 0.0689
      mae: 1.1516 ± 0.0028
      huber: 0.8172 ± 0.0029
      swd: 0.9035 ± 0.0470
      target_std: 4.2993 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq336_pred96_20250429_1806
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 336-196


```python
utils.reload_modules([utils])
cfg_time_mixer_336_196 = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_336_196 = execute_model_evaluation('ettm1', cfg_time_mixer_336_196, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.7071, mae: 1.3580, huber: 1.0034, swd: 1.6818, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 6.3115, mae: 1.2843, huber: 0.9409, swd: 1.0253, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.2452, mae: 1.5642, huber: 1.2120, swd: 1.7455, target_std: 4.7534
      Epoch 1 composite train-obj: 1.003365
            Val objective improved inf → 0.9409, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.0142, mae: 1.2607, huber: 0.9133, swd: 1.4676, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.2454, mae: 1.2911, huber: 0.9464, swd: 0.9816, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.1799, mae: 1.5712, huber: 1.2169, swd: 1.7842, target_std: 4.7534
      Epoch 2 composite train-obj: 0.913300
            No improvement (0.9464), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.6219, mae: 1.2122, huber: 0.8667, swd: 1.3157, target_std: 6.5012
    Epoch [3/50], Val Losses: mse: 6.4930, mae: 1.3322, huber: 0.9852, swd: 0.8918, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.2393, mae: 1.5611, huber: 1.2074, swd: 1.4564, target_std: 4.7534
      Epoch 3 composite train-obj: 0.866655
            No improvement (0.9852), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.1368, mae: 1.1532, huber: 0.8094, swd: 1.1261, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 6.7177, mae: 1.3584, huber: 1.0090, swd: 0.9124, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.5235, mae: 1.5977, huber: 1.2415, swd: 1.6166, target_std: 4.7534
      Epoch 4 composite train-obj: 0.809408
            No improvement (1.0090), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.6101, mae: 1.0863, huber: 0.7448, swd: 0.9081, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.8766, mae: 1.3769, huber: 1.0259, swd: 0.9530, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.8969, mae: 1.6375, huber: 1.2786, swd: 1.7764, target_std: 4.7534
      Epoch 5 composite train-obj: 0.744841
            No improvement (1.0259), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.1133, mae: 1.0191, huber: 0.6806, swd: 0.7164, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.9855, mae: 1.3996, huber: 1.0472, swd: 0.9764, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 10.1692, mae: 1.6598, huber: 1.2998, swd: 1.7882, target_std: 4.7534
      Epoch 6 composite train-obj: 0.680630
    Epoch [6/50], Test Losses: mse: 9.2452, mae: 1.5642, huber: 1.2120, swd: 1.7455, target_std: 4.7534
    Best round's Test MSE: 9.2452, MAE: 1.5642, SWD: 1.7455
    Best round's Validation MSE: 6.3115, MAE: 1.2843
    Best round's Test verification MSE : 9.2452, MAE: 1.5642, SWD: 1.7455
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6709, mae: 1.3521, huber: 0.9975, swd: 1.6981, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 6.4402, mae: 1.3023, huber: 0.9575, swd: 0.9681, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.1982, mae: 1.5542, huber: 1.2021, swd: 1.5468, target_std: 4.7534
      Epoch 1 composite train-obj: 0.997526
            Val objective improved inf → 0.9575, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9764, mae: 1.2576, huber: 0.9102, swd: 1.4929, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.3604, mae: 1.2942, huber: 0.9500, swd: 0.8838, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.1882, mae: 1.5515, huber: 1.1987, swd: 1.5467, target_std: 4.7534
      Epoch 2 composite train-obj: 0.910209
            Val objective improved 0.9575 → 0.9500, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.5855, mae: 1.2095, huber: 0.8638, swd: 1.3308, target_std: 6.5012
    Epoch [3/50], Val Losses: mse: 6.2968, mae: 1.3066, huber: 0.9601, swd: 0.9841, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.2350, mae: 1.5884, huber: 1.2321, swd: 1.9041, target_std: 4.7534
      Epoch 3 composite train-obj: 0.863759
            No improvement (0.9601), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0567, mae: 1.1451, huber: 0.8013, swd: 1.1095, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.5277, mae: 1.3389, huber: 0.9903, swd: 0.9239, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.4938, mae: 1.6046, huber: 1.2472, swd: 1.8127, target_std: 4.7534
      Epoch 4 composite train-obj: 0.801256
            No improvement (0.9903), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.4681, mae: 1.0705, huber: 0.7295, swd: 0.8653, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 7.0456, mae: 1.3933, huber: 1.0417, swd: 0.9753, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 10.0099, mae: 1.6501, huber: 1.2898, swd: 1.8804, target_std: 4.7534
      Epoch 5 composite train-obj: 0.729541
            No improvement (1.0417), counter 3/5
    Epoch [6/50], Train Losses: mse: 2.9566, mae: 1.0017, huber: 0.6637, swd: 0.6707, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 7.3048, mae: 1.4089, huber: 1.0573, swd: 1.0142, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 10.4101, mae: 1.6740, huber: 1.3134, swd: 1.9203, target_std: 4.7534
      Epoch 6 composite train-obj: 0.663744
            No improvement (1.0573), counter 4/5
    Epoch [7/50], Train Losses: mse: 2.5539, mae: 0.9424, huber: 0.6077, swd: 0.5374, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 7.4103, mae: 1.4152, huber: 1.0623, swd: 1.0274, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 10.6624, mae: 1.6994, huber: 1.3376, swd: 2.0964, target_std: 4.7534
      Epoch 7 composite train-obj: 0.607677
    Epoch [7/50], Test Losses: mse: 9.1882, mae: 1.5515, huber: 1.1987, swd: 1.5467, target_std: 4.7534
    Best round's Test MSE: 9.1882, MAE: 1.5515, SWD: 1.5467
    Best round's Validation MSE: 6.3604, MAE: 1.2942
    Best round's Test verification MSE : 9.1882, MAE: 1.5515, SWD: 1.5467
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6955, mae: 1.3590, huber: 1.0038, swd: 1.5284, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 6.3143, mae: 1.2890, huber: 0.9453, swd: 0.9328, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.2120, mae: 1.5645, huber: 1.2124, swd: 1.6022, target_std: 4.7534
      Epoch 1 composite train-obj: 1.003829
            Val objective improved inf → 0.9453, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9831, mae: 1.2562, huber: 0.9087, swd: 1.3092, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 6.2961, mae: 1.2896, huber: 0.9461, swd: 0.8321, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.0522, mae: 1.5463, huber: 1.1949, swd: 1.4662, target_std: 4.7534
      Epoch 2 composite train-obj: 0.908693
            No improvement (0.9461), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.6294, mae: 1.2113, huber: 0.8657, swd: 1.1873, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.3540, mae: 1.3165, huber: 0.9694, swd: 1.0156, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.3599, mae: 1.6209, huber: 1.2620, swd: 2.0126, target_std: 4.7534
      Epoch 3 composite train-obj: 0.865715
            No improvement (0.9694), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.1798, mae: 1.1563, huber: 0.8128, swd: 1.0413, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.6863, mae: 1.3569, huber: 1.0078, swd: 0.9209, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.5858, mae: 1.6228, huber: 1.2651, swd: 1.7093, target_std: 4.7534
      Epoch 4 composite train-obj: 0.812804
            No improvement (1.0078), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.6835, mae: 1.0938, huber: 0.7526, swd: 0.8711, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.9826, mae: 1.3817, huber: 1.0314, swd: 0.9597, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 10.0062, mae: 1.6574, huber: 1.2981, swd: 1.8782, target_std: 4.7534
      Epoch 5 composite train-obj: 0.752643
            No improvement (1.0314), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.1951, mae: 1.0297, huber: 0.6911, swd: 0.7032, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 7.3730, mae: 1.4219, huber: 1.0697, swd: 1.0052, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 10.1633, mae: 1.6707, huber: 1.3107, swd: 1.7543, target_std: 4.7534
      Epoch 6 composite train-obj: 0.691073
    Epoch [6/50], Test Losses: mse: 9.2120, mae: 1.5645, huber: 1.2124, swd: 1.6022, target_std: 4.7534
    Best round's Test MSE: 9.2120, MAE: 1.5645, SWD: 1.6022
    Best round's Validation MSE: 6.3143, MAE: 1.2890
    Best round's Test verification MSE : 9.2120, MAE: 1.5645, SWD: 1.6022
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq336_pred196_20250429_1812)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.2151 ± 0.0234
      mae: 1.5601 ± 0.0061
      huber: 1.2077 ± 0.0064
      swd: 1.6314 ± 0.0838
      target_std: 4.7534 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.3287 ± 0.0224
      mae: 1.2892 ± 0.0040
      huber: 0.9454 ± 0.0037
      swd: 0.9473 ± 0.0587
      target_std: 4.2875 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq336_pred196_20250429_1812
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 336-336


```python
utils.reload_modules([utils])
cfg_time_mixer_336_336 = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_336_336 = execute_model_evaluation('ettm1', cfg_time_mixer_336_336, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.5470, mae: 1.4758, huber: 1.1131, swd: 1.7752, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 7.6759, mae: 1.3999, huber: 1.0513, swd: 0.9949, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.6070, mae: 1.7153, huber: 1.3539, swd: 1.9565, target_std: 4.7502
      Epoch 1 composite train-obj: 1.113063
            Val objective improved inf → 1.0513, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8675, mae: 1.3855, huber: 1.0290, swd: 1.5716, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 7.4894, mae: 1.3961, huber: 1.0471, swd: 0.9160, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.3145, mae: 1.7069, huber: 1.3449, swd: 1.8877, target_std: 4.7502
      Epoch 2 composite train-obj: 1.029039
            Val objective improved 1.0513 → 1.0471, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.5567, mae: 1.3487, huber: 0.9936, swd: 1.4428, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 7.4444, mae: 1.4048, huber: 1.0536, swd: 0.8533, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.3792, mae: 1.7139, huber: 1.3510, swd: 1.8626, target_std: 4.7502
      Epoch 3 composite train-obj: 0.993572
            No improvement (1.0536), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1670, mae: 1.3035, huber: 0.9494, swd: 1.2837, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 7.7595, mae: 1.4384, huber: 1.0862, swd: 0.9044, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.4659, mae: 1.7280, huber: 1.3649, swd: 1.9445, target_std: 4.7502
      Epoch 4 composite train-obj: 0.949369
            No improvement (1.0862), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.6655, mae: 1.2434, huber: 0.8908, swd: 1.0666, target_std: 6.5013
    Epoch [5/50], Val Losses: mse: 7.8889, mae: 1.4701, huber: 1.1143, swd: 0.8984, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7479, mae: 1.7592, huber: 1.3939, swd: 1.9665, target_std: 4.7502
      Epoch 5 composite train-obj: 0.890844
            No improvement (1.1143), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.1383, mae: 1.1779, huber: 0.8275, swd: 0.8565, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 8.0974, mae: 1.5031, huber: 1.1448, swd: 1.0086, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.2415, mae: 1.8095, huber: 1.4406, swd: 2.1434, target_std: 4.7502
      Epoch 6 composite train-obj: 0.827465
            No improvement (1.1448), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.6819, mae: 1.1182, huber: 0.7700, swd: 0.7047, target_std: 6.5008
    Epoch [7/50], Val Losses: mse: 8.2342, mae: 1.5215, huber: 1.1626, swd: 0.9897, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 11.4929, mae: 1.8172, huber: 1.4479, swd: 2.0063, target_std: 4.7502
      Epoch 7 composite train-obj: 0.770026
    Epoch [7/50], Test Losses: mse: 10.3145, mae: 1.7069, huber: 1.3449, swd: 1.8877, target_std: 4.7502
    Best round's Test MSE: 10.3145, MAE: 1.7069, SWD: 1.8877
    Best round's Validation MSE: 7.4894, MAE: 1.3961
    Best round's Test verification MSE : 10.3145, MAE: 1.7069, SWD: 1.8877
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.6534, mae: 1.4846, huber: 1.1207, swd: 1.8168, target_std: 6.5009
    Epoch [1/50], Val Losses: mse: 7.6556, mae: 1.3969, huber: 1.0482, swd: 0.9387, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.6097, mae: 1.7099, huber: 1.3489, swd: 1.8688, target_std: 4.7502
      Epoch 1 composite train-obj: 1.120732
            Val objective improved inf → 1.0482, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8290, mae: 1.3832, huber: 1.0259, swd: 1.6178, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 7.7872, mae: 1.4301, huber: 1.0785, swd: 0.8716, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.3756, mae: 1.6917, huber: 1.3309, swd: 1.6270, target_std: 4.7502
      Epoch 2 composite train-obj: 1.025893
            No improvement (1.0785), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.4536, mae: 1.3385, huber: 0.9827, swd: 1.4453, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 7.9135, mae: 1.4470, huber: 1.0947, swd: 0.9193, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.3888, mae: 1.7006, huber: 1.3393, swd: 1.6564, target_std: 4.7502
      Epoch 3 composite train-obj: 0.982741
            No improvement (1.0947), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.9853, mae: 1.2832, huber: 0.9289, swd: 1.2184, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 7.7747, mae: 1.4551, huber: 1.1009, swd: 0.9701, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.5847, mae: 1.7409, huber: 1.3763, swd: 1.9259, target_std: 4.7502
      Epoch 4 composite train-obj: 0.928868
            No improvement (1.1009), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.4963, mae: 1.2237, huber: 0.8713, swd: 0.9927, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 7.7870, mae: 1.4733, huber: 1.1166, swd: 1.0038, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7961, mae: 1.7694, huber: 1.4017, swd: 2.0320, target_std: 4.7502
      Epoch 5 composite train-obj: 0.871310
            No improvement (1.1166), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.0344, mae: 1.1662, huber: 0.8159, swd: 0.8161, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 8.1062, mae: 1.5070, huber: 1.1489, swd: 1.1113, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.1005, mae: 1.8033, huber: 1.4344, swd: 2.2468, target_std: 4.7502
      Epoch 6 composite train-obj: 0.815856
    Epoch [6/50], Test Losses: mse: 10.6097, mae: 1.7099, huber: 1.3489, swd: 1.8688, target_std: 4.7502
    Best round's Test MSE: 10.6097, MAE: 1.7099, SWD: 1.8688
    Best round's Validation MSE: 7.6556, MAE: 1.3969
    Best round's Test verification MSE : 10.6097, MAE: 1.7099, SWD: 1.8688
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.5063, mae: 1.4696, huber: 1.1070, swd: 1.7183, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 7.7418, mae: 1.4166, huber: 1.0673, swd: 0.9265, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.3997, mae: 1.6950, huber: 1.3348, swd: 1.7819, target_std: 4.7502
      Epoch 1 composite train-obj: 1.106969
            Val objective improved inf → 1.0673, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.7785, mae: 1.3753, huber: 1.0195, swd: 1.5266, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 7.6165, mae: 1.4202, huber: 1.0702, swd: 0.8947, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.2127, mae: 1.6895, huber: 1.3285, swd: 1.7670, target_std: 4.7502
      Epoch 2 composite train-obj: 1.019508
            No improvement (1.0702), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.4162, mae: 1.3313, huber: 0.9770, swd: 1.3821, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 7.8796, mae: 1.4461, huber: 1.0939, swd: 0.8912, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.3926, mae: 1.7198, huber: 1.3564, swd: 1.8642, target_std: 4.7502
      Epoch 3 composite train-obj: 0.977039
            No improvement (1.0939), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.9134, mae: 1.2720, huber: 0.9192, swd: 1.1784, target_std: 6.5009
    Epoch [4/50], Val Losses: mse: 7.7516, mae: 1.4667, huber: 1.1104, swd: 0.9348, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.5898, mae: 1.7613, huber: 1.3938, swd: 2.0854, target_std: 4.7502
      Epoch 4 composite train-obj: 0.919237
            No improvement (1.1104), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.3331, mae: 1.2017, huber: 0.8507, swd: 0.9440, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 8.0856, mae: 1.5108, huber: 1.1520, swd: 0.9739, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.9599, mae: 1.7887, huber: 1.4205, swd: 2.0808, target_std: 4.7502
      Epoch 5 composite train-obj: 0.850683
            No improvement (1.1520), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.8176, mae: 1.1348, huber: 0.7861, swd: 0.7533, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 8.3722, mae: 1.5542, huber: 1.1929, swd: 1.0348, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.2666, mae: 1.8160, huber: 1.4459, swd: 2.0217, target_std: 4.7502
      Epoch 6 composite train-obj: 0.786122
    Epoch [6/50], Test Losses: mse: 10.3997, mae: 1.6950, huber: 1.3348, swd: 1.7819, target_std: 4.7502
    Best round's Test MSE: 10.3997, MAE: 1.6950, SWD: 1.7819
    Best round's Validation MSE: 7.7418, MAE: 1.4166
    Best round's Test verification MSE : 10.3997, MAE: 1.6950, SWD: 1.7819
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq336_pred336_20250429_1819)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.4413 ± 0.1240
      mae: 1.7039 ± 0.0065
      huber: 1.3429 ± 0.0059
      swd: 1.8461 ± 0.0461
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.6289 ± 0.1047
      mae: 1.4032 ± 0.0095
      huber: 1.0542 ± 0.0093
      swd: 0.9271 ± 0.0093
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq336_pred336_20250429_1819
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 336-720


```python
utils.reload_modules([utils])
cfg_time_mixer_336_720 = train_config.FlatTimeMixerConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_336_720 = execute_model_evaluation('ettm1', cfg_time_mixer_336_720, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5006, mae: 1.6117, huber: 1.2385, swd: 1.8020, target_std: 6.4987
    Epoch [1/50], Val Losses: mse: 9.2658, mae: 1.5537, huber: 1.1963, swd: 1.0567, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.5599, mae: 1.8686, huber: 1.4940, swd: 2.0602, target_std: 4.7606
      Epoch 1 composite train-obj: 1.238546
            Val objective improved inf → 1.1963, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.7286, mae: 1.5250, huber: 1.1570, swd: 1.6088, target_std: 6.4985
    Epoch [2/50], Val Losses: mse: 9.1950, mae: 1.5736, huber: 1.2146, swd: 0.9371, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 11.2432, mae: 1.8379, huber: 1.4646, swd: 1.6216, target_std: 4.7606
      Epoch 2 composite train-obj: 1.156998
            No improvement (1.2146), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.3528, mae: 1.4831, huber: 1.1164, swd: 1.4423, target_std: 6.4987
    Epoch [3/50], Val Losses: mse: 8.9776, mae: 1.5791, huber: 1.2186, swd: 1.0153, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 11.1431, mae: 1.8487, huber: 1.4735, swd: 1.7649, target_std: 4.7606
      Epoch 3 composite train-obj: 1.116400
            No improvement (1.2186), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.9284, mae: 1.4357, huber: 1.0700, swd: 1.2514, target_std: 6.4986
    Epoch [4/50], Val Losses: mse: 9.0203, mae: 1.5841, huber: 1.2228, swd: 1.0925, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.3079, mae: 1.8772, huber: 1.5003, swd: 2.1133, target_std: 4.7606
      Epoch 4 composite train-obj: 1.069977
            No improvement (1.2228), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.4342, mae: 1.3789, huber: 1.0146, swd: 1.0510, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 9.4917, mae: 1.6331, huber: 1.2690, swd: 1.0282, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.5393, mae: 1.8902, huber: 1.5133, swd: 1.9189, target_std: 4.7606
      Epoch 5 composite train-obj: 1.014588
            No improvement (1.2690), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.9355, mae: 1.3168, huber: 0.9543, swd: 0.8767, target_std: 6.4987
    Epoch [6/50], Val Losses: mse: 9.7900, mae: 1.6470, huber: 1.2829, swd: 1.1113, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.9409, mae: 1.9220, huber: 1.5440, swd: 2.1961, target_std: 4.7606
      Epoch 6 composite train-obj: 0.954270
    Epoch [6/50], Test Losses: mse: 11.5599, mae: 1.8686, huber: 1.4940, swd: 2.0602, target_std: 4.7606
    Best round's Test MSE: 11.5599, MAE: 1.8686, SWD: 2.0602
    Best round's Validation MSE: 9.2658, MAE: 1.5537
    Best round's Test verification MSE : 11.5599, MAE: 1.8686, SWD: 2.0602
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4073, mae: 1.6041, huber: 1.2315, swd: 1.7165, target_std: 6.4986
    Epoch [1/50], Val Losses: mse: 9.3202, mae: 1.5546, huber: 1.1979, swd: 1.0438, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.4855, mae: 1.8656, huber: 1.4912, swd: 2.0473, target_std: 4.7606
      Epoch 1 composite train-obj: 1.231505
            Val objective improved inf → 1.1979, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6485, mae: 1.5189, huber: 1.1504, swd: 1.4979, target_std: 6.4986
    Epoch [2/50], Val Losses: mse: 9.1065, mae: 1.5549, huber: 1.1967, swd: 0.9255, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 11.1687, mae: 1.8510, huber: 1.4767, swd: 2.0027, target_std: 4.7606
      Epoch 2 composite train-obj: 1.150420
            Val objective improved 1.1979 → 1.1967, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0688, mae: 1.4555, huber: 1.0886, swd: 1.2634, target_std: 6.4986
    Epoch [3/50], Val Losses: mse: 9.8981, mae: 1.6252, huber: 1.2628, swd: 0.9247, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 11.3356, mae: 1.8800, huber: 1.5037, swd: 1.9877, target_std: 4.7606
      Epoch 3 composite train-obj: 1.088561
            No improvement (1.2628), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.3940, mae: 1.3767, huber: 1.0120, swd: 0.9941, target_std: 6.4984
    Epoch [4/50], Val Losses: mse: 10.0803, mae: 1.6720, huber: 1.3064, swd: 0.9138, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.9748, mae: 1.9234, huber: 1.5461, swd: 2.1150, target_std: 4.7606
      Epoch 4 composite train-obj: 1.011963
            No improvement (1.3064), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.7571, mae: 1.2947, huber: 0.9327, swd: 0.7732, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 10.3404, mae: 1.6954, huber: 1.3281, swd: 0.9701, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 12.4190, mae: 1.9563, huber: 1.5773, swd: 2.2971, target_std: 4.7606
      Epoch 5 composite train-obj: 0.932651
            No improvement (1.3281), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.2415, mae: 1.2239, huber: 0.8644, swd: 0.6333, target_std: 6.4986
    Epoch [6/50], Val Losses: mse: 10.6813, mae: 1.7325, huber: 1.3624, swd: 0.9889, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 12.8997, mae: 1.9951, huber: 1.6129, swd: 2.2579, target_std: 4.7606
      Epoch 6 composite train-obj: 0.864417
            No improvement (1.3624), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.8468, mae: 1.1670, huber: 0.8099, swd: 0.5451, target_std: 6.4985
    Epoch [7/50], Val Losses: mse: 10.8696, mae: 1.7523, huber: 1.3810, swd: 1.0404, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 13.2953, mae: 2.0339, huber: 1.6493, swd: 2.4959, target_std: 4.7606
      Epoch 7 composite train-obj: 0.809885
    Epoch [7/50], Test Losses: mse: 11.1687, mae: 1.8510, huber: 1.4767, swd: 2.0027, target_std: 4.7606
    Best round's Test MSE: 11.1687, MAE: 1.8510, SWD: 2.0027
    Best round's Validation MSE: 9.1065, MAE: 1.5549
    Best round's Test verification MSE : 11.1687, MAE: 1.8510, SWD: 2.0027
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3374, mae: 1.5995, huber: 1.2273, swd: 1.8601, target_std: 6.4988
    Epoch [1/50], Val Losses: mse: 9.6483, mae: 1.5876, huber: 1.2293, swd: 1.0441, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.3980, mae: 1.8537, huber: 1.4803, swd: 1.8637, target_std: 4.7606
      Epoch 1 composite train-obj: 1.227264
            Val objective improved inf → 1.2293, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5097, mae: 1.5051, huber: 1.1374, swd: 1.5964, target_std: 6.4987
    Epoch [2/50], Val Losses: mse: 9.1341, mae: 1.5782, huber: 1.2183, swd: 1.2284, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 11.3598, mae: 1.9018, huber: 1.5243, swd: 2.5769, target_std: 4.7606
      Epoch 2 composite train-obj: 1.137423
            Val objective improved 1.2293 → 1.2183, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0529, mae: 1.4559, huber: 1.0893, swd: 1.4115, target_std: 6.4986
    Epoch [3/50], Val Losses: mse: 9.4862, mae: 1.6162, huber: 1.2539, swd: 1.0680, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 11.4532, mae: 1.8814, huber: 1.5052, swd: 1.9589, target_std: 4.7606
      Epoch 3 composite train-obj: 1.089262
            No improvement (1.2539), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.5375, mae: 1.3944, huber: 1.0291, swd: 1.1756, target_std: 6.4984
    Epoch [4/50], Val Losses: mse: 9.5707, mae: 1.6355, huber: 1.2701, swd: 1.2540, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 12.2387, mae: 1.9522, huber: 1.5726, swd: 2.5898, target_std: 4.7606
      Epoch 4 composite train-obj: 1.029107
            No improvement (1.2701), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9995, mae: 1.3269, huber: 0.9635, swd: 0.9524, target_std: 6.4986
    Epoch [5/50], Val Losses: mse: 9.8248, mae: 1.6747, huber: 1.3074, swd: 1.3065, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 12.8491, mae: 2.0015, huber: 1.6201, swd: 2.9233, target_std: 4.7606
      Epoch 5 composite train-obj: 0.963520
            No improvement (1.3074), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.5150, mae: 1.2628, huber: 0.9016, swd: 0.7864, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 10.3091, mae: 1.7123, huber: 1.3427, swd: 1.2693, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 12.8701, mae: 2.0110, huber: 1.6280, swd: 2.6644, target_std: 4.7606
      Epoch 6 composite train-obj: 0.901594
            No improvement (1.3427), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.1147, mae: 1.2081, huber: 0.8489, swd: 0.6658, target_std: 6.4986
    Epoch [7/50], Val Losses: mse: 10.2816, mae: 1.7225, huber: 1.3509, swd: 1.1719, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 13.0576, mae: 2.0334, huber: 1.6481, swd: 2.5466, target_std: 4.7606
      Epoch 7 composite train-obj: 0.848905
    Epoch [7/50], Test Losses: mse: 11.3598, mae: 1.9018, huber: 1.5243, swd: 2.5769, target_std: 4.7606
    Best round's Test MSE: 11.3598, MAE: 1.9018, SWD: 2.5769
    Best round's Validation MSE: 9.1341, MAE: 1.5782
    Best round's Test verification MSE : 11.3598, MAE: 1.9018, SWD: 2.5769
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq336_pred720_20250429_1827)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.3628 ± 0.1597
      mae: 1.8738 ± 0.0211
      huber: 1.4984 ± 0.0197
      swd: 2.2133 ± 0.2582
      target_std: 4.7606 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.1688 ± 0.0695
      mae: 1.5623 ± 0.0113
      huber: 1.2038 ± 0.0103
      swd: 1.0702 ± 0.1240
      target_std: 4.2736 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq336_pred720_20250429_1827
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### PatchTST


#### 336-96


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_336_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6500, mae: 1.3447, huber: 0.9885, swd: 1.5224, target_std: 6.5013
    Epoch [1/50], Val Losses: mse: 5.3213, mae: 1.1773, huber: 0.8373, swd: 0.9932, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.7989, mae: 1.4474, huber: 1.0963, swd: 1.7558, target_std: 4.7623
      Epoch 1 composite train-obj: 0.988460
            Val objective improved inf → 0.8373, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9627, mae: 1.2467, huber: 0.8971, swd: 1.3771, target_std: 6.5008
    Epoch [2/50], Val Losses: mse: 5.2654, mae: 1.1851, huber: 0.8447, swd: 1.0515, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.6757, mae: 1.4350, huber: 1.0858, swd: 1.7752, target_std: 4.7623
      Epoch 2 composite train-obj: 0.897133
            No improvement (0.8447), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.7623, mae: 1.2202, huber: 0.8724, swd: 1.3142, target_std: 6.5014
    Epoch [3/50], Val Losses: mse: 5.4127, mae: 1.1900, huber: 0.8491, swd: 0.9144, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.6244, mae: 1.4154, huber: 1.0666, swd: 1.4756, target_std: 4.7623
      Epoch 3 composite train-obj: 0.872360
            No improvement (0.8491), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.5886, mae: 1.1972, huber: 0.8508, swd: 1.2557, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 5.2680, mae: 1.1814, huber: 0.8412, swd: 0.9125, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.7357, mae: 1.4232, huber: 1.0745, swd: 1.5185, target_std: 4.7623
      Epoch 4 composite train-obj: 0.850845
            No improvement (0.8412), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.4147, mae: 1.1756, huber: 0.8306, swd: 1.1999, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.6741, mae: 1.2380, huber: 0.8962, swd: 1.1128, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 8.1336, mae: 1.4625, huber: 1.1130, swd: 1.7421, target_std: 4.7623
      Epoch 5 composite train-obj: 0.830575
            No improvement (0.8962), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.2583, mae: 1.1537, huber: 0.8103, swd: 1.1435, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 5.5478, mae: 1.2226, huber: 0.8826, swd: 1.1632, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.1219, mae: 1.4787, huber: 1.1276, swd: 1.9322, target_std: 4.7623
      Epoch 6 composite train-obj: 0.810287
    Epoch [6/50], Test Losses: mse: 7.7989, mae: 1.4474, huber: 1.0963, swd: 1.7558, target_std: 4.7623
    Best round's Test MSE: 7.7989, MAE: 1.4474, SWD: 1.7558
    Best round's Validation MSE: 5.3213, MAE: 1.1773
    Best round's Test verification MSE : 7.7989, MAE: 1.4474, SWD: 1.7558
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6620, mae: 1.3484, huber: 0.9918, swd: 1.5019, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 5.3198, mae: 1.1885, huber: 0.8442, swd: 0.9924, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.8390, mae: 1.4857, huber: 1.1275, swd: 1.9863, target_std: 4.7623
      Epoch 1 composite train-obj: 0.991829
            Val objective improved inf → 0.8442, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9379, mae: 1.2454, huber: 0.8958, swd: 1.3444, target_std: 6.5016
    Epoch [2/50], Val Losses: mse: 5.1883, mae: 1.1707, huber: 0.8305, swd: 0.9298, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.4929, mae: 1.4108, huber: 1.0629, swd: 1.6392, target_std: 4.7623
      Epoch 2 composite train-obj: 0.895757
            Val objective improved 0.8442 → 0.8305, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.7347, mae: 1.2181, huber: 0.8703, swd: 1.2863, target_std: 6.5008
    Epoch [3/50], Val Losses: mse: 5.3045, mae: 1.1929, huber: 0.8523, swd: 0.9067, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.6565, mae: 1.4357, huber: 1.0860, swd: 1.7115, target_std: 4.7623
      Epoch 3 composite train-obj: 0.870256
            No improvement (0.8523), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.5417, mae: 1.1943, huber: 0.8479, swd: 1.2243, target_std: 6.5008
    Epoch [4/50], Val Losses: mse: 5.4698, mae: 1.2079, huber: 0.8677, swd: 0.9598, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.7242, mae: 1.4269, huber: 1.0799, swd: 1.6443, target_std: 4.7623
      Epoch 4 composite train-obj: 0.847864
            No improvement (0.8677), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.3667, mae: 1.1697, huber: 0.8249, swd: 1.1526, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 5.3892, mae: 1.1978, huber: 0.8565, swd: 1.0115, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.9346, mae: 1.4592, huber: 1.1091, swd: 1.9080, target_std: 4.7623
      Epoch 5 composite train-obj: 0.824941
            No improvement (0.8565), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.2099, mae: 1.1470, huber: 0.8039, swd: 1.0914, target_std: 6.5014
    Epoch [6/50], Val Losses: mse: 5.6178, mae: 1.2254, huber: 0.8855, swd: 0.9120, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.0596, mae: 1.4330, huber: 1.0867, swd: 1.5113, target_std: 4.7623
      Epoch 6 composite train-obj: 0.803902
            No improvement (0.8855), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.0810, mae: 1.1283, huber: 0.7864, swd: 1.0443, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 6.1713, mae: 1.2519, huber: 0.9126, swd: 1.0277, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 8.5319, mae: 1.4771, huber: 1.1288, swd: 1.8542, target_std: 4.7623
      Epoch 7 composite train-obj: 0.786380
    Epoch [7/50], Test Losses: mse: 7.4929, mae: 1.4108, huber: 1.0629, swd: 1.6392, target_std: 4.7623
    Best round's Test MSE: 7.4929, MAE: 1.4108, SWD: 1.6392
    Best round's Validation MSE: 5.1883, MAE: 1.1707
    Best round's Test verification MSE : 7.4929, MAE: 1.4108, SWD: 1.6392
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6486, mae: 1.3465, huber: 0.9899, swd: 1.3845, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 5.1952, mae: 1.1632, huber: 0.8232, swd: 0.9602, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.8438, mae: 1.4500, huber: 1.0996, swd: 1.8322, target_std: 4.7623
      Epoch 1 composite train-obj: 0.989906
            Val objective improved inf → 0.8232, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9471, mae: 1.2454, huber: 0.8956, swd: 1.2590, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 5.2794, mae: 1.1770, huber: 0.8353, swd: 0.8545, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.6231, mae: 1.4320, huber: 1.0811, swd: 1.5539, target_std: 4.7623
      Epoch 2 composite train-obj: 0.895601
            No improvement (0.8353), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.7639, mae: 1.2195, huber: 0.8718, swd: 1.2116, target_std: 6.5013
    Epoch [3/50], Val Losses: mse: 5.3245, mae: 1.1836, huber: 0.8428, swd: 0.8439, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.6121, mae: 1.4318, huber: 1.0827, swd: 1.6369, target_std: 4.7623
      Epoch 3 composite train-obj: 0.871751
            No improvement (0.8428), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.6076, mae: 1.1988, huber: 0.8523, swd: 1.1591, target_std: 6.5015
    Epoch [4/50], Val Losses: mse: 5.2548, mae: 1.1884, huber: 0.8468, swd: 0.8876, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.5781, mae: 1.4168, huber: 1.0678, swd: 1.5014, target_std: 4.7623
      Epoch 4 composite train-obj: 0.852335
            No improvement (0.8468), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.4235, mae: 1.1749, huber: 0.8300, swd: 1.0992, target_std: 6.5010
    Epoch [5/50], Val Losses: mse: 5.3423, mae: 1.1916, huber: 0.8513, swd: 0.9577, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.9384, mae: 1.4651, huber: 1.1146, swd: 1.8508, target_std: 4.7623
      Epoch 5 composite train-obj: 0.829975
            No improvement (0.8513), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.2720, mae: 1.1551, huber: 0.8114, swd: 1.0496, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 5.6893, mae: 1.2334, huber: 0.8916, swd: 0.9552, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 8.0283, mae: 1.4573, huber: 1.1065, swd: 1.6361, target_std: 4.7623
      Epoch 6 composite train-obj: 0.811435
    Epoch [6/50], Test Losses: mse: 7.8438, mae: 1.4500, huber: 1.0996, swd: 1.8322, target_std: 4.7623
    Best round's Test MSE: 7.8438, MAE: 1.4500, SWD: 1.8322
    Best round's Validation MSE: 5.1952, MAE: 1.1632
    Best round's Test verification MSE : 7.8438, MAE: 1.4500, SWD: 1.8322
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq336_pred96_20250430_0144)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.7119 ± 0.1559
      mae: 1.4361 ± 0.0179
      huber: 1.0863 ± 0.0166
      swd: 1.7424 ± 0.0793
      target_std: 4.7623 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.2349 ± 0.0611
      mae: 1.1704 ± 0.0057
      huber: 0.8303 ± 0.0057
      swd: 0.9611 ± 0.0259
      target_std: 4.2993 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq336_pred96_20250430_0144
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 336-196


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_336_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.6293, mae: 1.4748, huber: 1.1104, swd: 1.7500, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 6.3149, mae: 1.3159, huber: 0.9660, swd: 1.1716, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.4320, mae: 1.6270, huber: 1.2649, swd: 2.1766, target_std: 4.7534
      Epoch 1 composite train-obj: 1.110364
            Val objective improved inf → 0.9660, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8087, mae: 1.3767, huber: 1.0175, swd: 1.5780, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 6.1568, mae: 1.3225, huber: 0.9702, swd: 1.0841, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.2088, mae: 1.6094, huber: 1.2474, swd: 2.0248, target_std: 4.7534
      Epoch 2 composite train-obj: 1.017487
            No improvement (0.9702), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.5598, mae: 1.3478, huber: 0.9899, swd: 1.4810, target_std: 6.5012
    Epoch [3/50], Val Losses: mse: 6.0796, mae: 1.3048, huber: 0.9540, swd: 1.0571, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.2566, mae: 1.6105, huber: 1.2494, swd: 2.1490, target_std: 4.7534
      Epoch 3 composite train-obj: 0.989941
            Val objective improved 0.9660 → 0.9540, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.3338, mae: 1.3191, huber: 0.9629, swd: 1.3779, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 6.4943, mae: 1.3449, huber: 0.9960, swd: 1.0461, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.1298, mae: 1.6140, huber: 1.2538, swd: 2.0204, target_std: 4.7534
      Epoch 4 composite train-obj: 0.962895
            No improvement (0.9960), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.1172, mae: 1.2913, huber: 0.9365, swd: 1.2815, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.7762, mae: 1.3631, huber: 1.0135, swd: 1.0768, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.4852, mae: 1.6101, huber: 1.2531, swd: 1.9211, target_std: 4.7534
      Epoch 5 composite train-obj: 0.936488
            No improvement (1.0135), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.9415, mae: 1.2682, huber: 0.9147, swd: 1.2061, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 7.1072, mae: 1.3940, huber: 1.0420, swd: 1.1798, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.8115, mae: 1.6660, huber: 1.3051, swd: 2.3156, target_std: 4.7534
      Epoch 6 composite train-obj: 0.914706
            No improvement (1.0420), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.7536, mae: 1.2434, huber: 0.8912, swd: 1.1311, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 7.3787, mae: 1.4056, huber: 1.0560, swd: 1.1160, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.9171, mae: 1.6332, huber: 1.2769, swd: 1.9432, target_std: 4.7534
      Epoch 7 composite train-obj: 0.891248
            No improvement (1.0560), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.6004, mae: 1.2219, huber: 0.8710, swd: 1.0627, target_std: 6.5011
    Epoch [8/50], Val Losses: mse: 6.8797, mae: 1.3800, huber: 1.0300, swd: 1.2362, target_std: 4.2875
    Epoch [8/50], Test Losses: mse: 9.8662, mae: 1.6636, huber: 1.3050, swd: 2.3543, target_std: 4.7534
      Epoch 8 composite train-obj: 0.870971
    Epoch [8/50], Test Losses: mse: 9.2566, mae: 1.6105, huber: 1.2494, swd: 2.1490, target_std: 4.7534
    Best round's Test MSE: 9.2566, MAE: 1.6105, SWD: 2.1490
    Best round's Validation MSE: 6.0796, MAE: 1.3048
    Best round's Test verification MSE : 9.2566, MAE: 1.6105, SWD: 2.1490
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.5462, mae: 1.4695, huber: 1.1051, swd: 1.7691, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 6.4496, mae: 1.3134, huber: 0.9652, swd: 1.0664, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.2324, mae: 1.5964, huber: 1.2380, swd: 1.8218, target_std: 4.7534
      Epoch 1 composite train-obj: 1.105126
            Val objective improved inf → 0.9652, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8067, mae: 1.3768, huber: 1.0175, swd: 1.6013, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.7796, mae: 1.3663, huber: 1.0142, swd: 1.0686, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.3324, mae: 1.6080, huber: 1.2476, swd: 1.5610, target_std: 4.7534
      Epoch 2 composite train-obj: 1.017540
            No improvement (1.0142), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.5181, mae: 1.3407, huber: 0.9834, swd: 1.4851, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 6.3809, mae: 1.3200, huber: 0.9694, swd: 1.1129, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.3207, mae: 1.6168, huber: 1.2571, swd: 2.1247, target_std: 4.7534
      Epoch 3 composite train-obj: 0.983377
            No improvement (0.9694), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.2897, mae: 1.3122, huber: 0.9564, swd: 1.3923, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.4413, mae: 1.3263, huber: 0.9761, swd: 1.1608, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.6319, mae: 1.6336, huber: 1.2745, swd: 2.2545, target_std: 4.7534
      Epoch 4 composite train-obj: 0.956419
            No improvement (0.9761), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.0661, mae: 1.2823, huber: 0.9282, swd: 1.2930, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 7.1036, mae: 1.3697, huber: 1.0203, swd: 0.9736, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.6119, mae: 1.6140, huber: 1.2582, swd: 1.9463, target_std: 4.7534
      Epoch 5 composite train-obj: 0.928166
            No improvement (1.0203), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.8792, mae: 1.2580, huber: 0.9051, swd: 1.2050, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.8457, mae: 1.3654, huber: 1.0145, swd: 1.1530, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.7742, mae: 1.6533, huber: 1.2934, swd: 2.3243, target_std: 4.7534
      Epoch 6 composite train-obj: 0.905056
    Epoch [6/50], Test Losses: mse: 9.2324, mae: 1.5964, huber: 1.2380, swd: 1.8218, target_std: 4.7534
    Best round's Test MSE: 9.2324, MAE: 1.5964, SWD: 1.8218
    Best round's Validation MSE: 6.4496, MAE: 1.3134
    Best round's Test verification MSE : 9.2324, MAE: 1.5964, SWD: 1.8218
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.5408, mae: 1.4684, huber: 1.1037, swd: 1.5543, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 6.2548, mae: 1.3163, huber: 0.9656, swd: 1.1595, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.5624, mae: 1.6547, huber: 1.2922, swd: 2.3650, target_std: 4.7534
      Epoch 1 composite train-obj: 1.103725
            Val objective improved inf → 0.9656, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8117, mae: 1.3749, huber: 1.0158, swd: 1.4122, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.4291, mae: 1.3287, huber: 0.9777, swd: 0.9737, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.1484, mae: 1.6013, huber: 1.2408, swd: 1.7509, target_std: 4.7534
      Epoch 2 composite train-obj: 1.015764
            No improvement (0.9777), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.5589, mae: 1.3438, huber: 0.9865, swd: 1.3305, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.1534, mae: 1.3216, huber: 0.9699, swd: 1.1059, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.1987, mae: 1.6289, huber: 1.2677, swd: 2.1754, target_std: 4.7534
      Epoch 3 composite train-obj: 0.986497
            No improvement (0.9699), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.3143, mae: 1.3154, huber: 0.9594, swd: 1.2487, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.3231, mae: 1.3217, huber: 0.9723, swd: 0.9550, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.3676, mae: 1.6190, huber: 1.2593, swd: 1.8063, target_std: 4.7534
      Epoch 4 composite train-obj: 0.959420
            No improvement (0.9723), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.0828, mae: 1.2866, huber: 0.9322, swd: 1.1675, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 6.5887, mae: 1.3517, huber: 1.0000, swd: 1.0128, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.5985, mae: 1.6351, huber: 1.2749, swd: 1.9251, target_std: 4.7534
      Epoch 5 composite train-obj: 0.932165
            No improvement (1.0000), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.8768, mae: 1.2596, huber: 0.9066, swd: 1.0845, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.6528, mae: 1.3549, huber: 1.0050, swd: 1.0669, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.5273, mae: 1.6332, huber: 1.2759, swd: 2.0674, target_std: 4.7534
      Epoch 6 composite train-obj: 0.906635
    Epoch [6/50], Test Losses: mse: 9.5624, mae: 1.6547, huber: 1.2922, swd: 2.3650, target_std: 4.7534
    Best round's Test MSE: 9.5624, MAE: 1.6547, SWD: 2.3650
    Best round's Validation MSE: 6.2548, MAE: 1.3163
    Best round's Test verification MSE : 9.5624, MAE: 1.6547, SWD: 2.3650
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq336_pred196_20250430_0201)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.3505 ± 0.1502
      mae: 1.6205 ± 0.0248
      huber: 1.2599 ± 0.0233
      swd: 2.1119 ± 0.2233
      target_std: 4.7534 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.2613 ± 0.1512
      mae: 1.3115 ± 0.0049
      huber: 0.9616 ± 0.0054
      swd: 1.0943 ± 0.0462
      target_std: 4.2875 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq336_pred196_20250430_0201
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 336-336


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_336_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3108, mae: 1.5739, huber: 1.2027, swd: 1.8129, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 7.5354, mae: 1.4262, huber: 1.0699, swd: 1.0137, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.4054, mae: 1.7477, huber: 1.3783, swd: 2.0961, target_std: 4.7502
      Epoch 1 composite train-obj: 1.202727
            Val objective improved inf → 1.0699, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5090, mae: 1.4811, huber: 1.1144, swd: 1.6405, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 7.3301, mae: 1.4139, huber: 1.0598, swd: 1.0085, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.0566, mae: 1.7256, huber: 1.3582, swd: 2.0829, target_std: 4.7502
      Epoch 2 composite train-obj: 1.114425
            Val objective improved 1.0699 → 1.0598, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2646, mae: 1.4507, huber: 1.0853, swd: 1.5245, target_std: 6.5010
    Epoch [3/50], Val Losses: mse: 7.6567, mae: 1.4427, huber: 1.0866, swd: 1.0468, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 9.9812, mae: 1.7183, huber: 1.3516, swd: 1.9862, target_std: 4.7502
      Epoch 3 composite train-obj: 1.085318
            No improvement (1.0866), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.0284, mae: 1.4226, huber: 1.0584, swd: 1.4241, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 8.4422, mae: 1.5082, huber: 1.1503, swd: 1.0779, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.3078, mae: 1.7293, huber: 1.3621, swd: 1.6871, target_std: 4.7502
      Epoch 4 composite train-obj: 1.058434
            No improvement (1.1503), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7739, mae: 1.3904, huber: 1.0280, swd: 1.3088, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 7.7159, mae: 1.4505, huber: 1.0953, swd: 1.1369, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7063, mae: 1.7735, huber: 1.4061, swd: 2.3204, target_std: 4.7502
      Epoch 5 composite train-obj: 1.027982
            No improvement (1.0953), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5384, mae: 1.3608, huber: 0.9998, swd: 1.2092, target_std: 6.5012
    Epoch [6/50], Val Losses: mse: 8.1741, mae: 1.5160, huber: 1.1549, swd: 1.0374, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.9253, mae: 1.7954, huber: 1.4249, swd: 1.7227, target_std: 4.7502
      Epoch 6 composite train-obj: 0.999772
            No improvement (1.1549), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.3223, mae: 1.3336, huber: 0.9738, swd: 1.1163, target_std: 6.5010
    Epoch [7/50], Val Losses: mse: 8.8637, mae: 1.5733, huber: 1.2103, swd: 1.1228, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 11.6427, mae: 1.8305, huber: 1.4599, swd: 1.6087, target_std: 4.7502
      Epoch 7 composite train-obj: 0.973843
    Epoch [7/50], Test Losses: mse: 10.0566, mae: 1.7256, huber: 1.3582, swd: 2.0829, target_std: 4.7502
    Best round's Test MSE: 10.0566, MAE: 1.7256, SWD: 2.0829
    Best round's Validation MSE: 7.3301, MAE: 1.4139
    Best round's Test verification MSE : 10.0566, MAE: 1.7256, SWD: 2.0829
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.2788, mae: 1.5692, huber: 1.1983, swd: 1.8855, target_std: 6.5010
    Epoch [1/50], Val Losses: mse: 7.4621, mae: 1.4084, huber: 1.0536, swd: 1.1288, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.9447, mae: 1.7674, huber: 1.3993, swd: 2.3292, target_std: 4.7502
      Epoch 1 composite train-obj: 1.198252
            Val objective improved inf → 1.0536, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5399, mae: 1.4834, huber: 1.1164, swd: 1.6988, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 7.6197, mae: 1.4450, huber: 1.0896, swd: 1.2752, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.2612, mae: 1.7462, huber: 1.3777, swd: 2.2834, target_std: 4.7502
      Epoch 2 composite train-obj: 1.116382
            No improvement (1.0896), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.2532, mae: 1.4492, huber: 1.0840, swd: 1.5794, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 7.5011, mae: 1.4247, huber: 1.0694, swd: 1.0389, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.2547, mae: 1.7214, huber: 1.3549, swd: 1.9097, target_std: 4.7502
      Epoch 3 composite train-obj: 1.083967
            No improvement (1.0694), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.0087, mae: 1.4197, huber: 1.0558, swd: 1.4690, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 7.9606, mae: 1.4691, huber: 1.1117, swd: 1.1410, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.4682, mae: 1.7415, huber: 1.3722, swd: 2.0159, target_std: 4.7502
      Epoch 4 composite train-obj: 1.055823
            No improvement (1.1117), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.7443, mae: 1.3873, huber: 1.0250, swd: 1.3450, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 7.9348, mae: 1.4933, huber: 1.1334, swd: 0.9573, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.9607, mae: 1.7878, huber: 1.4181, swd: 1.8526, target_std: 4.7502
      Epoch 5 composite train-obj: 1.024997
            No improvement (1.1334), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.5012, mae: 1.3562, huber: 0.9954, swd: 1.2307, target_std: 6.5009
    Epoch [6/50], Val Losses: mse: 8.1105, mae: 1.4869, huber: 1.1281, swd: 1.0053, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.0190, mae: 1.7790, huber: 1.4096, swd: 1.8876, target_std: 4.7502
      Epoch 6 composite train-obj: 0.995360
    Epoch [6/50], Test Losses: mse: 10.9447, mae: 1.7674, huber: 1.3993, swd: 2.3292, target_std: 4.7502
    Best round's Test MSE: 10.9447, MAE: 1.7674, SWD: 2.3292
    Best round's Validation MSE: 7.4621, MAE: 1.4084
    Best round's Test verification MSE : 10.9447, MAE: 1.7674, SWD: 2.3292
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.2854, mae: 1.5717, huber: 1.2003, swd: 1.7865, target_std: 6.5008
    Epoch [1/50], Val Losses: mse: 7.6284, mae: 1.4201, huber: 1.0658, swd: 0.9793, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.2823, mae: 1.7334, huber: 1.3654, swd: 2.0835, target_std: 4.7502
      Epoch 1 composite train-obj: 1.200276
            Val objective improved inf → 1.0658, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.5273, mae: 1.4818, huber: 1.1150, swd: 1.6248, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 7.3245, mae: 1.4084, huber: 1.0527, swd: 1.0103, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.3519, mae: 1.7423, huber: 1.3738, swd: 2.2987, target_std: 4.7502
      Epoch 2 composite train-obj: 1.114951
            Val objective improved 1.0658 → 1.0527, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2652, mae: 1.4502, huber: 1.0849, swd: 1.5162, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 7.5267, mae: 1.4491, huber: 1.0914, swd: 0.9627, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.1492, mae: 1.7279, huber: 1.3586, swd: 1.9650, target_std: 4.7502
      Epoch 3 composite train-obj: 1.084901
            No improvement (1.0914), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.9944, mae: 1.4169, huber: 1.0532, swd: 1.3931, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 8.1863, mae: 1.5102, huber: 1.1498, swd: 1.0262, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.3989, mae: 1.7467, huber: 1.3774, swd: 1.7901, target_std: 4.7502
      Epoch 4 composite train-obj: 1.053225
            No improvement (1.1498), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7392, mae: 1.3867, huber: 1.0243, swd: 1.2904, target_std: 6.5011
    Epoch [5/50], Val Losses: mse: 7.6760, mae: 1.4816, huber: 1.1212, swd: 1.2662, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 11.0180, mae: 1.8233, huber: 1.4518, swd: 2.7511, target_std: 4.7502
      Epoch 5 composite train-obj: 1.024320
            No improvement (1.1212), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5025, mae: 1.3572, huber: 0.9963, swd: 1.1855, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 7.6829, mae: 1.4672, huber: 1.1100, swd: 1.1279, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.8419, mae: 1.7690, huber: 1.4020, swd: 2.2529, target_std: 4.7502
      Epoch 6 composite train-obj: 0.996288
            No improvement (1.1100), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.2774, mae: 1.3295, huber: 0.9696, swd: 1.0930, target_std: 6.5010
    Epoch [7/50], Val Losses: mse: 8.1338, mae: 1.5254, huber: 1.1653, swd: 1.0644, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 11.1426, mae: 1.7850, huber: 1.4170, swd: 1.8450, target_std: 4.7502
      Epoch 7 composite train-obj: 0.969560
    Epoch [7/50], Test Losses: mse: 10.3519, mae: 1.7423, huber: 1.3738, swd: 2.2987, target_std: 4.7502
    Best round's Test MSE: 10.3519, MAE: 1.7423, SWD: 2.2987
    Best round's Validation MSE: 7.3245, MAE: 1.4084
    Best round's Test verification MSE : 10.3519, MAE: 1.7423, SWD: 2.2987
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq336_pred336_20250430_0216)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.4511 ± 0.3693
      mae: 1.7451 ± 0.0172
      huber: 1.3771 ± 0.0169
      swd: 2.2369 ± 0.1096
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.3722 ± 0.0636
      mae: 1.4103 ± 0.0026
      huber: 1.0554 ± 0.0031
      swd: 1.0492 ± 0.0563
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq336_pred336_20250430_0216
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 336-720


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_336_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2284, mae: 1.7084, huber: 1.3280, swd: 1.8839, target_std: 6.4987
    Epoch [1/50], Val Losses: mse: 9.9964, mae: 1.6289, huber: 1.2652, swd: 1.0787, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.2144, mae: 1.8780, huber: 1.4976, swd: 1.9423, target_std: 4.7606
      Epoch 1 composite train-obj: 1.327991
            Val objective improved inf → 1.2652, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3422, mae: 1.6156, huber: 1.2388, swd: 1.7057, target_std: 6.4986
    Epoch [2/50], Val Losses: mse: 8.7524, mae: 1.5606, huber: 1.1965, swd: 1.0899, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.8459, mae: 1.8664, huber: 1.4848, swd: 2.1281, target_std: 4.7606
      Epoch 2 composite train-obj: 1.238778
            Val objective improved 1.2652 → 1.1965, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.0178, mae: 1.5795, huber: 1.2037, swd: 1.5670, target_std: 6.4985
    Epoch [3/50], Val Losses: mse: 9.3343, mae: 1.5987, huber: 1.2356, swd: 1.3069, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.5075, mae: 1.8401, huber: 1.4615, swd: 2.1635, target_std: 4.7606
      Epoch 3 composite train-obj: 1.203682
            No improvement (1.2356), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.7331, mae: 1.5441, huber: 1.1695, swd: 1.4196, target_std: 6.4985
    Epoch [4/50], Val Losses: mse: 9.6037, mae: 1.6177, huber: 1.2539, swd: 1.2168, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 10.7162, mae: 1.8513, huber: 1.4736, swd: 2.0016, target_std: 4.7606
      Epoch 4 composite train-obj: 1.169524
            No improvement (1.2539), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.4753, mae: 1.5098, huber: 1.1369, swd: 1.2958, target_std: 6.4987
    Epoch [5/50], Val Losses: mse: 9.1846, mae: 1.6116, huber: 1.2463, swd: 1.2079, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 10.7889, mae: 1.8684, huber: 1.4887, swd: 2.1357, target_std: 4.7606
      Epoch 5 composite train-obj: 1.136877
            No improvement (1.2463), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.2408, mae: 1.4797, huber: 1.1081, swd: 1.1917, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 9.8869, mae: 1.6644, huber: 1.2969, swd: 1.0613, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.4304, mae: 1.9141, huber: 1.5336, swd: 1.8852, target_std: 4.7606
      Epoch 6 composite train-obj: 1.108074
            No improvement (1.2969), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.0328, mae: 1.4530, huber: 1.0825, swd: 1.1096, target_std: 6.4985
    Epoch [7/50], Val Losses: mse: 9.9133, mae: 1.6795, huber: 1.3115, swd: 1.1756, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.2477, mae: 1.8909, huber: 1.5108, swd: 1.8335, target_std: 4.7606
      Epoch 7 composite train-obj: 1.082504
    Epoch [7/50], Test Losses: mse: 10.8459, mae: 1.8664, huber: 1.4848, swd: 2.1281, target_std: 4.7606
    Best round's Test MSE: 10.8459, MAE: 1.8664, SWD: 2.1281
    Best round's Validation MSE: 8.7524, MAE: 1.5606
    Best round's Test verification MSE : 10.8459, MAE: 1.8664, SWD: 2.1281
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1570, mae: 1.7039, huber: 1.3237, swd: 1.7779, target_std: 6.4989
    Epoch [1/50], Val Losses: mse: 9.6493, mae: 1.6088, huber: 1.2439, swd: 0.8878, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 10.9873, mae: 1.8652, huber: 1.4850, swd: 1.7358, target_std: 4.7606
      Epoch 1 composite train-obj: 1.323659
            Val objective improved inf → 1.2439, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3308, mae: 1.6162, huber: 1.2392, swd: 1.6196, target_std: 6.4988
    Epoch [2/50], Val Losses: mse: 9.4476, mae: 1.6014, huber: 1.2370, swd: 0.9934, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.6472, mae: 1.8503, huber: 1.4708, swd: 1.8581, target_std: 4.7606
      Epoch 2 composite train-obj: 1.239237
            Val objective improved 1.2439 → 1.2370, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.9937, mae: 1.5775, huber: 1.2020, swd: 1.4863, target_std: 6.4985
    Epoch [3/50], Val Losses: mse: 8.8320, mae: 1.5632, huber: 1.2001, swd: 1.1358, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.7587, mae: 1.8598, huber: 1.4791, swd: 2.1644, target_std: 4.7606
      Epoch 3 composite train-obj: 1.201995
            Val objective improved 1.2370 → 1.2001, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.6851, mae: 1.5394, huber: 1.1655, swd: 1.3407, target_std: 6.4986
    Epoch [4/50], Val Losses: mse: 8.9759, mae: 1.6093, huber: 1.2424, swd: 0.9668, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.3647, mae: 1.9068, huber: 1.5265, swd: 1.8765, target_std: 4.7606
      Epoch 4 composite train-obj: 1.165459
            No improvement (1.2424), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.4229, mae: 1.5049, huber: 1.1326, swd: 1.2191, target_std: 6.4986
    Epoch [5/50], Val Losses: mse: 9.7421, mae: 1.6627, huber: 1.2954, swd: 1.0035, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.0342, mae: 1.8878, huber: 1.5078, swd: 1.6809, target_std: 4.7606
      Epoch 5 composite train-obj: 1.132550
            No improvement (1.2954), counter 2/5
    Epoch [6/50], Train Losses: mse: 6.1840, mae: 1.4746, huber: 1.1035, swd: 1.1200, target_std: 6.4986
    Epoch [6/50], Val Losses: mse: 9.5687, mae: 1.6348, huber: 1.2693, swd: 1.2137, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.1805, mae: 1.9108, huber: 1.5305, swd: 2.3948, target_std: 4.7606
      Epoch 6 composite train-obj: 1.103465
            No improvement (1.2693), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.9923, mae: 1.4500, huber: 1.0797, swd: 1.0491, target_std: 6.4986
    Epoch [7/50], Val Losses: mse: 9.5422, mae: 1.6480, huber: 1.2802, swd: 1.0799, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.7082, mae: 1.9432, huber: 1.5628, swd: 2.2952, target_std: 4.7606
      Epoch 7 composite train-obj: 1.079735
            No improvement (1.2802), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.7971, mae: 1.4259, huber: 1.0564, swd: 0.9801, target_std: 6.4986
    Epoch [8/50], Val Losses: mse: 9.6396, mae: 1.6652, huber: 1.2962, swd: 0.9789, target_std: 4.2736
    Epoch [8/50], Test Losses: mse: 12.0853, mae: 1.9700, huber: 1.5886, swd: 1.9799, target_std: 4.7606
      Epoch 8 composite train-obj: 1.056404
    Epoch [8/50], Test Losses: mse: 10.7587, mae: 1.8598, huber: 1.4791, swd: 2.1644, target_std: 4.7606
    Best round's Test MSE: 10.7587, MAE: 1.8598, SWD: 2.1644
    Best round's Validation MSE: 8.8320, MAE: 1.5632
    Best round's Test verification MSE : 10.7587, MAE: 1.8598, SWD: 2.1644
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1544, mae: 1.7036, huber: 1.3231, swd: 1.9482, target_std: 6.4985
    Epoch [1/50], Val Losses: mse: 8.8516, mae: 1.5639, huber: 1.2019, swd: 1.4110, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 11.3621, mae: 1.9145, huber: 1.5344, swd: 2.8638, target_std: 4.7606
      Epoch 1 composite train-obj: 1.323138
            Val objective improved inf → 1.2019, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3467, mae: 1.6180, huber: 1.2411, swd: 1.7975, target_std: 6.4986
    Epoch [2/50], Val Losses: mse: 9.7429, mae: 1.6152, huber: 1.2530, swd: 1.1811, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 10.7280, mae: 1.8439, huber: 1.4660, swd: 1.9792, target_std: 4.7606
      Epoch 2 composite train-obj: 1.241064
            No improvement (1.2530), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.0052, mae: 1.5793, huber: 1.2039, swd: 1.6273, target_std: 6.4985
    Epoch [3/50], Val Losses: mse: 9.5032, mae: 1.6152, huber: 1.2510, swd: 1.0949, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 10.8902, mae: 1.8434, huber: 1.4664, swd: 1.7521, target_std: 4.7606
      Epoch 3 composite train-obj: 1.203853
            No improvement (1.2510), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.7110, mae: 1.5429, huber: 1.1689, swd: 1.4774, target_std: 6.4986
    Epoch [4/50], Val Losses: mse: 9.0426, mae: 1.6066, huber: 1.2423, swd: 1.1455, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 10.8965, mae: 1.8591, huber: 1.4825, swd: 2.0699, target_std: 4.7606
      Epoch 4 composite train-obj: 1.168933
            No improvement (1.2423), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.4393, mae: 1.5068, huber: 1.1346, swd: 1.3404, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 8.9627, mae: 1.5974, huber: 1.2320, swd: 1.0404, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.4017, mae: 1.8954, huber: 1.5172, swd: 2.1206, target_std: 4.7606
      Epoch 5 composite train-obj: 1.134566
            No improvement (1.2320), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.1974, mae: 1.4757, huber: 1.1048, swd: 1.2214, target_std: 6.4986
    Epoch [6/50], Val Losses: mse: 10.2443, mae: 1.7222, huber: 1.3533, swd: 1.4750, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 12.2130, mae: 2.0044, huber: 1.6234, swd: 2.5256, target_std: 4.7606
      Epoch 6 composite train-obj: 1.104782
    Epoch [6/50], Test Losses: mse: 11.3621, mae: 1.9145, huber: 1.5344, swd: 2.8638, target_std: 4.7606
    Best round's Test MSE: 11.3621, MAE: 1.9145, SWD: 2.8638
    Best round's Validation MSE: 8.8516, MAE: 1.5639
    Best round's Test verification MSE : 11.3621, MAE: 1.9145, SWD: 2.8638
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq336_pred720_20250430_0222)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.9889 ± 0.2663
      mae: 1.8802 ± 0.0244
      huber: 1.4994 ± 0.0248
      swd: 2.3854 ± 0.3386
      target_std: 4.7606 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.8120 ± 0.0429
      mae: 1.5626 ± 0.0014
      huber: 1.1995 ± 0.0023
      swd: 1.2122 ± 0.1418
      target_std: 4.2736 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq336_pred720_20250430_0222
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear


#### 336-96


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_336_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 378
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 378
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.7295, mae: 1.3161, huber: 0.9643, swd: 1.7401, target_std: 6.5016
    Epoch [1/50], Val Losses: mse: 5.5313, mae: 1.1727, huber: 0.8341, swd: 0.8898, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 8.0026, mae: 1.4119, huber: 1.0667, swd: 1.3591, target_std: 4.7623
      Epoch 1 composite train-obj: 0.964288
            Val objective improved inf → 0.8341, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4506, mae: 1.1730, huber: 0.8322, swd: 1.3918, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 5.4875, mae: 1.1658, huber: 0.8289, swd: 0.9131, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.8759, mae: 1.3943, huber: 1.0523, swd: 1.3736, target_std: 4.7623
      Epoch 2 composite train-obj: 0.832241
            Val objective improved 0.8341 → 0.8289, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.4169, mae: 1.1670, huber: 0.8267, swd: 1.3732, target_std: 6.5012
    Epoch [3/50], Val Losses: mse: 5.4416, mae: 1.1611, huber: 0.8250, swd: 0.8995, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.8737, mae: 1.3938, huber: 1.0518, swd: 1.3695, target_std: 4.7623
      Epoch 3 composite train-obj: 0.826687
            Val objective improved 0.8289 → 0.8250, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.4098, mae: 1.1667, huber: 0.8265, swd: 1.3734, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 5.5175, mae: 1.1679, huber: 0.8292, swd: 0.8404, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 8.0085, mae: 1.4107, huber: 1.0664, swd: 1.3031, target_std: 4.7623
      Epoch 4 composite train-obj: 0.826516
            No improvement (0.8292), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.4048, mae: 1.1655, huber: 0.8253, swd: 1.3671, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.4053, mae: 1.1566, huber: 0.8199, swd: 0.8859, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.8617, mae: 1.3912, huber: 1.0495, swd: 1.3655, target_std: 4.7623
      Epoch 5 composite train-obj: 0.825327
            Val objective improved 0.8250 → 0.8199, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.4113, mae: 1.1671, huber: 0.8266, swd: 1.3687, target_std: 6.5008
    Epoch [6/50], Val Losses: mse: 5.4027, mae: 1.1649, huber: 0.8279, swd: 0.9786, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 7.7695, mae: 1.3865, huber: 1.0451, swd: 1.4493, target_std: 4.7623
      Epoch 6 composite train-obj: 0.826638
            No improvement (0.8279), counter 1/5
    Epoch [7/50], Train Losses: mse: 4.3998, mae: 1.1658, huber: 0.8255, swd: 1.3671, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 5.4725, mae: 1.1684, huber: 0.8315, swd: 0.9613, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 7.7763, mae: 1.3826, huber: 1.0406, swd: 1.3658, target_std: 4.7623
      Epoch 7 composite train-obj: 0.825477
            No improvement (0.8315), counter 2/5
    Epoch [8/50], Train Losses: mse: 4.4019, mae: 1.1656, huber: 0.8254, swd: 1.3647, target_std: 6.5013
    Epoch [8/50], Val Losses: mse: 5.4160, mae: 1.1583, huber: 0.8221, swd: 0.8949, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 7.8365, mae: 1.3883, huber: 1.0458, swd: 1.3505, target_std: 4.7623
      Epoch 8 composite train-obj: 0.825371
            No improvement (0.8221), counter 3/5
    Epoch [9/50], Train Losses: mse: 4.4012, mae: 1.1657, huber: 0.8254, swd: 1.3648, target_std: 6.5010
    Epoch [9/50], Val Losses: mse: 5.4770, mae: 1.1824, huber: 0.8417, swd: 0.9917, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 7.7847, mae: 1.3954, huber: 1.0509, swd: 1.4258, target_std: 4.7623
      Epoch 9 composite train-obj: 0.825440
            No improvement (0.8417), counter 4/5
    Epoch [10/50], Train Losses: mse: 4.4004, mae: 1.1660, huber: 0.8257, swd: 1.3663, target_std: 6.5013
    Epoch [10/50], Val Losses: mse: 5.3917, mae: 1.1573, huber: 0.8214, swd: 0.8953, target_std: 4.2993
    Epoch [10/50], Test Losses: mse: 7.8264, mae: 1.3909, huber: 1.0494, swd: 1.3992, target_std: 4.7623
      Epoch 10 composite train-obj: 0.825702
    Epoch [10/50], Test Losses: mse: 7.8617, mae: 1.3912, huber: 1.0495, swd: 1.3655, target_std: 4.7623
    Best round's Test MSE: 7.8617, MAE: 1.3912, SWD: 1.3655
    Best round's Validation MSE: 5.4053, MAE: 1.1566
    Best round's Test verification MSE : 7.8617, MAE: 1.3912, SWD: 1.3655
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6971, mae: 1.3158, huber: 0.9641, swd: 1.7327, target_std: 6.5013
    Epoch [1/50], Val Losses: mse: 5.4967, mae: 1.1775, huber: 0.8387, swd: 0.9678, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.8950, mae: 1.4042, huber: 1.0607, swd: 1.4814, target_std: 4.7623
      Epoch 1 composite train-obj: 0.964064
            Val objective improved inf → 0.8387, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4424, mae: 1.1714, huber: 0.8307, swd: 1.3747, target_std: 6.5014
    Epoch [2/50], Val Losses: mse: 5.4188, mae: 1.1564, huber: 0.8203, swd: 0.9102, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.8011, mae: 1.3883, huber: 1.0465, swd: 1.4381, target_std: 4.7623
      Epoch 2 composite train-obj: 0.830743
            Val objective improved 0.8387 → 0.8203, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.4142, mae: 1.1665, huber: 0.8261, swd: 1.3584, target_std: 6.5014
    Epoch [3/50], Val Losses: mse: 5.4967, mae: 1.1723, huber: 0.8345, swd: 0.9405, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.8115, mae: 1.3911, huber: 1.0486, swd: 1.4366, target_std: 4.7623
      Epoch 3 composite train-obj: 0.826133
            No improvement (0.8345), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.4136, mae: 1.1666, huber: 0.8264, swd: 1.3551, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 5.4302, mae: 1.1771, huber: 0.8389, swd: 1.0365, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 7.7653, mae: 1.3909, huber: 1.0494, swd: 1.5466, target_std: 4.7623
      Epoch 4 composite train-obj: 0.826365
            No improvement (0.8389), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.4054, mae: 1.1656, huber: 0.8255, swd: 1.3516, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 5.4519, mae: 1.1556, huber: 0.8198, swd: 0.8545, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.8861, mae: 1.3911, huber: 1.0500, swd: 1.3696, target_std: 4.7623
      Epoch 5 composite train-obj: 0.825474
            Val objective improved 0.8203 → 0.8198, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.4075, mae: 1.1661, huber: 0.8258, swd: 1.3522, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 5.4355, mae: 1.1626, huber: 0.8256, swd: 0.9096, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 7.8405, mae: 1.3862, huber: 1.0446, swd: 1.3838, target_std: 4.7623
      Epoch 6 composite train-obj: 0.825827
            No improvement (0.8256), counter 1/5
    Epoch [7/50], Train Losses: mse: 4.3916, mae: 1.1636, huber: 0.8236, swd: 1.3451, target_std: 6.5010
    Epoch [7/50], Val Losses: mse: 5.4328, mae: 1.1712, huber: 0.8332, swd: 0.9675, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 7.8224, mae: 1.3902, huber: 1.0484, swd: 1.4585, target_std: 4.7623
      Epoch 7 composite train-obj: 0.823552
            No improvement (0.8332), counter 2/5
    Epoch [8/50], Train Losses: mse: 4.4062, mae: 1.1670, huber: 0.8265, swd: 1.3521, target_std: 6.5015
    Epoch [8/50], Val Losses: mse: 5.4190, mae: 1.1578, huber: 0.8215, swd: 0.8938, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 7.8232, mae: 1.3887, huber: 1.0456, swd: 1.3925, target_std: 4.7623
      Epoch 8 composite train-obj: 0.826505
            No improvement (0.8215), counter 3/5
    Epoch [9/50], Train Losses: mse: 4.3934, mae: 1.1637, huber: 0.8237, swd: 1.3456, target_std: 6.5012
    Epoch [9/50], Val Losses: mse: 5.4482, mae: 1.1581, huber: 0.8223, swd: 0.8739, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 7.8462, mae: 1.3883, huber: 1.0467, swd: 1.3689, target_std: 4.7623
      Epoch 9 composite train-obj: 0.823682
            No improvement (0.8223), counter 4/5
    Epoch [10/50], Train Losses: mse: 4.4004, mae: 1.1656, huber: 0.8253, swd: 1.3476, target_std: 6.5014
    Epoch [10/50], Val Losses: mse: 5.4224, mae: 1.1618, huber: 0.8238, swd: 0.8828, target_std: 4.2993
    Epoch [10/50], Test Losses: mse: 7.8453, mae: 1.3934, huber: 1.0502, swd: 1.4027, target_std: 4.7623
      Epoch 10 composite train-obj: 0.825276
    Epoch [10/50], Test Losses: mse: 7.8861, mae: 1.3911, huber: 1.0500, swd: 1.3696, target_std: 4.7623
    Best round's Test MSE: 7.8861, MAE: 1.3911, SWD: 1.3696
    Best round's Validation MSE: 5.4519, MAE: 1.1556
    Best round's Test verification MSE : 7.8861, MAE: 1.3911, SWD: 1.3696
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.8363, mae: 1.3198, huber: 0.9680, swd: 1.6319, target_std: 6.5013
    Epoch [1/50], Val Losses: mse: 5.4586, mae: 1.1683, huber: 0.8305, swd: 0.8841, target_std: 4.2993
    Epoch [1/50], Test Losses: mse: 7.9056, mae: 1.4017, huber: 1.0588, swd: 1.3604, target_std: 4.7623
      Epoch 1 composite train-obj: 0.968034
            Val objective improved inf → 0.8305, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4455, mae: 1.1721, huber: 0.8313, swd: 1.2841, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 5.4889, mae: 1.1670, huber: 0.8307, swd: 0.8966, target_std: 4.2993
    Epoch [2/50], Test Losses: mse: 7.8564, mae: 1.3906, huber: 1.0495, swd: 1.3417, target_std: 4.7623
      Epoch 2 composite train-obj: 0.831290
            No improvement (0.8307), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.4111, mae: 1.1664, huber: 0.8262, swd: 1.2659, target_std: 6.5013
    Epoch [3/50], Val Losses: mse: 5.4585, mae: 1.1655, huber: 0.8284, swd: 0.8916, target_std: 4.2993
    Epoch [3/50], Test Losses: mse: 7.8142, mae: 1.3900, huber: 1.0478, swd: 1.3277, target_std: 4.7623
      Epoch 3 composite train-obj: 0.826160
            Val objective improved 0.8305 → 0.8284, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.4121, mae: 1.1671, huber: 0.8268, swd: 1.2650, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 5.4973, mae: 1.1646, huber: 0.8277, swd: 0.8099, target_std: 4.2993
    Epoch [4/50], Test Losses: mse: 8.0039, mae: 1.4043, huber: 1.0611, swd: 1.2479, target_std: 4.7623
      Epoch 4 composite train-obj: 0.826787
            Val objective improved 0.8284 → 0.8277, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.4072, mae: 1.1660, huber: 0.8257, swd: 1.2609, target_std: 6.5013
    Epoch [5/50], Val Losses: mse: 5.4913, mae: 1.1688, huber: 0.8312, swd: 0.8416, target_std: 4.2993
    Epoch [5/50], Test Losses: mse: 7.9547, mae: 1.4051, huber: 1.0608, swd: 1.2880, target_std: 4.7623
      Epoch 5 composite train-obj: 0.825712
            No improvement (0.8312), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.4093, mae: 1.1676, huber: 0.8270, swd: 1.2626, target_std: 6.5013
    Epoch [6/50], Val Losses: mse: 5.4131, mae: 1.1760, huber: 0.8375, swd: 0.9752, target_std: 4.2993
    Epoch [6/50], Test Losses: mse: 7.7333, mae: 1.3834, huber: 1.0417, swd: 1.3797, target_std: 4.7623
      Epoch 6 composite train-obj: 0.826965
            No improvement (0.8375), counter 2/5
    Epoch [7/50], Train Losses: mse: 4.4071, mae: 1.1664, huber: 0.8260, swd: 1.2619, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 5.4681, mae: 1.1790, huber: 0.8402, swd: 0.9655, target_std: 4.2993
    Epoch [7/50], Test Losses: mse: 7.7809, mae: 1.3893, huber: 1.0476, swd: 1.3880, target_std: 4.7623
      Epoch 7 composite train-obj: 0.825998
            No improvement (0.8402), counter 3/5
    Epoch [8/50], Train Losses: mse: 4.4021, mae: 1.1650, huber: 0.8249, swd: 1.2575, target_std: 6.5014
    Epoch [8/50], Val Losses: mse: 5.3859, mae: 1.1568, huber: 0.8203, swd: 0.8736, target_std: 4.2993
    Epoch [8/50], Test Losses: mse: 7.7673, mae: 1.3873, huber: 1.0454, swd: 1.3400, target_std: 4.7623
      Epoch 8 composite train-obj: 0.824865
            Val objective improved 0.8277 → 0.8203, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 4.4001, mae: 1.1656, huber: 0.8254, swd: 1.2579, target_std: 6.5012
    Epoch [9/50], Val Losses: mse: 5.3895, mae: 1.1602, huber: 0.8219, swd: 0.8400, target_std: 4.2993
    Epoch [9/50], Test Losses: mse: 7.8291, mae: 1.3915, huber: 1.0487, swd: 1.2965, target_std: 4.7623
      Epoch 9 composite train-obj: 0.825403
            No improvement (0.8219), counter 1/5
    Epoch [10/50], Train Losses: mse: 4.4015, mae: 1.1661, huber: 0.8258, swd: 1.2596, target_std: 6.5013
    Epoch [10/50], Val Losses: mse: 5.4459, mae: 1.1669, huber: 0.8298, swd: 0.8851, target_std: 4.2993
    Epoch [10/50], Test Losses: mse: 7.8339, mae: 1.3905, huber: 1.0480, swd: 1.3093, target_std: 4.7623
      Epoch 10 composite train-obj: 0.825788
            No improvement (0.8298), counter 2/5
    Epoch [11/50], Train Losses: mse: 4.4011, mae: 1.1659, huber: 0.8256, swd: 1.2570, target_std: 6.5010
    Epoch [11/50], Val Losses: mse: 5.4333, mae: 1.1656, huber: 0.8277, swd: 0.8693, target_std: 4.2993
    Epoch [11/50], Test Losses: mse: 7.8268, mae: 1.3895, huber: 1.0472, swd: 1.3100, target_std: 4.7623
      Epoch 11 composite train-obj: 0.825603
            No improvement (0.8277), counter 3/5
    Epoch [12/50], Train Losses: mse: 4.4004, mae: 1.1661, huber: 0.8258, swd: 1.2547, target_std: 6.5012
    Epoch [12/50], Val Losses: mse: 5.4279, mae: 1.1581, huber: 0.8221, swd: 0.8383, target_std: 4.2993
    Epoch [12/50], Test Losses: mse: 7.8572, mae: 1.3925, huber: 1.0508, swd: 1.3123, target_std: 4.7623
      Epoch 12 composite train-obj: 0.825764
            No improvement (0.8221), counter 4/5
    Epoch [13/50], Train Losses: mse: 4.4000, mae: 1.1657, huber: 0.8254, swd: 1.2569, target_std: 6.5013
    Epoch [13/50], Val Losses: mse: 5.4105, mae: 1.1536, huber: 0.8186, swd: 0.8292, target_std: 4.2993
    Epoch [13/50], Test Losses: mse: 7.8169, mae: 1.3848, huber: 1.0441, swd: 1.2622, target_std: 4.7623
      Epoch 13 composite train-obj: 0.825403
            Val objective improved 0.8203 → 0.8186, saving checkpoint.
    Epoch [14/50], Train Losses: mse: 4.4000, mae: 1.1655, huber: 0.8253, swd: 1.2569, target_std: 6.5014
    Epoch [14/50], Val Losses: mse: 5.4307, mae: 1.1669, huber: 0.8295, swd: 0.8790, target_std: 4.2993
    Epoch [14/50], Test Losses: mse: 7.8054, mae: 1.3883, huber: 1.0470, swd: 1.3122, target_std: 4.7623
      Epoch 14 composite train-obj: 0.825290
            No improvement (0.8295), counter 1/5
    Epoch [15/50], Train Losses: mse: 4.3974, mae: 1.1654, huber: 0.8250, swd: 1.2551, target_std: 6.5009
    Epoch [15/50], Val Losses: mse: 5.4492, mae: 1.1807, huber: 0.8414, swd: 0.9712, target_std: 4.2993
    Epoch [15/50], Test Losses: mse: 7.7474, mae: 1.3879, huber: 1.0456, swd: 1.3778, target_std: 4.7623
      Epoch 15 composite train-obj: 0.825032
            No improvement (0.8414), counter 2/5
    Epoch [16/50], Train Losses: mse: 4.4062, mae: 1.1664, huber: 0.8261, swd: 1.2576, target_std: 6.5012
    Epoch [16/50], Val Losses: mse: 5.4495, mae: 1.1643, huber: 0.8277, swd: 0.8612, target_std: 4.2993
    Epoch [16/50], Test Losses: mse: 7.7965, mae: 1.3855, huber: 1.0446, swd: 1.2961, target_std: 4.7623
      Epoch 16 composite train-obj: 0.826143
            No improvement (0.8277), counter 3/5
    Epoch [17/50], Train Losses: mse: 4.3937, mae: 1.1650, huber: 0.8247, swd: 1.2530, target_std: 6.5010
    Epoch [17/50], Val Losses: mse: 5.4948, mae: 1.1714, huber: 0.8339, swd: 0.8651, target_std: 4.2993
    Epoch [17/50], Test Losses: mse: 7.8374, mae: 1.3893, huber: 1.0470, swd: 1.2882, target_std: 4.7623
      Epoch 17 composite train-obj: 0.824686
            No improvement (0.8339), counter 4/5
    Epoch [18/50], Train Losses: mse: 4.3999, mae: 1.1659, huber: 0.8256, swd: 1.2582, target_std: 6.5010
    Epoch [18/50], Val Losses: mse: 5.4267, mae: 1.1668, huber: 0.8295, swd: 0.8864, target_std: 4.2993
    Epoch [18/50], Test Losses: mse: 7.8025, mae: 1.3885, huber: 1.0472, swd: 1.3410, target_std: 4.7623
      Epoch 18 composite train-obj: 0.825637
    Epoch [18/50], Test Losses: mse: 7.8169, mae: 1.3848, huber: 1.0441, swd: 1.2622, target_std: 4.7623
    Best round's Test MSE: 7.8169, MAE: 1.3848, SWD: 1.2622
    Best round's Validation MSE: 5.4105, MAE: 1.1536
    Best round's Test verification MSE : 7.8169, MAE: 1.3848, SWD: 1.2622
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq336_pred96_20250429_1851)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.8549 ± 0.0287
      mae: 1.3890 ± 0.0030
      huber: 1.0479 ± 0.0027
      swd: 1.3324 ± 0.0497
      target_std: 4.7623 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.4225 ± 0.0208
      mae: 1.1553 ± 0.0012
      huber: 0.8194 ± 0.0006
      swd: 0.8565 ± 0.0232
      target_std: 4.2993 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq336_pred96_20250429_1851
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 336-196


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_336_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.7430, mae: 1.4456, huber: 1.0862, swd: 1.9823, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 6.4682, mae: 1.2823, huber: 0.9375, swd: 0.9448, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.7262, mae: 1.5846, huber: 1.2312, swd: 1.6941, target_std: 4.7534
      Epoch 1 composite train-obj: 1.086220
            Val objective improved inf → 0.9375, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4881, mae: 1.3155, huber: 0.9648, swd: 1.6638, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 6.3902, mae: 1.2744, huber: 0.9299, swd: 0.9261, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.6443, mae: 1.5730, huber: 1.2203, swd: 1.6464, target_std: 4.7534
      Epoch 2 composite train-obj: 0.964758
            Val objective improved 0.9375 → 0.9299, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4539, mae: 1.3100, huber: 0.9598, swd: 1.6447, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.4435, mae: 1.2785, huber: 0.9347, swd: 0.9237, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.6766, mae: 1.5723, huber: 1.2201, swd: 1.6039, target_std: 4.7534
      Epoch 3 composite train-obj: 0.959849
            No improvement (0.9347), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4432, mae: 1.3093, huber: 0.9590, swd: 1.6401, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.4442, mae: 1.2829, huber: 0.9385, swd: 1.0051, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.5419, mae: 1.5605, huber: 1.2087, swd: 1.6345, target_std: 4.7534
      Epoch 4 composite train-obj: 0.958976
            No improvement (0.9385), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4331, mae: 1.3076, huber: 0.9576, swd: 1.6330, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 6.4717, mae: 1.2901, huber: 0.9453, swd: 1.0289, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.5184, mae: 1.5629, huber: 1.2111, swd: 1.6625, target_std: 4.7534
      Epoch 5 composite train-obj: 0.957636
            No improvement (0.9453), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.4459, mae: 1.3093, huber: 0.9593, swd: 1.6406, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.4270, mae: 1.2797, huber: 0.9355, swd: 0.9333, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.6043, mae: 1.5683, huber: 1.2166, swd: 1.6118, target_std: 4.7534
      Epoch 6 composite train-obj: 0.959312
            No improvement (0.9355), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4304, mae: 1.3084, huber: 0.9580, swd: 1.6315, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 6.4761, mae: 1.2846, huber: 0.9399, swd: 0.9156, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.7240, mae: 1.5750, huber: 1.2222, swd: 1.5839, target_std: 4.7534
      Epoch 7 composite train-obj: 0.957976
    Epoch [7/50], Test Losses: mse: 9.6443, mae: 1.5730, huber: 1.2203, swd: 1.6464, target_std: 4.7534
    Best round's Test MSE: 9.6443, MAE: 1.5730, SWD: 1.6464
    Best round's Validation MSE: 6.3902, MAE: 1.2744
    Best round's Test verification MSE : 9.6443, MAE: 1.5730, SWD: 1.6464
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.7303, mae: 1.4446, huber: 1.0851, swd: 2.0197, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 6.5181, mae: 1.2869, huber: 0.9417, swd: 0.8917, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.8170, mae: 1.5907, huber: 1.2368, swd: 1.6303, target_std: 4.7534
      Epoch 1 composite train-obj: 1.085079
            Val objective improved inf → 0.9417, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4905, mae: 1.3155, huber: 0.9649, swd: 1.7083, target_std: 6.5012
    Epoch [2/50], Val Losses: mse: 6.4628, mae: 1.2788, huber: 0.9352, swd: 0.9355, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.6867, mae: 1.5729, huber: 1.2213, swd: 1.6517, target_std: 4.7534
      Epoch 2 composite train-obj: 0.964876
            Val objective improved 0.9417 → 0.9352, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4601, mae: 1.3110, huber: 0.9608, swd: 1.6897, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.4124, mae: 1.2889, huber: 0.9434, swd: 1.0108, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.5840, mae: 1.5768, huber: 1.2237, swd: 1.7331, target_std: 4.7534
      Epoch 3 composite train-obj: 0.960830
            No improvement (0.9434), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4515, mae: 1.3099, huber: 0.9598, swd: 1.6840, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 6.4162, mae: 1.2809, huber: 0.9367, swd: 0.9686, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.5678, mae: 1.5668, huber: 1.2151, swd: 1.6398, target_std: 4.7534
      Epoch 4 composite train-obj: 0.959783
            No improvement (0.9367), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4431, mae: 1.3096, huber: 0.9593, swd: 1.6767, target_std: 6.5010
    Epoch [5/50], Val Losses: mse: 6.4191, mae: 1.2782, huber: 0.9345, swd: 0.9116, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.6926, mae: 1.5725, huber: 1.2212, swd: 1.6109, target_std: 4.7534
      Epoch 5 composite train-obj: 0.959332
            Val objective improved 0.9352 → 0.9345, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.4395, mae: 1.3097, huber: 0.9593, swd: 1.6751, target_std: 6.5010
    Epoch [6/50], Val Losses: mse: 6.5159, mae: 1.2952, huber: 0.9514, swd: 1.0998, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.5251, mae: 1.5589, huber: 1.2080, swd: 1.6790, target_std: 4.7534
      Epoch 6 composite train-obj: 0.959262
            No improvement (0.9514), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.4334, mae: 1.3081, huber: 0.9579, swd: 1.6721, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 6.4144, mae: 1.2942, huber: 0.9485, swd: 1.1200, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.4666, mae: 1.5649, huber: 1.2128, swd: 1.7431, target_std: 4.7534
      Epoch 7 composite train-obj: 0.957944
            No improvement (0.9485), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.4401, mae: 1.3089, huber: 0.9589, swd: 1.6729, target_std: 6.5012
    Epoch [8/50], Val Losses: mse: 6.4286, mae: 1.2810, huber: 0.9375, swd: 0.9585, target_std: 4.2875
    Epoch [8/50], Test Losses: mse: 9.5796, mae: 1.5646, huber: 1.2137, swd: 1.6390, target_std: 4.7534
      Epoch 8 composite train-obj: 0.958890
            No improvement (0.9375), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.4278, mae: 1.3082, huber: 0.9579, swd: 1.6701, target_std: 6.5011
    Epoch [9/50], Val Losses: mse: 6.5100, mae: 1.3021, huber: 0.9569, swd: 1.0801, target_std: 4.2875
    Epoch [9/50], Test Losses: mse: 9.5656, mae: 1.5668, huber: 1.2151, swd: 1.7232, target_std: 4.7534
      Epoch 9 composite train-obj: 0.957935
            No improvement (0.9569), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.4363, mae: 1.3098, huber: 0.9593, swd: 1.6724, target_std: 6.5011
    Epoch [10/50], Val Losses: mse: 6.4974, mae: 1.2999, huber: 0.9540, swd: 1.0418, target_std: 4.2875
    Epoch [10/50], Test Losses: mse: 9.5559, mae: 1.5684, huber: 1.2163, swd: 1.6824, target_std: 4.7534
      Epoch 10 composite train-obj: 0.959277
    Epoch [10/50], Test Losses: mse: 9.6926, mae: 1.5725, huber: 1.2212, swd: 1.6109, target_std: 4.7534
    Best round's Test MSE: 9.6926, MAE: 1.5725, SWD: 1.6109
    Best round's Validation MSE: 6.4191, MAE: 1.2782
    Best round's Test verification MSE : 9.6926, MAE: 1.5725, SWD: 1.6109
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.7585, mae: 1.4457, huber: 1.0861, swd: 1.7802, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 6.5272, mae: 1.2882, huber: 0.9427, swd: 0.8837, target_std: 4.2875
    Epoch [1/50], Test Losses: mse: 9.8214, mae: 1.5910, huber: 1.2371, swd: 1.5683, target_std: 4.7534
      Epoch 1 composite train-obj: 1.086113
            Val objective improved inf → 0.9427, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4949, mae: 1.3160, huber: 0.9655, swd: 1.5096, target_std: 6.5011
    Epoch [2/50], Val Losses: mse: 6.4875, mae: 1.2833, huber: 0.9390, swd: 0.9160, target_std: 4.2875
    Epoch [2/50], Test Losses: mse: 9.6928, mae: 1.5742, huber: 1.2222, swd: 1.5664, target_std: 4.7534
      Epoch 2 composite train-obj: 0.965458
            Val objective improved 0.9427 → 0.9390, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4672, mae: 1.3113, huber: 0.9612, swd: 1.4960, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 6.4541, mae: 1.2863, huber: 0.9410, swd: 0.9421, target_std: 4.2875
    Epoch [3/50], Test Losses: mse: 9.5844, mae: 1.5725, huber: 1.2200, swd: 1.5828, target_std: 4.7534
      Epoch 3 composite train-obj: 0.961234
            No improvement (0.9410), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4512, mae: 1.3102, huber: 0.9601, swd: 1.4855, target_std: 6.5012
    Epoch [4/50], Val Losses: mse: 6.4450, mae: 1.2775, huber: 0.9331, swd: 0.8396, target_std: 4.2875
    Epoch [4/50], Test Losses: mse: 9.7455, mae: 1.5782, huber: 1.2254, swd: 1.4881, target_std: 4.7534
      Epoch 4 composite train-obj: 0.960066
            Val objective improved 0.9390 → 0.9331, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.4367, mae: 1.3081, huber: 0.9579, swd: 1.4771, target_std: 6.5012
    Epoch [5/50], Val Losses: mse: 6.4310, mae: 1.2925, huber: 0.9473, swd: 1.0309, target_std: 4.2875
    Epoch [5/50], Test Losses: mse: 9.5114, mae: 1.5674, huber: 1.2152, swd: 1.6775, target_std: 4.7534
      Epoch 5 composite train-obj: 0.957946
            No improvement (0.9473), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.4366, mae: 1.3089, huber: 0.9587, swd: 1.4787, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 6.4130, mae: 1.2757, huber: 0.9325, swd: 0.8775, target_std: 4.2875
    Epoch [6/50], Test Losses: mse: 9.6205, mae: 1.5666, huber: 1.2150, swd: 1.5322, target_std: 4.7534
      Epoch 6 composite train-obj: 0.958719
            Val objective improved 0.9331 → 0.9325, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 5.4406, mae: 1.3091, huber: 0.9589, swd: 1.4783, target_std: 6.5012
    Epoch [7/50], Val Losses: mse: 6.4388, mae: 1.2834, huber: 0.9396, swd: 0.9412, target_std: 4.2875
    Epoch [7/50], Test Losses: mse: 9.5928, mae: 1.5672, huber: 1.2158, swd: 1.6002, target_std: 4.7534
      Epoch 7 composite train-obj: 0.958917
            No improvement (0.9396), counter 1/5
    Epoch [8/50], Train Losses: mse: 5.4362, mae: 1.3094, huber: 0.9590, swd: 1.4761, target_std: 6.5011
    Epoch [8/50], Val Losses: mse: 6.4297, mae: 1.2926, huber: 0.9481, swd: 1.0164, target_std: 4.2875
    Epoch [8/50], Test Losses: mse: 9.5583, mae: 1.5680, huber: 1.2162, swd: 1.6536, target_std: 4.7534
      Epoch 8 composite train-obj: 0.958997
            No improvement (0.9481), counter 2/5
    Epoch [9/50], Train Losses: mse: 5.4342, mae: 1.3085, huber: 0.9583, swd: 1.4716, target_std: 6.5011
    Epoch [9/50], Val Losses: mse: 6.5741, mae: 1.3090, huber: 0.9625, swd: 1.0310, target_std: 4.2875
    Epoch [9/50], Test Losses: mse: 9.5345, mae: 1.5660, huber: 1.2137, swd: 1.6034, target_std: 4.7534
      Epoch 9 composite train-obj: 0.958263
            No improvement (0.9625), counter 3/5
    Epoch [10/50], Train Losses: mse: 5.4294, mae: 1.3075, huber: 0.9574, swd: 1.4713, target_std: 6.5012
    Epoch [10/50], Val Losses: mse: 6.5600, mae: 1.3102, huber: 0.9649, swd: 1.0715, target_std: 4.2875
    Epoch [10/50], Test Losses: mse: 9.6046, mae: 1.5735, huber: 1.2224, swd: 1.7069, target_std: 4.7534
      Epoch 10 composite train-obj: 0.957383
            No improvement (0.9649), counter 4/5
    Epoch [11/50], Train Losses: mse: 5.4348, mae: 1.3086, huber: 0.9583, swd: 1.4738, target_std: 6.5011
    Epoch [11/50], Val Losses: mse: 6.4641, mae: 1.3025, huber: 0.9561, swd: 1.0296, target_std: 4.2875
    Epoch [11/50], Test Losses: mse: 9.5125, mae: 1.5709, huber: 1.2179, swd: 1.6657, target_std: 4.7534
      Epoch 11 composite train-obj: 0.958277
    Epoch [11/50], Test Losses: mse: 9.6205, mae: 1.5666, huber: 1.2150, swd: 1.5322, target_std: 4.7534
    Best round's Test MSE: 9.6205, MAE: 1.5666, SWD: 1.5322
    Best round's Validation MSE: 6.4130, MAE: 1.2757
    Best round's Test verification MSE : 9.6205, MAE: 1.5666, SWD: 1.5322
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq336_pred196_20250429_1857)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.6525 ± 0.0300
      mae: 1.5707 ± 0.0029
      huber: 1.2188 ± 0.0027
      swd: 1.5965 ± 0.0477
      target_std: 4.7534 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.4074 ± 0.0124
      mae: 1.2761 ± 0.0016
      huber: 0.9323 ± 0.0019
      swd: 0.9051 ± 0.0204
      target_std: 4.2875 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq336_pred196_20250429_1857
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 336-336


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_336_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3884, mae: 1.5409, huber: 1.1742, swd: 2.0056, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 7.9887, mae: 1.4105, huber: 1.0608, swd: 0.9599, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 11.0574, mae: 1.7270, huber: 1.3649, swd: 1.8101, target_std: 4.7502
      Epoch 1 composite train-obj: 1.174224
            Val objective improved inf → 1.0608, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2572, mae: 1.4273, huber: 1.0679, swd: 1.7612, target_std: 6.5009
    Epoch [2/50], Val Losses: mse: 7.9627, mae: 1.4093, huber: 1.0595, swd: 0.9846, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 10.9925, mae: 1.7158, huber: 1.3547, swd: 1.7620, target_std: 4.7502
      Epoch 2 composite train-obj: 1.067866
            Val objective improved 1.0608 → 1.0595, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2342, mae: 1.4244, huber: 1.0651, swd: 1.7494, target_std: 6.5011
    Epoch [3/50], Val Losses: mse: 7.8818, mae: 1.3997, huber: 1.0505, swd: 0.9500, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.9271, mae: 1.7124, huber: 1.3505, swd: 1.7484, target_std: 4.7502
      Epoch 3 composite train-obj: 1.065118
            Val objective improved 1.0595 → 1.0505, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.1988, mae: 1.4202, huber: 1.0611, swd: 1.7240, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 7.8345, mae: 1.3955, huber: 1.0459, swd: 0.9045, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.8965, mae: 1.7124, huber: 1.3509, swd: 1.7313, target_std: 4.7502
      Epoch 4 composite train-obj: 1.061072
            Val objective improved 1.0505 → 1.0459, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.2002, mae: 1.4212, huber: 1.0620, swd: 1.7211, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 7.8075, mae: 1.4010, huber: 1.0520, swd: 1.0204, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7841, mae: 1.7022, huber: 1.3421, swd: 1.7866, target_std: 4.7502
      Epoch 5 composite train-obj: 1.061966
            No improvement (1.0520), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.1988, mae: 1.4209, huber: 1.0617, swd: 1.7275, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 7.9053, mae: 1.4106, huber: 1.0601, swd: 0.9618, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.8965, mae: 1.7113, huber: 1.3504, swd: 1.7316, target_std: 4.7502
      Epoch 6 composite train-obj: 1.061718
            No improvement (1.0601), counter 2/5
    Epoch [7/50], Train Losses: mse: 6.1883, mae: 1.4197, huber: 1.0604, swd: 1.7133, target_std: 6.5011
    Epoch [7/50], Val Losses: mse: 7.9096, mae: 1.4237, huber: 1.0715, swd: 1.0700, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.7862, mae: 1.7092, huber: 1.3468, swd: 1.7798, target_std: 4.7502
      Epoch 7 composite train-obj: 1.060429
            No improvement (1.0715), counter 3/5
    Epoch [8/50], Train Losses: mse: 6.2113, mae: 1.4235, huber: 1.0639, swd: 1.7253, target_std: 6.5008
    Epoch [8/50], Val Losses: mse: 7.8500, mae: 1.4040, huber: 1.0539, swd: 0.9384, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.9314, mae: 1.7155, huber: 1.3542, swd: 1.7286, target_std: 4.7502
      Epoch 8 composite train-obj: 1.063927
            No improvement (1.0539), counter 4/5
    Epoch [9/50], Train Losses: mse: 6.1865, mae: 1.4199, huber: 1.0607, swd: 1.7100, target_std: 6.5009
    Epoch [9/50], Val Losses: mse: 7.8166, mae: 1.4001, huber: 1.0500, swd: 0.9461, target_std: 4.2763
    Epoch [9/50], Test Losses: mse: 10.8195, mae: 1.7029, huber: 1.3411, swd: 1.6936, target_std: 4.7502
      Epoch 9 composite train-obj: 1.060678
    Epoch [9/50], Test Losses: mse: 10.8965, mae: 1.7124, huber: 1.3509, swd: 1.7313, target_std: 4.7502
    Best round's Test MSE: 10.8965, MAE: 1.7124, SWD: 1.7313
    Best round's Validation MSE: 7.8345, MAE: 1.3955
    Best round's Test verification MSE : 10.8965, MAE: 1.7124, SWD: 1.7313
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4784, mae: 1.5420, huber: 1.1755, swd: 2.1066, target_std: 6.5012
    Epoch [1/50], Val Losses: mse: 7.9718, mae: 1.4082, huber: 1.0581, swd: 0.9606, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 11.0525, mae: 1.7276, huber: 1.3656, swd: 1.8640, target_std: 4.7502
      Epoch 1 composite train-obj: 1.175531
            Val objective improved inf → 1.0581, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2508, mae: 1.4267, huber: 1.0673, swd: 1.8269, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 7.9295, mae: 1.4026, huber: 1.0520, swd: 0.9095, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 11.0622, mae: 1.7244, huber: 1.3608, swd: 1.7651, target_std: 4.7502
      Epoch 2 composite train-obj: 1.067267
            Val objective improved 1.0581 → 1.0520, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2341, mae: 1.4240, huber: 1.0648, swd: 1.8194, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 7.8677, mae: 1.3969, huber: 1.0475, swd: 0.9482, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.9352, mae: 1.7149, huber: 1.3538, swd: 1.7930, target_std: 4.7502
      Epoch 3 composite train-obj: 1.064846
            Val objective improved 1.0520 → 1.0475, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.2097, mae: 1.4220, huber: 1.0628, swd: 1.8039, target_std: 6.5011
    Epoch [4/50], Val Losses: mse: 7.9733, mae: 1.4244, huber: 1.0748, swd: 1.1637, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.8315, mae: 1.7061, huber: 1.3456, swd: 1.9117, target_std: 4.7502
      Epoch 4 composite train-obj: 1.062766
            No improvement (1.0748), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.2064, mae: 1.4213, huber: 1.0622, swd: 1.7938, target_std: 6.5009
    Epoch [5/50], Val Losses: mse: 7.7627, mae: 1.4018, huber: 1.0518, swd: 1.1011, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7475, mae: 1.7020, huber: 1.3414, swd: 1.8959, target_std: 4.7502
      Epoch 5 composite train-obj: 1.062174
            No improvement (1.0518), counter 2/5
    Epoch [6/50], Train Losses: mse: 6.1970, mae: 1.4208, huber: 1.0616, swd: 1.7914, target_std: 6.5011
    Epoch [6/50], Val Losses: mse: 7.8504, mae: 1.3942, huber: 1.0445, swd: 0.8668, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 11.0337, mae: 1.7218, huber: 1.3605, swd: 1.7220, target_std: 4.7502
      Epoch 6 composite train-obj: 1.061556
            Val objective improved 1.0475 → 1.0445, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.1825, mae: 1.4188, huber: 1.0596, swd: 1.7833, target_std: 6.5009
    Epoch [7/50], Val Losses: mse: 7.8100, mae: 1.4007, huber: 1.0513, swd: 0.9654, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.8611, mae: 1.7115, huber: 1.3505, swd: 1.8180, target_std: 4.7502
      Epoch 7 composite train-obj: 1.059617
            No improvement (1.0513), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.1828, mae: 1.4195, huber: 1.0602, swd: 1.7824, target_std: 6.5012
    Epoch [8/50], Val Losses: mse: 7.8725, mae: 1.4087, huber: 1.0585, swd: 1.0367, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.8898, mae: 1.7143, huber: 1.3525, swd: 1.8475, target_std: 4.7502
      Epoch 8 composite train-obj: 1.060203
            No improvement (1.0585), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.1959, mae: 1.4209, huber: 1.0616, swd: 1.7913, target_std: 6.5010
    Epoch [9/50], Val Losses: mse: 7.7841, mae: 1.3960, huber: 1.0460, swd: 0.9844, target_std: 4.2763
    Epoch [9/50], Test Losses: mse: 10.8435, mae: 1.7055, huber: 1.3442, swd: 1.7772, target_std: 4.7502
      Epoch 9 composite train-obj: 1.061638
            No improvement (1.0460), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.1865, mae: 1.4195, huber: 1.0604, swd: 1.7856, target_std: 6.5011
    Epoch [10/50], Val Losses: mse: 7.8208, mae: 1.4120, huber: 1.0610, swd: 1.1172, target_std: 4.2763
    Epoch [10/50], Test Losses: mse: 10.7147, mae: 1.7025, huber: 1.3415, swd: 1.8668, target_std: 4.7502
      Epoch 10 composite train-obj: 1.060412
            No improvement (1.0610), counter 4/5
    Epoch [11/50], Train Losses: mse: 6.1802, mae: 1.4196, huber: 1.0603, swd: 1.7807, target_std: 6.5009
    Epoch [11/50], Val Losses: mse: 7.7782, mae: 1.4012, huber: 1.0504, swd: 1.0456, target_std: 4.2763
    Epoch [11/50], Test Losses: mse: 10.7702, mae: 1.7045, huber: 1.3430, swd: 1.8224, target_std: 4.7502
      Epoch 11 composite train-obj: 1.060269
    Epoch [11/50], Test Losses: mse: 11.0337, mae: 1.7218, huber: 1.3605, swd: 1.7220, target_std: 4.7502
    Best round's Test MSE: 11.0337, MAE: 1.7218, SWD: 1.7220
    Best round's Validation MSE: 7.8504, MAE: 1.3942
    Best round's Test verification MSE : 11.0337, MAE: 1.7218, SWD: 1.7220
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5248, mae: 1.5465, huber: 1.1798, swd: 2.0230, target_std: 6.5011
    Epoch [1/50], Val Losses: mse: 8.0587, mae: 1.4350, huber: 1.0828, swd: 1.2007, target_std: 4.2763
    Epoch [1/50], Test Losses: mse: 10.9139, mae: 1.7239, huber: 1.3613, swd: 2.0510, target_std: 4.7502
      Epoch 1 composite train-obj: 1.179783
            Val objective improved inf → 1.0828, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2522, mae: 1.4266, huber: 1.0672, swd: 1.7423, target_std: 6.5010
    Epoch [2/50], Val Losses: mse: 7.9266, mae: 1.4017, huber: 1.0512, swd: 0.9551, target_std: 4.2763
    Epoch [2/50], Test Losses: mse: 11.0074, mae: 1.7218, huber: 1.3596, swd: 1.8768, target_std: 4.7502
      Epoch 2 composite train-obj: 1.067208
            Val objective improved 1.0828 → 1.0512, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2254, mae: 1.4232, huber: 1.0640, swd: 1.7264, target_std: 6.5009
    Epoch [3/50], Val Losses: mse: 7.8774, mae: 1.4075, huber: 1.0583, swd: 1.0891, target_std: 4.2763
    Epoch [3/50], Test Losses: mse: 10.8677, mae: 1.7103, huber: 1.3496, swd: 1.9576, target_std: 4.7502
      Epoch 3 composite train-obj: 1.064044
            No improvement (1.0583), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.1986, mae: 1.4204, huber: 1.0611, swd: 1.7149, target_std: 6.5010
    Epoch [4/50], Val Losses: mse: 7.8434, mae: 1.3930, huber: 1.0438, swd: 0.9605, target_std: 4.2763
    Epoch [4/50], Test Losses: mse: 10.9414, mae: 1.7131, huber: 1.3515, swd: 1.8485, target_std: 4.7502
      Epoch 4 composite train-obj: 1.061093
            Val objective improved 1.0512 → 1.0438, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.1992, mae: 1.4202, huber: 1.0612, swd: 1.7108, target_std: 6.5007
    Epoch [5/50], Val Losses: mse: 7.7850, mae: 1.3976, huber: 1.0481, swd: 1.0599, target_std: 4.2763
    Epoch [5/50], Test Losses: mse: 10.7646, mae: 1.7087, huber: 1.3474, swd: 1.9372, target_std: 4.7502
      Epoch 5 composite train-obj: 1.061181
            No improvement (1.0481), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.1926, mae: 1.4204, huber: 1.0612, swd: 1.7083, target_std: 6.5009
    Epoch [6/50], Val Losses: mse: 7.8885, mae: 1.4133, huber: 1.0629, swd: 1.1143, target_std: 4.2763
    Epoch [6/50], Test Losses: mse: 10.7518, mae: 1.7028, huber: 1.3420, swd: 1.9138, target_std: 4.7502
      Epoch 6 composite train-obj: 1.061165
            No improvement (1.0629), counter 2/5
    Epoch [7/50], Train Losses: mse: 6.2029, mae: 1.4218, huber: 1.0624, swd: 1.7090, target_std: 6.5009
    Epoch [7/50], Val Losses: mse: 7.8936, mae: 1.4066, huber: 1.0565, swd: 1.0158, target_std: 4.2763
    Epoch [7/50], Test Losses: mse: 10.9255, mae: 1.7121, huber: 1.3516, swd: 1.8423, target_std: 4.7502
      Epoch 7 composite train-obj: 1.062414
            No improvement (1.0565), counter 3/5
    Epoch [8/50], Train Losses: mse: 6.1929, mae: 1.4211, huber: 1.0617, swd: 1.7034, target_std: 6.5009
    Epoch [8/50], Val Losses: mse: 7.8987, mae: 1.4180, huber: 1.0685, swd: 1.1806, target_std: 4.2763
    Epoch [8/50], Test Losses: mse: 10.7778, mae: 1.7049, huber: 1.3439, swd: 1.9700, target_std: 4.7502
      Epoch 8 composite train-obj: 1.061660
            No improvement (1.0685), counter 4/5
    Epoch [9/50], Train Losses: mse: 6.1773, mae: 1.4185, huber: 1.0594, swd: 1.6981, target_std: 6.5011
    Epoch [9/50], Val Losses: mse: 7.8658, mae: 1.4073, huber: 1.0582, swd: 1.0558, target_std: 4.2763
    Epoch [9/50], Test Losses: mse: 10.7783, mae: 1.7043, huber: 1.3437, swd: 1.8826, target_std: 4.7502
      Epoch 9 composite train-obj: 1.059432
    Epoch [9/50], Test Losses: mse: 10.9414, mae: 1.7131, huber: 1.3515, swd: 1.8485, target_std: 4.7502
    Best round's Test MSE: 10.9414, MAE: 1.7131, SWD: 1.8485
    Best round's Validation MSE: 7.8434, MAE: 1.3930
    Best round's Test verification MSE : 10.9414, MAE: 1.7131, SWD: 1.8485
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq336_pred336_20250429_1900)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.9572 ± 0.0571
      mae: 1.7158 ± 0.0043
      huber: 1.3543 ± 0.0044
      swd: 1.7673 ± 0.0575
      target_std: 4.7502 ± 0.0000
      count: 50.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.8428 ± 0.0065
      mae: 1.3942 ± 0.0010
      huber: 1.0447 ± 0.0009
      swd: 0.9106 ± 0.0385
      target_std: 4.2763 ± 0.0000
      count: 50.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq336_pred336_20250429_1900
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 336-720


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=336,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_336_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4314, mae: 1.6793, huber: 1.3026, swd: 2.0951, target_std: 6.4985
    Epoch [1/50], Val Losses: mse: 10.0732, mae: 1.5881, huber: 1.2301, swd: 1.1369, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 12.1866, mae: 1.8729, huber: 1.4991, swd: 1.8833, target_std: 4.7606
      Epoch 1 composite train-obj: 1.302604
            Val objective improved inf → 1.2301, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.2391, mae: 1.5733, huber: 1.2020, swd: 1.8569, target_std: 6.4985
    Epoch [2/50], Val Losses: mse: 9.8644, mae: 1.5654, huber: 1.2086, swd: 1.0458, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 12.0579, mae: 1.8624, huber: 1.4886, swd: 1.8108, target_std: 4.7606
      Epoch 2 composite train-obj: 1.201961
            Val objective improved 1.2301 → 1.2086, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.1902, mae: 1.5669, huber: 1.1958, swd: 1.8290, target_std: 6.4988
    Epoch [3/50], Val Losses: mse: 9.8350, mae: 1.5644, huber: 1.2070, swd: 1.0191, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 12.0754, mae: 1.8614, huber: 1.4880, swd: 1.7655, target_std: 4.7606
      Epoch 3 composite train-obj: 1.195837
            Val objective improved 1.2086 → 1.2070, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.1716, mae: 1.5645, huber: 1.1937, swd: 1.8178, target_std: 6.4986
    Epoch [4/50], Val Losses: mse: 9.8400, mae: 1.5801, huber: 1.2223, swd: 1.2098, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.8392, mae: 1.8495, huber: 1.4762, swd: 1.8689, target_std: 4.7606
      Epoch 4 composite train-obj: 1.193663
            No improvement (1.2223), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.1685, mae: 1.5645, huber: 1.1935, swd: 1.8103, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 9.7713, mae: 1.5697, huber: 1.2127, swd: 1.1706, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.8763, mae: 1.8501, huber: 1.4765, swd: 1.8217, target_std: 4.7606
      Epoch 5 composite train-obj: 1.193508
            No improvement (1.2127), counter 2/5
    Epoch [6/50], Train Losses: mse: 7.1407, mae: 1.5613, huber: 1.1904, swd: 1.7929, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 9.8429, mae: 1.5834, huber: 1.2249, swd: 1.1139, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.9244, mae: 1.8566, huber: 1.4834, swd: 1.7839, target_std: 4.7606
      Epoch 6 composite train-obj: 1.190440
            No improvement (1.2249), counter 3/5
    Epoch [7/50], Train Losses: mse: 7.1473, mae: 1.5618, huber: 1.1909, swd: 1.7973, target_std: 6.4986
    Epoch [7/50], Val Losses: mse: 9.8710, mae: 1.6024, huber: 1.2418, swd: 1.3505, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.8012, mae: 1.8538, huber: 1.4793, swd: 1.9025, target_std: 4.7606
      Epoch 7 composite train-obj: 1.190945
            No improvement (1.2418), counter 4/5
    Epoch [8/50], Train Losses: mse: 7.1340, mae: 1.5609, huber: 1.1899, swd: 1.7882, target_std: 6.4985
    Epoch [8/50], Val Losses: mse: 9.6280, mae: 1.5567, huber: 1.2002, swd: 1.0907, target_std: 4.2736
    Epoch [8/50], Test Losses: mse: 11.8443, mae: 1.8462, huber: 1.4741, swd: 1.7560, target_std: 4.7606
      Epoch 8 composite train-obj: 1.189882
            Val objective improved 1.2070 → 1.2002, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 7.1289, mae: 1.5601, huber: 1.1892, swd: 1.7751, target_std: 6.4985
    Epoch [9/50], Val Losses: mse: 9.7240, mae: 1.5727, huber: 1.2154, swd: 1.2020, target_std: 4.2736
    Epoch [9/50], Test Losses: mse: 11.7806, mae: 1.8433, huber: 1.4707, swd: 1.7953, target_std: 4.7606
      Epoch 9 composite train-obj: 1.189211
            No improvement (1.2154), counter 1/5
    Epoch [10/50], Train Losses: mse: 7.1486, mae: 1.5625, huber: 1.1914, swd: 1.7904, target_std: 6.4987
    Epoch [10/50], Val Losses: mse: 9.7144, mae: 1.5796, huber: 1.2210, swd: 1.2622, target_std: 4.2736
    Epoch [10/50], Test Losses: mse: 11.7515, mae: 1.8428, huber: 1.4708, swd: 1.8408, target_std: 4.7606
      Epoch 10 composite train-obj: 1.191394
            No improvement (1.2210), counter 2/5
    Epoch [11/50], Train Losses: mse: 7.1125, mae: 1.5580, huber: 1.1872, swd: 1.7680, target_std: 6.4986
    Epoch [11/50], Val Losses: mse: 9.8089, mae: 1.5838, huber: 1.2255, swd: 1.1389, target_std: 4.2736
    Epoch [11/50], Test Losses: mse: 11.9325, mae: 1.8597, huber: 1.4856, swd: 1.7550, target_std: 4.7606
      Epoch 11 composite train-obj: 1.187189
            No improvement (1.2255), counter 3/5
    Epoch [12/50], Train Losses: mse: 7.1248, mae: 1.5595, huber: 1.1885, swd: 1.7732, target_std: 6.4986
    Epoch [12/50], Val Losses: mse: 9.7556, mae: 1.5807, huber: 1.2225, swd: 1.1956, target_std: 4.2736
    Epoch [12/50], Test Losses: mse: 11.8936, mae: 1.8529, huber: 1.4808, swd: 1.7811, target_std: 4.7606
      Epoch 12 composite train-obj: 1.188489
            No improvement (1.2225), counter 4/5
    Epoch [13/50], Train Losses: mse: 7.1343, mae: 1.5606, huber: 1.1896, swd: 1.7724, target_std: 6.4988
    Epoch [13/50], Val Losses: mse: 9.7387, mae: 1.5829, huber: 1.2245, swd: 1.2440, target_std: 4.2736
    Epoch [13/50], Test Losses: mse: 11.7925, mae: 1.8461, huber: 1.4734, swd: 1.7850, target_std: 4.7606
      Epoch 13 composite train-obj: 1.189568
    Epoch [13/50], Test Losses: mse: 11.8443, mae: 1.8462, huber: 1.4741, swd: 1.7560, target_std: 4.7606
    Best round's Test MSE: 11.8443, MAE: 1.8462, SWD: 1.7560
    Best round's Validation MSE: 9.6280, MAE: 1.5567
    Best round's Test verification MSE : 11.8443, MAE: 1.8462, SWD: 1.7560
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.3684, mae: 1.6772, huber: 1.3005, swd: 1.9766, target_std: 6.4987
    Epoch [1/50], Val Losses: mse: 9.9601, mae: 1.5715, huber: 1.2142, swd: 0.9854, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 12.2199, mae: 1.8781, huber: 1.5041, swd: 1.8536, target_std: 4.7606
      Epoch 1 composite train-obj: 1.300505
            Val objective improved inf → 1.2142, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.2453, mae: 1.5736, huber: 1.2023, swd: 1.7670, target_std: 6.4985
    Epoch [2/50], Val Losses: mse: 9.9792, mae: 1.5938, huber: 1.2352, swd: 1.2690, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 11.9155, mae: 1.8562, huber: 1.4829, swd: 1.9737, target_std: 4.7606
      Epoch 2 composite train-obj: 1.202311
            No improvement (1.2352), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.2065, mae: 1.5687, huber: 1.1977, swd: 1.7451, target_std: 6.4986
    Epoch [3/50], Val Losses: mse: 9.9265, mae: 1.5843, huber: 1.2260, swd: 1.1664, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 11.9948, mae: 1.8623, huber: 1.4889, swd: 1.9059, target_std: 4.7606
      Epoch 3 composite train-obj: 1.197664
            No improvement (1.2260), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.1675, mae: 1.5647, huber: 1.1937, swd: 1.7263, target_std: 6.4985
    Epoch [4/50], Val Losses: mse: 9.7621, mae: 1.5621, huber: 1.2057, swd: 1.0426, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.9749, mae: 1.8554, huber: 1.4824, swd: 1.8063, target_std: 4.7606
      Epoch 4 composite train-obj: 1.193661
            Val objective improved 1.2142 → 1.2057, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 7.1571, mae: 1.5634, huber: 1.1924, swd: 1.7126, target_std: 6.4987
    Epoch [5/50], Val Losses: mse: 9.7937, mae: 1.5818, huber: 1.2242, swd: 1.2179, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.8426, mae: 1.8495, huber: 1.4772, swd: 1.9266, target_std: 4.7606
      Epoch 5 composite train-obj: 1.192439
            No improvement (1.2242), counter 1/5
    Epoch [6/50], Train Losses: mse: 7.1606, mae: 1.5637, huber: 1.1927, swd: 1.7161, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 9.7669, mae: 1.5812, huber: 1.2230, swd: 1.1878, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.8170, mae: 1.8468, huber: 1.4741, swd: 1.8901, target_std: 4.7606
      Epoch 6 composite train-obj: 1.192735
            No improvement (1.2230), counter 2/5
    Epoch [7/50], Train Losses: mse: 7.1365, mae: 1.5605, huber: 1.1896, swd: 1.6985, target_std: 6.4984
    Epoch [7/50], Val Losses: mse: 9.8287, mae: 1.5873, huber: 1.2284, swd: 1.1768, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.7931, mae: 1.8443, huber: 1.4717, swd: 1.8384, target_std: 4.7606
      Epoch 7 composite train-obj: 1.189602
            No improvement (1.2284), counter 3/5
    Epoch [8/50], Train Losses: mse: 7.1428, mae: 1.5618, huber: 1.1909, swd: 1.7016, target_std: 6.4987
    Epoch [8/50], Val Losses: mse: 9.8486, mae: 1.6023, huber: 1.2421, swd: 1.3553, target_std: 4.2736
    Epoch [8/50], Test Losses: mse: 11.7243, mae: 1.8499, huber: 1.4736, swd: 1.9474, target_std: 4.7606
      Epoch 8 composite train-obj: 1.190853
            No improvement (1.2421), counter 4/5
    Epoch [9/50], Train Losses: mse: 7.1253, mae: 1.5598, huber: 1.1888, swd: 1.6891, target_std: 6.4984
    Epoch [9/50], Val Losses: mse: 9.7593, mae: 1.5861, huber: 1.2266, swd: 1.1370, target_std: 4.2736
    Epoch [9/50], Test Losses: mse: 11.9529, mae: 1.8638, huber: 1.4904, swd: 1.8592, target_std: 4.7606
      Epoch 9 composite train-obj: 1.188771
    Epoch [9/50], Test Losses: mse: 11.9749, mae: 1.8554, huber: 1.4824, swd: 1.8063, target_std: 4.7606
    Best round's Test MSE: 11.9749, MAE: 1.8554, SWD: 1.8063
    Best round's Validation MSE: 9.7621, MAE: 1.5621
    Best round's Test verification MSE : 11.9749, MAE: 1.8554, SWD: 1.8063
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.3827, mae: 1.6780, huber: 1.3013, swd: 2.1683, target_std: 6.4987
    Epoch [1/50], Val Losses: mse: 10.0988, mae: 1.5933, huber: 1.2338, swd: 1.1974, target_std: 4.2736
    Epoch [1/50], Test Losses: mse: 12.1901, mae: 1.8754, huber: 1.5013, swd: 2.0035, target_std: 4.7606
      Epoch 1 composite train-obj: 1.301296
            Val objective improved inf → 1.2338, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.2411, mae: 1.5737, huber: 1.2023, swd: 1.9391, target_std: 6.4986
    Epoch [2/50], Val Losses: mse: 9.8352, mae: 1.5659, huber: 1.2079, swd: 1.0378, target_std: 4.2736
    Epoch [2/50], Test Losses: mse: 12.1185, mae: 1.8706, huber: 1.4961, swd: 1.9101, target_std: 4.7606
      Epoch 2 composite train-obj: 1.202262
            Val objective improved 1.2338 → 1.2079, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.1947, mae: 1.5681, huber: 1.1970, swd: 1.9114, target_std: 6.4984
    Epoch [3/50], Val Losses: mse: 9.9684, mae: 1.6028, huber: 1.2437, swd: 1.3843, target_std: 4.2736
    Epoch [3/50], Test Losses: mse: 11.9231, mae: 1.8615, huber: 1.4881, swd: 2.0966, target_std: 4.7606
      Epoch 3 composite train-obj: 1.196954
            No improvement (1.2437), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.1784, mae: 1.5656, huber: 1.1946, swd: 1.8998, target_std: 6.4986
    Epoch [4/50], Val Losses: mse: 9.7863, mae: 1.5640, huber: 1.2072, swd: 1.1512, target_std: 4.2736
    Epoch [4/50], Test Losses: mse: 11.9102, mae: 1.8547, huber: 1.4797, swd: 1.9132, target_std: 4.7606
      Epoch 4 composite train-obj: 1.194641
            Val objective improved 1.2079 → 1.2072, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 7.1618, mae: 1.5643, huber: 1.1932, swd: 1.8870, target_std: 6.4985
    Epoch [5/50], Val Losses: mse: 9.7225, mae: 1.5678, huber: 1.2112, swd: 1.2593, target_std: 4.2736
    Epoch [5/50], Test Losses: mse: 11.8387, mae: 1.8471, huber: 1.4746, swd: 1.9684, target_std: 4.7606
      Epoch 5 composite train-obj: 1.193217
            No improvement (1.2112), counter 1/5
    Epoch [6/50], Train Losses: mse: 7.1410, mae: 1.5610, huber: 1.1902, swd: 1.8702, target_std: 6.4985
    Epoch [6/50], Val Losses: mse: 9.6860, mae: 1.5672, huber: 1.2099, swd: 1.2282, target_std: 4.2736
    Epoch [6/50], Test Losses: mse: 11.8498, mae: 1.8501, huber: 1.4769, swd: 1.9572, target_std: 4.7606
      Epoch 6 composite train-obj: 1.190218
            No improvement (1.2099), counter 2/5
    Epoch [7/50], Train Losses: mse: 7.1446, mae: 1.5615, huber: 1.1907, swd: 1.8729, target_std: 6.4984
    Epoch [7/50], Val Losses: mse: 9.6336, mae: 1.5530, huber: 1.1961, swd: 1.0850, target_std: 4.2736
    Epoch [7/50], Test Losses: mse: 11.9244, mae: 1.8562, huber: 1.4820, swd: 1.8776, target_std: 4.7606
      Epoch 7 composite train-obj: 1.190684
            Val objective improved 1.2072 → 1.1961, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 7.1433, mae: 1.5616, huber: 1.1907, swd: 1.8668, target_std: 6.4985
    Epoch [8/50], Val Losses: mse: 9.8699, mae: 1.5948, huber: 1.2362, swd: 1.4180, target_std: 4.2736
    Epoch [8/50], Test Losses: mse: 11.8006, mae: 1.8462, huber: 1.4733, swd: 1.9740, target_std: 4.7606
      Epoch 8 composite train-obj: 1.190705
            No improvement (1.2362), counter 1/5
    Epoch [9/50], Train Losses: mse: 7.1315, mae: 1.5609, huber: 1.1898, swd: 1.8574, target_std: 6.4984
    Epoch [9/50], Val Losses: mse: 9.6167, mae: 1.5609, huber: 1.2039, swd: 1.1908, target_std: 4.2736
    Epoch [9/50], Test Losses: mse: 11.8364, mae: 1.8463, huber: 1.4744, swd: 1.9176, target_std: 4.7606
      Epoch 9 composite train-obj: 1.189767
            No improvement (1.2039), counter 2/5
    Epoch [10/50], Train Losses: mse: 7.1257, mae: 1.5600, huber: 1.1890, swd: 1.8530, target_std: 6.4985
    Epoch [10/50], Val Losses: mse: 9.7685, mae: 1.5795, huber: 1.2218, swd: 1.2500, target_std: 4.2736
    Epoch [10/50], Test Losses: mse: 11.9007, mae: 1.8530, huber: 1.4798, swd: 1.8943, target_std: 4.7606
      Epoch 10 composite train-obj: 1.189018
            No improvement (1.2218), counter 3/5
    Epoch [11/50], Train Losses: mse: 7.1294, mae: 1.5595, huber: 1.1886, swd: 1.8538, target_std: 6.4985
    Epoch [11/50], Val Losses: mse: 9.8610, mae: 1.6080, huber: 1.2468, swd: 1.4563, target_std: 4.2736
    Epoch [11/50], Test Losses: mse: 11.7222, mae: 1.8462, huber: 1.4727, swd: 1.9941, target_std: 4.7606
      Epoch 11 composite train-obj: 1.188641
            No improvement (1.2468), counter 4/5
    Epoch [12/50], Train Losses: mse: 7.1289, mae: 1.5604, huber: 1.1894, swd: 1.8504, target_std: 6.4985
    Epoch [12/50], Val Losses: mse: 9.6654, mae: 1.5748, huber: 1.2174, swd: 1.3096, target_std: 4.2736
    Epoch [12/50], Test Losses: mse: 11.7575, mae: 1.8422, huber: 1.4701, swd: 1.9343, target_std: 4.7606
      Epoch 12 composite train-obj: 1.189422
    Epoch [12/50], Test Losses: mse: 11.9244, mae: 1.8562, huber: 1.4820, swd: 1.8776, target_std: 4.7606
    Best round's Test MSE: 11.9244, MAE: 1.8562, SWD: 1.8776
    Best round's Validation MSE: 9.6336, MAE: 1.5530
    Best round's Test verification MSE : 11.9244, MAE: 1.8562, SWD: 1.8776
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq336_pred720_20250429_1904)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.9146 ± 0.0538
      mae: 1.8526 ± 0.0046
      huber: 1.4795 ± 0.0038
      swd: 1.8133 ± 0.0499
      target_std: 4.7606 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.6746 ± 0.0619
      mae: 1.5573 ± 0.0037
      huber: 1.2007 ± 0.0039
      swd: 1.0728 ± 0.0215
      target_std: 4.2736 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq336_pred720_20250429_1904
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


