# data


```python
%load_ext autoreload
%autoreload 2
import importlib
from importlib import reload  
  
import monotonic
import utils
from train import execute_model_evaluation
from train_config import FlatACLConfig
import train_config
import data_manager
from data_manager import DatasetManager
import metrics
from dataclasses import replace

reload(utils)
reload(monotonic)
reload(train_config)


%load_ext autoreload
%autoreload 2
# Initialize the data manager
data_mgr = DatasetManager(device='cuda')

# Load a synthetic dataset
data_mgr.load_csv('ettm1', './ettm1.csv')
# SCALE = False
# trajectory = utils.generate_trajectory('lorenz',steps=52200, dt=1e-2) 
# trajectory = utils.generate_hyperchaotic_rossler(steps=12000, dt=1e-3)
# trajectory_2 = utils.generate_henon(steps=52000) 
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    
    ==================================================
    Dataset: ettm1 (csv)
    ==================================================
    Shape: torch.Size([69680, 7])
    Channels: 7
    Length: 69680
    Source: ./ettm1.csv
    
    Sample data (first 2 rows):
    tensor([[ 5.8270,  2.0090,  1.5990,  0.4620,  4.2030,  1.3400, 30.5310],
            [ 5.7600,  2.0760,  1.4920,  0.4260,  4.2640,  1.4010, 30.4600]])
    ==================================================
    




    <data_manager.DatasetManager at 0x2199a374d70>



# Seq=196

### EigenACL

#### 196-96

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.6488, mae: 1.5001, huber: 1.1325, swd: 3.1839, ept: 61.0242
    Epoch [1/50], Val Losses: mse: 5.7988, mae: 1.2883, huber: 0.9402, swd: 1.5912, ept: 67.0014
    Epoch [1/50], Test Losses: mse: 7.8653, mae: 1.4866, huber: 1.1302, swd: 1.9871, ept: 55.6400
      Epoch 1 composite train-obj: 1.132540
            Val objective improved inf → 0.9402, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4570, mae: 1.2064, huber: 0.8561, swd: 1.4141, ept: 69.6759
    Epoch [2/50], Val Losses: mse: 5.5007, mae: 1.2256, huber: 0.8800, swd: 1.1471, ept: 69.8810
    Epoch [2/50], Test Losses: mse: 7.5949, mae: 1.4256, huber: 1.0710, swd: 1.4927, ept: 59.1529
      Epoch 2 composite train-obj: 0.856097
            Val objective improved 0.9402 → 0.8800, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1962, mae: 1.1585, huber: 0.8130, swd: 1.2937, ept: 71.3759
    Epoch [3/50], Val Losses: mse: 5.3792, mae: 1.2163, huber: 0.8720, swd: 1.1071, ept: 70.6835
    Epoch [3/50], Test Losses: mse: 7.5421, mae: 1.4152, huber: 1.0619, swd: 1.4874, ept: 59.7075
      Epoch 3 composite train-obj: 0.812972
            Val objective improved 0.8800 → 0.8720, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.0391, mae: 1.1339, huber: 0.7907, swd: 1.2361, ept: 72.3937
    Epoch [4/50], Val Losses: mse: 5.5696, mae: 1.2473, huber: 0.8994, swd: 1.1520, ept: 71.1049
    Epoch [4/50], Test Losses: mse: 7.7489, mae: 1.4330, huber: 1.0779, swd: 1.5097, ept: 60.0553
      Epoch 4 composite train-obj: 0.790694
            No improvement (0.8994), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.8918, mae: 1.1122, huber: 0.7708, swd: 1.1836, ept: 73.1122
    Epoch [5/50], Val Losses: mse: 5.6130, mae: 1.2624, huber: 0.9164, swd: 1.4090, ept: 70.5929
    Epoch [5/50], Test Losses: mse: 7.8306, mae: 1.4539, huber: 1.0994, swd: 1.8176, ept: 59.0182
      Epoch 5 composite train-obj: 0.770799
            No improvement (0.9164), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.7739, mae: 1.0947, huber: 0.7549, swd: 1.1507, ept: 73.5740
    Epoch [6/50], Val Losses: mse: 5.7375, mae: 1.2620, huber: 0.9176, swd: 1.3609, ept: 71.9906
    Epoch [6/50], Test Losses: mse: 7.9225, mae: 1.4444, huber: 1.0925, swd: 1.7478, ept: 60.4738
      Epoch 6 composite train-obj: 0.754923
            No improvement (0.9176), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.6343, mae: 1.0746, huber: 0.7362, swd: 1.0966, ept: 74.0245
    Epoch [7/50], Val Losses: mse: 5.8517, mae: 1.2686, huber: 0.9225, swd: 1.2958, ept: 72.0201
    Epoch [7/50], Test Losses: mse: 8.0963, mae: 1.4550, huber: 1.1013, swd: 1.7049, ept: 60.4119
      Epoch 7 composite train-obj: 0.736200
            No improvement (0.9225), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.5370, mae: 1.0620, huber: 0.7244, swd: 1.0684, ept: 74.2449
    Epoch [8/50], Val Losses: mse: 6.0993, mae: 1.3123, huber: 0.9625, swd: 1.4101, ept: 71.7439
    Epoch [8/50], Test Losses: mse: 8.2006, mae: 1.4660, huber: 1.1106, swd: 1.6554, ept: 61.0019
      Epoch 8 composite train-obj: 0.724448
    Epoch [8/50], Test Losses: mse: 7.5421, mae: 1.4152, huber: 1.0620, swd: 1.4875, ept: 59.7177
    Best round's Test MSE: 7.5421, MAE: 1.4152, SWD: 1.4874
    Best round's Validation MSE: 5.3792, MAE: 1.2163, SWD: 1.1071
    Best round's Test verification MSE : 7.5421, MAE: 1.4152, SWD: 1.4875
    Time taken: 84.66 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.9507, mae: 1.5294, huber: 1.1599, swd: 3.4073, ept: 60.3754
    Epoch [1/50], Val Losses: mse: 5.8768, mae: 1.2829, huber: 0.9317, swd: 1.2083, ept: 67.3788
    Epoch [1/50], Test Losses: mse: 8.1168, mae: 1.4987, huber: 1.1383, swd: 1.6917, ept: 55.5539
      Epoch 1 composite train-obj: 1.159935
            Val objective improved inf → 0.9317, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4900, mae: 1.2124, huber: 0.8613, swd: 1.3908, ept: 69.5131
    Epoch [2/50], Val Losses: mse: 5.5032, mae: 1.2371, huber: 0.8918, swd: 1.3231, ept: 69.4983
    Epoch [2/50], Test Losses: mse: 7.5801, mae: 1.4353, huber: 1.0815, swd: 1.7651, ept: 58.3197
      Epoch 2 composite train-obj: 0.861309
            Val objective improved 0.9317 → 0.8918, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.2681, mae: 1.1723, huber: 0.8252, swd: 1.3042, ept: 71.2055
    Epoch [3/50], Val Losses: mse: 5.4928, mae: 1.2177, huber: 0.8747, swd: 1.1519, ept: 70.1527
    Epoch [3/50], Test Losses: mse: 7.5066, mae: 1.4173, huber: 1.0655, swd: 1.6388, ept: 58.5936
      Epoch 3 composite train-obj: 0.825232
            Val objective improved 0.8918 → 0.8747, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.1388, mae: 1.1516, huber: 0.8067, swd: 1.2692, ept: 72.0848
    Epoch [4/50], Val Losses: mse: 5.4758, mae: 1.2232, huber: 0.8803, swd: 1.0645, ept: 71.7364
    Epoch [4/50], Test Losses: mse: 7.5670, mae: 1.4029, huber: 1.0528, swd: 1.4847, ept: 60.2077
      Epoch 4 composite train-obj: 0.806727
            No improvement (0.8803), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.0076, mae: 1.1293, huber: 0.7867, swd: 1.2178, ept: 72.7273
    Epoch [5/50], Val Losses: mse: 5.5649, mae: 1.2351, huber: 0.8906, swd: 1.1690, ept: 71.7551
    Epoch [5/50], Test Losses: mse: 7.6972, mae: 1.4302, huber: 1.0772, swd: 1.6524, ept: 60.1303
      Epoch 5 composite train-obj: 0.786690
            No improvement (0.8906), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.9147, mae: 1.1152, huber: 0.7738, swd: 1.1853, ept: 73.1947
    Epoch [6/50], Val Losses: mse: 5.4594, mae: 1.2340, huber: 0.8902, swd: 1.1892, ept: 71.4675
    Epoch [6/50], Test Losses: mse: 7.6574, mae: 1.4217, huber: 1.0692, swd: 1.6433, ept: 60.5594
      Epoch 6 composite train-obj: 0.773766
            No improvement (0.8902), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.7900, mae: 1.0951, huber: 0.7553, swd: 1.1282, ept: 73.6392
    Epoch [7/50], Val Losses: mse: 5.7037, mae: 1.2551, huber: 0.9110, swd: 1.2321, ept: 71.3764
    Epoch [7/50], Test Losses: mse: 7.9625, mae: 1.4378, huber: 1.0870, swd: 1.6860, ept: 60.0803
      Epoch 7 composite train-obj: 0.755290
            No improvement (0.9110), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.6872, mae: 1.0810, huber: 0.7422, swd: 1.0959, ept: 73.9661
    Epoch [8/50], Val Losses: mse: 5.7473, mae: 1.2842, huber: 0.9360, swd: 1.3202, ept: 72.0552
    Epoch [8/50], Test Losses: mse: 7.9470, mae: 1.4525, huber: 1.0981, swd: 1.7478, ept: 61.0036
      Epoch 8 composite train-obj: 0.742226
    Epoch [8/50], Test Losses: mse: 7.5070, mae: 1.4173, huber: 1.0655, swd: 1.6391, ept: 58.5924
    Best round's Test MSE: 7.5066, MAE: 1.4173, SWD: 1.6388
    Best round's Validation MSE: 5.4928, MAE: 1.2177, SWD: 1.1519
    Best round's Test verification MSE : 7.5070, MAE: 1.4173, SWD: 1.6391
    Time taken: 107.23 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.6149, mae: 1.4955, huber: 1.1281, swd: 3.0535, ept: 61.6839
    Epoch [1/50], Val Losses: mse: 5.7281, mae: 1.2503, huber: 0.9052, swd: 1.1379, ept: 68.9220
    Epoch [1/50], Test Losses: mse: 7.7891, mae: 1.4532, huber: 1.0992, swd: 1.4914, ept: 57.3117
      Epoch 1 composite train-obj: 1.128115
            Val objective improved inf → 0.9052, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3696, mae: 1.1925, huber: 0.8432, swd: 1.2529, ept: 70.1351
    Epoch [2/50], Val Losses: mse: 5.4588, mae: 1.2254, huber: 0.8793, swd: 1.0290, ept: 70.2708
    Epoch [2/50], Test Losses: mse: 7.5488, mae: 1.4304, huber: 1.0751, swd: 1.4023, ept: 59.1962
      Epoch 2 composite train-obj: 0.843203
            Val objective improved 0.9052 → 0.8793, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1581, mae: 1.1536, huber: 0.8085, swd: 1.1807, ept: 71.7327
    Epoch [3/50], Val Losses: mse: 5.4780, mae: 1.2333, huber: 0.8891, swd: 1.2288, ept: 70.6234
    Epoch [3/50], Test Losses: mse: 7.4807, mae: 1.4253, huber: 1.0733, swd: 1.6734, ept: 59.4341
      Epoch 3 composite train-obj: 0.808537
            No improvement (0.8891), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0161, mae: 1.1312, huber: 0.7885, swd: 1.1365, ept: 72.6120
    Epoch [4/50], Val Losses: mse: 5.4542, mae: 1.2432, huber: 0.8980, swd: 1.1868, ept: 71.5186
    Epoch [4/50], Test Losses: mse: 7.5657, mae: 1.4207, huber: 1.0687, swd: 1.5621, ept: 60.5235
      Epoch 4 composite train-obj: 0.788537
            No improvement (0.8980), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.8822, mae: 1.1076, huber: 0.7672, swd: 1.0824, ept: 73.2259
    Epoch [5/50], Val Losses: mse: 5.6107, mae: 1.2551, huber: 0.9106, swd: 1.2411, ept: 71.8349
    Epoch [5/50], Test Losses: mse: 7.6534, mae: 1.4322, huber: 1.0802, swd: 1.6742, ept: 60.3799
      Epoch 5 composite train-obj: 0.767216
            No improvement (0.9106), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.8026, mae: 1.0975, huber: 0.7579, swd: 1.0661, ept: 73.5737
    Epoch [6/50], Val Losses: mse: 5.8655, mae: 1.2595, huber: 0.9150, swd: 1.1575, ept: 71.9955
    Epoch [6/50], Test Losses: mse: 7.8164, mae: 1.4237, huber: 1.0726, swd: 1.4630, ept: 60.6920
      Epoch 6 composite train-obj: 0.757853
            No improvement (0.9150), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.6958, mae: 1.0787, huber: 0.7409, swd: 1.0241, ept: 73.9908
    Epoch [7/50], Val Losses: mse: 5.8327, mae: 1.2686, huber: 0.9212, swd: 1.1915, ept: 72.0029
    Epoch [7/50], Test Losses: mse: 7.8823, mae: 1.4351, huber: 1.0817, swd: 1.5319, ept: 60.9689
      Epoch 7 composite train-obj: 0.740856
    Epoch [7/50], Test Losses: mse: 7.5491, mae: 1.4304, huber: 1.0751, swd: 1.4025, ept: 59.1903
    Best round's Test MSE: 7.5488, MAE: 1.4304, SWD: 1.4023
    Best round's Validation MSE: 5.4588, MAE: 1.2254, SWD: 1.0290
    Best round's Test verification MSE : 7.5491, MAE: 1.4304, SWD: 1.4025
    Time taken: 88.38 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred96_20250512_1351)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5325 ± 0.0185
      mae: 1.4209 ± 0.0067
      huber: 1.0675 ± 0.0055
      swd: 1.5095 ± 0.0978
      ept: 59.1657 ± 0.4553
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.4436 ± 0.0476
      mae: 1.2198 ± 0.0040
      huber: 0.8753 ± 0.0030
      swd: 1.0960 ± 0.0508
      ept: 70.3690 ± 0.2276
      count: 53.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 281.95 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred96_20250512_1351
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### Ab: rotate back Koopman 


```python
importlib.reload(monotonic)
importlib.reload(train_config)
# utils.reload_modules([modules_to_reload_list])

cfg_ACL_196_96 = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
)
cfg_ACL_196_96.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg_ACL_196_96.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg_ACL_196_96.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg_ACL_196_96.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_96 = execute_model_evaluation('ettm1', cfg_ACL_196_96, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3529, mae: 1.4817, huber: 1.1146, swd: 3.0893, target_std: 6.5078
    Epoch [1/50], Val Losses: mse: 5.8989, mae: 1.2731, huber: 0.9245, swd: 1.2086, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 8.0342, mae: 1.4790, huber: 1.1221, swd: 1.6381, target_std: 4.7724
      Epoch 1 composite train-obj: 1.114643
            Val objective improved inf → 0.9245, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4087, mae: 1.1959, huber: 0.8474, swd: 1.3992, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.4479, mae: 1.2313, huber: 0.8875, swd: 1.3338, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.5393, mae: 1.4388, huber: 1.0866, swd: 1.8269, target_std: 4.7724
      Epoch 2 composite train-obj: 0.847350
            Val objective improved 0.9245 → 0.8875, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.0975, mae: 1.1414, huber: 0.7980, swd: 1.2553, target_std: 6.5075
    Epoch [3/50], Val Losses: mse: 5.5287, mae: 1.2214, huber: 0.8779, swd: 1.1590, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.6253, mae: 1.4179, huber: 1.0657, swd: 1.5730, target_std: 4.7724
      Epoch 3 composite train-obj: 0.798019
            Val objective improved 0.8875 → 0.8779, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.9927, mae: 1.1268, huber: 0.7849, swd: 1.2441, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.7579, mae: 1.2464, huber: 0.9010, swd: 1.2401, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.7851, mae: 1.4318, huber: 1.0786, swd: 1.6482, target_std: 4.7724
      Epoch 4 composite train-obj: 0.784918
            No improvement (0.9010), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.8317, mae: 1.1010, huber: 0.7613, swd: 1.1713, target_std: 6.5076
    Epoch [5/50], Val Losses: mse: 5.6634, mae: 1.2590, huber: 0.9152, swd: 1.4255, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.6836, mae: 1.4399, huber: 1.0882, swd: 1.8555, target_std: 4.7724
      Epoch 5 composite train-obj: 0.761320
            No improvement (0.9152), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.7196, mae: 1.0834, huber: 0.7454, swd: 1.1285, target_std: 6.5077
    Epoch [6/50], Val Losses: mse: 5.7068, mae: 1.2468, huber: 0.9050, swd: 1.2566, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.7872, mae: 1.4183, huber: 1.0696, swd: 1.6017, target_std: 4.7724
      Epoch 6 composite train-obj: 0.745377
            No improvement (0.9050), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.6083, mae: 1.0676, huber: 0.7307, swd: 1.1006, target_std: 6.5078
    Epoch [7/50], Val Losses: mse: 5.9167, mae: 1.2590, huber: 0.9167, swd: 1.2860, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 8.0124, mae: 1.4346, huber: 1.0846, swd: 1.6765, target_std: 4.7724
      Epoch 7 composite train-obj: 0.730694
            No improvement (0.9167), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.5124, mae: 1.0531, huber: 0.7173, swd: 1.0643, target_std: 6.5078
    Epoch [8/50], Val Losses: mse: 6.0982, mae: 1.2938, huber: 0.9488, swd: 1.4323, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.9877, mae: 1.4400, huber: 1.0894, swd: 1.7442, target_std: 4.7724
      Epoch 8 composite train-obj: 0.717327
    Epoch [8/50], Test Losses: mse: 7.6246, mae: 1.4178, huber: 1.0657, swd: 1.5729, target_std: 4.7724
    Best round's Test MSE: 7.6253, MAE: 1.4179, SWD: 1.5730
    Best round's Validation MSE: 5.5287, MAE: 1.2214
    Best round's Test verification MSE : 7.6246, MAE: 1.4178, SWD: 1.5729
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4402, mae: 1.4905, huber: 1.1229, swd: 3.1594, target_std: 6.5079
    Epoch [1/50], Val Losses: mse: 5.7655, mae: 1.2608, huber: 0.9142, swd: 1.1853, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.9157, mae: 1.4616, huber: 1.1068, swd: 1.6545, target_std: 4.7724
      Epoch 1 composite train-obj: 1.122944
            Val objective improved inf → 0.9142, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4217, mae: 1.1971, huber: 0.8483, swd: 1.3805, target_std: 6.5077
    Epoch [2/50], Val Losses: mse: 5.4269, mae: 1.2121, huber: 0.8692, swd: 1.1500, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.6107, mae: 1.4198, huber: 1.0676, swd: 1.6087, target_std: 4.7724
      Epoch 2 composite train-obj: 0.848272
            Val objective improved 0.9142 → 0.8692, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1758, mae: 1.1562, huber: 0.8114, swd: 1.2878, target_std: 6.5078
    Epoch [3/50], Val Losses: mse: 5.4862, mae: 1.2428, huber: 0.8978, swd: 1.4948, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.6943, mae: 1.4612, huber: 1.1052, swd: 2.1235, target_std: 4.7724
      Epoch 3 composite train-obj: 0.811375
            No improvement (0.8978), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0386, mae: 1.1332, huber: 0.7909, swd: 1.2433, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.5196, mae: 1.2381, huber: 0.8934, swd: 1.1903, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.4961, mae: 1.4147, huber: 1.0629, swd: 1.6236, target_std: 4.7724
      Epoch 4 composite train-obj: 0.790934
            No improvement (0.8934), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.9241, mae: 1.1143, huber: 0.7738, swd: 1.1983, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 5.6565, mae: 1.2371, huber: 0.8935, swd: 1.1558, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.7789, mae: 1.4275, huber: 1.0755, swd: 1.6265, target_std: 4.7724
      Epoch 5 composite train-obj: 0.773833
            No improvement (0.8935), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.7980, mae: 1.0943, huber: 0.7556, swd: 1.1470, target_std: 6.5076
    Epoch [6/50], Val Losses: mse: 5.6495, mae: 1.2604, huber: 0.9157, swd: 1.3186, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.6958, mae: 1.4362, huber: 1.0845, swd: 1.8217, target_std: 4.7724
      Epoch 6 composite train-obj: 0.755596
            No improvement (0.9157), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.6878, mae: 1.0780, huber: 0.7406, swd: 1.1119, target_std: 6.5074
    Epoch [7/50], Val Losses: mse: 5.7425, mae: 1.2750, huber: 0.9300, swd: 1.4218, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.8775, mae: 1.4433, huber: 1.0931, swd: 1.8725, target_std: 4.7724
      Epoch 7 composite train-obj: 0.740612
    Epoch [7/50], Test Losses: mse: 7.6103, mae: 1.4198, huber: 1.0676, swd: 1.6082, target_std: 4.7724
    Best round's Test MSE: 7.6107, MAE: 1.4198, SWD: 1.6087
    Best round's Validation MSE: 5.4269, MAE: 1.2121
    Best round's Test verification MSE : 7.6103, MAE: 1.4198, SWD: 1.6082
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.2986, mae: 1.4724, huber: 1.1055, swd: 2.8732, target_std: 6.5077
    Epoch [1/50], Val Losses: mse: 5.8261, mae: 1.2581, huber: 0.9121, swd: 1.1276, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.9028, mae: 1.4550, huber: 1.1007, swd: 1.4701, target_std: 4.7724
      Epoch 1 composite train-obj: 1.105517
            Val objective improved inf → 0.9121, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3651, mae: 1.1898, huber: 0.8412, swd: 1.2632, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.5410, mae: 1.2410, huber: 0.8965, swd: 1.2046, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.4321, mae: 1.4217, huber: 1.0700, swd: 1.5862, target_std: 4.7724
      Epoch 2 composite train-obj: 0.841212
            Val objective improved 0.9121 → 0.8965, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1473, mae: 1.1524, huber: 0.8079, swd: 1.2016, target_std: 6.5077
    Epoch [3/50], Val Losses: mse: 5.5173, mae: 1.2343, huber: 0.8904, swd: 1.2589, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.5152, mae: 1.4306, huber: 1.0779, swd: 1.7385, target_std: 4.7724
      Epoch 3 composite train-obj: 0.807874
            Val objective improved 0.8965 → 0.8904, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.9778, mae: 1.1242, huber: 0.7824, swd: 1.1340, target_std: 6.5076
    Epoch [4/50], Val Losses: mse: 5.5889, mae: 1.2303, huber: 0.8870, swd: 1.1276, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.5867, mae: 1.4138, huber: 1.0635, swd: 1.5204, target_std: 4.7724
      Epoch 4 composite train-obj: 0.782367
            Val objective improved 0.8904 → 0.8870, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.8621, mae: 1.1075, huber: 0.7670, swd: 1.1001, target_std: 6.5076
    Epoch [5/50], Val Losses: mse: 5.5449, mae: 1.2424, huber: 0.8985, swd: 1.2718, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.6608, mae: 1.4331, huber: 1.0816, swd: 1.7438, target_std: 4.7724
      Epoch 5 composite train-obj: 0.767002
            No improvement (0.8985), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.7408, mae: 1.0879, huber: 0.7491, swd: 1.0545, target_std: 6.5077
    Epoch [6/50], Val Losses: mse: 5.6625, mae: 1.2395, huber: 0.8969, swd: 1.1186, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.6545, mae: 1.4090, huber: 1.0593, swd: 1.4536, target_std: 4.7724
      Epoch 6 composite train-obj: 0.749133
            No improvement (0.8969), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.6319, mae: 1.0722, huber: 0.7347, swd: 1.0228, target_std: 6.5075
    Epoch [7/50], Val Losses: mse: 5.8340, mae: 1.2605, huber: 0.9164, swd: 1.2171, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.7736, mae: 1.4242, huber: 1.0741, swd: 1.5893, target_std: 4.7724
      Epoch 7 composite train-obj: 0.734736
            No improvement (0.9164), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.5326, mae: 1.0604, huber: 0.7236, swd: 0.9961, target_std: 6.5079
    Epoch [8/50], Val Losses: mse: 6.0180, mae: 1.2842, huber: 0.9370, swd: 1.1940, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.9805, mae: 1.4422, huber: 1.0892, swd: 1.5414, target_std: 4.7724
      Epoch 8 composite train-obj: 0.723572
            No improvement (0.9370), counter 4/5
    Epoch [9/50], Train Losses: mse: 3.4338, mae: 1.0454, huber: 0.7098, swd: 0.9640, target_std: 6.5075
    Epoch [9/50], Val Losses: mse: 6.1332, mae: 1.2670, huber: 0.9235, swd: 1.1916, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.1092, mae: 1.4462, huber: 1.0946, swd: 1.5873, target_std: 4.7724
      Epoch 9 composite train-obj: 0.709751
    Epoch [9/50], Test Losses: mse: 7.5870, mae: 1.4138, huber: 1.0635, swd: 1.5207, target_std: 4.7724
    Best round's Test MSE: 7.5867, MAE: 1.4138, SWD: 1.5204
    Best round's Validation MSE: 5.5889, MAE: 1.2303
    Best round's Test verification MSE : 7.5870, MAE: 1.4138, SWD: 1.5207
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred96_20250429_1558)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.6076 ± 0.0159
      mae: 1.4172 ± 0.0025
      huber: 1.0656 ± 0.0017
      swd: 1.5673 ± 0.0363
      target_std: 4.7724 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.5149 ± 0.0668
      mae: 1.2213 ± 0.0074
      huber: 0.8780 ± 0.0073
      swd: 1.1455 ± 0.0132
      target_std: 4.3035 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq196_pred96_20250429_1558
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### Ab: No rotate back Koopman
Note: seems no rotate back perform better than rotate back


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.2565, mae: 1.4680, huber: 1.1023, swd: 3.0823, target_std: 6.5078
    Epoch [1/50], Val Losses: mse: 5.8041, mae: 1.2664, huber: 0.9200, swd: 1.3888, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.9007, mae: 1.4614, huber: 1.1078, swd: 1.7626, target_std: 4.7724
      Epoch 1 composite train-obj: 1.102325
            Val objective improved inf → 0.9200, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3964, mae: 1.1910, huber: 0.8434, swd: 1.4007, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.5797, mae: 1.2758, huber: 0.9271, swd: 1.7520, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.6616, mae: 1.4856, huber: 1.1283, swd: 2.2636, target_std: 4.7724
      Epoch 2 composite train-obj: 0.843366
            No improvement (0.9271), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.1566, mae: 1.1481, huber: 0.8045, swd: 1.2903, target_std: 6.5075
    Epoch [3/50], Val Losses: mse: 5.5208, mae: 1.2225, huber: 0.8777, swd: 1.1611, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.5576, mae: 1.4119, huber: 1.0594, swd: 1.5481, target_std: 4.7724
      Epoch 3 composite train-obj: 0.804531
            Val objective improved 0.9200 → 0.8777, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.0583, mae: 1.1343, huber: 0.7921, swd: 1.2748, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.6238, mae: 1.2500, huber: 0.9015, swd: 1.2714, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.6294, mae: 1.4249, huber: 1.0704, swd: 1.6195, target_std: 4.7724
      Epoch 4 composite train-obj: 0.792137
            No improvement (0.9015), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.9162, mae: 1.1098, huber: 0.7699, swd: 1.2049, target_std: 6.5076
    Epoch [5/50], Val Losses: mse: 5.4964, mae: 1.2385, huber: 0.8950, swd: 1.3367, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.4700, mae: 1.4122, huber: 1.0622, swd: 1.7273, target_std: 4.7724
      Epoch 5 composite train-obj: 0.769945
            No improvement (0.8950), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.7942, mae: 1.0913, huber: 0.7532, swd: 1.1575, target_std: 6.5077
    Epoch [6/50], Val Losses: mse: 5.5829, mae: 1.2351, huber: 0.8917, swd: 1.2562, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.7102, mae: 1.4139, huber: 1.0645, swd: 1.6168, target_std: 4.7724
      Epoch 6 composite train-obj: 0.753193
            No improvement (0.8917), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.6969, mae: 1.0775, huber: 0.7405, swd: 1.1315, target_std: 6.5078
    Epoch [7/50], Val Losses: mse: 5.7660, mae: 1.2619, huber: 0.9172, swd: 1.3064, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.7528, mae: 1.4233, huber: 1.0726, swd: 1.6241, target_std: 4.7724
      Epoch 7 composite train-obj: 0.740460
            No improvement (0.9172), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.6038, mae: 1.0643, huber: 0.7284, swd: 1.0984, target_std: 6.5078
    Epoch [8/50], Val Losses: mse: 5.8477, mae: 1.2803, huber: 0.9353, swd: 1.4412, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.8000, mae: 1.4307, huber: 1.0822, swd: 1.7779, target_std: 4.7724
      Epoch 8 composite train-obj: 0.728351
    Epoch [8/50], Test Losses: mse: 7.5569, mae: 1.4118, huber: 1.0593, swd: 1.5479, target_std: 4.7724
    Best round's Test MSE: 7.5576, MAE: 1.4119, SWD: 1.5481
    Best round's Validation MSE: 5.5208, MAE: 1.2225
    Best round's Test verification MSE : 7.5569, MAE: 1.4118, SWD: 1.5479
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.2129, mae: 1.4618, huber: 1.0968, swd: 3.0880, target_std: 6.5079
    Epoch [1/50], Val Losses: mse: 5.6046, mae: 1.2413, huber: 0.8969, swd: 1.2521, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.6933, mae: 1.4345, huber: 1.0834, swd: 1.6508, target_std: 4.7724
      Epoch 1 composite train-obj: 1.096828
            Val objective improved inf → 0.8969, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3733, mae: 1.1878, huber: 0.8401, swd: 1.3638, target_std: 6.5077
    Epoch [2/50], Val Losses: mse: 5.4098, mae: 1.2194, huber: 0.8750, swd: 1.2174, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.5569, mae: 1.4129, huber: 1.0613, swd: 1.6082, target_std: 4.7724
      Epoch 2 composite train-obj: 0.840084
            Val objective improved 0.8969 → 0.8750, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1514, mae: 1.1484, huber: 0.8048, swd: 1.2785, target_std: 6.5078
    Epoch [3/50], Val Losses: mse: 5.4696, mae: 1.2423, huber: 0.8975, swd: 1.4465, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.5267, mae: 1.4262, huber: 1.0732, swd: 1.9226, target_std: 4.7724
      Epoch 3 composite train-obj: 0.804782
            No improvement (0.8975), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0218, mae: 1.1289, huber: 0.7870, swd: 1.2340, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.5793, mae: 1.2539, huber: 0.9089, swd: 1.4042, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.4961, mae: 1.4123, huber: 1.0613, swd: 1.7293, target_std: 4.7724
      Epoch 4 composite train-obj: 0.786961
            No improvement (0.9089), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.8883, mae: 1.1066, huber: 0.7668, swd: 1.1793, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 5.6629, mae: 1.2508, huber: 0.9069, swd: 1.2942, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.6415, mae: 1.4131, huber: 1.0628, swd: 1.6197, target_std: 4.7724
      Epoch 5 composite train-obj: 0.766794
            No improvement (0.9069), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.7706, mae: 1.0887, huber: 0.7505, swd: 1.1339, target_std: 6.5076
    Epoch [6/50], Val Losses: mse: 5.6370, mae: 1.2572, huber: 0.9128, swd: 1.3446, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.7369, mae: 1.4272, huber: 1.0774, swd: 1.7684, target_std: 4.7724
      Epoch 6 composite train-obj: 0.750490
            No improvement (0.9128), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.6470, mae: 1.0707, huber: 0.7341, swd: 1.0920, target_std: 6.5074
    Epoch [7/50], Val Losses: mse: 5.8362, mae: 1.2743, huber: 0.9301, swd: 1.3975, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.8693, mae: 1.4271, huber: 1.0776, swd: 1.6993, target_std: 4.7724
      Epoch 7 composite train-obj: 0.734054
    Epoch [7/50], Test Losses: mse: 7.5570, mae: 1.4130, huber: 1.0613, swd: 1.6089, target_std: 4.7724
    Best round's Test MSE: 7.5569, MAE: 1.4129, SWD: 1.6082
    Best round's Validation MSE: 5.4098, MAE: 1.2194
    Best round's Test verification MSE : 7.5570, MAE: 1.4130, SWD: 1.6089
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4125, mae: 1.4872, huber: 1.1196, swd: 3.0160, target_std: 6.5077
    Epoch [1/50], Val Losses: mse: 5.8030, mae: 1.2889, huber: 0.9407, swd: 1.5018, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.8992, mae: 1.4825, huber: 1.1266, swd: 1.8737, target_std: 4.7724
      Epoch 1 composite train-obj: 1.119566
            Val objective improved inf → 0.9407, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.4177, mae: 1.1979, huber: 0.8488, swd: 1.2966, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.4695, mae: 1.2412, huber: 0.8948, swd: 1.3161, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.4842, mae: 1.4358, huber: 1.0812, swd: 1.7124, target_std: 4.7724
      Epoch 2 composite train-obj: 0.848826
            Val objective improved 0.9407 → 0.8948, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.2006, mae: 1.1600, huber: 0.8148, swd: 1.2274, target_std: 6.5077
    Epoch [3/50], Val Losses: mse: 5.4996, mae: 1.2665, huber: 0.9173, swd: 1.5316, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.6130, mae: 1.4704, huber: 1.1126, swd: 1.9873, target_std: 4.7724
      Epoch 3 composite train-obj: 0.814832
            No improvement (0.9173), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0582, mae: 1.1364, huber: 0.7937, swd: 1.1787, target_std: 6.5076
    Epoch [4/50], Val Losses: mse: 5.3906, mae: 1.2064, huber: 0.8642, swd: 1.1661, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.5558, mae: 1.4079, huber: 1.0566, swd: 1.5745, target_std: 4.7724
      Epoch 4 composite train-obj: 0.793735
            Val objective improved 0.8948 → 0.8642, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.9261, mae: 1.1146, huber: 0.7739, swd: 1.1278, target_std: 6.5076
    Epoch [5/50], Val Losses: mse: 5.3576, mae: 1.2143, huber: 0.8714, swd: 1.2389, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.6935, mae: 1.4352, huber: 1.0827, swd: 1.8031, target_std: 4.7724
      Epoch 5 composite train-obj: 0.773910
            No improvement (0.8714), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.8245, mae: 1.0993, huber: 0.7600, swd: 1.0915, target_std: 6.5077
    Epoch [6/50], Val Losses: mse: 5.4596, mae: 1.2109, huber: 0.8689, swd: 1.0654, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.6201, mae: 1.4051, huber: 1.0548, swd: 1.5038, target_std: 4.7724
      Epoch 6 composite train-obj: 0.760047
            No improvement (0.8689), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.7035, mae: 1.0805, huber: 0.7428, swd: 1.0484, target_std: 6.5075
    Epoch [7/50], Val Losses: mse: 5.6250, mae: 1.2305, huber: 0.8880, swd: 1.1148, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.9167, mae: 1.4269, huber: 1.0768, swd: 1.5479, target_std: 4.7724
      Epoch 7 composite train-obj: 0.742792
            No improvement (0.8880), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.6088, mae: 1.0670, huber: 0.7303, swd: 1.0170, target_std: 6.5079
    Epoch [8/50], Val Losses: mse: 5.6226, mae: 1.2372, huber: 0.8936, swd: 1.1818, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.9560, mae: 1.4333, huber: 1.0825, swd: 1.6504, target_std: 4.7724
      Epoch 8 composite train-obj: 0.730273
            No improvement (0.8936), counter 4/5
    Epoch [9/50], Train Losses: mse: 3.5008, mae: 1.0528, huber: 0.7171, swd: 0.9862, target_std: 6.5075
    Epoch [9/50], Val Losses: mse: 5.7864, mae: 1.2489, huber: 0.9057, swd: 1.2851, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.0403, mae: 1.4541, huber: 1.1029, swd: 1.7981, target_std: 4.7724
      Epoch 9 composite train-obj: 0.717091
    Epoch [9/50], Test Losses: mse: 7.5551, mae: 1.4078, huber: 1.0565, swd: 1.5741, target_std: 4.7724
    Best round's Test MSE: 7.5558, MAE: 1.4079, SWD: 1.5745
    Best round's Validation MSE: 5.3906, MAE: 1.2064
    Best round's Test verification MSE : 7.5551, MAE: 1.4078, SWD: 1.5741
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred96_20250429_1607)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5568 ± 0.0007
      mae: 1.4109 ± 0.0022
      huber: 1.0591 ± 0.0019
      swd: 1.5769 ± 0.0246
      target_std: 4.7724 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.4404 ± 0.0574
      mae: 1.2161 ± 0.0070
      huber: 0.8723 ± 0.0059
      swd: 1.1815 ± 0.0254
      target_std: 4.3035 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq196_pred96_20250429_1607
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    


```python

```

#### 196-196

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.5422, mae: 1.6243, huber: 1.2488, swd: 3.4887, ept: 96.9019
    Epoch [1/50], Val Losses: mse: 7.5411, mae: 1.5079, huber: 1.1424, swd: 1.4265, ept: 101.3401
    Epoch [1/50], Test Losses: mse: 10.1932, mae: 1.7427, huber: 1.3688, swd: 2.1094, ept: 79.4803
      Epoch 1 composite train-obj: 1.248831
            Val objective improved inf → 1.1424, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5129, mae: 1.3612, huber: 1.0000, swd: 1.7035, ept: 111.3043
    Epoch [2/50], Val Losses: mse: 6.8516, mae: 1.3984, huber: 1.0419, swd: 1.3914, ept: 109.8072
    Epoch [2/50], Test Losses: mse: 9.4229, mae: 1.6326, huber: 1.2656, swd: 1.9535, ept: 86.1348
      Epoch 2 composite train-obj: 0.999998
            Val objective improved 1.1424 → 1.0419, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2628, mae: 1.3177, huber: 0.9610, swd: 1.5835, ept: 115.2275
    Epoch [3/50], Val Losses: mse: 7.3329, mae: 1.4575, huber: 1.0992, swd: 1.6451, ept: 109.7425
    Epoch [3/50], Test Losses: mse: 9.8428, mae: 1.6953, huber: 1.3269, swd: 2.4689, ept: 86.2450
      Epoch 3 composite train-obj: 0.960993
            No improvement (1.0992), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1442, mae: 1.2993, huber: 0.9445, swd: 1.5394, ept: 116.8259
    Epoch [4/50], Val Losses: mse: 8.8533, mae: 1.6320, huber: 1.2611, swd: 1.8348, ept: 99.6166
    Epoch [4/50], Test Losses: mse: 11.3354, mae: 1.8270, huber: 1.4499, swd: 2.2306, ept: 80.7747
      Epoch 4 composite train-obj: 0.944472
            No improvement (1.2611), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0778, mae: 1.2889, huber: 0.9351, swd: 1.5192, ept: 118.0431
    Epoch [5/50], Val Losses: mse: 7.8953, mae: 1.5277, huber: 1.1680, swd: 1.8941, ept: 107.2472
    Epoch [5/50], Test Losses: mse: 9.8355, mae: 1.6846, huber: 1.3169, swd: 2.2406, ept: 85.7937
      Epoch 5 composite train-obj: 0.935127
            No improvement (1.1680), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.9434, mae: 1.2688, huber: 0.9166, swd: 1.4376, ept: 119.4869
    Epoch [6/50], Val Losses: mse: 6.8397, mae: 1.4047, huber: 1.0515, swd: 1.5965, ept: 115.1359
    Epoch [6/50], Test Losses: mse: 9.5237, mae: 1.6296, huber: 1.2646, swd: 2.1338, ept: 89.9740
      Epoch 6 composite train-obj: 0.916587
            No improvement (1.0515), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.7838, mae: 1.2478, huber: 0.8967, swd: 1.3808, ept: 120.6304
    Epoch [7/50], Val Losses: mse: 7.2583, mae: 1.5056, huber: 1.1429, swd: 2.2670, ept: 109.0157
    Epoch [7/50], Test Losses: mse: 9.7189, mae: 1.7025, huber: 1.3316, swd: 2.8267, ept: 86.5449
      Epoch 7 composite train-obj: 0.896747
    Epoch [7/50], Test Losses: mse: 9.4230, mae: 1.6326, huber: 1.2656, swd: 1.9534, ept: 86.1398
    Best round's Test MSE: 9.4229, MAE: 1.6326, SWD: 1.9535
    Best round's Validation MSE: 6.8516, MAE: 1.3984, SWD: 1.3914
    Best round's Test verification MSE : 9.4230, MAE: 1.6326, SWD: 1.9534
    Time taken: 69.98 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.0143, mae: 1.6560, huber: 1.2800, swd: 3.8437, ept: 96.0032
    Epoch [1/50], Val Losses: mse: 9.3845, mae: 1.7788, huber: 1.3921, swd: 2.3736, ept: 88.9887
    Epoch [1/50], Test Losses: mse: 12.7651, mae: 2.0448, huber: 1.6550, swd: 3.0232, ept: 74.0464
      Epoch 1 composite train-obj: 1.280029
            Val objective improved inf → 1.3921, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.6064, mae: 1.3702, huber: 1.0095, swd: 1.7579, ept: 111.9132
    Epoch [2/50], Val Losses: mse: 7.8596, mae: 1.5275, huber: 1.1610, swd: 1.6505, ept: 103.8439
    Epoch [2/50], Test Losses: mse: 10.6663, mae: 1.7697, huber: 1.3958, swd: 2.3059, ept: 84.4246
      Epoch 2 composite train-obj: 1.009524
            Val objective improved 1.3921 → 1.1610, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3404, mae: 1.3273, huber: 0.9702, swd: 1.6421, ept: 115.7423
    Epoch [3/50], Val Losses: mse: 7.2018, mae: 1.4519, huber: 1.0930, swd: 1.5559, ept: 113.1393
    Epoch [3/50], Test Losses: mse: 9.9347, mae: 1.6902, huber: 1.3222, swd: 2.1830, ept: 89.0683
      Epoch 3 composite train-obj: 0.970247
            Val objective improved 1.1610 → 1.0930, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.1468, mae: 1.2994, huber: 0.9446, swd: 1.5671, ept: 117.5012
    Epoch [4/50], Val Losses: mse: 8.4413, mae: 1.6459, huber: 1.2694, swd: 2.0888, ept: 103.2135
    Epoch [4/50], Test Losses: mse: 11.2639, mae: 1.8591, huber: 1.4785, swd: 2.5406, ept: 83.9669
      Epoch 4 composite train-obj: 0.944602
            No improvement (1.2694), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.1381, mae: 1.2965, huber: 0.9422, swd: 1.5869, ept: 117.9375
    Epoch [5/50], Val Losses: mse: 7.1060, mae: 1.4618, huber: 1.1027, swd: 1.8537, ept: 108.9816
    Epoch [5/50], Test Losses: mse: 9.3941, mae: 1.6623, huber: 1.2935, swd: 2.3597, ept: 87.3078
      Epoch 5 composite train-obj: 0.942204
            No improvement (1.1027), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.9611, mae: 1.2721, huber: 0.9195, swd: 1.4993, ept: 119.6885
    Epoch [6/50], Val Losses: mse: 7.1687, mae: 1.4539, huber: 1.0965, swd: 1.6140, ept: 113.4389
    Epoch [6/50], Test Losses: mse: 9.4033, mae: 1.6342, huber: 1.2684, swd: 2.0356, ept: 90.1545
      Epoch 6 composite train-obj: 0.919502
            No improvement (1.0965), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.7980, mae: 1.2485, huber: 0.8975, swd: 1.4069, ept: 120.7616
    Epoch [7/50], Val Losses: mse: 8.7752, mae: 1.6848, huber: 1.3077, swd: 2.6546, ept: 97.4413
    Epoch [7/50], Test Losses: mse: 10.4232, mae: 1.8099, huber: 1.4299, swd: 3.0340, ept: 81.5607
      Epoch 7 composite train-obj: 0.897470
            No improvement (1.3077), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8716, mae: 1.2603, huber: 0.9082, swd: 1.4512, ept: 120.3085
    Epoch [8/50], Val Losses: mse: 7.6143, mae: 1.4800, huber: 1.1229, swd: 1.7143, ept: 116.2493
    Epoch [8/50], Test Losses: mse: 9.7979, mae: 1.6371, huber: 1.2727, swd: 1.9338, ept: 92.1369
      Epoch 8 composite train-obj: 0.908218
    Epoch [8/50], Test Losses: mse: 9.9348, mae: 1.6902, huber: 1.3222, swd: 2.1831, ept: 89.0692
    Best round's Test MSE: 9.9347, MAE: 1.6902, SWD: 2.1830
    Best round's Validation MSE: 7.2018, MAE: 1.4519, SWD: 1.5559
    Best round's Test verification MSE : 9.9348, MAE: 1.6902, SWD: 2.1831
    Time taken: 89.46 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.6099, mae: 1.6206, huber: 1.2465, swd: 3.1574, ept: 96.8796
    Epoch [1/50], Val Losses: mse: 7.5863, mae: 1.5308, huber: 1.1570, swd: 1.2854, ept: 98.1169
    Epoch [1/50], Test Losses: mse: 10.9492, mae: 1.8120, huber: 1.4310, swd: 1.8828, ept: 78.2264
      Epoch 1 composite train-obj: 1.246548
            Val objective improved inf → 1.1570, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4436, mae: 1.3434, huber: 0.9850, swd: 1.4833, ept: 113.5844
    Epoch [2/50], Val Losses: mse: 7.0701, mae: 1.4268, huber: 1.0707, swd: 1.3707, ept: 110.4628
    Epoch [2/50], Test Losses: mse: 9.5461, mae: 1.6511, huber: 1.2855, swd: 1.9563, ept: 87.8032
      Epoch 2 composite train-obj: 0.984966
            Val objective improved 1.1570 → 1.0707, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2772, mae: 1.3172, huber: 0.9610, swd: 1.4349, ept: 116.2646
    Epoch [3/50], Val Losses: mse: 9.5949, mae: 1.9587, huber: 1.5519, swd: 4.4528, ept: 70.0694
    Epoch [3/50], Test Losses: mse: 11.3217, mae: 2.1252, huber: 1.7144, swd: 4.9225, ept: 66.1533
      Epoch 3 composite train-obj: 0.961032
            No improvement (1.5519), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.4160, mae: 1.3334, huber: 0.9765, swd: 1.5617, ept: 115.8581
    Epoch [4/50], Val Losses: mse: 7.1925, mae: 1.4545, huber: 1.0957, swd: 1.2850, ept: 105.9169
    Epoch [4/50], Test Losses: mse: 9.9591, mae: 1.6975, huber: 1.3298, swd: 1.9864, ept: 84.6572
      Epoch 4 composite train-obj: 0.976527
            No improvement (1.0957), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0497, mae: 1.2825, huber: 0.9293, swd: 1.3382, ept: 118.6716
    Epoch [5/50], Val Losses: mse: 7.2641, mae: 1.4580, huber: 1.0978, swd: 1.3341, ept: 113.6763
    Epoch [5/50], Test Losses: mse: 9.9012, mae: 1.6667, huber: 1.2989, swd: 1.7442, ept: 90.1500
      Epoch 5 composite train-obj: 0.929300
            No improvement (1.0978), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8876, mae: 1.2595, huber: 0.9079, swd: 1.2742, ept: 120.1562
    Epoch [6/50], Val Losses: mse: 8.7233, mae: 1.6854, huber: 1.3056, swd: 2.0774, ept: 99.5805
    Epoch [6/50], Test Losses: mse: 10.8725, mae: 1.8133, huber: 1.4303, swd: 2.1907, ept: 83.4525
      Epoch 6 composite train-obj: 0.907943
            No improvement (1.3056), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8493, mae: 1.2529, huber: 0.9020, swd: 1.2597, ept: 120.4901
    Epoch [7/50], Val Losses: mse: 7.4122, mae: 1.4648, huber: 1.1099, swd: 1.5224, ept: 113.0930
    Epoch [7/50], Test Losses: mse: 9.4549, mae: 1.6091, huber: 1.2463, swd: 1.7379, ept: 91.3347
      Epoch 7 composite train-obj: 0.902004
    Epoch [7/50], Test Losses: mse: 9.5458, mae: 1.6510, huber: 1.2855, swd: 1.9564, ept: 87.8066
    Best round's Test MSE: 9.5461, MAE: 1.6511, SWD: 1.9563
    Best round's Validation MSE: 7.0701, MAE: 1.4268, SWD: 1.3707
    Best round's Test verification MSE : 9.5458, MAE: 1.6510, SWD: 1.9564
    Time taken: 85.84 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred196_20250512_1356)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.6346 ± 0.2181
      mae: 1.6579 ± 0.0240
      huber: 1.2911 ± 0.0234
      swd: 2.0309 ± 0.1076
      ept: 87.6687 ± 1.2014
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.0412 ± 0.1444
      mae: 1.4257 ± 0.0219
      huber: 1.0685 ± 0.0209
      swd: 1.4393 ± 0.0828
      ept: 111.1364 ± 1.4413
      count: 52.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 245.35 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred196_20250512_1356
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

##### Ab: rotate back Koopman + shift outside


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.9619, mae: 1.6516, huber: 1.2759, swd: 3.7812, target_std: 6.5129
    Epoch [1/50], Val Losses: mse: 8.3679, mae: 1.6492, huber: 1.2664, swd: 1.7619, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 11.5732, mae: 1.8983, huber: 1.5114, swd: 2.3395, target_std: 4.7639
      Epoch 1 composite train-obj: 1.275941
            Val objective improved inf → 1.2664, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5151, mae: 1.3528, huber: 0.9936, swd: 1.6614, target_std: 6.5076
    Epoch [2/50], Val Losses: mse: 6.9998, mae: 1.4483, huber: 1.0900, swd: 1.7163, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.5384, mae: 1.6664, huber: 1.2986, swd: 2.1203, target_std: 4.7639
      Epoch 2 composite train-obj: 0.993577
            Val objective improved 1.2664 → 1.0900, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2280, mae: 1.3093, huber: 0.9538, swd: 1.5423, target_std: 6.5153
    Epoch [3/50], Val Losses: mse: 9.0934, mae: 1.7273, huber: 1.3486, swd: 2.4701, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 11.8493, mae: 1.9164, huber: 1.5345, swd: 2.7286, target_std: 4.7639
      Epoch 3 composite train-obj: 0.953767
            No improvement (1.3486), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1656, mae: 1.2965, huber: 0.9426, swd: 1.5351, target_std: 6.5070
    Epoch [4/50], Val Losses: mse: 7.1859, mae: 1.5106, huber: 1.1472, swd: 2.2939, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.5833, mae: 1.7178, huber: 1.3462, swd: 2.8994, target_std: 4.7639
      Epoch 4 composite train-obj: 0.942613
            No improvement (1.1472), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0126, mae: 1.2757, huber: 0.9233, swd: 1.4821, target_std: 6.5069
    Epoch [5/50], Val Losses: mse: 7.2358, mae: 1.4675, huber: 1.1107, swd: 1.8161, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.6059, mae: 1.6528, huber: 1.2885, swd: 2.3567, target_std: 4.7639
      Epoch 5 composite train-obj: 0.923316
            No improvement (1.1107), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8043, mae: 1.2456, huber: 0.8953, swd: 1.3714, target_std: 6.5063
    Epoch [6/50], Val Losses: mse: 8.9664, mae: 1.6961, huber: 1.3226, swd: 2.7154, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.7095, mae: 1.7824, huber: 1.4052, swd: 2.5324, target_std: 4.7639
      Epoch 6 composite train-obj: 0.895308
            No improvement (1.3226), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.7282, mae: 1.2352, huber: 0.8855, swd: 1.3467, target_std: 6.5106
    Epoch [7/50], Val Losses: mse: 7.6813, mae: 1.5209, huber: 1.1651, swd: 2.0851, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.9759, mae: 1.6808, huber: 1.3163, swd: 2.4145, target_std: 4.7639
      Epoch 7 composite train-obj: 0.885496
    Epoch [7/50], Test Losses: mse: 9.5388, mae: 1.6665, huber: 1.2987, swd: 2.1206, target_std: 4.7639
    Best round's Test MSE: 9.5384, MAE: 1.6664, SWD: 2.1203
    Best round's Validation MSE: 6.9998, MAE: 1.4483
    Best round's Test verification MSE : 9.5388, MAE: 1.6665, SWD: 2.1206
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.7833, mae: 1.6463, huber: 1.2697, swd: 3.7500, target_std: 6.5071
    Epoch [1/50], Val Losses: mse: 8.0884, mae: 1.6866, huber: 1.3067, swd: 3.4350, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.5425, mae: 1.9000, huber: 1.5139, swd: 3.7967, target_std: 4.7639
      Epoch 1 composite train-obj: 1.269694
            Val objective improved inf → 1.3067, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5867, mae: 1.3663, huber: 1.0057, swd: 1.7798, target_std: 6.5135
    Epoch [2/50], Val Losses: mse: 7.5085, mae: 1.4795, huber: 1.1193, swd: 1.7622, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.0504, mae: 1.6942, huber: 1.3260, swd: 2.2271, target_std: 4.7639
      Epoch 2 composite train-obj: 1.005740
            Val objective improved 1.3067 → 1.1193, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2978, mae: 1.3176, huber: 0.9615, swd: 1.6046, target_std: 6.5048
    Epoch [3/50], Val Losses: mse: 7.0217, mae: 1.4364, huber: 1.0784, swd: 1.5570, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 9.3791, mae: 1.6196, huber: 1.2544, swd: 1.8032, target_std: 4.7639
      Epoch 3 composite train-obj: 0.961461
            Val objective improved 1.1193 → 1.0784, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.1259, mae: 1.2943, huber: 0.9402, swd: 1.5542, target_std: 6.5066
    Epoch [4/50], Val Losses: mse: 7.7037, mae: 1.5898, huber: 1.2190, swd: 2.9009, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.1933, mae: 1.7995, huber: 1.4205, swd: 3.5176, target_std: 4.7639
      Epoch 4 composite train-obj: 0.940201
            No improvement (1.2190), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.1254, mae: 1.2898, huber: 0.9365, swd: 1.5685, target_std: 6.5144
    Epoch [5/50], Val Losses: mse: 7.9221, mae: 1.5678, huber: 1.2038, swd: 2.0768, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.2385, mae: 1.7420, huber: 1.3708, swd: 2.3763, target_std: 4.7639
      Epoch 5 composite train-obj: 0.936541
            No improvement (1.2038), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.9634, mae: 1.2714, huber: 0.9194, swd: 1.5042, target_std: 6.5014
    Epoch [6/50], Val Losses: mse: 8.9122, mae: 1.6817, huber: 1.3198, swd: 2.8994, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.8965, mae: 1.6829, huber: 1.3173, swd: 2.1497, target_std: 4.7639
      Epoch 6 composite train-obj: 0.919420
            No improvement (1.3198), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.7806, mae: 1.2444, huber: 0.8942, swd: 1.4079, target_std: 6.5131
    Epoch [7/50], Val Losses: mse: 9.1328, mae: 1.7286, huber: 1.3495, swd: 2.9574, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 11.1032, mae: 1.8399, huber: 1.4571, swd: 2.7680, target_std: 4.7639
      Epoch 7 composite train-obj: 0.894165
            No improvement (1.3495), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.7754, mae: 1.2427, huber: 0.8927, swd: 1.4406, target_std: 6.5129
    Epoch [8/50], Val Losses: mse: 8.2841, mae: 1.5931, huber: 1.2334, swd: 2.4652, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 9.9495, mae: 1.6721, huber: 1.3073, swd: 2.1936, target_std: 4.7639
      Epoch 8 composite train-obj: 0.892717
    Epoch [8/50], Test Losses: mse: 9.3791, mae: 1.6196, huber: 1.2543, swd: 1.8029, target_std: 4.7639
    Best round's Test MSE: 9.3791, MAE: 1.6196, SWD: 1.8032
    Best round's Validation MSE: 7.0217, MAE: 1.4364
    Best round's Test verification MSE : 9.3791, MAE: 1.6196, SWD: 1.8029
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.6033, mae: 1.6350, huber: 1.2587, swd: 3.1895, target_std: 6.5060
    Epoch [1/50], Val Losses: mse: 7.1038, mae: 1.4807, huber: 1.1184, swd: 1.8115, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 9.8162, mae: 1.7181, huber: 1.3461, swd: 2.4019, target_std: 4.7639
      Epoch 1 composite train-obj: 1.258681
            Val objective improved inf → 1.1184, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4987, mae: 1.3556, huber: 0.9956, swd: 1.5208, target_std: 6.5103
    Epoch [2/50], Val Losses: mse: 7.1168, mae: 1.4222, huber: 1.0657, swd: 1.3116, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.7874, mae: 1.6593, huber: 1.2924, swd: 1.9524, target_std: 4.7639
      Epoch 2 composite train-obj: 0.995562
            Val objective improved 1.1184 → 1.0657, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2535, mae: 1.3160, huber: 0.9597, swd: 1.4252, target_std: 6.5132
    Epoch [3/50], Val Losses: mse: 8.9459, mae: 1.6900, huber: 1.3114, swd: 2.1491, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 11.7528, mae: 1.9043, huber: 1.5210, swd: 2.7281, target_std: 4.7639
      Epoch 3 composite train-obj: 0.959738
            No improvement (1.3114), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.2159, mae: 1.3082, huber: 0.9530, swd: 1.4274, target_std: 6.5026
    Epoch [4/50], Val Losses: mse: 6.9463, mae: 1.4480, huber: 1.0879, swd: 1.6684, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.6013, mae: 1.7006, huber: 1.3289, swd: 2.4221, target_std: 4.7639
      Epoch 4 composite train-obj: 0.952981
            No improvement (1.0879), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0238, mae: 1.2810, huber: 0.9279, swd: 1.3518, target_std: 6.5197
    Epoch [5/50], Val Losses: mse: 7.7315, mae: 1.5217, huber: 1.1602, swd: 1.4875, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.6930, mae: 1.7747, huber: 1.4040, swd: 2.3619, target_std: 4.7639
      Epoch 5 composite train-obj: 0.927947
            No improvement (1.1602), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.0302, mae: 1.2801, huber: 0.9272, swd: 1.3865, target_std: 6.5055
    Epoch [6/50], Val Losses: mse: 7.1508, mae: 1.4403, huber: 1.0856, swd: 1.5864, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.7023, mae: 1.6470, huber: 1.2826, swd: 2.1489, target_std: 4.7639
      Epoch 6 composite train-obj: 0.927211
            No improvement (1.0856), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8136, mae: 1.2493, huber: 0.8986, swd: 1.2623, target_std: 6.5041
    Epoch [7/50], Val Losses: mse: 7.4130, mae: 1.4906, huber: 1.1305, swd: 1.6587, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.4762, mae: 1.6461, huber: 1.2804, swd: 2.0439, target_std: 4.7639
      Epoch 7 composite train-obj: 0.898619
    Epoch [7/50], Test Losses: mse: 9.7871, mae: 1.6593, huber: 1.2924, swd: 1.9521, target_std: 4.7639
    Best round's Test MSE: 9.7874, MAE: 1.6593, SWD: 1.9524
    Best round's Validation MSE: 7.1168, MAE: 1.4222
    Best round's Test verification MSE : 9.7871, MAE: 1.6593, SWD: 1.9521
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred196_20250429_1653)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.5683 ± 0.1680
      mae: 1.6484 ± 0.0206
      huber: 1.2818 ± 0.0196
      swd: 1.9586 ± 0.1295
      target_std: 4.7639 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.0461 ± 0.0508
      mae: 1.4356 ± 0.0107
      huber: 1.0781 ± 0.0099
      swd: 1.5283 ± 0.1665
      target_std: 4.2884 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq196_pred196_20250429_1653
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

##### Ab: No rotate back Koopman




```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    [autoreload of data_generator failed: Traceback (most recent call last):
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 283, in check
        superreload(m, reload, self.old_objects)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 508, in superreload
        update_generic(old_obj, new_obj)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 405, in update_generic
        update(a, b)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 357, in update_class
        if update_generic(old_obj, new_obj):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 405, in update_generic
        update(a, b)
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 317, in update_function
        setattr(old, name, getattr(new, name))
    ValueError: __init__() requires a code object with 0 free vars, not 2147483648001
    ]
    

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.6499, mae: 1.6273, huber: 1.2531, swd: 3.6661, target_std: 6.5129
    Epoch [1/50], Val Losses: mse: 7.8637, mae: 1.5648, huber: 1.1921, swd: 1.5995, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 11.1394, mae: 1.8270, huber: 1.4485, swd: 2.2992, target_std: 4.7639
      Epoch 1 composite train-obj: 1.253081
            Val objective improved inf → 1.1921, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5031, mae: 1.3479, huber: 0.9897, swd: 1.6669, target_std: 6.5076
    Epoch [2/50], Val Losses: mse: 7.0262, mae: 1.4760, huber: 1.1146, swd: 2.0346, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.6115, mae: 1.7045, huber: 1.3334, swd: 2.4762, target_std: 4.7639
      Epoch 2 composite train-obj: 0.989669
            Val objective improved 1.1921 → 1.1146, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2743, mae: 1.3122, huber: 0.9570, swd: 1.5734, target_std: 6.5153
    Epoch [3/50], Val Losses: mse: 8.2067, mae: 1.5858, huber: 1.2181, swd: 1.8838, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 11.1717, mae: 1.8190, huber: 1.4467, swd: 2.4603, target_std: 4.7639
      Epoch 3 composite train-obj: 0.956977
            No improvement (1.2181), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1955, mae: 1.2989, huber: 0.9453, swd: 1.5412, target_std: 6.5070
    Epoch [4/50], Val Losses: mse: 6.8830, mae: 1.4633, huber: 1.1025, swd: 2.1630, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.5304, mae: 1.7004, huber: 1.3299, swd: 2.8635, target_std: 4.7639
      Epoch 4 composite train-obj: 0.945259
            Val objective improved 1.1146 → 1.1025, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.0593, mae: 1.2807, huber: 0.9283, swd: 1.5079, target_std: 6.5069
    Epoch [5/50], Val Losses: mse: 7.0724, mae: 1.4540, huber: 1.0972, swd: 1.8943, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.5598, mae: 1.6545, huber: 1.2900, swd: 2.5280, target_std: 4.7639
      Epoch 5 composite train-obj: 0.928304
            Val objective improved 1.1025 → 1.0972, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.8658, mae: 1.2529, huber: 0.9025, swd: 1.4093, target_std: 6.5063
    Epoch [6/50], Val Losses: mse: 8.6616, mae: 1.6744, huber: 1.2986, swd: 2.3369, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.8227, mae: 1.7956, huber: 1.4187, swd: 2.3951, target_std: 4.7639
      Epoch 6 composite train-obj: 0.902538
            No improvement (1.2986), counter 1/5
    Epoch [7/50], Train Losses: mse: 4.8137, mae: 1.2470, huber: 0.8969, swd: 1.4010, target_std: 6.5106
    Epoch [7/50], Val Losses: mse: 7.3323, mae: 1.4783, huber: 1.1230, swd: 2.0197, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.7536, mae: 1.6591, huber: 1.2959, swd: 2.4640, target_std: 4.7639
      Epoch 7 composite train-obj: 0.896922
            No improvement (1.1230), counter 2/5
    Epoch [8/50], Train Losses: mse: 4.7152, mae: 1.2334, huber: 0.8843, swd: 1.3577, target_std: 6.5297
    Epoch [8/50], Val Losses: mse: 9.9487, mae: 1.8181, huber: 1.4406, swd: 3.3682, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 11.5735, mae: 1.8872, huber: 1.5072, swd: 2.8155, target_std: 4.7639
      Epoch 8 composite train-obj: 0.884309
            No improvement (1.4406), counter 3/5
    Epoch [9/50], Train Losses: mse: 4.6738, mae: 1.2284, huber: 0.8796, swd: 1.3611, target_std: 6.5019
    Epoch [9/50], Val Losses: mse: 8.0385, mae: 1.5504, huber: 1.1906, swd: 2.2817, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 10.3218, mae: 1.7017, huber: 1.3348, swd: 2.3763, target_std: 4.7639
      Epoch 9 composite train-obj: 0.879599
            No improvement (1.1906), counter 4/5
    Epoch [10/50], Train Losses: mse: 4.5048, mae: 1.2046, huber: 0.8574, swd: 1.2918, target_std: 6.5098
    Epoch [10/50], Val Losses: mse: 7.5220, mae: 1.4944, huber: 1.1368, swd: 2.0903, target_std: 4.2884
    Epoch [10/50], Test Losses: mse: 9.9892, mae: 1.6781, huber: 1.3135, swd: 2.4426, target_std: 4.7639
      Epoch 10 composite train-obj: 0.857421
    Epoch [10/50], Test Losses: mse: 9.5590, mae: 1.6544, huber: 1.2900, swd: 2.5280, target_std: 4.7639
    Best round's Test MSE: 9.5598, MAE: 1.6545, SWD: 2.5280
    Best round's Validation MSE: 7.0724, MAE: 1.4540
    Best round's Test verification MSE : 9.5590, MAE: 1.6544, SWD: 2.5280
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4210, mae: 1.6148, huber: 1.2403, swd: 3.5932, target_std: 6.5071
    Epoch [1/50], Val Losses: mse: 8.2235, mae: 1.7307, huber: 1.3433, swd: 3.6967, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.5412, mae: 1.9233, huber: 1.5312, swd: 4.0165, target_std: 4.7639
      Epoch 1 composite train-obj: 1.240251
            Val objective improved inf → 1.3433, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5608, mae: 1.3556, huber: 0.9968, swd: 1.7704, target_std: 6.5135
    Epoch [2/50], Val Losses: mse: 7.3215, mae: 1.4574, huber: 1.0988, swd: 1.7105, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.1270, mae: 1.6969, huber: 1.3296, swd: 2.3063, target_std: 4.7639
      Epoch 2 composite train-obj: 0.996772
            Val objective improved 1.3433 → 1.0988, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3460, mae: 1.3190, huber: 0.9634, swd: 1.6316, target_std: 6.5048
    Epoch [3/50], Val Losses: mse: 6.9756, mae: 1.4260, huber: 1.0651, swd: 1.4792, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 9.6640, mae: 1.6439, huber: 1.2764, swd: 1.8706, target_std: 4.7639
      Epoch 3 composite train-obj: 0.963388
            Val objective improved 1.0988 → 1.0651, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.1824, mae: 1.2969, huber: 0.9433, swd: 1.5785, target_std: 6.5066
    Epoch [4/50], Val Losses: mse: 7.1536, mae: 1.4915, huber: 1.1287, swd: 2.3558, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.8312, mae: 1.7343, huber: 1.3606, swd: 2.9967, target_std: 4.7639
      Epoch 4 composite train-obj: 0.943314
            No improvement (1.1287), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.1813, mae: 1.2964, huber: 0.9430, swd: 1.6068, target_std: 6.5144
    Epoch [5/50], Val Losses: mse: 7.6097, mae: 1.5024, huber: 1.1426, swd: 1.7276, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.1960, mae: 1.7177, huber: 1.3499, swd: 2.3235, target_std: 4.7639
      Epoch 5 composite train-obj: 0.943000
            No improvement (1.1426), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.0036, mae: 1.2729, huber: 0.9213, swd: 1.5178, target_std: 6.5014
    Epoch [6/50], Val Losses: mse: 7.4894, mae: 1.5061, huber: 1.1437, swd: 1.7077, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.7696, mae: 1.6631, huber: 1.2945, swd: 1.9168, target_std: 4.7639
      Epoch 6 composite train-obj: 0.921323
            No improvement (1.1437), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.8355, mae: 1.2488, huber: 0.8988, swd: 1.4357, target_std: 6.5131
    Epoch [7/50], Val Losses: mse: 10.1743, mae: 1.9054, huber: 1.5056, swd: 3.6842, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 12.3384, mae: 2.0161, huber: 1.6176, swd: 3.5065, target_std: 4.7639
      Epoch 7 composite train-obj: 0.898811
            No improvement (1.5056), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.8647, mae: 1.2524, huber: 0.9022, swd: 1.4971, target_std: 6.5129
    Epoch [8/50], Val Losses: mse: 7.6027, mae: 1.5068, huber: 1.1494, swd: 2.0607, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 9.9204, mae: 1.6636, huber: 1.2993, swd: 2.2103, target_std: 4.7639
      Epoch 8 composite train-obj: 0.902233
    Epoch [8/50], Test Losses: mse: 9.6638, mae: 1.6439, huber: 1.2764, swd: 1.8706, target_std: 4.7639
    Best round's Test MSE: 9.6640, MAE: 1.6439, SWD: 1.8706
    Best round's Validation MSE: 6.9756, MAE: 1.4260
    Best round's Test verification MSE : 9.6638, MAE: 1.6439, SWD: 1.8706
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.5108, mae: 1.6280, huber: 1.2520, swd: 3.2087, target_std: 6.5060
    Epoch [1/50], Val Losses: mse: 6.9605, mae: 1.4441, huber: 1.0854, swd: 1.5706, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 9.7497, mae: 1.6933, huber: 1.3255, swd: 2.2658, target_std: 4.7639
      Epoch 1 composite train-obj: 1.252046
            Val objective improved inf → 1.0854, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5033, mae: 1.3557, huber: 0.9956, swd: 1.5226, target_std: 6.5103
    Epoch [2/50], Val Losses: mse: 7.1673, mae: 1.4279, huber: 1.0694, swd: 1.2655, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.0464, mae: 1.6903, huber: 1.3207, swd: 2.0206, target_std: 4.7639
      Epoch 2 composite train-obj: 0.995612
            Val objective improved 1.0854 → 1.0694, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.2874, mae: 1.3196, huber: 0.9631, swd: 1.4407, target_std: 6.5132
    Epoch [3/50], Val Losses: mse: 9.6234, mae: 1.7923, huber: 1.4059, swd: 2.5783, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 12.6472, mae: 2.0109, huber: 1.6217, swd: 3.1318, target_std: 4.7639
      Epoch 3 composite train-obj: 0.963135
            No improvement (1.4059), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.3028, mae: 1.3194, huber: 0.9632, swd: 1.4790, target_std: 6.5026
    Epoch [4/50], Val Losses: mse: 6.9183, mae: 1.4489, huber: 1.0881, swd: 1.7157, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.6184, mae: 1.6954, huber: 1.3236, swd: 2.4015, target_std: 4.7639
      Epoch 4 composite train-obj: 0.963186
            No improvement (1.0881), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0567, mae: 1.2847, huber: 0.9314, swd: 1.3608, target_std: 6.5197
    Epoch [5/50], Val Losses: mse: 7.4435, mae: 1.4791, huber: 1.1195, swd: 1.3837, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.3096, mae: 1.7158, huber: 1.3476, swd: 2.1023, target_std: 4.7639
      Epoch 5 composite train-obj: 0.931408
            No improvement (1.1195), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.0370, mae: 1.2816, huber: 0.9285, swd: 1.3729, target_std: 6.5055
    Epoch [6/50], Val Losses: mse: 7.1025, mae: 1.4460, huber: 1.0910, swd: 1.6742, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.5704, mae: 1.6495, huber: 1.2842, swd: 2.1694, target_std: 4.7639
      Epoch 6 composite train-obj: 0.928493
            No improvement (1.0910), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8405, mae: 1.2530, huber: 0.9021, swd: 1.2718, target_std: 6.5041
    Epoch [7/50], Val Losses: mse: 7.6069, mae: 1.5091, huber: 1.1501, swd: 1.7808, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.6566, mae: 1.6683, huber: 1.3021, swd: 2.2081, target_std: 4.7639
      Epoch 7 composite train-obj: 0.902105
    Epoch [7/50], Test Losses: mse: 10.0462, mae: 1.6903, huber: 1.3207, swd: 2.0205, target_std: 4.7639
    Best round's Test MSE: 10.0464, MAE: 1.6903, SWD: 2.0206
    Best round's Validation MSE: 7.1673, MAE: 1.4279
    Best round's Test verification MSE : 10.0462, MAE: 1.6903, SWD: 2.0205
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred196_20250429_1646)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.7567 ± 0.2092
      mae: 1.6629 ± 0.0199
      huber: 1.2957 ± 0.0185
      swd: 2.1398 ± 0.2813
      target_std: 4.7639 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.0718 ± 0.0782
      mae: 1.4359 ± 0.0128
      huber: 1.0773 ± 0.0142
      swd: 1.5463 ± 0.2610
      target_std: 4.2884 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq196_pred196_20250429_1646
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 196-336


##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.5213, mae: 1.7405, huber: 1.3588, swd: 3.5904, ept: 128.1242
    Epoch [1/50], Val Losses: mse: 8.4648, mae: 1.5678, huber: 1.2042, swd: 1.5836, ept: 145.3028
    Epoch [1/50], Test Losses: mse: 10.9974, mae: 1.8008, huber: 1.4267, swd: 2.1838, ept: 111.1870
      Epoch 1 composite train-obj: 1.358850
            Val objective improved inf → 1.2042, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2018, mae: 1.4587, huber: 1.0918, swd: 1.7527, ept: 152.9464
    Epoch [2/50], Val Losses: mse: 8.4250, mae: 1.5746, huber: 1.2146, swd: 1.8877, ept: 152.6309
    Epoch [2/50], Test Losses: mse: 10.3342, mae: 1.7387, huber: 1.3685, swd: 2.1085, ept: 119.3278
      Epoch 2 composite train-obj: 1.091791
            No improvement (1.2146), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.9542, mae: 1.4212, huber: 1.0574, swd: 1.6504, ept: 159.5713
    Epoch [3/50], Val Losses: mse: 9.2182, mae: 1.6647, huber: 1.3030, swd: 2.3606, ept: 154.4668
    Epoch [3/50], Test Losses: mse: 10.4592, mae: 1.7603, huber: 1.3890, swd: 2.2543, ept: 121.3127
      Epoch 3 composite train-obj: 1.057358
            No improvement (1.3030), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.7876, mae: 1.3962, huber: 1.0344, swd: 1.5742, ept: 163.0348
    Epoch [4/50], Val Losses: mse: 9.6315, mae: 1.7113, huber: 1.3504, swd: 2.7642, ept: 154.1011
    Epoch [4/50], Test Losses: mse: 10.5944, mae: 1.7783, huber: 1.4070, swd: 2.3587, ept: 120.0888
      Epoch 4 composite train-obj: 1.034413
            No improvement (1.3504), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.6543, mae: 1.3775, huber: 1.0171, swd: 1.5189, ept: 165.1449
    Epoch [5/50], Val Losses: mse: 10.2486, mae: 1.7686, huber: 1.4086, swd: 3.3082, ept: 156.7142
    Epoch [5/50], Test Losses: mse: 10.8839, mae: 1.8054, huber: 1.4341, swd: 2.7120, ept: 121.1750
      Epoch 5 composite train-obj: 1.017081
            No improvement (1.4086), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.5075, mae: 1.3577, huber: 0.9986, swd: 1.4513, ept: 166.7379
    Epoch [6/50], Val Losses: mse: 10.8652, mae: 1.8212, huber: 1.4593, swd: 3.6969, ept: 153.5869
    Epoch [6/50], Test Losses: mse: 11.2259, mae: 1.8304, huber: 1.4581, swd: 2.8446, ept: 120.6004
      Epoch 6 composite train-obj: 0.998559
    Epoch [6/50], Test Losses: mse: 10.9973, mae: 1.8008, huber: 1.4267, swd: 2.1839, ept: 111.1904
    Best round's Test MSE: 10.9974, MAE: 1.8008, SWD: 2.1838
    Best round's Validation MSE: 8.4648, MAE: 1.5678, SWD: 1.5836
    Best round's Test verification MSE : 10.9973, MAE: 1.8008, SWD: 2.1839
    Time taken: 77.28 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.6713, mae: 1.7484, huber: 1.3661, swd: 3.9606, ept: 128.8994
    Epoch [1/50], Val Losses: mse: 8.3449, mae: 1.5630, huber: 1.1995, swd: 1.7091, ept: 145.0491
    Epoch [1/50], Test Losses: mse: 11.0135, mae: 1.8087, huber: 1.4339, swd: 2.3904, ept: 111.0887
      Epoch 1 composite train-obj: 1.366076
            Val objective improved inf → 1.1995, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2477, mae: 1.4690, huber: 1.1007, swd: 1.8778, ept: 152.0420
    Epoch [2/50], Val Losses: mse: 8.2246, mae: 1.5345, huber: 1.1754, swd: 1.7317, ept: 152.4047
    Epoch [2/50], Test Losses: mse: 10.4388, mae: 1.7454, huber: 1.3742, swd: 2.2102, ept: 117.6058
      Epoch 2 composite train-obj: 1.100748
            Val objective improved 1.1995 → 1.1754, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.9551, mae: 1.4229, huber: 1.0585, swd: 1.7173, ept: 158.2857
    Epoch [3/50], Val Losses: mse: 8.6005, mae: 1.5878, huber: 1.2281, swd: 2.0694, ept: 155.6750
    Epoch [3/50], Test Losses: mse: 10.3024, mae: 1.7453, huber: 1.3738, swd: 2.3228, ept: 120.1168
      Epoch 3 composite train-obj: 1.058500
            No improvement (1.2281), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.7891, mae: 1.3979, huber: 1.0356, swd: 1.6361, ept: 161.3678
    Epoch [4/50], Val Losses: mse: 9.1874, mae: 1.6474, huber: 1.2874, swd: 2.2859, ept: 157.2001
    Epoch [4/50], Test Losses: mse: 10.2459, mae: 1.7382, huber: 1.3687, swd: 2.2100, ept: 122.0855
      Epoch 4 composite train-obj: 1.035637
            No improvement (1.2874), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.6854, mae: 1.3839, huber: 1.0227, swd: 1.6097, ept: 163.3728
    Epoch [5/50], Val Losses: mse: 9.1465, mae: 1.6366, huber: 1.2773, swd: 2.2807, ept: 158.7613
    Epoch [5/50], Test Losses: mse: 10.5666, mae: 1.7631, huber: 1.3919, swd: 2.3114, ept: 122.1782
      Epoch 5 composite train-obj: 1.022721
            No improvement (1.2773), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5458, mae: 1.3633, huber: 1.0035, swd: 1.5373, ept: 165.3066
    Epoch [6/50], Val Losses: mse: 9.3186, mae: 1.6722, huber: 1.3128, swd: 2.6590, ept: 156.4931
    Epoch [6/50], Test Losses: mse: 10.6778, mae: 1.7795, huber: 1.4079, swd: 2.5692, ept: 120.7403
      Epoch 6 composite train-obj: 1.003515
            No improvement (1.3128), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4234, mae: 1.3468, huber: 0.9880, swd: 1.4877, ept: 166.8014
    Epoch [7/50], Val Losses: mse: 9.2430, mae: 1.6564, huber: 1.2972, swd: 2.5528, ept: 159.3453
    Epoch [7/50], Test Losses: mse: 10.8680, mae: 1.7898, huber: 1.4182, swd: 2.7100, ept: 121.9641
      Epoch 7 composite train-obj: 0.988004
    Epoch [7/50], Test Losses: mse: 10.4389, mae: 1.7454, huber: 1.3742, swd: 2.2101, ept: 117.5922
    Best round's Test MSE: 10.4388, MAE: 1.7454, SWD: 2.2102
    Best round's Validation MSE: 8.2246, MAE: 1.5345, SWD: 1.7317
    Best round's Test verification MSE : 10.4389, MAE: 1.7454, SWD: 2.2101
    Time taken: 84.56 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4365, mae: 1.7284, huber: 1.3476, swd: 3.6093, ept: 130.9321
    Epoch [1/50], Val Losses: mse: 8.5929, mae: 1.6043, huber: 1.2358, swd: 1.5435, ept: 141.7727
    Epoch [1/50], Test Losses: mse: 11.3415, mae: 1.8476, huber: 1.4697, swd: 2.2055, ept: 109.9342
      Epoch 1 composite train-obj: 1.347606
            Val objective improved inf → 1.2358, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.1730, mae: 1.4551, huber: 1.0883, swd: 1.7234, ept: 153.8888
    Epoch [2/50], Val Losses: mse: 8.1646, mae: 1.5330, huber: 1.1727, swd: 1.6324, ept: 154.0794
    Epoch [2/50], Test Losses: mse: 10.3296, mae: 1.7318, huber: 1.3608, swd: 2.1054, ept: 119.6419
      Epoch 2 composite train-obj: 1.088322
            Val objective improved 1.2358 → 1.1727, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.9485, mae: 1.4206, huber: 1.0568, swd: 1.6270, ept: 159.0716
    Epoch [3/50], Val Losses: mse: 8.2946, mae: 1.5607, huber: 1.2007, swd: 1.9073, ept: 156.0136
    Epoch [3/50], Test Losses: mse: 10.2995, mae: 1.7468, huber: 1.3752, swd: 2.3969, ept: 121.7363
      Epoch 3 composite train-obj: 1.056804
            No improvement (1.2007), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8012, mae: 1.3993, huber: 1.0372, swd: 1.5697, ept: 162.1285
    Epoch [4/50], Val Losses: mse: 8.7985, mae: 1.6179, huber: 1.2578, swd: 2.1601, ept: 156.0492
    Epoch [4/50], Test Losses: mse: 10.5080, mae: 1.7664, huber: 1.3948, swd: 2.4732, ept: 120.2069
      Epoch 4 composite train-obj: 1.037218
            No improvement (1.2578), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.6537, mae: 1.3781, huber: 1.0175, swd: 1.5095, ept: 164.3354
    Epoch [5/50], Val Losses: mse: 9.1408, mae: 1.6517, huber: 1.2922, swd: 2.3571, ept: 160.8826
    Epoch [5/50], Test Losses: mse: 10.5932, mae: 1.7698, huber: 1.3987, swd: 2.4381, ept: 122.8000
      Epoch 5 composite train-obj: 1.017491
            No improvement (1.2922), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5228, mae: 1.3596, huber: 1.0002, swd: 1.4516, ept: 166.1301
    Epoch [6/50], Val Losses: mse: 9.5140, mae: 1.7072, huber: 1.3454, swd: 2.7468, ept: 157.0067
    Epoch [6/50], Test Losses: mse: 10.7547, mae: 1.7942, huber: 1.4228, swd: 2.6876, ept: 121.4911
      Epoch 6 composite train-obj: 1.000223
            No improvement (1.3454), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.3841, mae: 1.3410, huber: 0.9828, swd: 1.3917, ept: 167.5831
    Epoch [7/50], Val Losses: mse: 10.3173, mae: 1.7641, huber: 1.4022, swd: 3.1694, ept: 158.1987
    Epoch [7/50], Test Losses: mse: 11.3923, mae: 1.8331, huber: 1.4596, swd: 2.6627, ept: 121.2562
      Epoch 7 composite train-obj: 0.982821
    Epoch [7/50], Test Losses: mse: 10.3296, mae: 1.7318, huber: 1.3609, swd: 2.1056, ept: 119.6478
    Best round's Test MSE: 10.3296, MAE: 1.7318, SWD: 2.1054
    Best round's Validation MSE: 8.1646, MAE: 1.5330, SWD: 1.6324
    Best round's Test verification MSE : 10.3296, MAE: 1.7318, SWD: 2.1056
    Time taken: 80.76 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred336_20250512_1400)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5886 ± 0.2925
      mae: 1.7594 ± 0.0298
      huber: 1.3872 ± 0.0284
      swd: 2.1665 ± 0.0445
      ept: 116.1449 ± 3.6030
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.2847 ± 0.1297
      mae: 1.5451 ± 0.0160
      huber: 1.1841 ± 0.0142
      swd: 1.6493 ± 0.0616
      ept: 150.5956 ± 3.8046
      count: 51.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 242.70 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred336_20250512_1400
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### ab: no rotate back


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9538, mae: 1.8011, huber: 1.4115, swd: 3.8580, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.5460, mae: 1.6177, huber: 1.2509, swd: 2.1867, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1869, mae: 1.8445, huber: 1.4681, swd: 2.8046, target_std: 4.7581
      Epoch 1 composite train-obj: 1.411486
            Val objective improved inf → 1.2509, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3696, mae: 1.4804, huber: 1.1115, swd: 1.7989, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.3989, mae: 1.5695, huber: 1.2063, swd: 1.8150, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.7029, mae: 1.7837, huber: 1.4096, swd: 2.2971, target_std: 4.7581
      Epoch 2 composite train-obj: 1.111493
            Val objective improved 1.2509 → 1.2063, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.1143, mae: 1.4432, huber: 1.0775, swd: 1.6878, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 9.2586, mae: 1.6595, huber: 1.2959, swd: 2.3320, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.1893, mae: 1.8212, huber: 1.4468, swd: 2.4668, target_std: 4.7581
      Epoch 3 composite train-obj: 1.077480
            No improvement (1.2959), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.9313, mae: 1.4188, huber: 1.0550, swd: 1.6122, target_std: 6.5100
    Epoch [4/50], Val Losses: mse: 10.2009, mae: 1.7446, huber: 1.3843, swd: 3.1175, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.0914, mae: 1.8056, huber: 1.4343, swd: 2.4871, target_std: 4.7581
      Epoch 4 composite train-obj: 1.054987
            No improvement (1.3843), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7572, mae: 1.3947, huber: 1.0325, swd: 1.5392, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 10.2018, mae: 1.7402, huber: 1.3790, swd: 3.2124, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.5172, mae: 1.8379, huber: 1.4641, swd: 2.7218, target_std: 4.7581
      Epoch 5 composite train-obj: 1.032526
            No improvement (1.3790), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.6058, mae: 1.3729, huber: 1.0124, swd: 1.4774, target_std: 6.5100
    Epoch [6/50], Val Losses: mse: 10.5611, mae: 1.8075, huber: 1.4424, swd: 3.5148, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.1325, mae: 1.8349, huber: 1.4614, swd: 2.9237, target_std: 4.7581
      Epoch 6 composite train-obj: 1.012353
            No improvement (1.4424), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4839, mae: 1.3561, huber: 0.9967, swd: 1.4330, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 10.6267, mae: 1.7674, huber: 1.4068, swd: 3.2045, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.3509, mae: 1.8298, huber: 1.4577, swd: 2.8168, target_std: 4.7581
      Epoch 7 composite train-obj: 0.996719
    Epoch [7/50], Test Losses: mse: 10.7021, mae: 1.7836, huber: 1.4095, swd: 2.2969, target_std: 4.7581
    Best round's Test MSE: 10.7029, MAE: 1.7837, SWD: 2.2971
    Best round's Validation MSE: 8.3989, MAE: 1.5695
    Best round's Test verification MSE : 10.7021, MAE: 1.7836, SWD: 2.2969
    Time taken: 122.60 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.6421, mae: 1.7967, huber: 1.4056, swd: 3.9543, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.6305, mae: 1.5901, huber: 1.2277, swd: 1.8505, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1595, mae: 1.8142, huber: 1.4423, swd: 2.4203, target_std: 4.7581
      Epoch 1 composite train-obj: 1.405562
            Val objective improved inf → 1.2277, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3826, mae: 1.4988, huber: 1.1261, swd: 1.9239, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.5501, mae: 1.6006, huber: 1.2393, swd: 2.2374, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.4381, mae: 1.7608, huber: 1.3902, swd: 2.3893, target_std: 4.7581
      Epoch 2 composite train-obj: 1.126126
            No improvement (1.2393), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0433, mae: 1.4387, huber: 1.0729, swd: 1.7396, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 8.6637, mae: 1.5799, huber: 1.2213, swd: 1.9954, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.6283, mae: 1.7570, huber: 1.3868, swd: 2.1672, target_std: 4.7581
      Epoch 3 composite train-obj: 1.072873
            Val objective improved 1.2277 → 1.2213, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.8506, mae: 1.4116, huber: 1.0478, swd: 1.6693, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 9.5739, mae: 1.6941, huber: 1.3338, swd: 2.9714, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.0726, mae: 1.8090, huber: 1.4376, swd: 2.7821, target_std: 4.7581
      Epoch 4 composite train-obj: 1.047849
            No improvement (1.3338), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.6923, mae: 1.3898, huber: 1.0276, swd: 1.6072, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 9.2284, mae: 1.6715, huber: 1.3097, swd: 2.7158, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.8315, mae: 1.8046, huber: 1.4313, swd: 2.8569, target_std: 4.7581
      Epoch 5 composite train-obj: 1.027631
            No improvement (1.3097), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.5080, mae: 1.3625, huber: 1.0023, swd: 1.5188, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 10.0115, mae: 1.7277, huber: 1.3664, swd: 2.9743, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.0448, mae: 1.8207, huber: 1.4487, swd: 2.9823, target_std: 4.7581
      Epoch 6 composite train-obj: 1.002251
            No improvement (1.3664), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.4048, mae: 1.3482, huber: 0.9888, swd: 1.4846, target_std: 6.5100
    Epoch [7/50], Val Losses: mse: 10.3416, mae: 1.7692, huber: 1.4068, swd: 3.3777, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.2177, mae: 1.8301, huber: 1.4570, swd: 2.9813, target_std: 4.7581
      Epoch 7 composite train-obj: 0.988790
            No improvement (1.4068), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.2660, mae: 1.3296, huber: 0.9711, swd: 1.4291, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 10.8626, mae: 1.8173, huber: 1.4537, swd: 3.5458, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 11.4187, mae: 1.8468, huber: 1.4737, swd: 3.0965, target_std: 4.7581
      Epoch 8 composite train-obj: 0.971113
    Epoch [8/50], Test Losses: mse: 10.6287, mae: 1.7571, huber: 1.3869, swd: 2.1689, target_std: 4.7581
    Best round's Test MSE: 10.6283, MAE: 1.7570, SWD: 2.1672
    Best round's Validation MSE: 8.6637, MAE: 1.5799
    Best round's Test verification MSE : 10.6287, MAE: 1.7571, SWD: 2.1689
    Time taken: 188.10 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.1747, mae: 1.8215, huber: 1.4313, swd: 3.9336, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.6244, mae: 1.5988, huber: 1.2355, swd: 1.8660, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.2534, mae: 1.8185, huber: 1.4464, swd: 2.4836, target_std: 4.7581
      Epoch 1 composite train-obj: 1.431253
            Val objective improved inf → 1.2355, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3589, mae: 1.4780, huber: 1.1096, swd: 1.8023, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.6797, mae: 1.5824, huber: 1.2218, swd: 1.8086, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.9250, mae: 1.7767, huber: 1.4051, swd: 2.0913, target_std: 4.7581
      Epoch 2 composite train-obj: 1.109610
            Val objective improved 1.2355 → 1.2218, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0624, mae: 1.4351, huber: 1.0704, swd: 1.6533, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 8.6771, mae: 1.6399, huber: 1.2746, swd: 2.4742, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.6622, mae: 1.8019, huber: 1.4270, swd: 2.8496, target_std: 4.7581
      Epoch 3 composite train-obj: 1.070365
            No improvement (1.2746), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.9182, mae: 1.4172, huber: 1.0538, swd: 1.6115, target_std: 6.5100
    Epoch [4/50], Val Losses: mse: 9.0507, mae: 1.6424, huber: 1.2823, swd: 2.4579, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.8414, mae: 1.7889, huber: 1.4156, swd: 2.4970, target_std: 4.7581
      Epoch 4 composite train-obj: 1.053752
            No improvement (1.2823), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7078, mae: 1.3878, huber: 1.0263, swd: 1.5150, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 9.8598, mae: 1.7239, huber: 1.3621, swd: 2.9566, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.3635, mae: 1.8403, huber: 1.4662, swd: 2.8890, target_std: 4.7581
      Epoch 5 composite train-obj: 1.026346
            No improvement (1.3621), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5689, mae: 1.3682, huber: 1.0081, swd: 1.4585, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 9.8387, mae: 1.7237, huber: 1.3614, swd: 3.0117, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.1597, mae: 1.8277, huber: 1.4541, swd: 2.9397, target_std: 4.7581
      Epoch 6 composite train-obj: 1.008086
            No improvement (1.3614), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4206, mae: 1.3474, huber: 0.9885, swd: 1.3983, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 9.9789, mae: 1.7311, huber: 1.3675, swd: 3.0012, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.2937, mae: 1.8315, huber: 1.4581, swd: 2.8941, target_std: 4.7581
      Epoch 7 composite train-obj: 0.988536
    Epoch [7/50], Test Losses: mse: 10.9252, mae: 1.7768, huber: 1.4051, swd: 2.0917, target_std: 4.7581
    Best round's Test MSE: 10.9250, MAE: 1.7767, SWD: 2.0913
    Best round's Validation MSE: 8.6797, MAE: 1.5824
    Best round's Test verification MSE : 10.9252, MAE: 1.7768, SWD: 2.0917
    Time taken: 128.91 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred336_20250502_2246)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.7521 ± 0.1260
      mae: 1.7725 ± 0.0113
      huber: 1.4005 ± 0.0098
      swd: 2.1852 ± 0.0850
      target_std: 4.7581 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.5808 ± 0.1287
      mae: 1.5772 ± 0.0056
      huber: 1.2164 ± 0.0072
      swd: 1.8730 ± 0.0866
      target_std: 4.2787 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 439.73 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred336_20250502_2246
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### ab: rotate back


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=True,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.0637, mae: 1.8117, huber: 1.4217, swd: 3.9562, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.5630, mae: 1.6299, huber: 1.2623, swd: 2.3360, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1227, mae: 1.8595, huber: 1.4820, swd: 2.9671, target_std: 4.7581
      Epoch 1 composite train-obj: 1.421686
            Val objective improved inf → 1.2623, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3490, mae: 1.4808, huber: 1.1119, swd: 1.7904, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.3458, mae: 1.5530, huber: 1.1918, swd: 1.7086, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.6736, mae: 1.7742, huber: 1.4024, swd: 2.2501, target_std: 4.7581
      Epoch 2 composite train-obj: 1.111931
            Val objective improved 1.2623 → 1.1918, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0917, mae: 1.4398, huber: 1.0747, swd: 1.6803, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 9.0909, mae: 1.6405, huber: 1.2763, swd: 2.2143, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.2794, mae: 1.8240, huber: 1.4494, swd: 2.3985, target_std: 4.7581
      Epoch 3 composite train-obj: 1.074667
            No improvement (1.2763), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.9332, mae: 1.4178, huber: 1.0544, swd: 1.6193, target_std: 6.5100
    Epoch [4/50], Val Losses: mse: 9.7323, mae: 1.7049, huber: 1.3440, swd: 2.7472, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.9727, mae: 1.7950, huber: 1.4229, swd: 2.3201, target_std: 4.7581
      Epoch 4 composite train-obj: 1.054380
            No improvement (1.3440), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7657, mae: 1.3942, huber: 1.0324, swd: 1.5574, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 10.2648, mae: 1.7597, huber: 1.3976, swd: 3.2895, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.3420, mae: 1.8375, huber: 1.4637, swd: 2.7977, target_std: 4.7581
      Epoch 5 composite train-obj: 1.032414
            No improvement (1.3976), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.6108, mae: 1.3720, huber: 1.0119, swd: 1.4909, target_std: 6.5100
    Epoch [6/50], Val Losses: mse: 10.4725, mae: 1.8115, huber: 1.4451, swd: 3.4846, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.1528, mae: 1.8470, huber: 1.4722, swd: 2.9946, target_std: 4.7581
      Epoch 6 composite train-obj: 1.011896
            No improvement (1.4451), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.4940, mae: 1.3565, huber: 0.9973, swd: 1.4499, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 10.7319, mae: 1.7921, huber: 1.4312, swd: 3.4804, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.5934, mae: 1.8570, huber: 1.4844, swd: 3.0444, target_std: 4.7581
      Epoch 7 composite train-obj: 0.997296
    Epoch [7/50], Test Losses: mse: 10.6731, mae: 1.7741, huber: 1.4023, swd: 2.2494, target_std: 4.7581
    Best round's Test MSE: 10.6736, MAE: 1.7742, SWD: 2.2501
    Best round's Validation MSE: 8.3458, MAE: 1.5530
    Best round's Test verification MSE : 10.6731, MAE: 1.7741, SWD: 2.2494
    Time taken: 125.50 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9018, mae: 1.8213, huber: 1.4292, swd: 4.1431, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.6607, mae: 1.5992, huber: 1.2348, swd: 1.8797, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1759, mae: 1.8220, huber: 1.4483, swd: 2.4137, target_std: 4.7581
      Epoch 1 composite train-obj: 1.429221
            Val objective improved inf → 1.2348, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4231, mae: 1.5053, huber: 1.1323, swd: 1.9544, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.8704, mae: 1.6280, huber: 1.2660, swd: 2.3145, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.5694, mae: 1.7759, huber: 1.4049, swd: 2.4842, target_std: 4.7581
      Epoch 2 composite train-obj: 1.132319
            No improvement (1.2660), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.1161, mae: 1.4499, huber: 1.0833, swd: 1.7809, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 8.8270, mae: 1.5907, huber: 1.2306, swd: 2.0193, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.5377, mae: 1.7572, huber: 1.3861, swd: 2.2396, target_std: 4.7581
      Epoch 3 composite train-obj: 1.083267
            Val objective improved 1.2348 → 1.2306, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.9119, mae: 1.4196, huber: 1.0556, swd: 1.7026, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 9.4228, mae: 1.6863, huber: 1.3239, swd: 2.7275, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.6942, mae: 1.7895, huber: 1.4176, swd: 2.7064, target_std: 4.7581
      Epoch 4 composite train-obj: 1.055641
            No improvement (1.3239), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.7583, mae: 1.3994, huber: 1.0367, swd: 1.6396, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 9.3792, mae: 1.6977, huber: 1.3308, swd: 2.7991, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.7026, mae: 1.8100, huber: 1.4344, swd: 2.9329, target_std: 4.7581
      Epoch 5 composite train-obj: 1.036748
            No improvement (1.3308), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.5692, mae: 1.3714, huber: 1.0106, swd: 1.5482, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 10.1534, mae: 1.7662, huber: 1.4021, swd: 3.3164, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.0287, mae: 1.8363, huber: 1.4624, swd: 3.0963, target_std: 4.7581
      Epoch 6 composite train-obj: 1.010644
            No improvement (1.4021), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.4483, mae: 1.3550, huber: 0.9951, swd: 1.5062, target_std: 6.5100
    Epoch [7/50], Val Losses: mse: 10.3050, mae: 1.7656, huber: 1.4032, swd: 3.3766, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.2884, mae: 1.8265, huber: 1.4540, swd: 2.9735, target_std: 4.7581
      Epoch 7 composite train-obj: 0.995087
            No improvement (1.4032), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.3169, mae: 1.3369, huber: 0.9781, swd: 1.4556, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 10.7674, mae: 1.7920, huber: 1.4299, swd: 3.3388, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 11.3282, mae: 1.8326, huber: 1.4601, swd: 2.9003, target_std: 4.7581
      Epoch 8 composite train-obj: 0.978079
    Epoch [8/50], Test Losses: mse: 10.5377, mae: 1.7572, huber: 1.3862, swd: 2.2400, target_std: 4.7581
    Best round's Test MSE: 10.5377, MAE: 1.7572, SWD: 2.2396
    Best round's Validation MSE: 8.8270, MAE: 1.5907
    Best round's Test verification MSE : 10.5377, MAE: 1.7572, SWD: 2.2400
    Time taken: 142.07 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.2223, mae: 1.8196, huber: 1.4299, swd: 3.9562, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 8.6679, mae: 1.6002, huber: 1.2374, swd: 1.7602, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.2601, mae: 1.8154, huber: 1.4440, swd: 2.3281, target_std: 4.7581
      Epoch 1 composite train-obj: 1.429858
            Val objective improved inf → 1.2374, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3774, mae: 1.4818, huber: 1.1131, swd: 1.8028, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 8.6698, mae: 1.5979, huber: 1.2336, swd: 1.8177, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.8612, mae: 1.7816, huber: 1.4080, swd: 2.1614, target_std: 4.7581
      Epoch 2 composite train-obj: 1.113144
            Val objective improved 1.2374 → 1.2336, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0971, mae: 1.4404, huber: 1.0752, swd: 1.6622, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 8.4473, mae: 1.5949, huber: 1.2325, swd: 2.1674, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.5484, mae: 1.7764, huber: 1.4039, swd: 2.5908, target_std: 4.7581
      Epoch 3 composite train-obj: 1.075151
            Val objective improved 1.2336 → 1.2325, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.9052, mae: 1.4157, huber: 1.0522, swd: 1.5991, target_std: 6.5100
    Epoch [4/50], Val Losses: mse: 8.6965, mae: 1.6057, huber: 1.2452, swd: 2.2335, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.8011, mae: 1.7816, huber: 1.4087, swd: 2.4478, target_std: 4.7581
      Epoch 4 composite train-obj: 1.052162
            No improvement (1.2452), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.7215, mae: 1.3921, huber: 1.0301, swd: 1.5279, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 9.3449, mae: 1.6680, huber: 1.3071, swd: 2.5301, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.3398, mae: 1.8303, huber: 1.4571, swd: 2.7307, target_std: 4.7581
      Epoch 5 composite train-obj: 1.030059
            No improvement (1.3071), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.5735, mae: 1.3706, huber: 1.0100, swd: 1.4704, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 9.6883, mae: 1.7001, huber: 1.3379, swd: 2.7757, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 10.9948, mae: 1.8022, huber: 1.4299, swd: 2.7738, target_std: 4.7581
      Epoch 6 composite train-obj: 1.009970
            No improvement (1.3379), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.4061, mae: 1.3464, huber: 0.9874, swd: 1.3935, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 10.1145, mae: 1.7385, huber: 1.3757, swd: 2.9989, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.2601, mae: 1.8298, huber: 1.4570, swd: 2.9022, target_std: 4.7581
      Epoch 7 composite train-obj: 0.987395
            No improvement (1.3757), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.2751, mae: 1.3279, huber: 0.9700, swd: 1.3343, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 10.2073, mae: 1.7454, huber: 1.3851, swd: 3.1475, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 11.4801, mae: 1.8441, huber: 1.4711, swd: 2.9660, target_std: 4.7581
      Epoch 8 composite train-obj: 0.969966
    Epoch [8/50], Test Losses: mse: 10.5490, mae: 1.7764, huber: 1.4039, swd: 2.5907, target_std: 4.7581
    Best round's Test MSE: 10.5484, MAE: 1.7764, SWD: 2.5908
    Best round's Validation MSE: 8.4473, MAE: 1.5949
    Best round's Test verification MSE : 10.5490, MAE: 1.7764, SWD: 2.5907
    Time taken: 136.07 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred336_20250502_2302)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5866 ± 0.0617
      mae: 1.7692 ± 0.0086
      huber: 1.3975 ± 0.0080
      swd: 2.3602 ± 0.1632
      target_std: 4.7581 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.5400 ± 0.2071
      mae: 1.5795 ± 0.0189
      huber: 1.2183 ± 0.0188
      swd: 1.9651 ± 0.1912
      target_std: 4.2787 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 403.72 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred336_20250502_2302
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 196-720

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.3349, mae: 1.8483, huber: 1.4595, swd: 3.6723, ept: 187.2108
    Epoch [1/50], Val Losses: mse: 10.7828, mae: 1.7976, huber: 1.4287, swd: 2.4110, ept: 196.2144
    Epoch [1/50], Test Losses: mse: 11.5960, mae: 1.9207, huber: 1.5385, swd: 2.4943, ept: 174.3267
      Epoch 1 composite train-obj: 1.459452
            Val objective improved inf → 1.4287, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9370, mae: 1.5809, huber: 1.2039, swd: 1.7936, ept: 223.5324
    Epoch [2/50], Val Losses: mse: 11.4515, mae: 1.8648, huber: 1.4975, swd: 2.9647, ept: 199.6603
    Epoch [2/50], Test Losses: mse: 10.9836, mae: 1.8760, huber: 1.4953, swd: 2.4128, ept: 185.1197
      Epoch 2 composite train-obj: 1.203857
            No improvement (1.4975), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6922, mae: 1.5459, huber: 1.1717, swd: 1.6901, ept: 234.3924
    Epoch [3/50], Val Losses: mse: 11.4334, mae: 1.8525, huber: 1.4864, swd: 2.9243, ept: 205.1412
    Epoch [3/50], Test Losses: mse: 11.1531, mae: 1.8847, huber: 1.5039, swd: 2.3441, ept: 185.8491
      Epoch 3 composite train-obj: 1.171728
            No improvement (1.4864), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.4904, mae: 1.5168, huber: 1.1449, swd: 1.5823, ept: 240.9452
    Epoch [4/50], Val Losses: mse: 13.5178, mae: 2.0591, huber: 1.6922, swd: 4.8182, ept: 191.5484
    Epoch [4/50], Test Losses: mse: 11.4792, mae: 1.9325, huber: 1.5516, swd: 2.9818, ept: 177.1147
      Epoch 4 composite train-obj: 1.144907
            No improvement (1.6922), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.3979, mae: 1.5036, huber: 1.1328, swd: 1.5604, ept: 243.7077
    Epoch [5/50], Val Losses: mse: 12.3776, mae: 1.9796, huber: 1.6108, swd: 4.1280, ept: 201.8560
    Epoch [5/50], Test Losses: mse: 11.5657, mae: 1.9434, huber: 1.5608, swd: 3.1598, ept: 179.2889
      Epoch 5 composite train-obj: 1.132780
            No improvement (1.6108), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.2657, mae: 1.4849, huber: 1.1153, swd: 1.4991, ept: 246.8182
    Epoch [6/50], Val Losses: mse: 12.3720, mae: 1.9705, huber: 1.6028, swd: 3.9603, ept: 209.4374
    Epoch [6/50], Test Losses: mse: 11.6166, mae: 1.9401, huber: 1.5579, swd: 2.9958, ept: 183.6443
      Epoch 6 composite train-obj: 1.115314
    Epoch [6/50], Test Losses: mse: 11.5958, mae: 1.9207, huber: 1.5385, swd: 2.4942, ept: 174.3302
    Best round's Test MSE: 11.5960, MAE: 1.9207, SWD: 2.4943
    Best round's Validation MSE: 10.7828, MAE: 1.7976, SWD: 2.4110
    Best round's Test verification MSE : 11.5958, MAE: 1.9207, SWD: 2.4942
    Time taken: 69.42 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4699, mae: 1.8547, huber: 1.4660, swd: 3.6002, ept: 186.6544
    Epoch [1/50], Val Losses: mse: 10.7269, mae: 1.7654, huber: 1.3974, swd: 1.8898, ept: 195.8090
    Epoch [1/50], Test Losses: mse: 11.9933, mae: 1.9442, huber: 1.5619, swd: 2.3120, ept: 170.1414
      Epoch 1 composite train-obj: 1.465995
            Val objective improved inf → 1.3974, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9647, mae: 1.5821, huber: 1.2057, swd: 1.7062, ept: 226.1968
    Epoch [2/50], Val Losses: mse: 10.9754, mae: 1.8218, huber: 1.4539, swd: 2.5450, ept: 202.2230
    Epoch [2/50], Test Losses: mse: 10.9941, mae: 1.8783, huber: 1.4975, swd: 2.4929, ept: 185.0564
      Epoch 2 composite train-obj: 1.205652
            No improvement (1.4539), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6792, mae: 1.5436, huber: 1.1698, swd: 1.5836, ept: 236.0219
    Epoch [3/50], Val Losses: mse: 11.5174, mae: 1.8582, huber: 1.4929, swd: 2.7368, ept: 202.7948
    Epoch [3/50], Test Losses: mse: 11.3885, mae: 1.8999, huber: 1.5193, swd: 2.3828, ept: 181.3800
      Epoch 3 composite train-obj: 1.169835
            No improvement (1.4929), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5289, mae: 1.5231, huber: 1.1510, swd: 1.5373, ept: 240.2111
    Epoch [4/50], Val Losses: mse: 12.2176, mae: 1.9321, huber: 1.5674, swd: 3.2737, ept: 205.0061
    Epoch [4/50], Test Losses: mse: 11.4188, mae: 1.9165, huber: 1.5357, swd: 2.4935, ept: 181.8664
      Epoch 4 composite train-obj: 1.150952
            No improvement (1.5674), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.3672, mae: 1.5003, huber: 1.1297, swd: 1.4577, ept: 243.5805
    Epoch [5/50], Val Losses: mse: 12.3589, mae: 1.9649, huber: 1.5978, swd: 3.6054, ept: 203.0951
    Epoch [5/50], Test Losses: mse: 11.5085, mae: 1.9390, huber: 1.5571, swd: 2.9400, ept: 182.9586
      Epoch 5 composite train-obj: 1.129677
            No improvement (1.5978), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.2434, mae: 1.4823, huber: 1.1129, swd: 1.4052, ept: 246.0991
    Epoch [6/50], Val Losses: mse: 13.1158, mae: 2.0347, huber: 1.6668, swd: 4.0427, ept: 202.7070
    Epoch [6/50], Test Losses: mse: 11.5709, mae: 1.9486, huber: 1.5669, swd: 3.0625, ept: 178.3945
      Epoch 6 composite train-obj: 1.112908
    Epoch [6/50], Test Losses: mse: 11.9929, mae: 1.9442, huber: 1.5619, swd: 2.3115, ept: 170.0892
    Best round's Test MSE: 11.9933, MAE: 1.9442, SWD: 2.3120
    Best round's Validation MSE: 10.7269, MAE: 1.7654, SWD: 1.8898
    Best round's Test verification MSE : 11.9929, MAE: 1.9442, SWD: 2.3115
    Time taken: 69.91 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.1440, mae: 1.8357, huber: 1.4473, swd: 3.6488, ept: 188.3325
    Epoch [1/50], Val Losses: mse: 10.4875, mae: 1.7673, huber: 1.3982, swd: 2.3652, ept: 190.6598
    Epoch [1/50], Test Losses: mse: 11.5650, mae: 1.9206, huber: 1.5378, swd: 2.6223, ept: 176.2243
      Epoch 1 composite train-obj: 1.447336
            Val objective improved inf → 1.3982, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9381, mae: 1.5791, huber: 1.2028, swd: 1.8474, ept: 226.0748
    Epoch [2/50], Val Losses: mse: 10.9781, mae: 1.8107, huber: 1.4452, swd: 2.6659, ept: 205.3115
    Epoch [2/50], Test Losses: mse: 10.9871, mae: 1.8739, huber: 1.4939, swd: 2.4241, ept: 183.7761
      Epoch 2 composite train-obj: 1.202826
            No improvement (1.4452), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6774, mae: 1.5435, huber: 1.1699, swd: 1.7394, ept: 236.3740
    Epoch [3/50], Val Losses: mse: 11.4101, mae: 1.8498, huber: 1.4850, swd: 2.9692, ept: 204.5975
    Epoch [3/50], Test Losses: mse: 11.2198, mae: 1.8870, huber: 1.5065, swd: 2.3595, ept: 183.9570
      Epoch 3 composite train-obj: 1.169946
            No improvement (1.4850), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5198, mae: 1.5218, huber: 1.1498, swd: 1.6728, ept: 241.3426
    Epoch [4/50], Val Losses: mse: 11.4325, mae: 1.8618, huber: 1.4963, swd: 3.1368, ept: 208.0336
    Epoch [4/50], Test Losses: mse: 11.1509, mae: 1.8883, huber: 1.5065, swd: 2.5280, ept: 187.7503
      Epoch 4 composite train-obj: 1.149803
            No improvement (1.4963), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.3858, mae: 1.5023, huber: 1.1316, swd: 1.6087, ept: 244.1849
    Epoch [5/50], Val Losses: mse: 12.2384, mae: 1.9475, huber: 1.5819, swd: 3.9316, ept: 208.1489
    Epoch [5/50], Test Losses: mse: 11.3630, mae: 1.9128, huber: 1.5309, swd: 2.7523, ept: 184.2596
      Epoch 5 composite train-obj: 1.131629
            No improvement (1.5819), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.2554, mae: 1.4833, huber: 1.1140, swd: 1.5428, ept: 247.1601
    Epoch [6/50], Val Losses: mse: 12.1736, mae: 1.9272, huber: 1.5618, swd: 3.6469, ept: 210.0794
    Epoch [6/50], Test Losses: mse: 11.4980, mae: 1.9185, huber: 1.5353, swd: 2.6054, ept: 180.6817
      Epoch 6 composite train-obj: 1.113964
    Epoch [6/50], Test Losses: mse: 11.5650, mae: 1.9206, huber: 1.5378, swd: 2.6224, ept: 176.2085
    Best round's Test MSE: 11.5650, MAE: 1.9206, SWD: 2.6223
    Best round's Validation MSE: 10.4875, MAE: 1.7673, SWD: 2.3652
    Best round's Test verification MSE : 11.5650, MAE: 1.9206, SWD: 2.6224
    Time taken: 67.25 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred720_20250512_1404)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.7181 ± 0.1950
      mae: 1.9285 ± 0.0111
      huber: 1.5461 ± 0.0112
      swd: 2.4762 ± 0.1273
      ept: 173.5641 ± 2.5412
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.6657 ± 0.1281
      mae: 1.7768 ± 0.0148
      huber: 1.4081 ± 0.0146
      swd: 2.2220 ± 0.2356
      ept: 194.2277 ± 2.5283
      count: 48.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 206.68 seconds
    
    Experiment complete: ACL_ettm1_seq196_pred720_20250512_1404
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

##### ab: no rotate back


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_196_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.6422, mae: 1.8750, huber: 1.4846, swd: 3.8233, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 10.8332, mae: 1.7909, huber: 1.4211, swd: 2.0676, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.3233, mae: 1.9681, huber: 1.5843, swd: 2.2939, target_std: 4.7636
      Epoch 1 composite train-obj: 1.484574
            Val objective improved inf → 1.4211, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1455, mae: 1.6029, huber: 1.2252, swd: 1.8634, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 10.9352, mae: 1.8009, huber: 1.4348, swd: 2.4780, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.5395, mae: 1.9092, huber: 1.5281, swd: 2.3306, target_std: 4.7636
      Epoch 2 composite train-obj: 1.225207
            No improvement (1.4348), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.8188, mae: 1.5583, huber: 1.1844, swd: 1.7090, target_std: 6.5087
    Epoch [3/50], Val Losses: mse: 11.3617, mae: 1.8619, huber: 1.4949, swd: 3.0851, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.3977, mae: 1.9172, huber: 1.5354, swd: 2.5967, target_std: 4.7636
      Epoch 3 composite train-obj: 1.184400
            No improvement (1.4949), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.6304, mae: 1.5320, huber: 1.1599, swd: 1.6251, target_std: 6.5086
    Epoch [4/50], Val Losses: mse: 12.7063, mae: 1.9825, huber: 1.6155, swd: 4.1276, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.7183, mae: 1.9515, huber: 1.5697, swd: 2.8385, target_std: 4.7636
      Epoch 4 composite train-obj: 1.159921
            No improvement (1.6155), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.5279, mae: 1.5166, huber: 1.1457, swd: 1.5930, target_std: 6.5086
    Epoch [5/50], Val Losses: mse: 13.1926, mae: 2.0035, huber: 1.6390, swd: 4.4683, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 12.1564, mae: 1.9780, huber: 1.5960, swd: 2.8488, target_std: 4.7636
      Epoch 5 composite train-obj: 1.145659
            No improvement (1.6390), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.4153, mae: 1.5017, huber: 1.1318, swd: 1.5540, target_std: 6.5086
    Epoch [6/50], Val Losses: mse: 13.4845, mae: 2.0375, huber: 1.6706, swd: 4.6919, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 12.1883, mae: 1.9889, huber: 1.6055, swd: 3.0304, target_std: 4.7636
      Epoch 6 composite train-obj: 1.131792
    Epoch [6/50], Test Losses: mse: 12.3237, mae: 1.9681, huber: 1.5844, swd: 2.2942, target_std: 4.7636
    Best round's Test MSE: 12.3233, MAE: 1.9681, SWD: 2.2939
    Best round's Validation MSE: 10.8332, MAE: 1.7909
    Best round's Test verification MSE : 12.3237, MAE: 1.9681, SWD: 2.2942
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.6064, mae: 1.8728, huber: 1.4823, swd: 3.6941, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 10.9366, mae: 1.8093, huber: 1.4385, swd: 2.1321, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.1636, mae: 1.9741, huber: 1.5893, swd: 2.5916, target_std: 4.7636
      Epoch 1 composite train-obj: 1.482337
            Val objective improved inf → 1.4385, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.0754, mae: 1.5972, huber: 1.2192, swd: 1.7150, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 11.4558, mae: 1.8514, huber: 1.4848, swd: 2.5368, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.6440, mae: 1.9259, huber: 1.5438, swd: 2.3988, target_std: 4.7636
      Epoch 2 composite train-obj: 1.219232
            No improvement (1.4848), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.7920, mae: 1.5556, huber: 1.1814, swd: 1.6013, target_std: 6.5087
    Epoch [3/50], Val Losses: mse: 11.4768, mae: 1.8744, huber: 1.5076, swd: 2.9037, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.3429, mae: 1.9080, huber: 1.5262, swd: 2.5462, target_std: 4.7636
      Epoch 3 composite train-obj: 1.181421
            No improvement (1.5076), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.6387, mae: 1.5340, huber: 1.1617, swd: 1.5551, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 12.3641, mae: 1.9473, huber: 1.5809, swd: 3.2966, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.5698, mae: 1.9273, huber: 1.5450, swd: 2.4031, target_std: 4.7636
      Epoch 4 composite train-obj: 1.161651
            No improvement (1.5809), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.5027, mae: 1.5143, huber: 1.1434, swd: 1.4950, target_std: 6.5086
    Epoch [5/50], Val Losses: mse: 12.2593, mae: 1.9572, huber: 1.5899, swd: 3.5052, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.3734, mae: 1.9213, huber: 1.5388, swd: 2.6195, target_std: 4.7636
      Epoch 5 composite train-obj: 1.143405
            No improvement (1.5899), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.3614, mae: 1.4948, huber: 1.1253, swd: 1.4320, target_std: 6.5086
    Epoch [6/50], Val Losses: mse: 13.2471, mae: 2.0310, huber: 1.6646, swd: 4.2934, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.8916, mae: 1.9645, huber: 1.5825, swd: 2.9618, target_std: 4.7636
      Epoch 6 composite train-obj: 1.125251
    Epoch [6/50], Test Losses: mse: 12.1634, mae: 1.9741, huber: 1.5893, swd: 2.5911, target_std: 4.7636
    Best round's Test MSE: 12.1636, MAE: 1.9741, SWD: 2.5916
    Best round's Validation MSE: 10.9366, MAE: 1.8093
    Best round's Test verification MSE : 12.1634, MAE: 1.9741, SWD: 2.5911
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.9893, mae: 1.8992, huber: 1.5080, swd: 4.2508, target_std: 6.5086
    Epoch [1/50], Val Losses: mse: 10.7899, mae: 1.8212, huber: 1.4483, swd: 2.7096, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 11.9577, mae: 1.9691, huber: 1.5835, swd: 3.0240, target_std: 4.7636
      Epoch 1 composite train-obj: 1.508046
            Val objective improved inf → 1.4483, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1155, mae: 1.6005, huber: 1.2227, swd: 1.9130, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 10.9416, mae: 1.7968, huber: 1.4318, swd: 2.5449, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.5652, mae: 1.9109, huber: 1.5294, swd: 2.3619, target_std: 4.7636
      Epoch 2 composite train-obj: 1.222748
            Val objective improved 1.4483 → 1.4318, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7559, mae: 1.5500, huber: 1.1764, swd: 1.7273, target_std: 6.5087
    Epoch [3/50], Val Losses: mse: 11.3120, mae: 1.8605, huber: 1.4939, swd: 3.2313, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.5514, mae: 1.9173, huber: 1.5342, swd: 2.5492, target_std: 4.7636
      Epoch 3 composite train-obj: 1.176397
            No improvement (1.4939), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.6308, mae: 1.5332, huber: 1.1610, swd: 1.7012, target_std: 6.5086
    Epoch [4/50], Val Losses: mse: 13.2219, mae: 2.0388, huber: 1.6721, swd: 4.9685, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.8154, mae: 1.9612, huber: 1.5786, swd: 3.1215, target_std: 4.7636
      Epoch 4 composite train-obj: 1.160961
            No improvement (1.6721), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.4526, mae: 1.5084, huber: 1.1379, swd: 1.6188, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 12.9839, mae: 2.0248, huber: 1.6582, swd: 4.6957, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.6348, mae: 1.9449, huber: 1.5631, swd: 3.1063, target_std: 4.7636
      Epoch 5 composite train-obj: 1.137860
            No improvement (1.6582), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.3095, mae: 1.4879, huber: 1.1188, swd: 1.5427, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 13.3032, mae: 2.0334, huber: 1.6675, swd: 5.0878, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 12.2950, mae: 1.9954, huber: 1.6114, swd: 3.4955, target_std: 4.7636
      Epoch 6 composite train-obj: 1.118767
            No improvement (1.6675), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.2021, mae: 1.4734, huber: 1.1051, swd: 1.4987, target_std: 6.5088
    Epoch [7/50], Val Losses: mse: 12.5367, mae: 1.9631, huber: 1.5957, swd: 4.2736, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 12.4697, mae: 2.0016, huber: 1.6163, swd: 3.3353, target_std: 4.7636
      Epoch 7 composite train-obj: 1.105099
    Epoch [7/50], Test Losses: mse: 11.5652, mae: 1.9108, huber: 1.5294, swd: 2.3618, target_std: 4.7636
    Best round's Test MSE: 11.5652, MAE: 1.9109, SWD: 2.3619
    Best round's Validation MSE: 10.9416, MAE: 1.7968
    Best round's Test verification MSE : 11.5652, MAE: 1.9108, SWD: 2.3618
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq196_pred720_20250429_1715)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.0174 ± 0.3263
      mae: 1.9510 ± 0.0285
      huber: 1.5677 ± 0.0272
      swd: 2.4158 ± 0.1274
      target_std: 4.7636 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 10.9038 ± 0.0500
      mae: 1.7990 ± 0.0077
      huber: 1.4305 ± 0.0072
      swd: 2.2482 ± 0.2114
      target_std: 4.2634 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq196_pred720_20250429_1715
    Model: ACL
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### TimeMixer

#### 196-96


```python
utils.reload_modules([utils])
cfg_time_mixer_196_96 = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_196_96 = execute_model_evaluation('ettm1', cfg_time_mixer_196_96, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.9958, mae: 1.2472, huber: 0.9016, swd: 1.5550, target_std: 6.5076
    Epoch [1/50], Val Losses: mse: 5.1648, mae: 1.1408, huber: 0.8069, swd: 0.8958, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.8434, mae: 1.3681, huber: 1.0280, swd: 1.3585, target_std: 4.7724
      Epoch 1 composite train-obj: 0.901551
            Val objective improved inf → 0.8069, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3648, mae: 1.1521, huber: 0.8140, swd: 1.3702, target_std: 6.5076
    Epoch [2/50], Val Losses: mse: 4.9952, mae: 1.1315, huber: 0.7982, swd: 0.9241, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.6302, mae: 1.3744, huber: 1.0321, swd: 1.4735, target_std: 4.7724
      Epoch 2 composite train-obj: 0.814019
            Val objective improved 0.8069 → 0.7982, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.2079, mae: 1.1302, huber: 0.7940, swd: 1.3184, target_std: 6.5079
    Epoch [3/50], Val Losses: mse: 4.9603, mae: 1.1262, huber: 0.7939, swd: 0.8473, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.4418, mae: 1.3592, huber: 1.0169, swd: 1.3533, target_std: 4.7724
      Epoch 3 composite train-obj: 0.793978
            Val objective improved 0.7982 → 0.7939, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.0730, mae: 1.1114, huber: 0.7766, swd: 1.2723, target_std: 6.5076
    Epoch [4/50], Val Losses: mse: 4.9166, mae: 1.1349, huber: 0.8018, swd: 0.8096, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.4203, mae: 1.3635, huber: 1.0216, swd: 1.3386, target_std: 4.7724
      Epoch 4 composite train-obj: 0.776620
            No improvement (0.8018), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.9371, mae: 1.0948, huber: 0.7609, swd: 1.2329, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 4.9501, mae: 1.1443, huber: 0.8109, swd: 0.8654, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.3422, mae: 1.3524, huber: 1.0119, swd: 1.3466, target_std: 4.7724
      Epoch 5 composite train-obj: 0.760919
            No improvement (0.8109), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.8179, mae: 1.0798, huber: 0.7467, swd: 1.1978, target_std: 6.5078
    Epoch [6/50], Val Losses: mse: 4.9224, mae: 1.1413, huber: 0.8070, swd: 0.8911, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.3856, mae: 1.3616, huber: 1.0191, swd: 1.4608, target_std: 4.7724
      Epoch 6 composite train-obj: 0.746720
            No improvement (0.8070), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.6908, mae: 1.0642, huber: 0.7317, swd: 1.1602, target_std: 6.5076
    Epoch [7/50], Val Losses: mse: 5.0774, mae: 1.1594, huber: 0.8237, swd: 1.0076, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.5293, mae: 1.3947, huber: 1.0488, swd: 1.7022, target_std: 4.7724
      Epoch 7 composite train-obj: 0.731714
            No improvement (0.8237), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.5602, mae: 1.0485, huber: 0.7166, swd: 1.1198, target_std: 6.5076
    Epoch [8/50], Val Losses: mse: 5.0550, mae: 1.1655, huber: 0.8294, swd: 0.9454, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.6441, mae: 1.3873, huber: 1.0433, swd: 1.5423, target_std: 4.7724
      Epoch 8 composite train-obj: 0.716579
    Epoch [8/50], Test Losses: mse: 7.4418, mae: 1.3592, huber: 1.0169, swd: 1.3533, target_std: 4.7724
    Best round's Test MSE: 7.4418, MAE: 1.3592, SWD: 1.3533
    Best round's Validation MSE: 4.9603, MAE: 1.1262
    Best round's Test verification MSE : 7.4418, MAE: 1.3592, SWD: 1.3533
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.0339, mae: 1.2500, huber: 0.9044, swd: 1.5545, target_std: 6.5075
    Epoch [1/50], Val Losses: mse: 5.1207, mae: 1.1336, huber: 0.7999, swd: 0.8538, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.8981, mae: 1.3789, huber: 1.0370, swd: 1.3664, target_std: 4.7724
      Epoch 1 composite train-obj: 0.904356
            Val objective improved inf → 0.7999, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3956, mae: 1.1559, huber: 0.8173, swd: 1.3604, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 4.9917, mae: 1.1233, huber: 0.7908, swd: 0.8717, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.6395, mae: 1.3606, huber: 1.0201, swd: 1.3917, target_std: 4.7724
      Epoch 2 composite train-obj: 0.817291
            Val objective improved 0.7999 → 0.7908, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.1990, mae: 1.1297, huber: 0.7931, swd: 1.3045, target_std: 6.5077
    Epoch [3/50], Val Losses: mse: 4.9864, mae: 1.1265, huber: 0.7939, swd: 0.8614, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.5346, mae: 1.3696, huber: 1.0274, swd: 1.4932, target_std: 4.7724
      Epoch 3 composite train-obj: 0.793133
            No improvement (0.7939), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.0424, mae: 1.1093, huber: 0.7743, swd: 1.2572, target_std: 6.5075
    Epoch [4/50], Val Losses: mse: 5.0181, mae: 1.1328, huber: 0.8004, swd: 0.8760, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.5254, mae: 1.3628, huber: 1.0206, swd: 1.4536, target_std: 4.7724
      Epoch 4 composite train-obj: 0.774320
            No improvement (0.8004), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.9000, mae: 1.0896, huber: 0.7558, swd: 1.2091, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 4.9525, mae: 1.1388, huber: 0.8055, swd: 0.8483, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.4644, mae: 1.3625, huber: 1.0198, swd: 1.3896, target_std: 4.7724
      Epoch 5 composite train-obj: 0.755820
            No improvement (0.8055), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.7606, mae: 1.0712, huber: 0.7385, swd: 1.1634, target_std: 6.5080
    Epoch [6/50], Val Losses: mse: 4.9425, mae: 1.1418, huber: 0.8083, swd: 0.8506, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.5640, mae: 1.3667, huber: 1.0235, swd: 1.4156, target_std: 4.7724
      Epoch 6 composite train-obj: 0.738455
            No improvement (0.8083), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.6265, mae: 1.0536, huber: 0.7216, swd: 1.1154, target_std: 6.5076
    Epoch [7/50], Val Losses: mse: 5.0265, mae: 1.1549, huber: 0.8196, swd: 0.9151, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.5185, mae: 1.3771, huber: 1.0324, swd: 1.4678, target_std: 4.7724
      Epoch 7 composite train-obj: 0.721625
    Epoch [7/50], Test Losses: mse: 7.6395, mae: 1.3606, huber: 1.0201, swd: 1.3917, target_std: 4.7724
    Best round's Test MSE: 7.6395, MAE: 1.3606, SWD: 1.3917
    Best round's Validation MSE: 4.9917, MAE: 1.1233
    Best round's Test verification MSE : 7.6395, MAE: 1.3606, SWD: 1.3917
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.1731, mae: 1.2650, huber: 0.9186, swd: 1.4667, target_std: 6.5079
    Epoch [1/50], Val Losses: mse: 5.1353, mae: 1.1446, huber: 0.8106, swd: 0.8580, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.7744, mae: 1.3761, huber: 1.0352, swd: 1.2763, target_std: 4.7724
      Epoch 1 composite train-obj: 0.918606
            Val objective improved inf → 0.8106, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3940, mae: 1.1572, huber: 0.8186, swd: 1.2623, target_std: 6.5077
    Epoch [2/50], Val Losses: mse: 5.0044, mae: 1.1275, huber: 0.7951, swd: 0.8486, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.6136, mae: 1.3592, huber: 1.0192, swd: 1.2985, target_std: 4.7724
      Epoch 2 composite train-obj: 0.818641
            Val objective improved 0.8106 → 0.7951, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.2313, mae: 1.1336, huber: 0.7970, swd: 1.2156, target_std: 6.5075
    Epoch [3/50], Val Losses: mse: 4.9797, mae: 1.1279, huber: 0.7954, swd: 0.8495, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.4941, mae: 1.3587, huber: 1.0185, swd: 1.3259, target_std: 4.7724
      Epoch 3 composite train-obj: 0.797002
            No improvement (0.7954), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.1112, mae: 1.1159, huber: 0.7809, swd: 1.1809, target_std: 6.5078
    Epoch [4/50], Val Losses: mse: 4.9114, mae: 1.1272, huber: 0.7943, swd: 0.8643, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.5718, mae: 1.3770, huber: 1.0340, swd: 1.4234, target_std: 4.7724
      Epoch 4 composite train-obj: 0.780909
            Val objective improved 0.7951 → 0.7943, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.9892, mae: 1.0994, huber: 0.7655, swd: 1.1434, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 4.8810, mae: 1.1311, huber: 0.7979, swd: 0.8999, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.4712, mae: 1.3793, huber: 1.0360, swd: 1.4896, target_std: 4.7724
      Epoch 5 composite train-obj: 0.765518
            No improvement (0.7979), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.8770, mae: 1.0836, huber: 0.7508, swd: 1.1093, target_std: 6.5075
    Epoch [6/50], Val Losses: mse: 4.9225, mae: 1.1352, huber: 0.8016, swd: 0.8400, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.5126, mae: 1.3686, huber: 1.0264, swd: 1.3816, target_std: 4.7724
      Epoch 6 composite train-obj: 0.750798
            No improvement (0.8016), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.7607, mae: 1.0686, huber: 0.7365, swd: 1.0740, target_std: 6.5078
    Epoch [7/50], Val Losses: mse: 4.9857, mae: 1.1425, huber: 0.8079, swd: 0.8590, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.5658, mae: 1.3881, huber: 1.0432, swd: 1.4595, target_std: 4.7724
      Epoch 7 composite train-obj: 0.736541
            No improvement (0.8079), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.6271, mae: 1.0515, huber: 0.7202, swd: 1.0317, target_std: 6.5079
    Epoch [8/50], Val Losses: mse: 5.0039, mae: 1.1527, huber: 0.8163, swd: 0.8833, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 7.7032, mae: 1.3977, huber: 1.0512, swd: 1.4719, target_std: 4.7724
      Epoch 8 composite train-obj: 0.720207
            No improvement (0.8163), counter 4/5
    Epoch [9/50], Train Losses: mse: 3.4845, mae: 1.0335, huber: 0.7029, swd: 0.9860, target_std: 6.5076
    Epoch [9/50], Val Losses: mse: 5.0754, mae: 1.1730, huber: 0.8361, swd: 0.8758, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 7.7840, mae: 1.3915, huber: 1.0464, swd: 1.3670, target_std: 4.7724
      Epoch 9 composite train-obj: 0.702911
    Epoch [9/50], Test Losses: mse: 7.5718, mae: 1.3770, huber: 1.0340, swd: 1.4234, target_std: 4.7724
    Best round's Test MSE: 7.5718, MAE: 1.3770, SWD: 1.4234
    Best round's Validation MSE: 4.9114, MAE: 1.1272
    Best round's Test verification MSE : 7.5718, MAE: 1.3770, SWD: 1.4234
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq196_pred96_20250429_1613)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5510 ± 0.0820
      mae: 1.3656 ± 0.0081
      huber: 1.0237 ± 0.0074
      swd: 1.3895 ± 0.0286
      target_std: 4.7724 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 4.9545 ± 0.0330
      mae: 1.1256 ± 0.0016
      huber: 0.7930 ± 0.0015
      swd: 0.8611 ± 0.0102
      target_std: 4.3035 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq196_pred96_20250429_1613
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 196-196


```python
utils.reload_modules([utils])
cfg_time_mixer_196_196 = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_196_196 = execute_model_evaluation('ettm1', cfg_time_mixer_196_196, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.2208, mae: 1.3990, huber: 1.0432, swd: 1.8491, target_std: 6.5102
    Epoch [1/50], Val Losses: mse: 6.0560, mae: 1.2671, huber: 0.9227, swd: 0.9751, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 9.9889, mae: 1.5993, huber: 1.2447, swd: 1.8198, target_std: 4.7639
      Epoch 1 composite train-obj: 1.043229
            Val objective improved inf → 0.9227, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.4991, mae: 1.3104, huber: 0.9613, swd: 1.6751, target_std: 6.5037
    Epoch [2/50], Val Losses: mse: 5.9975, mae: 1.2584, huber: 0.9150, swd: 0.9149, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.6789, mae: 1.5778, huber: 1.2238, swd: 1.6722, target_std: 4.7639
      Epoch 2 composite train-obj: 0.961349
            Val objective improved 0.9227 → 0.9150, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3093, mae: 1.2874, huber: 0.9396, swd: 1.6011, target_std: 6.5053
    Epoch [3/50], Val Losses: mse: 6.1314, mae: 1.2778, huber: 0.9338, swd: 0.9547, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 9.5772, mae: 1.5828, huber: 1.2290, swd: 1.7276, target_std: 4.7639
      Epoch 3 composite train-obj: 0.939635
            No improvement (0.9338), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1506, mae: 1.2699, huber: 0.9227, swd: 1.5481, target_std: 6.5034
    Epoch [4/50], Val Losses: mse: 6.0836, mae: 1.2795, huber: 0.9350, swd: 1.0271, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.3758, mae: 1.5755, huber: 1.2212, swd: 1.8267, target_std: 4.7639
      Epoch 4 composite train-obj: 0.922742
            No improvement (0.9350), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.0304, mae: 1.2557, huber: 0.9090, swd: 1.5128, target_std: 6.5080
    Epoch [5/50], Val Losses: mse: 6.2615, mae: 1.2862, huber: 0.9422, swd: 0.9406, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.5525, mae: 1.5743, huber: 1.2203, swd: 1.6743, target_std: 4.7639
      Epoch 5 composite train-obj: 0.909002
            No improvement (0.9422), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8749, mae: 1.2374, huber: 0.8913, swd: 1.4506, target_std: 6.5162
    Epoch [6/50], Val Losses: mse: 6.1327, mae: 1.2887, huber: 0.9438, swd: 0.8567, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.4068, mae: 1.5619, huber: 1.2079, swd: 1.5482, target_std: 4.7639
      Epoch 6 composite train-obj: 0.891296
            No improvement (0.9438), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.7513, mae: 1.2228, huber: 0.8773, swd: 1.4035, target_std: 6.5102
    Epoch [7/50], Val Losses: mse: 6.5538, mae: 1.3299, huber: 0.9826, swd: 0.9712, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.6467, mae: 1.5784, huber: 1.2236, swd: 1.6298, target_std: 4.7639
      Epoch 7 composite train-obj: 0.877296
    Epoch [7/50], Test Losses: mse: 9.6789, mae: 1.5778, huber: 1.2238, swd: 1.6722, target_std: 4.7639
    Best round's Test MSE: 9.6789, MAE: 1.5778, SWD: 1.6722
    Best round's Validation MSE: 5.9975, MAE: 1.2584
    Best round's Test verification MSE : 9.6789, MAE: 1.5778, SWD: 1.6722
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.1910, mae: 1.3973, huber: 1.0418, swd: 1.9031, target_std: 6.5045
    Epoch [1/50], Val Losses: mse: 6.2095, mae: 1.2680, huber: 0.9243, swd: 0.9803, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.0983, mae: 1.5869, huber: 1.2340, swd: 1.7007, target_std: 4.7639
      Epoch 1 composite train-obj: 1.041757
            Val objective improved inf → 0.9243, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5065, mae: 1.3105, huber: 0.9612, swd: 1.7176, target_std: 6.5064
    Epoch [2/50], Val Losses: mse: 5.9936, mae: 1.2577, huber: 0.9152, swd: 0.8730, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.6123, mae: 1.5660, huber: 1.2134, swd: 1.5644, target_std: 4.7639
      Epoch 2 composite train-obj: 0.961246
            Val objective improved 0.9243 → 0.9152, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3004, mae: 1.2865, huber: 0.9388, swd: 1.6347, target_std: 6.5109
    Epoch [3/50], Val Losses: mse: 6.1254, mae: 1.2704, huber: 0.9271, swd: 0.9483, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 9.5739, mae: 1.5865, huber: 1.2321, swd: 1.8094, target_std: 4.7639
      Epoch 3 composite train-obj: 0.938818
            No improvement (0.9271), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1287, mae: 1.2675, huber: 0.9205, swd: 1.5764, target_std: 6.5091
    Epoch [4/50], Val Losses: mse: 6.5201, mae: 1.3049, huber: 0.9603, swd: 0.8846, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.8141, mae: 1.5683, huber: 1.2157, swd: 1.5380, target_std: 4.7639
      Epoch 4 composite train-obj: 0.920477
            No improvement (0.9603), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9664, mae: 1.2483, huber: 0.9020, swd: 1.5323, target_std: 6.5218
    Epoch [5/50], Val Losses: mse: 5.9962, mae: 1.2647, huber: 0.9212, swd: 0.8889, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.4347, mae: 1.5745, huber: 1.2204, swd: 1.7520, target_std: 4.7639
      Epoch 5 composite train-obj: 0.902039
            No improvement (0.9212), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8181, mae: 1.2325, huber: 0.8868, swd: 1.4869, target_std: 6.5023
    Epoch [6/50], Val Losses: mse: 6.3516, mae: 1.3012, huber: 0.9563, swd: 0.8836, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.6913, mae: 1.5760, huber: 1.2220, swd: 1.6054, target_std: 4.7639
      Epoch 6 composite train-obj: 0.886799
            No improvement (0.9563), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.6190, mae: 1.2087, huber: 0.8641, swd: 1.3978, target_std: 6.5047
    Epoch [7/50], Val Losses: mse: 6.5058, mae: 1.3214, huber: 0.9749, swd: 0.9628, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.0470, mae: 1.6127, huber: 1.2570, swd: 1.7769, target_std: 4.7639
      Epoch 7 composite train-obj: 0.864058
    Epoch [7/50], Test Losses: mse: 9.6123, mae: 1.5660, huber: 1.2134, swd: 1.5644, target_std: 4.7639
    Best round's Test MSE: 9.6123, MAE: 1.5660, SWD: 1.5644
    Best round's Validation MSE: 5.9936, MAE: 1.2577
    Best round's Test verification MSE : 9.6123, MAE: 1.5660, SWD: 1.5644
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.3291, mae: 1.4111, huber: 1.0547, swd: 1.6826, target_std: 6.5069
    Epoch [1/50], Val Losses: mse: 6.2146, mae: 1.2979, huber: 0.9509, swd: 1.1573, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.3296, mae: 1.6663, huber: 1.3070, swd: 2.1917, target_std: 4.7639
      Epoch 1 composite train-obj: 1.054724
            Val objective improved inf → 0.9509, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.5389, mae: 1.3149, huber: 0.9653, swd: 1.5201, target_std: 6.5113
    Epoch [2/50], Val Losses: mse: 6.5365, mae: 1.3216, huber: 0.9744, swd: 1.0803, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.4984, mae: 1.6585, huber: 1.3022, swd: 1.8336, target_std: 4.7639
      Epoch 2 composite train-obj: 0.965287
            No improvement (0.9744), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.3168, mae: 1.2887, huber: 0.9409, swd: 1.4480, target_std: 6.4943
    Epoch [3/50], Val Losses: mse: 6.7840, mae: 1.3825, huber: 1.0299, swd: 1.3180, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.5207, mae: 1.7094, huber: 1.3493, swd: 2.1228, target_std: 4.7639
      Epoch 3 composite train-obj: 0.940873
            No improvement (1.0299), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.2810, mae: 1.2867, huber: 0.9386, swd: 1.4629, target_std: 6.5059
    Epoch [4/50], Val Losses: mse: 6.5990, mae: 1.3068, huber: 0.9627, swd: 0.8621, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.0298, mae: 1.5745, huber: 1.2231, swd: 1.4650, target_std: 4.7639
      Epoch 4 composite train-obj: 0.938580
            No improvement (0.9627), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.0537, mae: 1.2600, huber: 0.9134, swd: 1.3818, target_std: 6.5181
    Epoch [5/50], Val Losses: mse: 6.1047, mae: 1.2768, huber: 0.9332, swd: 0.7902, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.3744, mae: 1.5549, huber: 1.2032, swd: 1.3889, target_std: 4.7639
      Epoch 5 composite train-obj: 0.913365
            Val objective improved 0.9509 → 0.9332, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.8750, mae: 1.2412, huber: 0.8951, swd: 1.3316, target_std: 6.5103
    Epoch [6/50], Val Losses: mse: 6.0153, mae: 1.2723, huber: 0.9287, swd: 0.8642, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 9.3474, mae: 1.5715, huber: 1.2175, swd: 1.6137, target_std: 4.7639
      Epoch 6 composite train-obj: 0.895117
            Val objective improved 0.9332 → 0.9287, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 4.7325, mae: 1.2255, huber: 0.8799, swd: 1.2867, target_std: 6.4999
    Epoch [7/50], Val Losses: mse: 6.1020, mae: 1.2919, huber: 0.9460, swd: 1.0198, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 9.6036, mae: 1.6142, huber: 1.2569, swd: 1.9946, target_std: 4.7639
      Epoch 7 composite train-obj: 0.879885
            No improvement (0.9460), counter 1/5
    Epoch [8/50], Train Losses: mse: 4.6134, mae: 1.2108, huber: 0.8657, swd: 1.2454, target_std: 6.5048
    Epoch [8/50], Val Losses: mse: 6.1319, mae: 1.2912, huber: 0.9453, swd: 0.9195, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 9.5525, mae: 1.5911, huber: 1.2346, swd: 1.7189, target_std: 4.7639
      Epoch 8 composite train-obj: 0.865707
            No improvement (0.9453), counter 2/5
    Epoch [9/50], Train Losses: mse: 4.4614, mae: 1.1928, huber: 0.8483, swd: 1.1886, target_std: 6.5148
    Epoch [9/50], Val Losses: mse: 6.2705, mae: 1.3050, huber: 0.9585, swd: 0.8637, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 9.6905, mae: 1.5862, huber: 1.2303, swd: 1.5549, target_std: 4.7639
      Epoch 9 composite train-obj: 0.848299
            No improvement (0.9585), counter 3/5
    Epoch [10/50], Train Losses: mse: 4.3582, mae: 1.1789, huber: 0.8351, swd: 1.1429, target_std: 6.5069
    Epoch [10/50], Val Losses: mse: 6.7570, mae: 1.3277, huber: 0.9797, swd: 0.9668, target_std: 4.2884
    Epoch [10/50], Test Losses: mse: 10.9385, mae: 1.6879, huber: 1.3270, swd: 2.0611, target_std: 4.7639
      Epoch 10 composite train-obj: 0.835070
            No improvement (0.9797), counter 4/5
    Epoch [11/50], Train Losses: mse: 4.2412, mae: 1.1652, huber: 0.8217, swd: 1.0871, target_std: 6.5294
    Epoch [11/50], Val Losses: mse: 6.3646, mae: 1.3177, huber: 0.9706, swd: 0.9256, target_std: 4.2884
    Epoch [11/50], Test Losses: mse: 9.8655, mae: 1.6119, huber: 1.2544, swd: 1.7871, target_std: 4.7639
      Epoch 11 composite train-obj: 0.821669
    Epoch [11/50], Test Losses: mse: 9.3474, mae: 1.5715, huber: 1.2175, swd: 1.6137, target_std: 4.7639
    Best round's Test MSE: 9.3474, MAE: 1.5715, SWD: 1.6137
    Best round's Validation MSE: 6.0153, MAE: 1.2723
    Best round's Test verification MSE : 9.3474, MAE: 1.5715, SWD: 1.6137
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq196_pred196_20250429_1618)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.5462 ± 0.1432
      mae: 1.5717 ± 0.0048
      huber: 1.2182 ± 0.0043
      swd: 1.6168 ± 0.0441
      target_std: 4.7639 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.0021 ± 0.0095
      mae: 1.2628 ± 0.0067
      huber: 0.9196 ± 0.0064
      swd: 0.8840 ± 0.0221
      target_std: 4.2884 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq196_pred196_20250429_1618
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 196-336


```python
utils.reload_modules([utils])
cfg_time_mixer_196_336 = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_196_336 = execute_model_evaluation('ettm1', cfg_time_mixer_196_336, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0815, mae: 1.5193, huber: 1.1560, swd: 1.9965, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 7.6242, mae: 1.3873, huber: 1.0382, swd: 0.8996, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.6893, mae: 1.7409, huber: 1.3803, swd: 1.7719, target_std: 4.7581
      Epoch 1 composite train-obj: 1.155961
            Val objective improved inf → 1.0382, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3914, mae: 1.4312, huber: 1.0735, swd: 1.7850, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.5308, mae: 1.3849, huber: 1.0352, swd: 0.9308, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 11.4458, mae: 1.7414, huber: 1.3796, swd: 1.8382, target_std: 4.7581
      Epoch 2 composite train-obj: 1.073542
            Val objective improved 1.0382 → 1.0352, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2180, mae: 1.4134, huber: 1.0566, swd: 1.7298, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.5552, mae: 1.3861, huber: 1.0376, swd: 0.8372, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.1215, mae: 1.7139, huber: 1.3538, swd: 1.6415, target_std: 4.7581
      Epoch 3 composite train-obj: 1.056647
            No improvement (1.0376), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.0619, mae: 1.3976, huber: 1.0416, swd: 1.6760, target_std: 6.5100
    Epoch [4/50], Val Losses: mse: 7.5886, mae: 1.3975, huber: 1.0477, swd: 0.8083, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.9835, mae: 1.7097, huber: 1.3484, swd: 1.5641, target_std: 4.7581
      Epoch 4 composite train-obj: 1.041607
            No improvement (1.0477), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.9186, mae: 1.3835, huber: 1.0281, swd: 1.6298, target_std: 6.5098
    Epoch [5/50], Val Losses: mse: 7.5792, mae: 1.3939, huber: 1.0448, swd: 0.8451, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.9156, mae: 1.7109, huber: 1.3502, swd: 1.6998, target_std: 4.7581
      Epoch 5 composite train-obj: 1.028056
            No improvement (1.0448), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.7709, mae: 1.3685, huber: 1.0134, swd: 1.5786, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.3204, mae: 1.3862, huber: 1.0365, swd: 0.8868, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 10.6264, mae: 1.7279, huber: 1.3635, swd: 1.9363, target_std: 4.7581
      Epoch 6 composite train-obj: 1.013436
            No improvement (1.0365), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.5883, mae: 1.3491, huber: 0.9944, swd: 1.5118, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 7.6521, mae: 1.4177, huber: 1.0672, swd: 0.8745, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 10.7039, mae: 1.7143, huber: 1.3521, swd: 1.7538, target_std: 4.7581
      Epoch 7 composite train-obj: 0.994425
    Epoch [7/50], Test Losses: mse: 11.4458, mae: 1.7414, huber: 1.3796, swd: 1.8382, target_std: 4.7581
    Best round's Test MSE: 11.4458, MAE: 1.7414, SWD: 1.8382
    Best round's Validation MSE: 7.5308, MAE: 1.3849
    Best round's Test verification MSE : 11.4458, MAE: 1.7414, SWD: 1.8382
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.1683, mae: 1.5238, huber: 1.1598, swd: 2.0794, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 7.5198, mae: 1.3882, huber: 1.0387, swd: 1.0412, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.6054, mae: 1.7520, huber: 1.3906, swd: 2.0487, target_std: 4.7581
      Epoch 1 composite train-obj: 1.159847
            Val objective improved inf → 1.0387, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3394, mae: 1.4306, huber: 1.0728, swd: 1.8693, target_std: 6.5100
    Epoch [2/50], Val Losses: mse: 7.4940, mae: 1.3990, huber: 1.0491, swd: 0.8917, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 11.0275, mae: 1.7066, huber: 1.3475, swd: 1.6269, target_std: 4.7581
      Epoch 2 composite train-obj: 1.072761
            No improvement (1.0491), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0860, mae: 1.4049, huber: 1.0480, swd: 1.7710, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.4186, mae: 1.3886, huber: 1.0388, swd: 0.8940, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.8080, mae: 1.6973, huber: 1.3371, swd: 1.6867, target_std: 4.7581
      Epoch 3 composite train-obj: 1.048043
            No improvement (1.0388), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.8922, mae: 1.3846, huber: 1.0284, swd: 1.7006, target_std: 6.5098
    Epoch [4/50], Val Losses: mse: 7.2691, mae: 1.3811, huber: 1.0318, swd: 0.8710, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.6129, mae: 1.6892, huber: 1.3282, swd: 1.7247, target_std: 4.7581
      Epoch 4 composite train-obj: 1.028418
            Val objective improved 1.0387 → 1.0318, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.6994, mae: 1.3642, huber: 1.0084, swd: 1.6181, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.3111, mae: 1.3913, huber: 1.0404, swd: 0.9875, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.5989, mae: 1.7068, huber: 1.3439, swd: 1.9745, target_std: 4.7581
      Epoch 5 composite train-obj: 1.008440
            No improvement (1.0404), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.5209, mae: 1.3443, huber: 0.9891, swd: 1.5412, target_std: 6.5100
    Epoch [6/50], Val Losses: mse: 7.2249, mae: 1.3925, huber: 1.0410, swd: 0.9264, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 10.6705, mae: 1.7209, huber: 1.3563, swd: 1.9748, target_std: 4.7581
      Epoch 6 composite train-obj: 0.989097
            No improvement (1.0410), counter 2/5
    Epoch [7/50], Train Losses: mse: 5.3299, mae: 1.3229, huber: 0.9683, swd: 1.4500, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 7.5382, mae: 1.4152, huber: 1.0635, swd: 0.9767, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 10.7275, mae: 1.7197, huber: 1.3553, swd: 1.9631, target_std: 4.7581
      Epoch 7 composite train-obj: 0.968299
            No improvement (1.0635), counter 3/5
    Epoch [8/50], Train Losses: mse: 5.1482, mae: 1.3018, huber: 0.9478, swd: 1.3639, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 7.5719, mae: 1.4241, huber: 1.0714, swd: 0.9563, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 10.8917, mae: 1.7293, huber: 1.3650, swd: 1.9507, target_std: 4.7581
      Epoch 8 composite train-obj: 0.947789
            No improvement (1.0714), counter 4/5
    Epoch [9/50], Train Losses: mse: 4.9708, mae: 1.2807, huber: 0.9274, swd: 1.2788, target_std: 6.5099
    Epoch [9/50], Val Losses: mse: 7.6868, mae: 1.4380, huber: 1.0848, swd: 1.0079, target_std: 4.2787
    Epoch [9/50], Test Losses: mse: 10.9630, mae: 1.7419, huber: 1.3769, swd: 2.0173, target_std: 4.7581
      Epoch 9 composite train-obj: 0.927445
    Epoch [9/50], Test Losses: mse: 10.6129, mae: 1.6892, huber: 1.3282, swd: 1.7247, target_std: 4.7581
    Best round's Test MSE: 10.6129, MAE: 1.6892, SWD: 1.7247
    Best round's Validation MSE: 7.2691, MAE: 1.3811
    Best round's Test verification MSE : 10.6129, MAE: 1.6892, SWD: 1.7247
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.6730, mae: 1.5715, huber: 1.2059, swd: 2.0541, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 7.7399, mae: 1.4078, huber: 1.0577, swd: 1.0839, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.8743, mae: 1.7678, huber: 1.4069, swd: 2.1259, target_std: 4.7581
      Epoch 1 composite train-obj: 1.205860
            Val objective improved inf → 1.0577, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4209, mae: 1.4393, huber: 1.0811, swd: 1.7988, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.7496, mae: 1.4053, huber: 1.0554, swd: 0.9525, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 11.6444, mae: 1.7356, huber: 1.3762, swd: 1.8355, target_std: 4.7581
      Epoch 2 composite train-obj: 1.081058
            Val objective improved 1.0577 → 1.0554, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.2571, mae: 1.4208, huber: 1.0635, swd: 1.7337, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 7.4057, mae: 1.3804, huber: 1.0319, swd: 0.9155, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.0406, mae: 1.7159, huber: 1.3552, swd: 1.8547, target_std: 4.7581
      Epoch 3 composite train-obj: 1.063506
            Val objective improved 1.0554 → 1.0319, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.1263, mae: 1.4065, huber: 1.0499, swd: 1.6864, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 7.4043, mae: 1.3823, huber: 1.0335, swd: 0.9213, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.8557, mae: 1.7107, huber: 1.3489, swd: 1.9066, target_std: 4.7581
      Epoch 4 composite train-obj: 1.049933
            No improvement (1.0335), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.0181, mae: 1.3947, huber: 1.0387, swd: 1.6530, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.3707, mae: 1.3814, huber: 1.0323, swd: 0.8750, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.7129, mae: 1.7091, huber: 1.3461, swd: 1.8618, target_std: 4.7581
      Epoch 5 composite train-obj: 1.038685
            No improvement (1.0323), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.9014, mae: 1.3827, huber: 1.0270, swd: 1.6144, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.2811, mae: 1.3837, huber: 1.0336, swd: 0.9469, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 10.5577, mae: 1.7108, huber: 1.3467, swd: 1.9522, target_std: 4.7581
      Epoch 6 composite train-obj: 1.026979
            No improvement (1.0336), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.7879, mae: 1.3716, huber: 1.0161, swd: 1.5808, target_std: 6.5098
    Epoch [7/50], Val Losses: mse: 7.2389, mae: 1.3832, huber: 1.0334, swd: 0.9659, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 10.5606, mae: 1.7178, huber: 1.3537, swd: 2.0663, target_std: 4.7581
      Epoch 7 composite train-obj: 1.016133
            No improvement (1.0334), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.6506, mae: 1.3569, huber: 1.0017, swd: 1.5299, target_std: 6.5098
    Epoch [8/50], Val Losses: mse: 7.4585, mae: 1.3992, huber: 1.0488, swd: 1.0095, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 10.7720, mae: 1.7467, huber: 1.3817, swd: 2.1980, target_std: 4.7581
      Epoch 8 composite train-obj: 1.001699
    Epoch [8/50], Test Losses: mse: 11.0406, mae: 1.7159, huber: 1.3552, swd: 1.8547, target_std: 4.7581
    Best round's Test MSE: 11.0406, MAE: 1.7159, SWD: 1.8547
    Best round's Validation MSE: 7.4057, MAE: 1.3804
    Best round's Test verification MSE : 11.0406, MAE: 1.7159, SWD: 1.8547
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq196_pred336_20250429_1632)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.0331 ± 0.3401
      mae: 1.7155 ± 0.0213
      huber: 1.3543 ± 0.0210
      swd: 1.8059 ± 0.0578
      target_std: 4.7581 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.4018 ± 0.1069
      mae: 1.3821 ± 0.0020
      huber: 1.0330 ± 0.0016
      swd: 0.9058 ± 0.0254
      target_std: 4.2787 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq196_pred336_20250429_1632
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 196-720



```python
utils.reload_modules([utils])
cfg_time_mixer_196_720 = train_config.FlatTimeMixerConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_196_720 = execute_model_evaluation('ettm1', cfg_time_mixer_196_720, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1111, mae: 1.6672, huber: 1.2935, swd: 2.1113, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 9.5818, mae: 1.5661, huber: 1.2074, swd: 0.9646, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.6926, mae: 1.9143, huber: 1.5402, swd: 1.8800, target_std: 4.7636
      Epoch 1 composite train-obj: 1.293472
            Val objective improved inf → 1.2074, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3230, mae: 1.5827, huber: 1.2131, swd: 1.8991, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 9.1009, mae: 1.5424, huber: 1.1844, swd: 1.0992, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 12.1122, mae: 1.9076, huber: 1.5322, swd: 2.2335, target_std: 4.7636
      Epoch 2 composite train-obj: 1.213107
            Val objective improved 1.2074 → 1.1844, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.0292, mae: 1.5590, huber: 1.1899, swd: 1.8075, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.2278, mae: 1.5543, huber: 1.1966, swd: 0.9813, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.7479, mae: 1.8689, huber: 1.4957, swd: 1.9204, target_std: 4.7636
      Epoch 3 composite train-obj: 1.189878
            No improvement (1.1966), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.8380, mae: 1.5406, huber: 1.1722, swd: 1.7399, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 9.1729, mae: 1.5550, huber: 1.1973, swd: 1.0635, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.5941, mae: 1.8669, huber: 1.4935, swd: 2.0534, target_std: 4.7636
      Epoch 4 composite train-obj: 1.172173
            No improvement (1.1973), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.6730, mae: 1.5236, huber: 1.1556, swd: 1.6785, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 8.7939, mae: 1.5386, huber: 1.1792, swd: 1.1833, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 12.1509, mae: 1.9332, huber: 1.5561, swd: 2.7324, target_std: 4.7636
      Epoch 5 composite train-obj: 1.155626
            Val objective improved 1.1844 → 1.1792, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.4941, mae: 1.5043, huber: 1.1367, swd: 1.5990, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 8.9440, mae: 1.5455, huber: 1.1861, swd: 0.9750, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.7830, mae: 1.8762, huber: 1.5021, swd: 2.0373, target_std: 4.7636
      Epoch 6 composite train-obj: 1.136671
            No improvement (1.1861), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.2824, mae: 1.4807, huber: 1.1136, swd: 1.4947, target_std: 6.5087
    Epoch [7/50], Val Losses: mse: 9.1491, mae: 1.5644, huber: 1.2044, swd: 1.0737, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 11.9176, mae: 1.8903, huber: 1.5155, swd: 2.2172, target_std: 4.7636
      Epoch 7 composite train-obj: 1.113578
            No improvement (1.2044), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.0756, mae: 1.4574, huber: 1.0907, swd: 1.3931, target_std: 6.5087
    Epoch [8/50], Val Losses: mse: 9.3986, mae: 1.5884, huber: 1.2280, swd: 1.1342, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 11.9155, mae: 1.9062, huber: 1.5305, swd: 2.2949, target_std: 4.7636
      Epoch 8 composite train-obj: 1.090692
            No improvement (1.2280), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.8664, mae: 1.4340, huber: 1.0678, swd: 1.2966, target_std: 6.5086
    Epoch [9/50], Val Losses: mse: 9.3641, mae: 1.6003, huber: 1.2385, swd: 1.1169, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 12.0820, mae: 1.9142, huber: 1.5373, swd: 2.2147, target_std: 4.7636
      Epoch 9 composite train-obj: 1.067809
            No improvement (1.2385), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.6807, mae: 1.4117, huber: 1.0460, swd: 1.2058, target_std: 6.5087
    Epoch [10/50], Val Losses: mse: 9.4741, mae: 1.6161, huber: 1.2528, swd: 1.0788, target_std: 4.2634
    Epoch [10/50], Test Losses: mse: 12.3265, mae: 1.9312, huber: 1.5534, swd: 2.2027, target_std: 4.7636
      Epoch 10 composite train-obj: 1.045974
    Epoch [10/50], Test Losses: mse: 12.1509, mae: 1.9332, huber: 1.5561, swd: 2.7324, target_std: 4.7636
    Best round's Test MSE: 12.1509, MAE: 1.9332, SWD: 2.7324
    Best round's Validation MSE: 8.7939, MAE: 1.5386
    Best round's Test verification MSE : 12.1509, MAE: 1.9332, SWD: 2.7324
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1128, mae: 1.6643, huber: 1.2909, swd: 2.0195, target_std: 6.5086
    Epoch [1/50], Val Losses: mse: 9.4650, mae: 1.5515, huber: 1.1945, swd: 0.9712, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.6794, mae: 1.9079, huber: 1.5337, swd: 1.9215, target_std: 4.7636
      Epoch 1 composite train-obj: 1.290939
            Val objective improved inf → 1.1945, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3142, mae: 1.5800, huber: 1.2113, swd: 1.8035, target_std: 6.5086
    Epoch [2/50], Val Losses: mse: 9.1868, mae: 1.5468, huber: 1.1896, swd: 0.9970, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 12.0072, mae: 1.8871, huber: 1.5120, swd: 2.0459, target_std: 4.7636
      Epoch 2 composite train-obj: 1.211294
            Val objective improved 1.1945 → 1.1896, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.0290, mae: 1.5551, huber: 1.1870, swd: 1.7191, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.0875, mae: 1.5483, huber: 1.1907, swd: 0.9933, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.7176, mae: 1.8792, huber: 1.5039, swd: 2.0879, target_std: 4.7636
      Epoch 3 composite train-obj: 1.186980
            No improvement (1.1907), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.8243, mae: 1.5356, huber: 1.1679, swd: 1.6478, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 8.9338, mae: 1.5460, huber: 1.1876, swd: 1.0406, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.6648, mae: 1.8877, huber: 1.5109, swd: 2.3074, target_std: 4.7636
      Epoch 4 composite train-obj: 1.167948
            Val objective improved 1.1896 → 1.1876, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.6487, mae: 1.5172, huber: 1.1499, swd: 1.5802, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 8.9026, mae: 1.5464, huber: 1.1864, swd: 1.0469, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.8100, mae: 1.9051, huber: 1.5255, swd: 2.4353, target_std: 4.7636
      Epoch 5 composite train-obj: 1.149914
            Val objective improved 1.1876 → 1.1864, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.4808, mae: 1.4990, huber: 1.1320, swd: 1.5111, target_std: 6.5088
    Epoch [6/50], Val Losses: mse: 9.3324, mae: 1.5763, huber: 1.2160, swd: 0.9385, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.6910, mae: 1.8847, huber: 1.5078, swd: 2.1144, target_std: 4.7636
      Epoch 6 composite train-obj: 1.131971
            No improvement (1.2160), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.3166, mae: 1.4805, huber: 1.1138, swd: 1.4389, target_std: 6.5088
    Epoch [7/50], Val Losses: mse: 9.1463, mae: 1.5697, huber: 1.2085, swd: 0.9494, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 11.9427, mae: 1.9048, huber: 1.5273, swd: 2.2071, target_std: 4.7636
      Epoch 7 composite train-obj: 1.113803
            No improvement (1.2085), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.1485, mae: 1.4615, huber: 1.0951, swd: 1.3580, target_std: 6.5086
    Epoch [8/50], Val Losses: mse: 9.8305, mae: 1.6160, huber: 1.2542, swd: 0.9721, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 11.8344, mae: 1.9017, huber: 1.5242, swd: 2.0926, target_std: 4.7636
      Epoch 8 composite train-obj: 1.095107
            No improvement (1.2542), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.9756, mae: 1.4417, huber: 1.0757, swd: 1.2728, target_std: 6.5087
    Epoch [9/50], Val Losses: mse: 9.3722, mae: 1.5968, huber: 1.2342, swd: 0.9806, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 11.9689, mae: 1.9221, huber: 1.5432, swd: 2.3556, target_std: 4.7636
      Epoch 9 composite train-obj: 1.075672
            No improvement (1.2342), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.8255, mae: 1.4238, huber: 1.0581, swd: 1.1988, target_std: 6.5088
    Epoch [10/50], Val Losses: mse: 9.8105, mae: 1.6256, huber: 1.2620, swd: 1.0190, target_std: 4.2634
    Epoch [10/50], Test Losses: mse: 12.0348, mae: 1.9252, huber: 1.5459, swd: 2.2612, target_std: 4.7636
      Epoch 10 composite train-obj: 1.058101
    Epoch [10/50], Test Losses: mse: 11.8100, mae: 1.9051, huber: 1.5255, swd: 2.4353, target_std: 4.7636
    Best round's Test MSE: 11.8100, MAE: 1.9051, SWD: 2.4353
    Best round's Validation MSE: 8.9026, MAE: 1.5464
    Best round's Test verification MSE : 11.8100, MAE: 1.9051, SWD: 2.4353
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.3864, mae: 1.6934, huber: 1.3188, swd: 2.2730, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 9.7830, mae: 1.5755, huber: 1.2180, swd: 1.1558, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.8802, mae: 1.9225, huber: 1.5487, swd: 2.1657, target_std: 4.7636
      Epoch 1 composite train-obj: 1.318788
            Val objective improved inf → 1.2180, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.4176, mae: 1.5912, huber: 1.2214, swd: 2.0065, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 9.5735, mae: 1.5684, huber: 1.2104, swd: 1.1630, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 12.4280, mae: 1.9040, huber: 1.5295, swd: 2.1253, target_std: 4.7636
      Epoch 2 composite train-obj: 1.221416
            Val objective improved 1.2180 → 1.2104, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.2190, mae: 1.5722, huber: 1.2031, swd: 1.9329, target_std: 6.5087
    Epoch [3/50], Val Losses: mse: 9.6033, mae: 1.5886, huber: 1.2291, swd: 1.3627, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 12.3739, mae: 1.9386, huber: 1.5624, swd: 2.5489, target_std: 4.7636
      Epoch 3 composite train-obj: 1.203068
            No improvement (1.2291), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.0441, mae: 1.5564, huber: 1.1878, swd: 1.8713, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 9.1553, mae: 1.5509, huber: 1.1928, swd: 1.1445, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.8152, mae: 1.8817, huber: 1.5081, swd: 2.3014, target_std: 4.7636
      Epoch 4 composite train-obj: 1.187792
            Val objective improved 1.2104 → 1.1928, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.8864, mae: 1.5424, huber: 1.1741, swd: 1.8157, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 9.2840, mae: 1.5584, huber: 1.2001, swd: 0.9966, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.6801, mae: 1.8587, huber: 1.4858, swd: 1.9543, target_std: 4.7636
      Epoch 5 composite train-obj: 1.174074
            No improvement (1.2001), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.7292, mae: 1.5265, huber: 1.1585, swd: 1.7520, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 8.8779, mae: 1.5463, huber: 1.1868, swd: 1.0229, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.7955, mae: 1.8824, huber: 1.5073, swd: 2.2019, target_std: 4.7636
      Epoch 6 composite train-obj: 1.158510
            Val objective improved 1.1928 → 1.1868, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.5515, mae: 1.5086, huber: 1.1409, swd: 1.6699, target_std: 6.5086
    Epoch [7/50], Val Losses: mse: 9.1760, mae: 1.5955, huber: 1.2332, swd: 1.6282, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 12.3309, mae: 1.9901, huber: 1.6099, swd: 3.5292, target_std: 4.7636
      Epoch 7 composite train-obj: 1.140908
            No improvement (1.2332), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.3718, mae: 1.4895, huber: 1.1221, swd: 1.5811, target_std: 6.5086
    Epoch [8/50], Val Losses: mse: 9.0707, mae: 1.5674, huber: 1.2069, swd: 1.1667, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 11.8194, mae: 1.9006, huber: 1.5238, swd: 2.5278, target_std: 4.7636
      Epoch 8 composite train-obj: 1.122105
            No improvement (1.2069), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.1852, mae: 1.4685, huber: 1.1015, swd: 1.4875, target_std: 6.5086
    Epoch [9/50], Val Losses: mse: 9.3627, mae: 1.5935, huber: 1.2312, swd: 1.1448, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 11.8573, mae: 1.9036, huber: 1.5255, swd: 2.4032, target_std: 4.7636
      Epoch 9 composite train-obj: 1.101472
            No improvement (1.2312), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.0034, mae: 1.4479, huber: 1.0812, swd: 1.3889, target_std: 6.5087
    Epoch [10/50], Val Losses: mse: 9.2758, mae: 1.5954, huber: 1.2326, swd: 1.3144, target_std: 4.2634
    Epoch [10/50], Test Losses: mse: 12.2460, mae: 1.9560, huber: 1.5755, swd: 2.8919, target_std: 4.7636
      Epoch 10 composite train-obj: 1.081229
            No improvement (1.2326), counter 4/5
    Epoch [11/50], Train Losses: mse: 5.8307, mae: 1.4277, huber: 1.0614, swd: 1.3016, target_std: 6.5087
    Epoch [11/50], Val Losses: mse: 9.4935, mae: 1.6179, huber: 1.2545, swd: 1.2758, target_std: 4.2634
    Epoch [11/50], Test Losses: mse: 11.9965, mae: 1.9216, huber: 1.5431, swd: 2.5500, target_std: 4.7636
      Epoch 11 composite train-obj: 1.061388
    Epoch [11/50], Test Losses: mse: 11.7955, mae: 1.8824, huber: 1.5073, swd: 2.2019, target_std: 4.7636
    Best round's Test MSE: 11.7955, MAE: 1.8824, SWD: 2.2019
    Best round's Validation MSE: 8.8779, MAE: 1.5463
    Best round's Test verification MSE : 11.7955, MAE: 1.8824, SWD: 2.2019
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq196_pred720_20250429_1638)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.9188 ± 0.1642
      mae: 1.9069 ± 0.0208
      huber: 1.5297 ± 0.0201
      swd: 2.4565 ± 0.2171
      target_std: 4.7636 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.8581 ± 0.0466
      mae: 1.5438 ± 0.0036
      huber: 1.1841 ± 0.0035
      swd: 1.0844 ± 0.0706
      target_std: 4.2634 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq196_pred720_20250429_1638
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python

```

### PatchTST

#### 196-96



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_336_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.6940, mae: 1.3377, huber: 0.9851, swd: 1.5853, target_std: 6.5076
    Epoch [1/50], Val Losses: mse: 5.1673, mae: 1.1655, huber: 0.8290, swd: 1.0056, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.8772, mae: 1.4100, huber: 1.0656, swd: 1.4932, target_std: 4.7724
      Epoch 1 composite train-obj: 0.985057
            Val objective improved inf → 0.8290, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1892, mae: 1.2632, huber: 0.9157, swd: 1.4791, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.1102, mae: 1.1551, huber: 0.8188, swd: 1.0843, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 8.0291, mae: 1.4490, huber: 1.1012, swd: 1.8437, target_std: 4.7724
      Epoch 2 composite train-obj: 0.915726
            Val objective improved 0.8290 → 0.8188, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.0345, mae: 1.2401, huber: 0.8946, swd: 1.4276, target_std: 6.5076
    Epoch [3/50], Val Losses: mse: 5.1369, mae: 1.1502, huber: 0.8151, swd: 1.0486, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.9457, mae: 1.4300, huber: 1.0844, swd: 1.8080, target_std: 4.7724
      Epoch 3 composite train-obj: 0.894586
            Val objective improved 0.8188 → 0.8151, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.9328, mae: 1.2259, huber: 0.8815, swd: 1.3962, target_std: 6.5078
    Epoch [4/50], Val Losses: mse: 5.1033, mae: 1.1465, huber: 0.8118, swd: 1.0181, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 8.0000, mae: 1.4324, huber: 1.0871, swd: 1.8135, target_std: 4.7724
      Epoch 4 composite train-obj: 0.881509
            Val objective improved 0.8151 → 0.8118, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.8184, mae: 1.2110, huber: 0.8677, swd: 1.3544, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 5.2441, mae: 1.1543, huber: 0.8193, swd: 1.0226, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 8.0097, mae: 1.4283, huber: 1.0831, swd: 1.7306, target_std: 4.7724
      Epoch 5 composite train-obj: 0.867712
            No improvement (0.8193), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.7156, mae: 1.1980, huber: 0.8555, swd: 1.3228, target_std: 6.5078
    Epoch [6/50], Val Losses: mse: 5.2040, mae: 1.1635, huber: 0.8289, swd: 0.9895, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.9814, mae: 1.4148, huber: 1.0710, swd: 1.7207, target_std: 4.7724
      Epoch 6 composite train-obj: 0.855457
            No improvement (0.8289), counter 2/5
    Epoch [7/50], Train Losses: mse: 4.6330, mae: 1.1869, huber: 0.8451, swd: 1.2917, target_std: 6.5076
    Epoch [7/50], Val Losses: mse: 5.2594, mae: 1.1603, huber: 0.8242, swd: 1.0480, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 8.0522, mae: 1.4245, huber: 1.0801, swd: 1.7964, target_std: 4.7724
      Epoch 7 composite train-obj: 0.845103
            No improvement (0.8242), counter 3/5
    Epoch [8/50], Train Losses: mse: 4.5302, mae: 1.1742, huber: 0.8329, swd: 1.2542, target_std: 6.5075
    Epoch [8/50], Val Losses: mse: 5.4849, mae: 1.2003, huber: 0.8631, swd: 0.9543, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 8.3523, mae: 1.4304, huber: 1.0872, swd: 1.5795, target_std: 4.7724
      Epoch 8 composite train-obj: 0.832882
            No improvement (0.8631), counter 4/5
    Epoch [9/50], Train Losses: mse: 4.4393, mae: 1.1625, huber: 0.8218, swd: 1.2208, target_std: 6.5076
    Epoch [9/50], Val Losses: mse: 5.2920, mae: 1.1639, huber: 0.8283, swd: 0.9874, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.1809, mae: 1.4296, huber: 1.0859, swd: 1.7044, target_std: 4.7724
      Epoch 9 composite train-obj: 0.821840
    Epoch [9/50], Test Losses: mse: 8.0000, mae: 1.4324, huber: 1.0871, swd: 1.8135, target_std: 4.7724
    Best round's Test MSE: 8.0000, MAE: 1.4324, SWD: 1.8135
    Best round's Validation MSE: 5.1033, MAE: 1.1465
    Best round's Test verification MSE : 8.0000, MAE: 1.4324, SWD: 1.8135
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.7004, mae: 1.3370, huber: 0.9843, swd: 1.5612, target_std: 6.5077
    Epoch [1/50], Val Losses: mse: 5.1877, mae: 1.1612, huber: 0.8217, swd: 0.8743, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 7.9015, mae: 1.4167, huber: 1.0690, swd: 1.4317, target_std: 4.7724
      Epoch 1 composite train-obj: 0.984288
            Val objective improved inf → 0.8217, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1967, mae: 1.2607, huber: 0.9135, swd: 1.4501, target_std: 6.5077
    Epoch [2/50], Val Losses: mse: 5.1223, mae: 1.1517, huber: 0.8156, swd: 1.0871, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.9673, mae: 1.4333, huber: 1.0870, swd: 1.8378, target_std: 4.7724
      Epoch 2 composite train-obj: 0.913537
            Val objective improved 0.8217 → 0.8156, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.0377, mae: 1.2398, huber: 0.8941, swd: 1.4111, target_std: 6.5077
    Epoch [3/50], Val Losses: mse: 5.1843, mae: 1.1564, huber: 0.8192, swd: 1.0095, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.7952, mae: 1.4134, huber: 1.0674, swd: 1.6896, target_std: 4.7724
      Epoch 3 composite train-obj: 0.894146
            No improvement (0.8192), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.8933, mae: 1.2224, huber: 0.8780, swd: 1.3724, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.0861, mae: 1.1484, huber: 0.8114, swd: 0.9152, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.7003, mae: 1.3924, huber: 1.0464, swd: 1.5135, target_std: 4.7724
      Epoch 4 composite train-obj: 0.877959
            Val objective improved 0.8156 → 0.8114, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.7760, mae: 1.2083, huber: 0.8647, swd: 1.3317, target_std: 6.5079
    Epoch [5/50], Val Losses: mse: 5.0804, mae: 1.1535, huber: 0.8175, swd: 0.9952, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 7.9396, mae: 1.4413, huber: 1.0950, swd: 1.9262, target_std: 4.7724
      Epoch 5 composite train-obj: 0.864656
            No improvement (0.8175), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.6631, mae: 1.1922, huber: 0.8498, swd: 1.2880, target_std: 6.5075
    Epoch [6/50], Val Losses: mse: 5.1520, mae: 1.1619, huber: 0.8262, swd: 1.0563, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 8.0455, mae: 1.4515, huber: 1.1052, swd: 2.0471, target_std: 4.7724
      Epoch 6 composite train-obj: 0.849760
            No improvement (0.8262), counter 2/5
    Epoch [7/50], Train Losses: mse: 4.5661, mae: 1.1795, huber: 0.8378, swd: 1.2543, target_std: 6.5076
    Epoch [7/50], Val Losses: mse: 5.3098, mae: 1.1691, huber: 0.8330, swd: 0.9935, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.9406, mae: 1.4166, huber: 1.0705, swd: 1.6937, target_std: 4.7724
      Epoch 7 composite train-obj: 0.837810
            No improvement (0.8330), counter 3/5
    Epoch [8/50], Train Losses: mse: 4.4725, mae: 1.1674, huber: 0.8264, swd: 1.2218, target_std: 6.5078
    Epoch [8/50], Val Losses: mse: 5.3927, mae: 1.1721, huber: 0.8363, swd: 1.0713, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 8.2162, mae: 1.4422, huber: 1.0974, swd: 1.9711, target_std: 4.7724
      Epoch 8 composite train-obj: 0.826440
            No improvement (0.8363), counter 4/5
    Epoch [9/50], Train Losses: mse: 4.3900, mae: 1.1570, huber: 0.8165, swd: 1.1931, target_std: 6.5076
    Epoch [9/50], Val Losses: mse: 5.4312, mae: 1.1867, huber: 0.8491, swd: 1.0545, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.3699, mae: 1.4365, huber: 1.0912, swd: 1.7572, target_std: 4.7724
      Epoch 9 composite train-obj: 0.816471
    Epoch [9/50], Test Losses: mse: 7.7003, mae: 1.3924, huber: 1.0464, swd: 1.5135, target_std: 4.7724
    Best round's Test MSE: 7.7003, MAE: 1.3924, SWD: 1.5135
    Best round's Validation MSE: 5.0861, MAE: 1.1484
    Best round's Test verification MSE : 7.7003, MAE: 1.3924, SWD: 1.5135
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.7002, mae: 1.3369, huber: 0.9843, swd: 1.4602, target_std: 6.5079
    Epoch [1/50], Val Losses: mse: 5.2909, mae: 1.1779, huber: 0.8386, swd: 1.0751, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 8.1123, mae: 1.4617, huber: 1.1130, swd: 1.7873, target_std: 4.7724
      Epoch 1 composite train-obj: 0.984303
            Val objective improved inf → 0.8386, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.2068, mae: 1.2648, huber: 0.9173, swd: 1.3629, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.1174, mae: 1.1487, huber: 0.8129, swd: 0.9149, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 7.9080, mae: 1.4187, huber: 1.0733, swd: 1.5956, target_std: 4.7724
      Epoch 2 composite train-obj: 0.917319
            Val objective improved 0.8386 → 0.8129, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.0267, mae: 1.2405, huber: 0.8949, swd: 1.3145, target_std: 6.5075
    Epoch [3/50], Val Losses: mse: 5.1032, mae: 1.1527, huber: 0.8165, swd: 0.9152, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 7.8560, mae: 1.4033, huber: 1.0601, swd: 1.5260, target_std: 4.7724
      Epoch 3 composite train-obj: 0.894935
            No improvement (0.8165), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.8751, mae: 1.2221, huber: 0.8777, swd: 1.2778, target_std: 6.5074
    Epoch [4/50], Val Losses: mse: 5.1117, mae: 1.1579, huber: 0.8193, swd: 0.9469, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.9186, mae: 1.4206, huber: 1.0735, swd: 1.6515, target_std: 4.7724
      Epoch 4 composite train-obj: 0.877733
            No improvement (0.8193), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.7509, mae: 1.2065, huber: 0.8631, swd: 1.2387, target_std: 6.5076
    Epoch [5/50], Val Losses: mse: 5.2583, mae: 1.1570, huber: 0.8203, swd: 0.9333, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 8.3425, mae: 1.4601, huber: 1.1119, swd: 1.8821, target_std: 4.7724
      Epoch 5 composite train-obj: 0.863092
            No improvement (0.8203), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.6369, mae: 1.1922, huber: 0.8497, swd: 1.2018, target_std: 6.5077
    Epoch [6/50], Val Losses: mse: 5.2641, mae: 1.1630, huber: 0.8272, swd: 0.8745, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 8.2938, mae: 1.4332, huber: 1.0888, swd: 1.6943, target_std: 4.7724
      Epoch 6 composite train-obj: 0.849691
            No improvement (0.8272), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.5437, mae: 1.1792, huber: 0.8375, swd: 1.1672, target_std: 6.5078
    Epoch [7/50], Val Losses: mse: 5.5236, mae: 1.1757, huber: 0.8401, swd: 0.8959, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 8.5182, mae: 1.4502, huber: 1.1054, swd: 1.7196, target_std: 4.7724
      Epoch 7 composite train-obj: 0.837482
    Epoch [7/50], Test Losses: mse: 7.9080, mae: 1.4187, huber: 1.0733, swd: 1.5956, target_std: 4.7724
    Best round's Test MSE: 7.9080, MAE: 1.4187, SWD: 1.5956
    Best round's Validation MSE: 5.1174, MAE: 1.1487
    Best round's Test verification MSE : 7.9080, MAE: 1.4187, SWD: 1.5956
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq196_pred96_20250430_0312)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.8695 ± 0.1254
      mae: 1.4145 ± 0.0166
      huber: 1.0690 ± 0.0169
      swd: 1.6409 ± 0.1266
      target_std: 4.7724 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.1023 ± 0.0128
      mae: 1.1479 ± 0.0010
      huber: 0.8120 ± 0.0006
      swd: 0.9494 ± 0.0486
      target_std: 4.3035 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq196_pred96_20250430_0312
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 196-196



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_196_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.7070, mae: 1.4732, huber: 1.1115, swd: 1.8752, target_std: 6.5062
    Epoch [1/50], Val Losses: mse: 6.2035, mae: 1.3212, huber: 0.9695, swd: 0.9698, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 9.9762, mae: 1.6401, huber: 1.2800, swd: 1.7262, target_std: 4.7639
      Epoch 1 composite train-obj: 1.111511
            Val objective improved inf → 0.9695, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.1624, mae: 1.4058, huber: 1.0479, swd: 1.7642, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 6.2643, mae: 1.3152, huber: 0.9658, swd: 1.0244, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.0103, mae: 1.6447, huber: 1.2865, swd: 1.9345, target_std: 4.7639
      Epoch 2 composite train-obj: 1.047912
            Val objective improved 0.9695 → 0.9658, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0047, mae: 1.3858, huber: 1.0292, swd: 1.7092, target_std: 6.5071
    Epoch [3/50], Val Losses: mse: 6.3694, mae: 1.3381, huber: 0.9838, swd: 1.0327, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.1384, mae: 1.6593, huber: 1.2970, swd: 1.8819, target_std: 4.7639
      Epoch 3 composite train-obj: 1.029197
            No improvement (0.9838), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8441, mae: 1.3668, huber: 1.0112, swd: 1.6569, target_std: 6.5074
    Epoch [4/50], Val Losses: mse: 6.2377, mae: 1.3236, huber: 0.9727, swd: 1.2277, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.9189, mae: 1.6479, huber: 1.2873, swd: 2.3127, target_std: 4.7639
      Epoch 4 composite train-obj: 1.011247
            No improvement (0.9727), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7252, mae: 1.3510, huber: 0.9965, swd: 1.6277, target_std: 6.5074
    Epoch [5/50], Val Losses: mse: 7.2947, mae: 1.4176, huber: 1.0593, swd: 1.1775, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 11.1940, mae: 1.7129, huber: 1.3467, swd: 1.8978, target_std: 4.7639
      Epoch 5 composite train-obj: 0.996498
            No improvement (1.0593), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.7508, mae: 1.3541, huber: 0.9999, swd: 1.6451, target_std: 6.5021
    Epoch [6/50], Val Losses: mse: 6.3744, mae: 1.2995, huber: 0.9533, swd: 1.1141, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.1246, mae: 1.6429, huber: 1.2861, swd: 2.2153, target_std: 4.7639
      Epoch 6 composite train-obj: 0.999855
            Val objective improved 0.9658 → 0.9533, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 5.5405, mae: 1.3257, huber: 0.9732, swd: 1.5417, target_std: 6.5081
    Epoch [7/50], Val Losses: mse: 6.4599, mae: 1.3204, huber: 0.9710, swd: 1.3263, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.6255, mae: 1.6816, huber: 1.3231, swd: 2.5067, target_std: 4.7639
      Epoch 7 composite train-obj: 0.973175
            No improvement (0.9710), counter 1/5
    Epoch [8/50], Train Losses: mse: 5.5560, mae: 1.3270, huber: 0.9742, swd: 1.5435, target_std: 6.5115
    Epoch [8/50], Val Losses: mse: 6.5984, mae: 1.3144, huber: 0.9680, swd: 1.0084, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 10.3493, mae: 1.6383, huber: 1.2814, swd: 1.9402, target_std: 4.7639
      Epoch 8 composite train-obj: 0.974218
            No improvement (0.9680), counter 2/5
    Epoch [9/50], Train Losses: mse: 5.3452, mae: 1.3026, huber: 0.9509, swd: 1.4566, target_std: 6.5112
    Epoch [9/50], Val Losses: mse: 6.7120, mae: 1.3323, huber: 0.9854, swd: 1.2366, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 10.7058, mae: 1.6962, huber: 1.3377, swd: 2.6504, target_std: 4.7639
      Epoch 9 composite train-obj: 0.950896
            No improvement (0.9854), counter 3/5
    Epoch [10/50], Train Losses: mse: 5.2497, mae: 1.2916, huber: 0.9403, swd: 1.4291, target_std: 6.5050
    Epoch [10/50], Val Losses: mse: 6.6521, mae: 1.3286, huber: 0.9809, swd: 1.1055, target_std: 4.2884
    Epoch [10/50], Test Losses: mse: 10.4578, mae: 1.6550, huber: 1.2966, swd: 2.2838, target_std: 4.7639
      Epoch 10 composite train-obj: 0.940303
            No improvement (0.9809), counter 4/5
    Epoch [11/50], Train Losses: mse: 5.2106, mae: 1.2871, huber: 0.9359, swd: 1.4099, target_std: 6.5097
    Epoch [11/50], Val Losses: mse: 6.5822, mae: 1.3394, huber: 0.9902, swd: 1.3796, target_std: 4.2884
    Epoch [11/50], Test Losses: mse: 10.3863, mae: 1.6715, huber: 1.3129, swd: 2.5163, target_std: 4.7639
      Epoch 11 composite train-obj: 0.935895
    Epoch [11/50], Test Losses: mse: 10.1246, mae: 1.6429, huber: 1.2861, swd: 2.2153, target_std: 4.7639
    Best round's Test MSE: 10.1246, MAE: 1.6429, SWD: 2.2153
    Best round's Validation MSE: 6.3744, MAE: 1.2995
    Best round's Test verification MSE : 10.1246, MAE: 1.6429, SWD: 2.2153
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.6973, mae: 1.4704, huber: 1.1091, swd: 1.9140, target_std: 6.5120
    Epoch [1/50], Val Losses: mse: 6.2764, mae: 1.3253, huber: 0.9722, swd: 0.9196, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.0247, mae: 1.6417, huber: 1.2800, swd: 1.6036, target_std: 4.7639
      Epoch 1 composite train-obj: 1.109087
            Val objective improved inf → 0.9722, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.1651, mae: 1.4045, huber: 1.0468, swd: 1.8024, target_std: 6.5223
    Epoch [2/50], Val Losses: mse: 6.3646, mae: 1.3299, huber: 0.9782, swd: 0.9488, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 9.7838, mae: 1.6200, huber: 1.2603, swd: 1.6613, target_std: 4.7639
      Epoch 2 composite train-obj: 1.046786
            No improvement (0.9782), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.9706, mae: 1.3812, huber: 1.0249, swd: 1.7430, target_std: 6.5129
    Epoch [3/50], Val Losses: mse: 6.2646, mae: 1.2926, huber: 0.9450, swd: 1.1539, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.4315, mae: 1.6629, huber: 1.3050, swd: 2.4750, target_std: 4.7639
      Epoch 3 composite train-obj: 1.024851
            Val objective improved 0.9722 → 0.9450, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.8811, mae: 1.3672, huber: 1.0120, swd: 1.7055, target_std: 6.5038
    Epoch [4/50], Val Losses: mse: 6.3087, mae: 1.3197, huber: 0.9673, swd: 1.1258, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.2911, mae: 1.6695, huber: 1.3073, swd: 2.0735, target_std: 4.7639
      Epoch 4 composite train-obj: 1.012010
            No improvement (0.9673), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.7487, mae: 1.3540, huber: 0.9992, swd: 1.6568, target_std: 6.5061
    Epoch [5/50], Val Losses: mse: 6.2415, mae: 1.3005, huber: 0.9523, swd: 0.9904, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 9.8877, mae: 1.6231, huber: 1.2654, swd: 1.8937, target_std: 4.7639
      Epoch 5 composite train-obj: 0.999212
            No improvement (0.9523), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.5366, mae: 1.3272, huber: 0.9739, swd: 1.5788, target_std: 6.5229
    Epoch [6/50], Val Losses: mse: 6.4982, mae: 1.3210, huber: 0.9713, swd: 1.0201, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.0213, mae: 1.6100, huber: 1.2541, swd: 1.7627, target_std: 4.7639
      Epoch 6 composite train-obj: 0.973944
            No improvement (0.9713), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.4897, mae: 1.3213, huber: 0.9684, swd: 1.5645, target_std: 6.5101
    Epoch [7/50], Val Losses: mse: 8.5164, mae: 1.4484, huber: 1.0965, swd: 1.1729, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 11.3371, mae: 1.6898, huber: 1.3296, swd: 1.9672, target_std: 4.7639
      Epoch 7 composite train-obj: 0.968374
            No improvement (1.0965), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.4092, mae: 1.3126, huber: 0.9600, swd: 1.5258, target_std: 6.5059
    Epoch [8/50], Val Losses: mse: 6.8296, mae: 1.3420, huber: 0.9929, swd: 1.2514, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 10.0236, mae: 1.6361, huber: 1.2795, swd: 2.1356, target_std: 4.7639
      Epoch 8 composite train-obj: 0.960031
    Epoch [8/50], Test Losses: mse: 10.4315, mae: 1.6629, huber: 1.3050, swd: 2.4750, target_std: 4.7639
    Best round's Test MSE: 10.4315, MAE: 1.6629, SWD: 2.4750
    Best round's Validation MSE: 6.2646, MAE: 1.2926
    Best round's Test verification MSE : 10.4315, MAE: 1.6629, SWD: 2.4750
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.7421, mae: 1.4753, huber: 1.1136, swd: 1.6925, target_std: 6.5051
    Epoch [1/50], Val Losses: mse: 6.6451, mae: 1.4083, huber: 1.0465, swd: 1.1584, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 11.1986, mae: 1.8230, huber: 1.4492, swd: 2.1864, target_std: 4.7639
      Epoch 1 composite train-obj: 1.113638
            Val objective improved inf → 1.0465, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.2814, mae: 1.4182, huber: 1.0599, swd: 1.6180, target_std: 6.5129
    Epoch [2/50], Val Losses: mse: 6.7911, mae: 1.3515, huber: 0.9960, swd: 1.1025, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 11.0978, mae: 1.7271, huber: 1.3595, swd: 2.1979, target_std: 4.7639
      Epoch 2 composite train-obj: 1.059871
            Val objective improved 1.0465 → 0.9960, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.1682, mae: 1.4015, huber: 1.0445, swd: 1.5869, target_std: 6.5049
    Epoch [3/50], Val Losses: mse: 6.2392, mae: 1.3044, huber: 0.9547, swd: 1.2077, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.3531, mae: 1.6864, huber: 1.3246, swd: 2.4321, target_std: 4.7639
      Epoch 3 composite train-obj: 1.044483
            Val objective improved 0.9960 → 0.9547, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.8936, mae: 1.3716, huber: 1.0162, swd: 1.5003, target_std: 6.5199
    Epoch [4/50], Val Losses: mse: 6.1955, mae: 1.3024, huber: 0.9541, swd: 1.1025, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 9.9612, mae: 1.6503, huber: 1.2913, swd: 2.2336, target_std: 4.7639
      Epoch 4 composite train-obj: 1.016153
            Val objective improved 0.9547 → 0.9541, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.7371, mae: 1.3521, huber: 0.9978, swd: 1.4543, target_std: 6.5126
    Epoch [5/50], Val Losses: mse: 7.0597, mae: 1.3543, huber: 1.0063, swd: 0.9650, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.5114, mae: 1.6648, huber: 1.3067, swd: 1.9390, target_std: 4.7639
      Epoch 5 composite train-obj: 0.997787
            No improvement (1.0063), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.6510, mae: 1.3413, huber: 0.9877, swd: 1.4264, target_std: 6.5090
    Epoch [6/50], Val Losses: mse: 6.5714, mae: 1.3339, huber: 0.9828, swd: 1.2245, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.5985, mae: 1.7110, huber: 1.3502, swd: 2.5110, target_std: 4.7639
      Epoch 6 composite train-obj: 0.987705
            No improvement (0.9828), counter 2/5
    Epoch [7/50], Train Losses: mse: 5.7770, mae: 1.3568, huber: 1.0026, swd: 1.4738, target_std: 6.5071
    Epoch [7/50], Val Losses: mse: 6.3722, mae: 1.2917, huber: 0.9463, swd: 1.0187, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.0017, mae: 1.6209, huber: 1.2661, swd: 2.0159, target_std: 4.7639
      Epoch 7 composite train-obj: 1.002596
            Val objective improved 0.9541 → 0.9463, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 5.4742, mae: 1.3199, huber: 0.9673, swd: 1.3660, target_std: 6.5059
    Epoch [8/50], Val Losses: mse: 6.6312, mae: 1.3264, huber: 0.9782, swd: 0.9165, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 9.8682, mae: 1.6093, huber: 1.2530, swd: 1.7330, target_std: 4.7639
      Epoch 8 composite train-obj: 0.967268
            No improvement (0.9782), counter 1/5
    Epoch [9/50], Train Losses: mse: 5.3627, mae: 1.3058, huber: 0.9540, swd: 1.3268, target_std: 6.5013
    Epoch [9/50], Val Losses: mse: 7.0246, mae: 1.3465, huber: 0.9981, swd: 0.9440, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 10.1333, mae: 1.6290, huber: 1.2714, swd: 1.8229, target_std: 4.7639
      Epoch 9 composite train-obj: 0.953980
            No improvement (0.9981), counter 2/5
    Epoch [10/50], Train Losses: mse: 5.2895, mae: 1.2976, huber: 0.9460, swd: 1.2990, target_std: 6.5004
    Epoch [10/50], Val Losses: mse: 6.8311, mae: 1.3363, huber: 0.9889, swd: 1.1068, target_std: 4.2884
    Epoch [10/50], Test Losses: mse: 10.1193, mae: 1.6276, huber: 1.2719, swd: 1.9030, target_std: 4.7639
      Epoch 10 composite train-obj: 0.946021
            No improvement (0.9889), counter 3/5
    Epoch [11/50], Train Losses: mse: 5.2047, mae: 1.2871, huber: 0.9359, swd: 1.2706, target_std: 6.5036
    Epoch [11/50], Val Losses: mse: 6.8625, mae: 1.3421, huber: 0.9958, swd: 1.0475, target_std: 4.2884
    Epoch [11/50], Test Losses: mse: 9.9887, mae: 1.6350, huber: 1.2790, swd: 1.9577, target_std: 4.7639
      Epoch 11 composite train-obj: 0.935857
            No improvement (0.9958), counter 4/5
    Epoch [12/50], Train Losses: mse: 5.1260, mae: 1.2777, huber: 0.9267, swd: 1.2422, target_std: 6.5043
    Epoch [12/50], Val Losses: mse: 7.1142, mae: 1.3575, huber: 1.0086, swd: 1.0040, target_std: 4.2884
    Epoch [12/50], Test Losses: mse: 10.5311, mae: 1.6660, huber: 1.3076, swd: 2.0699, target_std: 4.7639
      Epoch 12 composite train-obj: 0.926703
    Epoch [12/50], Test Losses: mse: 10.0017, mae: 1.6209, huber: 1.2661, swd: 2.0159, target_std: 4.7639
    Best round's Test MSE: 10.0017, MAE: 1.6209, SWD: 2.0159
    Best round's Validation MSE: 6.3722, MAE: 1.2917
    Best round's Test verification MSE : 10.0017, MAE: 1.6209, SWD: 2.0159
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq196_pred196_20250430_0341)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.1859 ± 0.1808
      mae: 1.6422 ± 0.0172
      huber: 1.2858 ± 0.0159
      swd: 2.2354 ± 0.1880
      target_std: 4.7639 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.3371 ± 0.0513
      mae: 1.2946 ± 0.0035
      huber: 0.9482 ± 0.0036
      swd: 1.0955 ± 0.0567
      target_std: 4.2884 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq196_pred196_20250430_0341
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 196-336



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_196_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5195, mae: 1.5820, huber: 1.2131, swd: 1.9927, target_std: 6.5098
    Epoch [1/50], Val Losses: mse: 7.3879, mae: 1.4107, huber: 1.0543, swd: 1.0460, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1904, mae: 1.7704, huber: 1.4025, swd: 2.1711, target_std: 4.7581
      Epoch 1 composite train-obj: 1.213114
            Val objective improved inf → 1.0543, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9114, mae: 1.5122, huber: 1.1469, swd: 1.8632, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.8286, mae: 1.4410, huber: 1.0852, swd: 1.0184, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.8706, mae: 1.7357, huber: 1.3718, swd: 1.9429, target_std: 4.7581
      Epoch 2 composite train-obj: 1.146945
            No improvement (1.0852), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.7109, mae: 1.4895, huber: 1.1255, swd: 1.7971, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.4698, mae: 1.4074, huber: 1.0555, swd: 1.0616, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.9322, mae: 1.7546, huber: 1.3909, swd: 2.3664, target_std: 4.7581
      Epoch 3 composite train-obj: 1.125474
            No improvement (1.0555), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5457, mae: 1.4711, huber: 1.1079, swd: 1.7381, target_std: 6.5098
    Epoch [4/50], Val Losses: mse: 7.5005, mae: 1.4171, huber: 1.0622, swd: 1.0191, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.8513, mae: 1.7445, huber: 1.3793, swd: 2.2093, target_std: 4.7581
      Epoch 4 composite train-obj: 1.107856
            No improvement (1.0622), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.4019, mae: 1.4545, huber: 1.0921, swd: 1.6826, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.3482, mae: 1.4182, huber: 1.0629, swd: 1.0952, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.8816, mae: 1.7498, huber: 1.3850, swd: 2.1629, target_std: 4.7581
      Epoch 5 composite train-obj: 1.092064
            No improvement (1.0629), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.2777, mae: 1.4394, huber: 1.0777, swd: 1.6316, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.5746, mae: 1.4336, huber: 1.0774, swd: 1.0669, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.1521, mae: 1.7583, huber: 1.3934, swd: 2.0790, target_std: 4.7581
      Epoch 6 composite train-obj: 1.077734
    Epoch [6/50], Test Losses: mse: 11.1904, mae: 1.7704, huber: 1.4025, swd: 2.1711, target_std: 4.7581
    Best round's Test MSE: 11.1904, MAE: 1.7704, SWD: 2.1711
    Best round's Validation MSE: 7.3879, MAE: 1.4107
    Best round's Test verification MSE : 11.1904, MAE: 1.7704, SWD: 2.1711
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4832, mae: 1.5800, huber: 1.2113, swd: 2.0864, target_std: 6.5100
    Epoch [1/50], Val Losses: mse: 7.6820, mae: 1.4292, huber: 1.0744, swd: 1.0319, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1794, mae: 1.7625, huber: 1.3970, swd: 2.0867, target_std: 4.7581
      Epoch 1 composite train-obj: 1.211346
            Val objective improved inf → 1.0744, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9260, mae: 1.5145, huber: 1.1492, swd: 1.9628, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.2438, mae: 1.4000, huber: 1.0466, swd: 1.0735, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.8490, mae: 1.7442, huber: 1.3797, swd: 2.1793, target_std: 4.7581
      Epoch 2 composite train-obj: 1.149208
            Val objective improved 1.0744 → 1.0466, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7239, mae: 1.4921, huber: 1.1280, swd: 1.8945, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 7.5131, mae: 1.4199, huber: 1.0660, swd: 1.1059, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.6982, mae: 1.7206, huber: 1.3570, swd: 1.9395, target_std: 4.7581
      Epoch 3 composite train-obj: 1.127962
            No improvement (1.0660), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.5358, mae: 1.4709, huber: 1.1078, swd: 1.8134, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 7.4740, mae: 1.4069, huber: 1.0541, swd: 1.1021, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.0286, mae: 1.7630, huber: 1.3979, swd: 2.4564, target_std: 4.7581
      Epoch 4 composite train-obj: 1.107788
            No improvement (1.0541), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.3722, mae: 1.4522, huber: 1.0899, swd: 1.7348, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.5971, mae: 1.4201, huber: 1.0667, swd: 1.1967, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.9822, mae: 1.7528, huber: 1.3885, swd: 2.4105, target_std: 4.7581
      Epoch 5 composite train-obj: 1.089883
            No improvement (1.0667), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.2115, mae: 1.4329, huber: 1.0714, swd: 1.6600, target_std: 6.5100
    Epoch [6/50], Val Losses: mse: 7.5534, mae: 1.4165, huber: 1.0628, swd: 1.1182, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 10.8824, mae: 1.7449, huber: 1.3797, swd: 2.2453, target_std: 4.7581
      Epoch 6 composite train-obj: 1.071409
            No improvement (1.0628), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.0773, mae: 1.4172, huber: 1.0563, swd: 1.5966, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 8.1407, mae: 1.4714, huber: 1.1165, swd: 1.1397, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 10.8655, mae: 1.7408, huber: 1.3770, swd: 2.0701, target_std: 4.7581
      Epoch 7 composite train-obj: 1.056328
    Epoch [7/50], Test Losses: mse: 10.8490, mae: 1.7442, huber: 1.3797, swd: 2.1793, target_std: 4.7581
    Best round's Test MSE: 10.8490, MAE: 1.7442, SWD: 2.1793
    Best round's Validation MSE: 7.2438, MAE: 1.4000
    Best round's Test verification MSE : 10.8490, MAE: 1.7442, SWD: 2.1793
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4855, mae: 1.5790, huber: 1.2104, swd: 1.9712, target_std: 6.5098
    Epoch [1/50], Val Losses: mse: 7.2193, mae: 1.3937, huber: 1.0403, swd: 0.9977, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 11.1332, mae: 1.7705, huber: 1.4035, swd: 2.2223, target_std: 4.7581
      Epoch 1 composite train-obj: 1.210441
            Val objective improved inf → 1.0403, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.8946, mae: 1.5121, huber: 1.1468, swd: 1.8411, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.3837, mae: 1.4070, huber: 1.0529, swd: 0.9931, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 10.8342, mae: 1.7360, huber: 1.3729, swd: 2.0723, target_std: 4.7581
      Epoch 2 composite train-obj: 1.146815
            No improvement (1.0529), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6899, mae: 1.4885, huber: 1.1244, swd: 1.7715, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.4044, mae: 1.4132, huber: 1.0599, swd: 1.0900, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 10.8339, mae: 1.7499, huber: 1.3861, swd: 2.3462, target_std: 4.7581
      Epoch 3 composite train-obj: 1.124436
            No improvement (1.0599), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5097, mae: 1.4685, huber: 1.1055, swd: 1.7049, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 7.4055, mae: 1.4131, huber: 1.0600, swd: 1.1176, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 10.9186, mae: 1.7608, huber: 1.3966, swd: 2.5019, target_std: 4.7581
      Epoch 4 composite train-obj: 1.105513
            No improvement (1.0600), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.3438, mae: 1.4502, huber: 1.0880, swd: 1.6429, target_std: 6.5100
    Epoch [5/50], Val Losses: mse: 7.8695, mae: 1.4570, huber: 1.1018, swd: 1.1507, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 10.9184, mae: 1.7523, huber: 1.3885, swd: 2.1827, target_std: 4.7581
      Epoch 5 composite train-obj: 1.087984
            No improvement (1.1018), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.2029, mae: 1.4331, huber: 1.0716, swd: 1.5813, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.9903, mae: 1.4505, huber: 1.0956, swd: 1.0782, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.0956, mae: 1.7518, huber: 1.3879, swd: 2.1835, target_std: 4.7581
      Epoch 6 composite train-obj: 1.071581
    Epoch [6/50], Test Losses: mse: 11.1332, mae: 1.7705, huber: 1.4035, swd: 2.2223, target_std: 4.7581
    Best round's Test MSE: 11.1332, MAE: 1.7705, SWD: 2.2223
    Best round's Validation MSE: 7.2193, MAE: 1.3937
    Best round's Test verification MSE : 11.1332, MAE: 1.7705, SWD: 2.2223
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq196_pred336_20250430_0347)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.0575 ± 0.1493
      mae: 1.7617 ± 0.0124
      huber: 1.3953 ± 0.0110
      swd: 2.1909 ± 0.0225
      target_std: 4.7581 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.2837 ± 0.0744
      mae: 1.4015 ± 0.0070
      huber: 1.0471 ± 0.0057
      swd: 1.0391 ± 0.0313
      target_std: 4.2787 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq196_pred336_20250430_0347
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 196-720



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_196_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4564, mae: 1.7196, huber: 1.3413, swd: 2.1348, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 8.9424, mae: 1.5469, huber: 1.1870, swd: 1.2283, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.2397, mae: 1.9339, huber: 1.5561, swd: 2.6233, target_std: 4.7636
      Epoch 1 composite train-obj: 1.341282
            Val objective improved inf → 1.1870, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.8471, mae: 1.6572, huber: 1.2814, swd: 2.0199, target_std: 6.5086
    Epoch [2/50], Val Losses: mse: 8.8476, mae: 1.5430, huber: 1.1816, swd: 1.0873, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.4870, mae: 1.8846, huber: 1.5074, swd: 2.3175, target_std: 4.7636
      Epoch 2 composite train-obj: 1.281426
            Val objective improved 1.1870 → 1.1816, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.6360, mae: 1.6347, huber: 1.2598, swd: 1.9411, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 8.8695, mae: 1.5494, huber: 1.1886, swd: 1.1263, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.4844, mae: 1.8776, huber: 1.5014, swd: 2.2980, target_std: 4.7636
      Epoch 3 composite train-obj: 1.259834
            No improvement (1.1886), counter 1/5
    Epoch [4/50], Train Losses: mse: 7.4454, mae: 1.6147, huber: 1.2405, swd: 1.8523, target_std: 6.5088
    Epoch [4/50], Val Losses: mse: 8.7250, mae: 1.5435, huber: 1.1834, swd: 1.2474, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.4438, mae: 1.8931, huber: 1.5170, swd: 2.6058, target_std: 4.7636
      Epoch 4 composite train-obj: 1.240497
            No improvement (1.1834), counter 2/5
    Epoch [5/50], Train Losses: mse: 7.2763, mae: 1.5954, huber: 1.2218, swd: 1.7651, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 9.9551, mae: 1.6211, huber: 1.2587, swd: 1.0479, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.4950, mae: 1.8786, huber: 1.5015, swd: 1.9434, target_std: 4.7636
      Epoch 5 composite train-obj: 1.221848
            No improvement (1.2587), counter 3/5
    Epoch [6/50], Train Losses: mse: 7.1183, mae: 1.5769, huber: 1.2040, swd: 1.6833, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 8.9553, mae: 1.5644, huber: 1.2033, swd: 1.0646, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.4982, mae: 1.8855, huber: 1.5093, swd: 2.2776, target_std: 4.7636
      Epoch 6 composite train-obj: 1.203975
            No improvement (1.2033), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.9792, mae: 1.5605, huber: 1.1882, swd: 1.6170, target_std: 6.5086
    Epoch [7/50], Val Losses: mse: 9.2567, mae: 1.5780, huber: 1.2177, swd: 1.0915, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 11.5658, mae: 1.8839, huber: 1.5082, swd: 2.1892, target_std: 4.7636
      Epoch 7 composite train-obj: 1.188196
    Epoch [7/50], Test Losses: mse: 11.4870, mae: 1.8846, huber: 1.5074, swd: 2.3175, target_std: 4.7636
    Best round's Test MSE: 11.4870, MAE: 1.8846, SWD: 2.3175
    Best round's Validation MSE: 8.8476, MAE: 1.5430
    Best round's Test verification MSE : 11.4870, MAE: 1.8846, SWD: 2.3175
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4406, mae: 1.7186, huber: 1.3402, swd: 2.0235, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 9.8328, mae: 1.5958, huber: 1.2342, swd: 0.9441, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.2332, mae: 1.9009, huber: 1.5257, swd: 1.9790, target_std: 4.7636
      Epoch 1 composite train-obj: 1.340159
            Val objective improved inf → 1.2342, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.8742, mae: 1.6582, huber: 1.2824, swd: 1.9189, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 9.5840, mae: 1.5788, huber: 1.2188, swd: 1.0193, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.8133, mae: 1.8960, huber: 1.5197, swd: 2.1989, target_std: 4.7636
      Epoch 2 composite train-obj: 1.282374
            Val objective improved 1.2342 → 1.2188, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.6582, mae: 1.6362, huber: 1.2612, swd: 1.8375, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.1849, mae: 1.5674, huber: 1.2050, swd: 0.9656, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.4501, mae: 1.8674, huber: 1.4915, swd: 1.9717, target_std: 4.7636
      Epoch 3 composite train-obj: 1.261187
            Val objective improved 1.2188 → 1.2050, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.4652, mae: 1.6157, huber: 1.2413, swd: 1.7528, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 8.7718, mae: 1.5432, huber: 1.1827, swd: 1.0175, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.5680, mae: 1.8770, huber: 1.5017, swd: 2.1434, target_std: 4.7636
      Epoch 4 composite train-obj: 1.241338
            Val objective improved 1.2050 → 1.1827, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 7.2961, mae: 1.5968, huber: 1.2230, swd: 1.6803, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 8.9334, mae: 1.5556, huber: 1.1947, swd: 1.0110, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.5927, mae: 1.8838, huber: 1.5091, swd: 2.2875, target_std: 4.7636
      Epoch 5 composite train-obj: 1.223021
            No improvement (1.1947), counter 1/5
    Epoch [6/50], Train Losses: mse: 7.1366, mae: 1.5786, huber: 1.2054, swd: 1.6099, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 8.8747, mae: 1.5508, huber: 1.1889, swd: 1.0539, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.7113, mae: 1.9042, huber: 1.5274, swd: 2.4649, target_std: 4.7636
      Epoch 6 composite train-obj: 1.205443
            No improvement (1.1889), counter 2/5
    Epoch [7/50], Train Losses: mse: 6.9862, mae: 1.5616, huber: 1.1890, swd: 1.5478, target_std: 6.5087
    Epoch [7/50], Val Losses: mse: 8.8429, mae: 1.5463, huber: 1.1846, swd: 0.9697, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 11.6398, mae: 1.8860, huber: 1.5103, swd: 2.1760, target_std: 4.7636
      Epoch 7 composite train-obj: 1.188951
            No improvement (1.1846), counter 3/5
    Epoch [8/50], Train Losses: mse: 6.8513, mae: 1.5454, huber: 1.1734, swd: 1.4897, target_std: 6.5087
    Epoch [8/50], Val Losses: mse: 8.9996, mae: 1.5754, huber: 1.2113, swd: 1.0699, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 11.5473, mae: 1.8960, huber: 1.5183, swd: 2.2493, target_std: 4.7636
      Epoch 8 composite train-obj: 1.173385
            No improvement (1.2113), counter 4/5
    Epoch [9/50], Train Losses: mse: 6.7357, mae: 1.5318, huber: 1.1603, swd: 1.4400, target_std: 6.5087
    Epoch [9/50], Val Losses: mse: 9.1344, mae: 1.5949, huber: 1.2307, swd: 1.1064, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 11.4986, mae: 1.8964, huber: 1.5186, swd: 2.2731, target_std: 4.7636
      Epoch 9 composite train-obj: 1.160313
    Epoch [9/50], Test Losses: mse: 11.5680, mae: 1.8770, huber: 1.5017, swd: 2.1434, target_std: 4.7636
    Best round's Test MSE: 11.5680, MAE: 1.8770, SWD: 2.1434
    Best round's Validation MSE: 8.7718, MAE: 1.5432
    Best round's Test verification MSE : 11.5680, MAE: 1.8770, SWD: 2.1434
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4448, mae: 1.7194, huber: 1.3410, swd: 2.2153, target_std: 6.5086
    Epoch [1/50], Val Losses: mse: 9.5872, mae: 1.6099, huber: 1.2460, swd: 0.9802, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 12.0997, mae: 1.8993, huber: 1.5236, swd: 1.7753, target_std: 4.7636
      Epoch 1 composite train-obj: 1.341049
            Val objective improved inf → 1.2460, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.8607, mae: 1.6575, huber: 1.2817, swd: 2.0914, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 9.2323, mae: 1.5892, huber: 1.2235, swd: 1.2275, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 11.7280, mae: 1.8996, huber: 1.5207, swd: 2.3165, target_std: 4.7636
      Epoch 2 composite train-obj: 1.281716
            Val objective improved 1.2460 → 1.2235, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.6480, mae: 1.6358, huber: 1.2607, swd: 2.0098, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.2838, mae: 1.5772, huber: 1.2159, swd: 1.1227, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 11.6330, mae: 1.8837, huber: 1.5071, swd: 2.2585, target_std: 4.7636
      Epoch 3 composite train-obj: 1.260671
            Val objective improved 1.2235 → 1.2159, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.4769, mae: 1.6167, huber: 1.2424, swd: 1.9346, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 9.1325, mae: 1.5622, huber: 1.2007, swd: 1.1632, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 11.7186, mae: 1.9009, huber: 1.5231, swd: 2.5728, target_std: 4.7636
      Epoch 4 composite train-obj: 1.242432
            Val objective improved 1.2159 → 1.2007, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 7.3073, mae: 1.5978, huber: 1.2242, swd: 1.8496, target_std: 6.5086
    Epoch [5/50], Val Losses: mse: 9.2264, mae: 1.5820, huber: 1.2213, swd: 1.2431, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 11.4195, mae: 1.8717, huber: 1.4967, swd: 2.2987, target_std: 4.7636
      Epoch 5 composite train-obj: 1.224164
            No improvement (1.2213), counter 1/5
    Epoch [6/50], Train Losses: mse: 7.1526, mae: 1.5797, huber: 1.2066, swd: 1.7695, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 9.4898, mae: 1.5967, huber: 1.2341, swd: 1.1074, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 11.7037, mae: 1.8867, huber: 1.5105, swd: 2.1986, target_std: 4.7636
      Epoch 6 composite train-obj: 1.206632
            No improvement (1.2341), counter 2/5
    Epoch [7/50], Train Losses: mse: 7.0231, mae: 1.5639, huber: 1.1914, swd: 1.7064, target_std: 6.5086
    Epoch [7/50], Val Losses: mse: 9.3635, mae: 1.5926, huber: 1.2297, swd: 1.3478, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 11.9071, mae: 1.9155, huber: 1.5365, swd: 2.6726, target_std: 4.7636
      Epoch 7 composite train-obj: 1.191389
            No improvement (1.2297), counter 3/5
    Epoch [8/50], Train Losses: mse: 6.8990, mae: 1.5494, huber: 1.1773, swd: 1.6442, target_std: 6.5086
    Epoch [8/50], Val Losses: mse: 9.2275, mae: 1.5724, huber: 1.2108, swd: 1.1948, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 11.9780, mae: 1.9084, huber: 1.5313, swd: 2.5901, target_std: 4.7636
      Epoch 8 composite train-obj: 1.177322
            No improvement (1.2108), counter 4/5
    Epoch [9/50], Train Losses: mse: 6.7839, mae: 1.5362, huber: 1.1646, swd: 1.5867, target_std: 6.5087
    Epoch [9/50], Val Losses: mse: 9.3625, mae: 1.6029, huber: 1.2384, swd: 1.1687, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 11.7421, mae: 1.8989, huber: 1.5206, swd: 2.2806, target_std: 4.7636
      Epoch 9 composite train-obj: 1.164587
    Epoch [9/50], Test Losses: mse: 11.7186, mae: 1.9009, huber: 1.5231, swd: 2.5728, target_std: 4.7636
    Best round's Test MSE: 11.7186, MAE: 1.9009, SWD: 2.5728
    Best round's Validation MSE: 9.1325, MAE: 1.5622
    Best round's Test verification MSE : 11.7186, MAE: 1.9009, SWD: 2.5728
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq196_pred720_20250430_0350)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.5912 ± 0.0960
      mae: 1.8875 ± 0.0100
      huber: 1.5107 ± 0.0091
      swd: 2.3446 ± 0.1764
      target_std: 4.7636 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.9173 ± 0.1553
      mae: 1.5495 ± 0.0090
      huber: 1.1883 ± 0.0087
      swd: 1.0893 ± 0.0595
      target_std: 4.2634 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm1_seq196_pred720_20250430_0350
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### 196-96



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_196_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.3516, mae: 1.3512, huber: 0.9992, swd: 1.8664, target_std: 6.5079
    Epoch [1/50], Val Losses: mse: 5.2839, mae: 1.1494, huber: 0.8135, swd: 0.9070, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 8.2145, mae: 1.4000, huber: 1.0566, swd: 1.3721, target_std: 4.7724
      Epoch 1 composite train-obj: 0.999248
            Val objective improved inf → 0.8135, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.6485, mae: 1.1821, huber: 0.8424, swd: 1.4427, target_std: 6.5077
    Epoch [2/50], Val Losses: mse: 5.2188, mae: 1.1426, huber: 0.8077, swd: 0.9269, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 8.0832, mae: 1.3884, huber: 1.0471, swd: 1.3995, target_std: 4.7724
      Epoch 2 composite train-obj: 0.842373
            Val objective improved 0.8135 → 0.8077, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6161, mae: 1.1768, huber: 0.8377, swd: 1.4252, target_std: 6.5078
    Epoch [3/50], Val Losses: mse: 5.2101, mae: 1.1364, huber: 0.8016, swd: 0.8645, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 8.1373, mae: 1.3884, huber: 1.0464, swd: 1.3238, target_std: 4.7724
      Epoch 3 composite train-obj: 0.837740
            Val objective improved 0.8077 → 0.8016, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.6084, mae: 1.1769, huber: 0.8376, swd: 1.4210, target_std: 6.5078
    Epoch [4/50], Val Losses: mse: 5.1819, mae: 1.1411, huber: 0.8059, swd: 0.9389, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 7.9938, mae: 1.3782, huber: 1.0367, swd: 1.3585, target_std: 4.7724
      Epoch 4 composite train-obj: 0.837625
            No improvement (0.8059), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.6026, mae: 1.1757, huber: 0.8367, swd: 1.4185, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 5.1857, mae: 1.1383, huber: 0.8030, swd: 0.8741, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 8.0715, mae: 1.3841, huber: 1.0414, swd: 1.3100, target_std: 4.7724
      Epoch 5 composite train-obj: 0.836701
            No improvement (0.8030), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.5959, mae: 1.1754, huber: 0.8361, swd: 1.4148, target_std: 6.5076
    Epoch [6/50], Val Losses: mse: 5.1867, mae: 1.1406, huber: 0.8059, swd: 0.9075, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 8.0707, mae: 1.3828, huber: 1.0423, swd: 1.3508, target_std: 4.7724
      Epoch 6 composite train-obj: 0.836104
            No improvement (0.8059), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.5951, mae: 1.1754, huber: 0.8362, swd: 1.4129, target_std: 6.5078
    Epoch [7/50], Val Losses: mse: 5.2339, mae: 1.1336, huber: 0.7993, swd: 0.8305, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 8.1710, mae: 1.3863, huber: 1.0449, swd: 1.2536, target_std: 4.7724
      Epoch 7 composite train-obj: 0.836205
            Val objective improved 0.8016 → 0.7993, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 4.5929, mae: 1.1753, huber: 0.8361, swd: 1.4123, target_std: 6.5078
    Epoch [8/50], Val Losses: mse: 5.1939, mae: 1.1372, huber: 0.8026, swd: 0.8900, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 8.0410, mae: 1.3812, huber: 1.0404, swd: 1.3311, target_std: 4.7724
      Epoch 8 composite train-obj: 0.836070
            No improvement (0.8026), counter 1/5
    Epoch [9/50], Train Losses: mse: 4.5975, mae: 1.1765, huber: 0.8373, swd: 1.4163, target_std: 6.5078
    Epoch [9/50], Val Losses: mse: 5.2007, mae: 1.1546, huber: 0.8177, swd: 1.0062, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 7.9071, mae: 1.3755, huber: 1.0346, swd: 1.3981, target_std: 4.7724
      Epoch 9 composite train-obj: 0.837251
            No improvement (0.8177), counter 2/5
    Epoch [10/50], Train Losses: mse: 4.5906, mae: 1.1757, huber: 0.8364, swd: 1.4112, target_std: 6.5078
    Epoch [10/50], Val Losses: mse: 5.1986, mae: 1.1421, huber: 0.8073, swd: 0.9194, target_std: 4.3035
    Epoch [10/50], Test Losses: mse: 8.0503, mae: 1.3792, huber: 1.0390, swd: 1.3469, target_std: 4.7724
      Epoch 10 composite train-obj: 0.836371
            No improvement (0.8073), counter 3/5
    Epoch [11/50], Train Losses: mse: 4.5939, mae: 1.1754, huber: 0.8362, swd: 1.4114, target_std: 6.5077
    Epoch [11/50], Val Losses: mse: 5.1904, mae: 1.1435, huber: 0.8076, swd: 0.9220, target_std: 4.3035
    Epoch [11/50], Test Losses: mse: 8.0257, mae: 1.3844, huber: 1.0429, swd: 1.3692, target_std: 4.7724
      Epoch 11 composite train-obj: 0.836240
            No improvement (0.8076), counter 4/5
    Epoch [12/50], Train Losses: mse: 4.5893, mae: 1.1756, huber: 0.8362, swd: 1.4079, target_std: 6.5078
    Epoch [12/50], Val Losses: mse: 5.1885, mae: 1.1396, huber: 0.8044, swd: 0.9077, target_std: 4.3035
    Epoch [12/50], Test Losses: mse: 8.0779, mae: 1.3865, huber: 1.0440, swd: 1.3631, target_std: 4.7724
      Epoch 12 composite train-obj: 0.836157
    Epoch [12/50], Test Losses: mse: 8.1710, mae: 1.3863, huber: 1.0449, swd: 1.2536, target_std: 4.7724
    Best round's Test MSE: 8.1710, MAE: 1.3863, SWD: 1.2536
    Best round's Validation MSE: 5.2339, MAE: 1.1336
    Best round's Test verification MSE : 8.1710, MAE: 1.3863, SWD: 1.2536
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.1376, mae: 1.3431, huber: 0.9913, swd: 1.8402, target_std: 6.5076
    Epoch [1/50], Val Losses: mse: 5.2624, mae: 1.1453, huber: 0.8096, swd: 0.8971, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 8.2082, mae: 1.3991, huber: 1.0557, swd: 1.4035, target_std: 4.7724
      Epoch 1 composite train-obj: 0.991327
            Val objective improved inf → 0.8096, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.6564, mae: 1.1832, huber: 0.8435, swd: 1.4328, target_std: 6.5078
    Epoch [2/50], Val Losses: mse: 5.1918, mae: 1.1412, huber: 0.8065, swd: 0.9400, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 8.0465, mae: 1.3837, huber: 1.0428, swd: 1.4321, target_std: 4.7724
      Epoch 2 composite train-obj: 0.843545
            Val objective improved 0.8096 → 0.8065, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6185, mae: 1.1771, huber: 0.8379, swd: 1.4111, target_std: 6.5080
    Epoch [3/50], Val Losses: mse: 5.1728, mae: 1.1360, huber: 0.8022, swd: 0.9275, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 8.0436, mae: 1.3825, huber: 1.0414, swd: 1.4292, target_std: 4.7724
      Epoch 3 composite train-obj: 0.837939
            Val objective improved 0.8065 → 0.8022, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.6077, mae: 1.1769, huber: 0.8376, swd: 1.4066, target_std: 6.5077
    Epoch [4/50], Val Losses: mse: 5.1921, mae: 1.1370, huber: 0.8024, swd: 0.9129, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 8.0447, mae: 1.3793, huber: 1.0381, swd: 1.3956, target_std: 4.7724
      Epoch 4 composite train-obj: 0.837564
            No improvement (0.8024), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.5979, mae: 1.1756, huber: 0.8365, swd: 1.4011, target_std: 6.5077
    Epoch [5/50], Val Losses: mse: 5.2113, mae: 1.1349, huber: 0.8005, swd: 0.8561, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 8.1293, mae: 1.3859, huber: 1.0437, swd: 1.3316, target_std: 4.7724
      Epoch 5 composite train-obj: 0.836493
            Val objective improved 0.8022 → 0.8005, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.5996, mae: 1.1756, huber: 0.8365, swd: 1.3985, target_std: 6.5078
    Epoch [6/50], Val Losses: mse: 5.1858, mae: 1.1357, huber: 0.8017, swd: 0.9063, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 8.0621, mae: 1.3806, huber: 1.0397, swd: 1.3946, target_std: 4.7724
      Epoch 6 composite train-obj: 0.836461
            No improvement (0.8017), counter 1/5
    Epoch [7/50], Train Losses: mse: 4.5979, mae: 1.1762, huber: 0.8369, swd: 1.3991, target_std: 6.5079
    Epoch [7/50], Val Losses: mse: 5.1842, mae: 1.1361, huber: 0.8013, swd: 0.8925, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 8.0372, mae: 1.3755, huber: 1.0359, swd: 1.3665, target_std: 4.7724
      Epoch 7 composite train-obj: 0.836918
            No improvement (0.8013), counter 2/5
    Epoch [8/50], Train Losses: mse: 4.5951, mae: 1.1753, huber: 0.8362, swd: 1.3965, target_std: 6.5077
    Epoch [8/50], Val Losses: mse: 5.1953, mae: 1.1444, huber: 0.8089, swd: 0.9411, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 8.0284, mae: 1.3789, huber: 1.0386, swd: 1.4086, target_std: 4.7724
      Epoch 8 composite train-obj: 0.836152
            No improvement (0.8089), counter 3/5
    Epoch [9/50], Train Losses: mse: 4.5923, mae: 1.1752, huber: 0.8359, swd: 1.3955, target_std: 6.5076
    Epoch [9/50], Val Losses: mse: 5.1740, mae: 1.1380, huber: 0.8030, swd: 0.9177, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.0056, mae: 1.3791, huber: 1.0381, swd: 1.3961, target_std: 4.7724
      Epoch 9 composite train-obj: 0.835912
            No improvement (0.8030), counter 4/5
    Epoch [10/50], Train Losses: mse: 4.5944, mae: 1.1762, huber: 0.8369, swd: 1.3968, target_std: 6.5077
    Epoch [10/50], Val Losses: mse: 5.2190, mae: 1.1527, huber: 0.8160, swd: 0.9664, target_std: 4.3035
    Epoch [10/50], Test Losses: mse: 8.0450, mae: 1.3889, huber: 1.0474, swd: 1.4527, target_std: 4.7724
      Epoch 10 composite train-obj: 0.836863
    Epoch [10/50], Test Losses: mse: 8.1293, mae: 1.3859, huber: 1.0437, swd: 1.3316, target_std: 4.7724
    Best round's Test MSE: 8.1293, MAE: 1.3859, SWD: 1.3316
    Best round's Validation MSE: 5.2113, MAE: 1.1349
    Best round's Test verification MSE : 8.1293, MAE: 1.3859, SWD: 1.3316
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.3111, mae: 1.3497, huber: 0.9976, swd: 1.7123, target_std: 6.5077
    Epoch [1/50], Val Losses: mse: 5.2561, mae: 1.1466, huber: 0.8105, swd: 0.8559, target_std: 4.3035
    Epoch [1/50], Test Losses: mse: 8.2004, mae: 1.3992, huber: 1.0560, swd: 1.3149, target_std: 4.7724
      Epoch 1 composite train-obj: 0.997598
            Val objective improved inf → 0.8105, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.6471, mae: 1.1824, huber: 0.8426, swd: 1.3314, target_std: 6.5075
    Epoch [2/50], Val Losses: mse: 5.1954, mae: 1.1445, huber: 0.8085, swd: 0.9088, target_std: 4.3035
    Epoch [2/50], Test Losses: mse: 8.0333, mae: 1.3835, huber: 1.0425, swd: 1.3499, target_std: 4.7724
      Epoch 2 composite train-obj: 0.842589
            Val objective improved 0.8105 → 0.8085, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6165, mae: 1.1774, huber: 0.8383, swd: 1.3157, target_std: 6.5076
    Epoch [3/50], Val Losses: mse: 5.2250, mae: 1.1360, huber: 0.8012, swd: 0.7975, target_std: 4.3035
    Epoch [3/50], Test Losses: mse: 8.1661, mae: 1.3861, huber: 1.0444, swd: 1.2202, target_std: 4.7724
      Epoch 3 composite train-obj: 0.838268
            Val objective improved 0.8085 → 0.8012, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.6060, mae: 1.1762, huber: 0.8370, swd: 1.3075, target_std: 6.5078
    Epoch [4/50], Val Losses: mse: 5.1759, mae: 1.1339, huber: 0.7997, swd: 0.8381, target_std: 4.3035
    Epoch [4/50], Test Losses: mse: 8.0543, mae: 1.3805, huber: 1.0390, swd: 1.2728, target_std: 4.7724
      Epoch 4 composite train-obj: 0.837008
            Val objective improved 0.8012 → 0.7997, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.6052, mae: 1.1765, huber: 0.8373, swd: 1.3054, target_std: 6.5078
    Epoch [5/50], Val Losses: mse: 5.2090, mae: 1.1338, huber: 0.7991, swd: 0.8018, target_std: 4.3035
    Epoch [5/50], Test Losses: mse: 8.1104, mae: 1.3828, huber: 1.0414, swd: 1.2252, target_std: 4.7724
      Epoch 5 composite train-obj: 0.837292
            Val objective improved 0.7997 → 0.7991, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 4.5968, mae: 1.1758, huber: 0.8364, swd: 1.3025, target_std: 6.5075
    Epoch [6/50], Val Losses: mse: 5.1810, mae: 1.1445, huber: 0.8094, swd: 0.9129, target_std: 4.3035
    Epoch [6/50], Test Losses: mse: 7.9769, mae: 1.3785, huber: 1.0378, swd: 1.3372, target_std: 4.7724
      Epoch 6 composite train-obj: 0.836444
            No improvement (0.8094), counter 1/5
    Epoch [7/50], Train Losses: mse: 4.5968, mae: 1.1756, huber: 0.8363, swd: 1.3016, target_std: 6.5077
    Epoch [7/50], Val Losses: mse: 5.2095, mae: 1.1490, huber: 0.8134, swd: 0.9285, target_std: 4.3035
    Epoch [7/50], Test Losses: mse: 7.9920, mae: 1.3800, huber: 1.0391, swd: 1.3294, target_std: 4.7724
      Epoch 7 composite train-obj: 0.836301
            No improvement (0.8134), counter 2/5
    Epoch [8/50], Train Losses: mse: 4.5976, mae: 1.1762, huber: 0.8370, swd: 1.3041, target_std: 6.5079
    Epoch [8/50], Val Losses: mse: 5.2056, mae: 1.1370, huber: 0.8026, swd: 0.8232, target_std: 4.3035
    Epoch [8/50], Test Losses: mse: 8.1024, mae: 1.3845, huber: 1.0430, swd: 1.2550, target_std: 4.7724
      Epoch 8 composite train-obj: 0.836961
            No improvement (0.8026), counter 3/5
    Epoch [9/50], Train Losses: mse: 4.5980, mae: 1.1762, huber: 0.8369, swd: 1.3028, target_std: 6.5077
    Epoch [9/50], Val Losses: mse: 5.1861, mae: 1.1366, huber: 0.8023, swd: 0.8293, target_std: 4.3035
    Epoch [9/50], Test Losses: mse: 8.0993, mae: 1.3840, huber: 1.0433, swd: 1.2622, target_std: 4.7724
      Epoch 9 composite train-obj: 0.836906
            No improvement (0.8023), counter 4/5
    Epoch [10/50], Train Losses: mse: 4.5933, mae: 1.1760, huber: 0.8367, swd: 1.3011, target_std: 6.5079
    Epoch [10/50], Val Losses: mse: 5.2250, mae: 1.1396, huber: 0.8045, swd: 0.8106, target_std: 4.3035
    Epoch [10/50], Test Losses: mse: 8.1494, mae: 1.3872, huber: 1.0454, swd: 1.2308, target_std: 4.7724
      Epoch 10 composite train-obj: 0.836710
    Epoch [10/50], Test Losses: mse: 8.1104, mae: 1.3828, huber: 1.0414, swd: 1.2252, target_std: 4.7724
    Best round's Test MSE: 8.1104, MAE: 1.3828, SWD: 1.2252
    Best round's Validation MSE: 5.2090, MAE: 1.1338
    Best round's Test verification MSE : 8.1104, MAE: 1.3828, SWD: 1.2252
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq196_pred96_20250430_0419)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.1369 ± 0.0253
      mae: 1.3850 ± 0.0016
      huber: 1.0433 ± 0.0014
      swd: 1.2701 ± 0.0450
      target_std: 4.7724 ± 0.0000
      count: 53.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.2181 ± 0.0112
      mae: 1.1341 ± 0.0006
      huber: 0.7996 ± 0.0006
      swd: 0.8295 ± 0.0222
      target_std: 4.3035 ± 0.0000
      count: 53.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq196_pred96_20250430_0419
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 196-196



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_196_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 52
    Test Batches: 106
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3364, mae: 1.4824, huber: 1.1224, swd: 2.1514, target_std: 6.5061
    Epoch [1/50], Val Losses: mse: 6.3828, mae: 1.2837, huber: 0.9373, swd: 0.9054, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.6813, mae: 1.6187, huber: 1.2634, swd: 1.6551, target_std: 4.7639
      Epoch 1 composite train-obj: 1.122435
            Val objective improved inf → 0.9373, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8054, mae: 1.3356, huber: 0.9855, swd: 1.7693, target_std: 6.5043
    Epoch [2/50], Val Losses: mse: 6.4320, mae: 1.3057, huber: 0.9542, swd: 0.9176, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.8191, mae: 1.6362, huber: 1.2788, swd: 1.6279, target_std: 4.7639
      Epoch 2 composite train-obj: 0.985504
            No improvement (0.9542), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.7622, mae: 1.3300, huber: 0.9801, swd: 1.7477, target_std: 6.5199
    Epoch [3/50], Val Losses: mse: 6.7086, mae: 1.3604, huber: 0.9999, swd: 0.8795, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 11.2919, mae: 1.7022, huber: 1.3356, swd: 1.5906, target_std: 4.7639
      Epoch 3 composite train-obj: 0.980092
            No improvement (0.9999), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.7938, mae: 1.3361, huber: 0.9857, swd: 1.7605, target_std: 6.5044
    Epoch [4/50], Val Losses: mse: 6.1864, mae: 1.2642, huber: 0.9186, swd: 0.9031, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.4557, mae: 1.6040, huber: 1.2497, swd: 1.6002, target_std: 4.7639
      Epoch 4 composite train-obj: 0.985663
            Val objective improved 0.9373 → 0.9186, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.7340, mae: 1.3266, huber: 0.9770, swd: 1.7264, target_std: 6.5050
    Epoch [5/50], Val Losses: mse: 6.3802, mae: 1.3014, huber: 0.9525, swd: 0.9100, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.5849, mae: 1.6151, huber: 1.2596, swd: 1.6247, target_std: 4.7639
      Epoch 5 composite train-obj: 0.977020
            No improvement (0.9525), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.7468, mae: 1.3282, huber: 0.9784, swd: 1.7236, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 6.3526, mae: 1.3065, huber: 0.9607, swd: 1.2820, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.2155, mae: 1.5937, huber: 1.2409, swd: 1.8599, target_std: 4.7639
      Epoch 6 composite train-obj: 0.978405
            No improvement (0.9607), counter 2/5
    Epoch [7/50], Train Losses: mse: 5.7188, mae: 1.3253, huber: 0.9757, swd: 1.7178, target_std: 6.5002
    Epoch [7/50], Val Losses: mse: 6.4171, mae: 1.3124, huber: 0.9642, swd: 1.1060, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.2531, mae: 1.5944, huber: 1.2403, swd: 1.7248, target_std: 4.7639
      Epoch 7 composite train-obj: 0.975654
            No improvement (0.9642), counter 3/5
    Epoch [8/50], Train Losses: mse: 5.7445, mae: 1.3297, huber: 0.9797, swd: 1.7228, target_std: 6.5091
    Epoch [8/50], Val Losses: mse: 6.9210, mae: 1.4297, huber: 1.0662, swd: 1.6763, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 10.5676, mae: 1.6796, huber: 1.3122, swd: 2.1816, target_std: 4.7639
      Epoch 8 composite train-obj: 0.979731
            No improvement (1.0662), counter 4/5
    Epoch [9/50], Train Losses: mse: 5.7628, mae: 1.3337, huber: 0.9831, swd: 1.7435, target_std: 6.5029
    Epoch [9/50], Val Losses: mse: 6.3289, mae: 1.3021, huber: 0.9544, swd: 1.0843, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 10.2405, mae: 1.5926, huber: 1.2382, swd: 1.7105, target_std: 4.7639
      Epoch 9 composite train-obj: 0.983091
    Epoch [9/50], Test Losses: mse: 10.4557, mae: 1.6040, huber: 1.2497, swd: 1.6002, target_std: 4.7639
    Best round's Test MSE: 10.4557, MAE: 1.6040, SWD: 1.6002
    Best round's Validation MSE: 6.1864, MAE: 1.2642
    Best round's Test verification MSE : 10.4557, MAE: 1.6040, SWD: 1.6002
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3743, mae: 1.4829, huber: 1.1230, swd: 2.2234, target_std: 6.5092
    Epoch [1/50], Val Losses: mse: 6.4332, mae: 1.2977, huber: 0.9473, swd: 0.9122, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.7876, mae: 1.6375, huber: 1.2774, swd: 1.6457, target_std: 4.7639
      Epoch 1 composite train-obj: 1.123009
            Val objective improved inf → 0.9473, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8272, mae: 1.3380, huber: 0.9875, swd: 1.8104, target_std: 6.5057
    Epoch [2/50], Val Losses: mse: 6.2747, mae: 1.2688, huber: 0.9230, swd: 0.8739, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.6076, mae: 1.6121, huber: 1.2569, swd: 1.5949, target_std: 4.7639
      Epoch 2 composite train-obj: 0.987522
            Val objective improved 0.9473 → 0.9230, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.7698, mae: 1.3309, huber: 0.9811, swd: 1.7913, target_std: 6.5160
    Epoch [3/50], Val Losses: mse: 6.7364, mae: 1.4078, huber: 1.0447, swd: 1.4606, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.4708, mae: 1.6708, huber: 1.3030, swd: 2.1206, target_std: 4.7639
      Epoch 3 composite train-obj: 0.981132
            No improvement (1.0447), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.7762, mae: 1.3341, huber: 0.9837, swd: 1.8072, target_std: 6.5197
    Epoch [4/50], Val Losses: mse: 6.5960, mae: 1.3866, huber: 1.0215, swd: 1.0720, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.5499, mae: 1.6795, huber: 1.3089, swd: 1.7125, target_std: 4.7639
      Epoch 4 composite train-obj: 0.983690
            No improvement (1.0215), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.7914, mae: 1.3364, huber: 0.9859, swd: 1.7786, target_std: 6.5048
    Epoch [5/50], Val Losses: mse: 6.2121, mae: 1.2646, huber: 0.9176, swd: 0.8715, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.4589, mae: 1.6046, huber: 1.2470, swd: 1.5593, target_std: 4.7639
      Epoch 5 composite train-obj: 0.985885
            Val objective improved 0.9230 → 0.9176, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.7336, mae: 1.3262, huber: 0.9766, swd: 1.7601, target_std: 6.5046
    Epoch [6/50], Val Losses: mse: 6.4580, mae: 1.3159, huber: 0.9679, swd: 1.0725, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.2805, mae: 1.5982, huber: 1.2435, swd: 1.7051, target_std: 4.7639
      Epoch 6 composite train-obj: 0.976588
            No improvement (0.9679), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.7324, mae: 1.3272, huber: 0.9775, swd: 1.7573, target_std: 6.5077
    Epoch [7/50], Val Losses: mse: 6.3108, mae: 1.2943, huber: 0.9471, swd: 1.1004, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.2806, mae: 1.5969, huber: 1.2421, swd: 1.7100, target_std: 4.7639
      Epoch 7 composite train-obj: 0.977478
            No improvement (0.9471), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.7267, mae: 1.3273, huber: 0.9775, swd: 1.7582, target_std: 6.5062
    Epoch [8/50], Val Losses: mse: 6.4753, mae: 1.3253, huber: 0.9712, swd: 0.8994, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 10.6190, mae: 1.6367, huber: 1.2765, swd: 1.5959, target_std: 4.7639
      Epoch 8 composite train-obj: 0.977453
            No improvement (0.9712), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.7328, mae: 1.3280, huber: 0.9780, swd: 1.7564, target_std: 6.5106
    Epoch [9/50], Val Losses: mse: 6.1776, mae: 1.2722, huber: 0.9247, swd: 0.9336, target_std: 4.2884
    Epoch [9/50], Test Losses: mse: 10.3552, mae: 1.6052, huber: 1.2485, swd: 1.6005, target_std: 4.7639
      Epoch 9 composite train-obj: 0.978027
            No improvement (0.9247), counter 4/5
    Epoch [10/50], Train Losses: mse: 5.7365, mae: 1.3290, huber: 0.9789, swd: 1.7667, target_std: 6.5237
    Epoch [10/50], Val Losses: mse: 6.7193, mae: 1.4119, huber: 1.0372, swd: 1.2124, target_std: 4.2884
    Epoch [10/50], Test Losses: mse: 10.9725, mae: 1.7284, huber: 1.3491, swd: 2.0927, target_std: 4.7639
      Epoch 10 composite train-obj: 0.978885
    Epoch [10/50], Test Losses: mse: 10.4589, mae: 1.6046, huber: 1.2470, swd: 1.5593, target_std: 4.7639
    Best round's Test MSE: 10.4589, MAE: 1.6046, SWD: 1.5593
    Best round's Validation MSE: 6.2121, MAE: 1.2646
    Best round's Test verification MSE : 10.4589, MAE: 1.6046, SWD: 1.5593
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.3095, mae: 1.4811, huber: 1.1214, swd: 1.9647, target_std: 6.5123
    Epoch [1/50], Val Losses: mse: 6.2899, mae: 1.2789, huber: 0.9315, swd: 0.8881, target_std: 4.2884
    Epoch [1/50], Test Losses: mse: 10.6489, mae: 1.6269, huber: 1.2710, swd: 1.6195, target_std: 4.7639
      Epoch 1 composite train-obj: 1.121423
            Val objective improved inf → 0.9315, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8342, mae: 1.3378, huber: 0.9875, swd: 1.5992, target_std: 6.5111
    Epoch [2/50], Val Losses: mse: 6.2550, mae: 1.2924, huber: 0.9395, swd: 0.9420, target_std: 4.2884
    Epoch [2/50], Test Losses: mse: 10.5751, mae: 1.6364, huber: 1.2770, swd: 1.6613, target_std: 4.7639
      Epoch 2 composite train-obj: 0.987482
            No improvement (0.9395), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.8291, mae: 1.3384, huber: 0.9881, swd: 1.6354, target_std: 6.5022
    Epoch [3/50], Val Losses: mse: 6.2053, mae: 1.2642, huber: 0.9211, swd: 0.9415, target_std: 4.2884
    Epoch [3/50], Test Losses: mse: 10.3824, mae: 1.5902, huber: 1.2378, swd: 1.6317, target_std: 4.7639
      Epoch 3 composite train-obj: 0.988103
            Val objective improved 0.9315 → 0.9211, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.7549, mae: 1.3282, huber: 0.9785, swd: 1.5853, target_std: 6.5028
    Epoch [4/50], Val Losses: mse: 6.3847, mae: 1.3149, huber: 0.9640, swd: 1.0294, target_std: 4.2884
    Epoch [4/50], Test Losses: mse: 10.3059, mae: 1.6174, huber: 1.2606, swd: 1.7160, target_std: 4.7639
      Epoch 4 composite train-obj: 0.978468
            No improvement (0.9640), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.7390, mae: 1.3282, huber: 0.9785, swd: 1.5677, target_std: 6.5142
    Epoch [5/50], Val Losses: mse: 6.3663, mae: 1.3072, huber: 0.9546, swd: 0.8001, target_std: 4.2884
    Epoch [5/50], Test Losses: mse: 10.6060, mae: 1.6343, huber: 1.2742, swd: 1.4702, target_std: 4.7639
      Epoch 5 composite train-obj: 0.978481
            No improvement (0.9546), counter 2/5
    Epoch [6/50], Train Losses: mse: 5.7400, mae: 1.3288, huber: 0.9788, swd: 1.5585, target_std: 6.5066
    Epoch [6/50], Val Losses: mse: 6.3547, mae: 1.2917, huber: 0.9444, swd: 0.8997, target_std: 4.2884
    Epoch [6/50], Test Losses: mse: 10.5541, mae: 1.6121, huber: 1.2569, swd: 1.5883, target_std: 4.7639
      Epoch 6 composite train-obj: 0.978827
            No improvement (0.9444), counter 3/5
    Epoch [7/50], Train Losses: mse: 5.7179, mae: 1.3257, huber: 0.9759, swd: 1.5506, target_std: 6.5146
    Epoch [7/50], Val Losses: mse: 6.5125, mae: 1.3682, huber: 1.0068, swd: 1.1105, target_std: 4.2884
    Epoch [7/50], Test Losses: mse: 10.2776, mae: 1.6486, huber: 1.2827, swd: 1.6935, target_std: 4.7639
      Epoch 7 composite train-obj: 0.975858
            No improvement (1.0068), counter 4/5
    Epoch [8/50], Train Losses: mse: 5.7417, mae: 1.3308, huber: 0.9805, swd: 1.5600, target_std: 6.5116
    Epoch [8/50], Val Losses: mse: 6.2531, mae: 1.2875, huber: 0.9359, swd: 0.8227, target_std: 4.2884
    Epoch [8/50], Test Losses: mse: 10.4561, mae: 1.6217, huber: 1.2619, swd: 1.4803, target_std: 4.7639
      Epoch 8 composite train-obj: 0.980499
    Epoch [8/50], Test Losses: mse: 10.3824, mae: 1.5902, huber: 1.2378, swd: 1.6317, target_std: 4.7639
    Best round's Test MSE: 10.3824, MAE: 1.5902, SWD: 1.6317
    Best round's Validation MSE: 6.2053, MAE: 1.2642
    Best round's Test verification MSE : 10.3824, MAE: 1.5902, SWD: 1.6317
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq196_pred196_20250430_0421)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.4323 ± 0.0353
      mae: 1.5996 ± 0.0067
      huber: 1.2448 ± 0.0051
      swd: 1.5971 ± 0.0296
      target_std: 4.7639 ± 0.0000
      count: 52.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.2013 ± 0.0109
      mae: 1.2643 ± 0.0002
      huber: 0.9191 ± 0.0015
      swd: 0.9054 ± 0.0286
      target_std: 4.2884 ± 0.0000
      count: 52.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq196_pred196_20250430_0421
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 196-336



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_196_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 377
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 377
    Validation Batches: 51
    Test Batches: 105
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2141, mae: 1.5933, huber: 1.2261, swd: 2.2392, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 7.6698, mae: 1.3792, huber: 1.0299, swd: 0.9437, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 12.0091, mae: 1.7503, huber: 1.3883, swd: 1.8192, target_std: 4.7581
      Epoch 1 composite train-obj: 1.226072
            Val objective improved inf → 1.0299, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6614, mae: 1.4529, huber: 1.0938, swd: 1.9134, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.6344, mae: 1.3840, huber: 1.0345, swd: 1.0157, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 11.8091, mae: 1.7321, huber: 1.3718, swd: 1.8296, target_std: 4.7581
      Epoch 2 composite train-obj: 1.093821
            No improvement (1.0345), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6080, mae: 1.4468, huber: 1.0879, swd: 1.8836, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.5859, mae: 1.3849, huber: 1.0335, swd: 1.0436, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.6995, mae: 1.7288, huber: 1.3683, swd: 1.8282, target_std: 4.7581
      Epoch 3 composite train-obj: 1.087905
            No improvement (1.0335), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5899, mae: 1.4453, huber: 1.0866, swd: 1.8704, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 7.5290, mae: 1.3725, huber: 1.0238, swd: 0.9869, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.7039, mae: 1.7243, huber: 1.3639, swd: 1.7701, target_std: 4.7581
      Epoch 4 composite train-obj: 1.086554
            Val objective improved 1.0299 → 1.0238, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.5751, mae: 1.4442, huber: 1.0853, swd: 1.8592, target_std: 6.5098
    Epoch [5/50], Val Losses: mse: 7.6243, mae: 1.3879, huber: 1.0384, swd: 1.0497, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.6672, mae: 1.7206, huber: 1.3610, swd: 1.7825, target_std: 4.7581
      Epoch 5 composite train-obj: 1.085327
            No improvement (1.0384), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.5623, mae: 1.4435, huber: 1.0846, swd: 1.8496, target_std: 6.5100
    Epoch [6/50], Val Losses: mse: 7.5684, mae: 1.3775, huber: 1.0289, swd: 0.9936, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.7254, mae: 1.7235, huber: 1.3639, swd: 1.7570, target_std: 4.7581
      Epoch 6 composite train-obj: 1.084644
            No improvement (1.0289), counter 2/5
    Epoch [7/50], Train Losses: mse: 6.5586, mae: 1.4425, huber: 1.0837, swd: 1.8479, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 7.5162, mae: 1.3708, huber: 1.0226, swd: 0.9766, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.6770, mae: 1.7208, huber: 1.3606, swd: 1.7302, target_std: 4.7581
      Epoch 7 composite train-obj: 1.083732
            Val objective improved 1.0238 → 1.0226, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 6.5514, mae: 1.4426, huber: 1.0838, swd: 1.8415, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 7.5204, mae: 1.3728, huber: 1.0246, swd: 0.9842, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 11.6375, mae: 1.7179, huber: 1.3578, swd: 1.7234, target_std: 4.7581
      Epoch 8 composite train-obj: 1.083754
            No improvement (1.0246), counter 1/5
    Epoch [9/50], Train Losses: mse: 6.5484, mae: 1.4421, huber: 1.0833, swd: 1.8381, target_std: 6.5099
    Epoch [9/50], Val Losses: mse: 7.6140, mae: 1.3752, huber: 1.0272, swd: 0.9172, target_std: 4.2787
    Epoch [9/50], Test Losses: mse: 11.8829, mae: 1.7320, huber: 1.3715, swd: 1.6827, target_std: 4.7581
      Epoch 9 composite train-obj: 1.083333
            No improvement (1.0272), counter 2/5
    Epoch [10/50], Train Losses: mse: 6.5470, mae: 1.4423, huber: 1.0834, swd: 1.8378, target_std: 6.5100
    Epoch [10/50], Val Losses: mse: 7.6205, mae: 1.3793, huber: 1.0298, swd: 0.9001, target_std: 4.2787
    Epoch [10/50], Test Losses: mse: 11.9078, mae: 1.7387, huber: 1.3760, swd: 1.6661, target_std: 4.7581
      Epoch 10 composite train-obj: 1.083408
            No improvement (1.0298), counter 3/5
    Epoch [11/50], Train Losses: mse: 6.5505, mae: 1.4427, huber: 1.0837, swd: 1.8356, target_std: 6.5099
    Epoch [11/50], Val Losses: mse: 7.4837, mae: 1.3787, huber: 1.0287, swd: 1.0262, target_std: 4.2787
    Epoch [11/50], Test Losses: mse: 11.5661, mae: 1.7178, huber: 1.3576, swd: 1.7728, target_std: 4.7581
      Epoch 11 composite train-obj: 1.083741
            No improvement (1.0287), counter 4/5
    Epoch [12/50], Train Losses: mse: 6.5394, mae: 1.4415, huber: 1.0827, swd: 1.8306, target_std: 6.5099
    Epoch [12/50], Val Losses: mse: 7.5425, mae: 1.3812, huber: 1.0325, swd: 1.0495, target_std: 4.2787
    Epoch [12/50], Test Losses: mse: 11.5158, mae: 1.7113, huber: 1.3512, swd: 1.7306, target_std: 4.7581
      Epoch 12 composite train-obj: 1.082727
    Epoch [12/50], Test Losses: mse: 11.6770, mae: 1.7208, huber: 1.3606, swd: 1.7302, target_std: 4.7581
    Best round's Test MSE: 11.6770, MAE: 1.7208, SWD: 1.7302
    Best round's Validation MSE: 7.5162, MAE: 1.3708
    Best round's Test verification MSE : 11.6770, MAE: 1.7208, SWD: 1.7302
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1564, mae: 1.5884, huber: 1.2212, swd: 2.3506, target_std: 6.5099
    Epoch [1/50], Val Losses: mse: 7.6981, mae: 1.3792, huber: 1.0301, swd: 0.9457, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 12.0863, mae: 1.7509, huber: 1.3893, swd: 1.8601, target_std: 4.7581
      Epoch 1 composite train-obj: 1.221224
            Val objective improved inf → 1.0301, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6530, mae: 1.4518, huber: 1.0928, swd: 1.9944, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.5882, mae: 1.3804, huber: 1.0310, swd: 1.0452, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 11.7858, mae: 1.7333, huber: 1.3730, swd: 1.9097, target_std: 4.7581
      Epoch 2 composite train-obj: 1.092754
            No improvement (1.0310), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.6134, mae: 1.4474, huber: 1.0886, swd: 1.9727, target_std: 6.5099
    Epoch [3/50], Val Losses: mse: 7.6044, mae: 1.3767, huber: 1.0277, swd: 0.9922, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.7995, mae: 1.7309, huber: 1.3692, swd: 1.8408, target_std: 4.7581
      Epoch 3 composite train-obj: 1.088573
            Val objective improved 1.0301 → 1.0277, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.5807, mae: 1.4443, huber: 1.0854, swd: 1.9509, target_std: 6.5099
    Epoch [4/50], Val Losses: mse: 7.6369, mae: 1.3830, huber: 1.0328, swd: 1.0258, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.7846, mae: 1.7278, huber: 1.3671, swd: 1.8124, target_std: 4.7581
      Epoch 4 composite train-obj: 1.085443
            No improvement (1.0328), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.5774, mae: 1.4441, huber: 1.0853, swd: 1.9429, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.5996, mae: 1.3748, huber: 1.0264, swd: 0.9871, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.8066, mae: 1.7266, huber: 1.3668, swd: 1.7883, target_std: 4.7581
      Epoch 5 composite train-obj: 1.085345
            Val objective improved 1.0277 → 1.0264, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 6.5551, mae: 1.4421, huber: 1.0833, swd: 1.9300, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.5737, mae: 1.3846, huber: 1.0346, swd: 1.0719, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.6318, mae: 1.7208, huber: 1.3602, swd: 1.8359, target_std: 4.7581
      Epoch 6 composite train-obj: 1.083325
            No improvement (1.0346), counter 1/5
    Epoch [7/50], Train Losses: mse: 6.5649, mae: 1.4440, huber: 1.0851, swd: 1.9317, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 7.5967, mae: 1.3854, huber: 1.0358, swd: 1.0679, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.7327, mae: 1.7286, huber: 1.3680, swd: 1.8655, target_std: 4.7581
      Epoch 7 composite train-obj: 1.085091
            No improvement (1.0358), counter 2/5
    Epoch [8/50], Train Losses: mse: 6.5466, mae: 1.4417, huber: 1.0829, swd: 1.9203, target_std: 6.5099
    Epoch [8/50], Val Losses: mse: 7.5561, mae: 1.3852, huber: 1.0354, swd: 1.1063, target_std: 4.2787
    Epoch [8/50], Test Losses: mse: 11.6407, mae: 1.7226, huber: 1.3630, swd: 1.8827, target_std: 4.7581
      Epoch 8 composite train-obj: 1.082922
            No improvement (1.0354), counter 3/5
    Epoch [9/50], Train Losses: mse: 6.5531, mae: 1.4427, huber: 1.0839, swd: 1.9232, target_std: 6.5099
    Epoch [9/50], Val Losses: mse: 7.5583, mae: 1.3833, huber: 1.0325, swd: 1.0579, target_std: 4.2787
    Epoch [9/50], Test Losses: mse: 11.6298, mae: 1.7210, huber: 1.3604, swd: 1.8049, target_std: 4.7581
      Epoch 9 composite train-obj: 1.083891
            No improvement (1.0325), counter 4/5
    Epoch [10/50], Train Losses: mse: 6.5444, mae: 1.4420, huber: 1.0831, swd: 1.9196, target_std: 6.5099
    Epoch [10/50], Val Losses: mse: 7.5784, mae: 1.3859, huber: 1.0371, swd: 1.0839, target_std: 4.2787
    Epoch [10/50], Test Losses: mse: 11.5930, mae: 1.7177, huber: 1.3576, swd: 1.8332, target_std: 4.7581
      Epoch 10 composite train-obj: 1.083088
    Epoch [10/50], Test Losses: mse: 11.8066, mae: 1.7266, huber: 1.3668, swd: 1.7883, target_std: 4.7581
    Best round's Test MSE: 11.8066, MAE: 1.7266, SWD: 1.7883
    Best round's Validation MSE: 7.5996, MAE: 1.3748
    Best round's Test verification MSE : 11.8066, MAE: 1.7266, SWD: 1.7883
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2561, mae: 1.5910, huber: 1.2237, swd: 2.2054, target_std: 6.5100
    Epoch [1/50], Val Losses: mse: 7.7458, mae: 1.3855, huber: 1.0360, swd: 1.0018, target_std: 4.2787
    Epoch [1/50], Test Losses: mse: 12.0895, mae: 1.7520, huber: 1.3904, swd: 1.9681, target_std: 4.7581
      Epoch 1 composite train-obj: 1.223664
            Val objective improved inf → 1.0360, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.6636, mae: 1.4536, huber: 1.0945, swd: 1.9074, target_std: 6.5099
    Epoch [2/50], Val Losses: mse: 7.6128, mae: 1.3694, huber: 1.0204, swd: 0.9224, target_std: 4.2787
    Epoch [2/50], Test Losses: mse: 12.0037, mae: 1.7449, huber: 1.3823, swd: 1.8713, target_std: 4.7581
      Epoch 2 composite train-obj: 1.094452
            Val objective improved 1.0360 → 1.0204, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.6143, mae: 1.4473, huber: 1.0886, swd: 1.8803, target_std: 6.5100
    Epoch [3/50], Val Losses: mse: 7.6303, mae: 1.3785, huber: 1.0303, swd: 1.0350, target_std: 4.2787
    Epoch [3/50], Test Losses: mse: 11.8563, mae: 1.7316, huber: 1.3710, swd: 1.9354, target_std: 4.7581
      Epoch 3 composite train-obj: 1.088607
            No improvement (1.0303), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.5836, mae: 1.4441, huber: 1.0854, swd: 1.8629, target_std: 6.5101
    Epoch [4/50], Val Losses: mse: 7.5919, mae: 1.3743, huber: 1.0264, swd: 1.0023, target_std: 4.2787
    Epoch [4/50], Test Losses: mse: 11.8094, mae: 1.7290, huber: 1.3685, swd: 1.8929, target_std: 4.7581
      Epoch 4 composite train-obj: 1.085430
            No improvement (1.0264), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.5735, mae: 1.4438, huber: 1.0851, swd: 1.8520, target_std: 6.5099
    Epoch [5/50], Val Losses: mse: 7.5395, mae: 1.3797, huber: 1.0304, swd: 1.0808, target_std: 4.2787
    Epoch [5/50], Test Losses: mse: 11.6744, mae: 1.7242, huber: 1.3642, swd: 1.9637, target_std: 4.7581
      Epoch 5 composite train-obj: 1.085076
            No improvement (1.0304), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.5610, mae: 1.4425, huber: 1.0837, swd: 1.8458, target_std: 6.5099
    Epoch [6/50], Val Losses: mse: 7.5471, mae: 1.3698, huber: 1.0216, swd: 0.9674, target_std: 4.2787
    Epoch [6/50], Test Losses: mse: 11.7967, mae: 1.7285, huber: 1.3677, swd: 1.8523, target_std: 4.7581
      Epoch 6 composite train-obj: 1.083748
            No improvement (1.0216), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.5596, mae: 1.4437, huber: 1.0847, swd: 1.8419, target_std: 6.5099
    Epoch [7/50], Val Losses: mse: 7.5902, mae: 1.3833, huber: 1.0348, swd: 1.0803, target_std: 4.2787
    Epoch [7/50], Test Losses: mse: 11.6716, mae: 1.7209, huber: 1.3605, swd: 1.9111, target_std: 4.7581
      Epoch 7 composite train-obj: 1.084665
    Epoch [7/50], Test Losses: mse: 12.0037, mae: 1.7449, huber: 1.3823, swd: 1.8713, target_std: 4.7581
    Best round's Test MSE: 12.0037, MAE: 1.7449, SWD: 1.8713
    Best round's Validation MSE: 7.6128, MAE: 1.3694
    Best round's Test verification MSE : 12.0037, MAE: 1.7449, SWD: 1.8713
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq196_pred336_20250430_0423)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 11.8291 ± 0.1343
      mae: 1.7307 ± 0.0102
      huber: 1.3699 ± 0.0091
      swd: 1.7966 ± 0.0579
      target_std: 4.7581 ± 0.0000
      count: 51.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.5762 ± 0.0428
      mae: 1.3717 ± 0.0023
      huber: 1.0232 ± 0.0025
      swd: 0.9620 ± 0.0283
      target_std: 4.2787 ± 0.0000
      count: 51.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq196_pred336_20250430_0423
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 196-720



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=196,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_196_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([196, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 196, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 196
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.0917, mae: 1.7262, huber: 1.3486, swd: 2.3625, target_std: 6.5087
    Epoch [1/50], Val Losses: mse: 9.8990, mae: 1.5765, huber: 1.2175, swd: 1.2201, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 13.1901, mae: 1.9207, huber: 1.5451, swd: 2.0931, target_std: 4.7636
      Epoch 1 composite train-obj: 1.348643
            Val objective improved inf → 1.2175, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.6525, mae: 1.6003, huber: 1.2291, swd: 2.0492, target_std: 6.5086
    Epoch [2/50], Val Losses: mse: 9.8923, mae: 1.5752, huber: 1.2167, swd: 1.2084, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 13.0687, mae: 1.9027, huber: 1.5291, swd: 1.9969, target_std: 4.7636
      Epoch 2 composite train-obj: 1.229145
            Val objective improved 1.2175 → 1.2167, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.5946, mae: 1.5940, huber: 1.2230, swd: 2.0144, target_std: 6.5087
    Epoch [3/50], Val Losses: mse: 9.8525, mae: 1.5606, huber: 1.2034, swd: 1.0787, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 13.1550, mae: 1.9051, huber: 1.5294, swd: 1.8621, target_std: 4.7636
      Epoch 3 composite train-obj: 1.223040
            Val objective improved 1.2167 → 1.2034, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.5629, mae: 1.5910, huber: 1.2201, swd: 1.9960, target_std: 6.5086
    Epoch [4/50], Val Losses: mse: 9.7749, mae: 1.5625, huber: 1.2047, swd: 1.1643, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 12.9754, mae: 1.8922, huber: 1.5189, swd: 1.8955, target_std: 4.7636
      Epoch 4 composite train-obj: 1.220093
            No improvement (1.2047), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.5463, mae: 1.5893, huber: 1.2184, swd: 1.9816, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 9.7660, mae: 1.5654, huber: 1.2078, swd: 1.1610, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 12.9727, mae: 1.8932, huber: 1.5192, swd: 1.8598, target_std: 4.7636
      Epoch 5 composite train-obj: 1.218407
            No improvement (1.2078), counter 2/5
    Epoch [6/50], Train Losses: mse: 7.5212, mae: 1.5864, huber: 1.2157, swd: 1.9592, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 9.7575, mae: 1.5675, huber: 1.2097, swd: 1.1498, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 12.9961, mae: 1.8977, huber: 1.5239, swd: 1.8603, target_std: 4.7636
      Epoch 6 composite train-obj: 1.215697
            No improvement (1.2097), counter 3/5
    Epoch [7/50], Train Losses: mse: 7.5172, mae: 1.5864, huber: 1.2156, swd: 1.9548, target_std: 6.5087
    Epoch [7/50], Val Losses: mse: 9.7475, mae: 1.5626, huber: 1.2051, swd: 1.1398, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 12.9468, mae: 1.8878, huber: 1.5160, swd: 1.7953, target_std: 4.7636
      Epoch 7 composite train-obj: 1.215641
            No improvement (1.2051), counter 4/5
    Epoch [8/50], Train Losses: mse: 7.5091, mae: 1.5853, huber: 1.2145, swd: 1.9468, target_std: 6.5086
    Epoch [8/50], Val Losses: mse: 9.8698, mae: 1.6077, huber: 1.2457, swd: 1.4174, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 12.8744, mae: 1.9046, huber: 1.5293, swd: 2.0292, target_std: 4.7636
      Epoch 8 composite train-obj: 1.214483
    Epoch [8/50], Test Losses: mse: 13.1550, mae: 1.9051, huber: 1.5294, swd: 1.8621, target_std: 4.7636
    Best round's Test MSE: 13.1550, MAE: 1.9051, SWD: 1.8621
    Best round's Validation MSE: 9.8525, MAE: 1.5606
    Best round's Test verification MSE : 13.1550, MAE: 1.9051, SWD: 1.8621
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1774, mae: 1.7290, huber: 1.3514, swd: 2.2495, target_std: 6.5086
    Epoch [1/50], Val Losses: mse: 10.0943, mae: 1.5785, huber: 1.2207, swd: 1.1040, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 13.3755, mae: 1.9196, huber: 1.5452, swd: 1.9924, target_std: 4.7636
      Epoch 1 composite train-obj: 1.351396
            Val objective improved inf → 1.2207, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.6540, mae: 1.6007, huber: 1.2295, swd: 1.9501, target_std: 6.5087
    Epoch [2/50], Val Losses: mse: 9.8952, mae: 1.5628, huber: 1.2054, swd: 1.0633, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 13.2034, mae: 1.9059, huber: 1.5324, swd: 1.9332, target_std: 4.7636
      Epoch 2 composite train-obj: 1.229469
            Val objective improved 1.2207 → 1.2054, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 7.5963, mae: 1.5940, huber: 1.2231, swd: 1.9185, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.7353, mae: 1.5518, huber: 1.1952, swd: 1.0450, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 13.0608, mae: 1.8967, huber: 1.5240, swd: 1.9133, target_std: 4.7636
      Epoch 3 composite train-obj: 1.223133
            Val objective improved 1.2054 → 1.1952, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 7.5618, mae: 1.5906, huber: 1.2196, swd: 1.8949, target_std: 6.5086
    Epoch [4/50], Val Losses: mse: 9.8259, mae: 1.5700, huber: 1.2115, swd: 1.0903, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 13.0088, mae: 1.8967, huber: 1.5236, swd: 1.8984, target_std: 4.7636
      Epoch 4 composite train-obj: 1.219640
            No improvement (1.2115), counter 1/5
    Epoch [5/50], Train Losses: mse: 7.5319, mae: 1.5878, huber: 1.2170, swd: 1.8742, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 9.8304, mae: 1.5658, huber: 1.2091, swd: 1.0866, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 13.0709, mae: 1.8971, huber: 1.5248, swd: 1.8615, target_std: 4.7636
      Epoch 5 composite train-obj: 1.217036
            No improvement (1.2091), counter 2/5
    Epoch [6/50], Train Losses: mse: 7.5271, mae: 1.5875, huber: 1.2167, swd: 1.8669, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 9.6723, mae: 1.5547, huber: 1.1976, swd: 1.0836, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 12.9463, mae: 1.8896, huber: 1.5169, swd: 1.8730, target_std: 4.7636
      Epoch 6 composite train-obj: 1.216732
            No improvement (1.1976), counter 3/5
    Epoch [7/50], Train Losses: mse: 7.5099, mae: 1.5853, huber: 1.2146, swd: 1.8550, target_std: 6.5086
    Epoch [7/50], Val Losses: mse: 9.7343, mae: 1.5668, huber: 1.2096, swd: 1.1612, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 12.8130, mae: 1.8793, huber: 1.5074, swd: 1.8705, target_std: 4.7636
      Epoch 7 composite train-obj: 1.214623
            No improvement (1.2096), counter 4/5
    Epoch [8/50], Train Losses: mse: 7.5038, mae: 1.5850, huber: 1.2142, swd: 1.8498, target_std: 6.5087
    Epoch [8/50], Val Losses: mse: 9.7336, mae: 1.5677, huber: 1.2093, swd: 1.0909, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 12.9720, mae: 1.8926, huber: 1.5203, swd: 1.8265, target_std: 4.7636
      Epoch 8 composite train-obj: 1.214164
    Epoch [8/50], Test Losses: mse: 13.0608, mae: 1.8967, huber: 1.5240, swd: 1.9133, target_std: 4.7636
    Best round's Test MSE: 13.0608, MAE: 1.8967, SWD: 1.9133
    Best round's Validation MSE: 9.7353, MAE: 1.5518
    Best round's Test verification MSE : 13.0608, MAE: 1.8967, SWD: 1.9133
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1845, mae: 1.7294, huber: 1.3518, swd: 2.4840, target_std: 6.5086
    Epoch [1/50], Val Losses: mse: 9.9884, mae: 1.5708, huber: 1.2130, swd: 1.1478, target_std: 4.2634
    Epoch [1/50], Test Losses: mse: 13.3705, mae: 1.9212, huber: 1.5472, swd: 2.1187, target_std: 4.7636
      Epoch 1 composite train-obj: 1.351806
            Val objective improved inf → 1.2130, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.6562, mae: 1.6009, huber: 1.2296, swd: 2.1390, target_std: 6.5086
    Epoch [2/50], Val Losses: mse: 9.8986, mae: 1.5707, huber: 1.2133, swd: 1.2718, target_std: 4.2634
    Epoch [2/50], Test Losses: mse: 13.0931, mae: 1.9025, huber: 1.5283, swd: 2.1240, target_std: 4.7636
      Epoch 2 composite train-obj: 1.229638
            No improvement (1.2133), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.5957, mae: 1.5937, huber: 1.2228, swd: 2.1041, target_std: 6.5086
    Epoch [3/50], Val Losses: mse: 9.9017, mae: 1.5844, huber: 1.2249, swd: 1.3764, target_std: 4.2634
    Epoch [3/50], Test Losses: mse: 12.9428, mae: 1.8936, huber: 1.5202, swd: 2.1362, target_std: 4.7636
      Epoch 3 composite train-obj: 1.222845
            No improvement (1.2249), counter 2/5
    Epoch [4/50], Train Losses: mse: 7.5559, mae: 1.5898, huber: 1.2190, swd: 2.0746, target_std: 6.5087
    Epoch [4/50], Val Losses: mse: 9.8064, mae: 1.5729, huber: 1.2150, swd: 1.2782, target_std: 4.2634
    Epoch [4/50], Test Losses: mse: 12.9457, mae: 1.8924, huber: 1.5195, swd: 2.0677, target_std: 4.7636
      Epoch 4 composite train-obj: 1.218964
            No improvement (1.2150), counter 3/5
    Epoch [5/50], Train Losses: mse: 7.5414, mae: 1.5887, huber: 1.2179, swd: 2.0590, target_std: 6.5087
    Epoch [5/50], Val Losses: mse: 9.7425, mae: 1.5609, huber: 1.2040, swd: 1.1951, target_std: 4.2634
    Epoch [5/50], Test Losses: mse: 13.0352, mae: 1.8977, huber: 1.5250, swd: 2.0065, target_std: 4.7636
      Epoch 5 composite train-obj: 1.217901
            Val objective improved 1.2130 → 1.2040, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 7.5121, mae: 1.5858, huber: 1.2150, swd: 2.0386, target_std: 6.5087
    Epoch [6/50], Val Losses: mse: 9.7123, mae: 1.5721, huber: 1.2130, swd: 1.3331, target_std: 4.2634
    Epoch [6/50], Test Losses: mse: 12.8182, mae: 1.8870, huber: 1.5132, swd: 2.0551, target_std: 4.7636
      Epoch 6 composite train-obj: 1.215033
            No improvement (1.2130), counter 1/5
    Epoch [7/50], Train Losses: mse: 7.5110, mae: 1.5857, huber: 1.2150, swd: 2.0372, target_std: 6.5087
    Epoch [7/50], Val Losses: mse: 9.8484, mae: 1.5739, huber: 1.2166, swd: 1.2350, target_std: 4.2634
    Epoch [7/50], Test Losses: mse: 12.9834, mae: 1.8919, huber: 1.5189, swd: 1.9572, target_std: 4.7636
      Epoch 7 composite train-obj: 1.214984
            No improvement (1.2166), counter 2/5
    Epoch [8/50], Train Losses: mse: 7.5066, mae: 1.5850, huber: 1.2142, swd: 2.0263, target_std: 6.5087
    Epoch [8/50], Val Losses: mse: 9.7404, mae: 1.5874, huber: 1.2274, swd: 1.4303, target_std: 4.2634
    Epoch [8/50], Test Losses: mse: 12.7271, mae: 1.8844, huber: 1.5116, swd: 2.0924, target_std: 4.7636
      Epoch 8 composite train-obj: 1.214216
            No improvement (1.2274), counter 3/5
    Epoch [9/50], Train Losses: mse: 7.5045, mae: 1.5852, huber: 1.2144, swd: 2.0245, target_std: 6.5086
    Epoch [9/50], Val Losses: mse: 9.6163, mae: 1.5574, huber: 1.1994, swd: 1.2143, target_std: 4.2634
    Epoch [9/50], Test Losses: mse: 12.8193, mae: 1.8821, huber: 1.5096, swd: 1.9510, target_std: 4.7636
      Epoch 9 composite train-obj: 1.214436
            Val objective improved 1.2040 → 1.1994, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 7.4978, mae: 1.5844, huber: 1.2136, swd: 2.0161, target_std: 6.5086
    Epoch [10/50], Val Losses: mse: 9.7200, mae: 1.5726, huber: 1.2147, swd: 1.2977, target_std: 4.2634
    Epoch [10/50], Test Losses: mse: 12.7799, mae: 1.8798, huber: 1.5073, swd: 1.9627, target_std: 4.7636
      Epoch 10 composite train-obj: 1.213624
            No improvement (1.2147), counter 1/5
    Epoch [11/50], Train Losses: mse: 7.5010, mae: 1.5846, huber: 1.2138, swd: 2.0129, target_std: 6.5087
    Epoch [11/50], Val Losses: mse: 9.6450, mae: 1.5608, huber: 1.2030, swd: 1.2051, target_std: 4.2634
    Epoch [11/50], Test Losses: mse: 12.8603, mae: 1.8847, huber: 1.5126, swd: 1.9270, target_std: 4.7636
      Epoch 11 composite train-obj: 1.213798
            No improvement (1.2030), counter 2/5
    Epoch [12/50], Train Losses: mse: 7.4965, mae: 1.5843, huber: 1.2135, swd: 2.0105, target_std: 6.5086
    Epoch [12/50], Val Losses: mse: 9.6361, mae: 1.5692, huber: 1.2099, swd: 1.3044, target_std: 4.2634
    Epoch [12/50], Test Losses: mse: 12.7192, mae: 1.8785, huber: 1.5060, swd: 1.9711, target_std: 4.7636
      Epoch 12 composite train-obj: 1.213472
            No improvement (1.2099), counter 3/5
    Epoch [13/50], Train Losses: mse: 7.4918, mae: 1.5839, huber: 1.2131, swd: 2.0077, target_std: 6.5086
    Epoch [13/50], Val Losses: mse: 9.7842, mae: 1.5829, huber: 1.2241, swd: 1.3472, target_std: 4.2634
    Epoch [13/50], Test Losses: mse: 12.8229, mae: 1.8859, huber: 1.5136, swd: 1.9695, target_std: 4.7636
      Epoch 13 composite train-obj: 1.213064
            No improvement (1.2241), counter 4/5
    Epoch [14/50], Train Losses: mse: 7.4993, mae: 1.5849, huber: 1.2140, swd: 2.0115, target_std: 6.5086
    Epoch [14/50], Val Losses: mse: 9.7463, mae: 1.5704, huber: 1.2127, swd: 1.2274, target_std: 4.2634
    Epoch [14/50], Test Losses: mse: 12.8865, mae: 1.8852, huber: 1.5127, swd: 1.8895, target_std: 4.7636
      Epoch 14 composite train-obj: 1.214026
    Epoch [14/50], Test Losses: mse: 12.8193, mae: 1.8821, huber: 1.5096, swd: 1.9510, target_std: 4.7636
    Best round's Test MSE: 12.8193, MAE: 1.8821, SWD: 1.9510
    Best round's Validation MSE: 9.6163, MAE: 1.5574
    Best round's Test verification MSE : 12.8193, MAE: 1.8821, SWD: 1.9510
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq196_pred720_20250430_0425)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 13.0117 ± 0.1414
      mae: 1.8946 ± 0.0095
      huber: 1.5210 ± 0.0084
      swd: 1.9088 ± 0.0365
      target_std: 4.7636 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.7347 ± 0.0964
      mae: 1.5566 ± 0.0036
      huber: 1.1993 ± 0.0034
      swd: 1.1126 ± 0.0732
      target_std: 4.2634 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq196_pred720_20250430_0425
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 196
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


