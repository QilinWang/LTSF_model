# data


```python
%load_ext autoreload
%autoreload 2
import importlib
from importlib import reload  
  
import monotonic
import utils
from train import execute_model_evaluation
from train_config import FlatACLConfig
import train_config
import data_manager
from data_manager import DatasetManager
import metrics
from dataclasses import replace

reload(utils)
reload(monotonic)
reload(train_config)


%load_ext autoreload
%autoreload 2 
data_mgr = DatasetManager(device='cuda')
 
data_mgr.load_csv('ettm2', './ettm2.csv')
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    
    ==================================================
    Dataset: ettm2 (csv)
    ==================================================
    Shape: torch.Size([69680, 7])
    Channels: 7
    Length: 69680
    Source: ./ettm2.csv
    
    Sample data (first 2 rows):
    tensor([[41.1300, 12.4810, 36.5360,  9.3550,  4.4240,  1.3110, 38.6620],
            [39.6220, 11.3090, 35.5440,  8.5510,  3.2090,  1.2580, 38.2230]])
    ==================================================
    




    <data_manager.DatasetManager at 0x2934e80d310>



# Seq=720

### EigenACL

#### pred=96

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 36.1769, mae: 2.9721, huber: 2.5545, swd: 25.2537, ept: 80.8240
    Epoch [1/50], Val Losses: mse: 16.8326, mae: 2.6044, huber: 2.1933, swd: 7.4823, ept: 80.2024
    Epoch [1/50], Test Losses: mse: 11.5972, mae: 2.2482, huber: 1.8258, swd: 4.8194, ept: 85.8196
      Epoch 1 composite train-obj: 2.554512
            Val objective improved inf → 2.1933, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.9064, mae: 2.1019, huber: 1.6945, swd: 6.7069, ept: 88.2619
    Epoch [2/50], Val Losses: mse: 13.4806, mae: 2.3039, huber: 1.8969, swd: 7.1154, ept: 83.9828
    Epoch [2/50], Test Losses: mse: 9.0827, mae: 1.9711, huber: 1.5537, swd: 4.4865, ept: 87.6647
      Epoch 2 composite train-obj: 1.694526
            Val objective improved 2.1933 → 1.8969, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.3402, mae: 1.9364, huber: 1.5341, swd: 6.1267, ept: 89.5812
    Epoch [3/50], Val Losses: mse: 13.2452, mae: 2.2896, huber: 1.8848, swd: 6.9826, ept: 83.3749
    Epoch [3/50], Test Losses: mse: 8.9725, mae: 1.9323, huber: 1.5193, swd: 4.4865, ept: 87.3995
      Epoch 3 composite train-obj: 1.534103
            Val objective improved 1.8969 → 1.8848, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.6048, mae: 1.8584, huber: 1.4594, swd: 5.5784, ept: 90.0305
    Epoch [4/50], Val Losses: mse: 12.6459, mae: 2.2281, huber: 1.8261, swd: 6.7133, ept: 83.7217
    Epoch [4/50], Test Losses: mse: 8.5807, mae: 1.8879, huber: 1.4792, swd: 4.2483, ept: 87.5133
      Epoch 4 composite train-obj: 1.459359
            Val objective improved 1.8848 → 1.8261, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 10.4368, mae: 1.8469, huber: 1.4484, swd: 5.4832, ept: 90.0906
    Epoch [5/50], Val Losses: mse: 12.5518, mae: 2.2227, huber: 1.8198, swd: 6.6192, ept: 84.2999
    Epoch [5/50], Test Losses: mse: 8.7594, mae: 1.9407, huber: 1.5246, swd: 4.3744, ept: 88.5666
      Epoch 5 composite train-obj: 1.448385
            Val objective improved 1.8261 → 1.8198, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 10.0992, mae: 1.8140, huber: 1.4174, swd: 5.2575, ept: 90.2800
    Epoch [6/50], Val Losses: mse: 12.8206, mae: 2.2305, huber: 1.8307, swd: 6.9444, ept: 83.1507
    Epoch [6/50], Test Losses: mse: 8.9895, mae: 1.9200, huber: 1.5102, swd: 4.6742, ept: 86.7684
      Epoch 6 composite train-obj: 1.417376
            No improvement (1.8307), counter 1/5
    Epoch [7/50], Train Losses: mse: 9.8401, mae: 1.7826, huber: 1.3875, swd: 5.1088, ept: 90.4470
    Epoch [7/50], Val Losses: mse: 12.3762, mae: 2.1961, huber: 1.7982, swd: 6.6121, ept: 83.8630
    Epoch [7/50], Test Losses: mse: 8.6267, mae: 1.9015, huber: 1.4907, swd: 4.3944, ept: 87.4839
      Epoch 7 composite train-obj: 1.387455
            Val objective improved 1.8198 → 1.7982, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 9.4640, mae: 1.7494, huber: 1.3560, swd: 4.8369, ept: 90.5843
    Epoch [8/50], Val Losses: mse: 12.2578, mae: 2.1884, huber: 1.7917, swd: 6.4326, ept: 83.7062
    Epoch [8/50], Test Losses: mse: 8.7407, mae: 1.8937, huber: 1.4861, swd: 4.4872, ept: 87.4359
      Epoch 8 composite train-obj: 1.355978
            Val objective improved 1.7982 → 1.7917, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 9.1292, mae: 1.7192, huber: 1.3269, swd: 4.5964, ept: 90.7612
    Epoch [9/50], Val Losses: mse: 12.4822, mae: 2.2143, huber: 1.8185, swd: 6.8448, ept: 83.6164
    Epoch [9/50], Test Losses: mse: 8.8430, mae: 1.9042, huber: 1.4962, swd: 4.6652, ept: 87.7242
      Epoch 9 composite train-obj: 1.326945
            No improvement (1.8185), counter 1/5
    Epoch [10/50], Train Losses: mse: 8.9661, mae: 1.7064, huber: 1.3148, swd: 4.4796, ept: 90.8281
    Epoch [10/50], Val Losses: mse: 12.5773, mae: 2.2118, huber: 1.8174, swd: 6.8948, ept: 83.4165
    Epoch [10/50], Test Losses: mse: 9.0376, mae: 1.8932, huber: 1.4876, swd: 4.7873, ept: 87.5463
      Epoch 10 composite train-obj: 1.314850
            No improvement (1.8174), counter 2/5
    Epoch [11/50], Train Losses: mse: 8.7251, mae: 1.6892, huber: 1.2983, swd: 4.3073, ept: 90.9513
    Epoch [11/50], Val Losses: mse: 13.3973, mae: 2.2670, huber: 1.8725, swd: 7.6507, ept: 82.8113
    Epoch [11/50], Test Losses: mse: 9.4494, mae: 1.9443, huber: 1.5360, swd: 5.1105, ept: 87.0439
      Epoch 11 composite train-obj: 1.298276
            No improvement (1.8725), counter 3/5
    Epoch [12/50], Train Losses: mse: 8.4325, mae: 1.6577, huber: 1.2684, swd: 4.0953, ept: 91.0745
    Epoch [12/50], Val Losses: mse: 13.1058, mae: 2.2660, huber: 1.8718, swd: 7.5437, ept: 83.2317
    Epoch [12/50], Test Losses: mse: 9.0960, mae: 1.9388, huber: 1.5289, swd: 4.9276, ept: 87.8773
      Epoch 12 composite train-obj: 1.268356
            No improvement (1.8718), counter 4/5
    Epoch [13/50], Train Losses: mse: 8.2092, mae: 1.6356, huber: 1.2472, swd: 3.9326, ept: 91.1705
    Epoch [13/50], Val Losses: mse: 13.7536, mae: 2.2814, huber: 1.8902, swd: 8.0561, ept: 82.5745
    Epoch [13/50], Test Losses: mse: 9.4883, mae: 1.9535, huber: 1.5445, swd: 5.2055, ept: 86.5501
      Epoch 13 composite train-obj: 1.247231
    Epoch [13/50], Test Losses: mse: 8.7408, mae: 1.8937, huber: 1.4861, swd: 4.4872, ept: 87.4367
    Best round's Test MSE: 8.7407, MAE: 1.8937, SWD: 4.4872
    Best round's Validation MSE: 12.2578, MAE: 2.1884, SWD: 6.4326
    Best round's Test verification MSE : 8.7408, MAE: 1.8937, SWD: 4.4872
    Time taken: 149.07 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 37.0190, mae: 2.9939, huber: 2.5761, swd: 24.9851, ept: 80.2875
    Epoch [1/50], Val Losses: mse: 14.9688, mae: 2.4435, huber: 2.0335, swd: 7.6494, ept: 82.7460
    Epoch [1/50], Test Losses: mse: 10.0841, mae: 2.1104, huber: 1.6870, swd: 4.8510, ept: 87.7458
      Epoch 1 composite train-obj: 2.576127
            Val objective improved inf → 2.0335, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.9820, mae: 1.9997, huber: 1.5941, swd: 6.2833, ept: 89.2490
    Epoch [2/50], Val Losses: mse: 13.0650, mae: 2.2646, huber: 1.8589, swd: 6.4975, ept: 84.3388
    Epoch [2/50], Test Losses: mse: 8.7390, mae: 1.9256, huber: 1.5104, swd: 4.0505, ept: 88.3598
      Epoch 2 composite train-obj: 1.594110
            Val objective improved 2.0335 → 1.8589, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 10.8699, mae: 1.9002, huber: 1.4988, swd: 5.5486, ept: 89.8506
    Epoch [3/50], Val Losses: mse: 12.6980, mae: 2.2289, huber: 1.8260, swd: 6.4473, ept: 84.1909
    Epoch [3/50], Test Losses: mse: 8.6336, mae: 1.9135, huber: 1.4993, swd: 4.1578, ept: 88.7250
      Epoch 3 composite train-obj: 1.498762
            Val objective improved 1.8589 → 1.8260, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.2933, mae: 1.8501, huber: 1.4514, swd: 5.1438, ept: 90.0921
    Epoch [4/50], Val Losses: mse: 12.7535, mae: 2.2459, huber: 1.8425, swd: 6.4161, ept: 83.3494
    Epoch [4/50], Test Losses: mse: 8.3770, mae: 1.8786, huber: 1.4680, swd: 3.8310, ept: 88.1020
      Epoch 4 composite train-obj: 1.451369
            No improvement (1.8425), counter 1/5
    Epoch [5/50], Train Losses: mse: 9.8910, mae: 1.8064, huber: 1.4094, swd: 4.8953, ept: 90.3712
    Epoch [5/50], Val Losses: mse: 12.8656, mae: 2.2506, huber: 1.8487, swd: 6.4797, ept: 83.2536
    Epoch [5/50], Test Losses: mse: 8.9974, mae: 1.9101, huber: 1.5011, swd: 4.2923, ept: 87.0344
      Epoch 5 composite train-obj: 1.409400
            No improvement (1.8487), counter 2/5
    Epoch [6/50], Train Losses: mse: 9.6221, mae: 1.7819, huber: 1.3861, swd: 4.7446, ept: 90.4771
    Epoch [6/50], Val Losses: mse: 12.5359, mae: 2.2117, huber: 1.8129, swd: 6.5617, ept: 83.5296
    Epoch [6/50], Test Losses: mse: 8.6881, mae: 1.8983, huber: 1.4871, swd: 4.2242, ept: 88.3946
      Epoch 6 composite train-obj: 1.386054
            Val objective improved 1.8260 → 1.8129, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 9.3922, mae: 1.7523, huber: 1.3579, swd: 4.6224, ept: 90.6392
    Epoch [7/50], Val Losses: mse: 12.2625, mae: 2.1817, huber: 1.7838, swd: 6.4269, ept: 83.7792
    Epoch [7/50], Test Losses: mse: 8.6043, mae: 1.8536, huber: 1.4467, swd: 4.2098, ept: 88.0704
      Epoch 7 composite train-obj: 1.357881
            Val objective improved 1.8129 → 1.7838, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 9.1665, mae: 1.7274, huber: 1.3339, swd: 4.4605, ept: 90.7691
    Epoch [8/50], Val Losses: mse: 12.5224, mae: 2.2260, huber: 1.8283, swd: 6.8420, ept: 83.1402
    Epoch [8/50], Test Losses: mse: 8.7519, mae: 1.9181, huber: 1.5074, swd: 4.4430, ept: 88.5623
      Epoch 8 composite train-obj: 1.333942
            No improvement (1.8283), counter 1/5
    Epoch [9/50], Train Losses: mse: 8.9248, mae: 1.6998, huber: 1.3077, swd: 4.3052, ept: 90.9074
    Epoch [9/50], Val Losses: mse: 13.1322, mae: 2.2581, huber: 1.8596, swd: 7.4269, ept: 82.9836
    Epoch [9/50], Test Losses: mse: 9.0169, mae: 1.9256, huber: 1.5164, swd: 4.7148, ept: 88.1236
      Epoch 9 composite train-obj: 1.307730
            No improvement (1.8596), counter 2/5
    Epoch [10/50], Train Losses: mse: 8.7422, mae: 1.6825, huber: 1.2910, swd: 4.1905, ept: 91.0308
    Epoch [10/50], Val Losses: mse: 12.7863, mae: 2.2307, huber: 1.8325, swd: 6.9586, ept: 83.3462
    Epoch [10/50], Test Losses: mse: 9.0318, mae: 1.9138, huber: 1.5040, swd: 4.6900, ept: 87.8367
      Epoch 10 composite train-obj: 1.291025
            No improvement (1.8325), counter 3/5
    Epoch [11/50], Train Losses: mse: 8.4577, mae: 1.6512, huber: 1.2614, swd: 3.9933, ept: 91.1909
    Epoch [11/50], Val Losses: mse: 14.4876, mae: 2.3612, huber: 1.9597, swd: 8.1735, ept: 81.7789
    Epoch [11/50], Test Losses: mse: 10.0246, mae: 1.9823, huber: 1.5723, swd: 5.2740, ept: 85.9713
      Epoch 11 composite train-obj: 1.261358
            No improvement (1.9597), counter 4/5
    Epoch [12/50], Train Losses: mse: 8.2418, mae: 1.6301, huber: 1.2416, swd: 3.8408, ept: 91.2799
    Epoch [12/50], Val Losses: mse: 13.1327, mae: 2.2630, huber: 1.8645, swd: 7.0629, ept: 82.8002
    Epoch [12/50], Test Losses: mse: 8.9629, mae: 1.8768, huber: 1.4695, swd: 4.4939, ept: 87.4448
      Epoch 12 composite train-obj: 1.241593
    Epoch [12/50], Test Losses: mse: 8.6042, mae: 1.8536, huber: 1.4467, swd: 4.2098, ept: 88.0697
    Best round's Test MSE: 8.6043, MAE: 1.8536, SWD: 4.2098
    Best round's Validation MSE: 12.2625, MAE: 2.1817, SWD: 6.4269
    Best round's Test verification MSE : 8.6042, MAE: 1.8536, SWD: 4.2098
    Time taken: 141.31 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 36.1364, mae: 2.9536, huber: 2.5367, swd: 22.4228, ept: 81.6162
    Epoch [1/50], Val Losses: mse: 15.6505, mae: 2.5098, huber: 2.1013, swd: 6.5463, ept: 82.2092
    Epoch [1/50], Test Losses: mse: 10.6745, mae: 2.1334, huber: 1.7142, swd: 4.1361, ept: 87.0551
      Epoch 1 composite train-obj: 2.536661
            Val objective improved inf → 2.1013, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.3037, mae: 2.0385, huber: 1.6328, swd: 5.7621, ept: 88.8775
    Epoch [2/50], Val Losses: mse: 12.7763, mae: 2.2639, huber: 1.8556, swd: 5.8828, ept: 84.3912
    Epoch [2/50], Test Losses: mse: 8.5804, mae: 1.9163, huber: 1.5014, swd: 3.6522, ept: 88.2605
      Epoch 2 composite train-obj: 1.632834
            Val objective improved 2.1013 → 1.8556, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 10.7953, mae: 1.8918, huber: 1.4911, swd: 5.1284, ept: 89.9755
    Epoch [3/50], Val Losses: mse: 12.4449, mae: 2.2300, huber: 1.8226, swd: 5.7372, ept: 84.0929
    Epoch [3/50], Test Losses: mse: 8.5200, mae: 1.8803, huber: 1.4701, swd: 3.7428, ept: 88.1502
      Epoch 3 composite train-obj: 1.491091
            Val objective improved 1.8556 → 1.8226, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.3101, mae: 1.8524, huber: 1.4534, swd: 4.8463, ept: 90.1277
    Epoch [4/50], Val Losses: mse: 12.5553, mae: 2.2303, huber: 1.8244, swd: 6.0509, ept: 83.6594
    Epoch [4/50], Test Losses: mse: 8.4277, mae: 1.8856, huber: 1.4760, swd: 3.7418, ept: 88.8259
      Epoch 4 composite train-obj: 1.453383
            No improvement (1.8244), counter 1/5
    Epoch [5/50], Train Losses: mse: 9.6936, mae: 1.7806, huber: 1.3847, swd: 4.4579, ept: 90.5246
    Epoch [5/50], Val Losses: mse: 12.4663, mae: 2.2180, huber: 1.8152, swd: 5.8709, ept: 83.4370
    Epoch [5/50], Test Losses: mse: 8.5220, mae: 1.8786, huber: 1.4695, swd: 3.7540, ept: 88.4591
      Epoch 5 composite train-obj: 1.384658
            Val objective improved 1.8226 → 1.8152, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 9.4953, mae: 1.7600, huber: 1.3653, swd: 4.3389, ept: 90.6348
    Epoch [6/50], Val Losses: mse: 12.2299, mae: 2.2015, huber: 1.8028, swd: 5.9017, ept: 83.6417
    Epoch [6/50], Test Losses: mse: 8.3250, mae: 1.8433, huber: 1.4380, swd: 3.7313, ept: 88.3377
      Epoch 6 composite train-obj: 1.365312
            Val objective improved 1.8152 → 1.8028, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 9.2351, mae: 1.7299, huber: 1.3370, swd: 4.2019, ept: 90.7934
    Epoch [7/50], Val Losses: mse: 12.7826, mae: 2.2393, huber: 1.8410, swd: 6.1925, ept: 82.9711
    Epoch [7/50], Test Losses: mse: 8.4879, mae: 1.8383, huber: 1.4340, swd: 3.8037, ept: 87.6336
      Epoch 7 composite train-obj: 1.337017
            No improvement (1.8410), counter 1/5
    Epoch [8/50], Train Losses: mse: 9.0170, mae: 1.7102, huber: 1.3184, swd: 4.0582, ept: 90.8745
    Epoch [8/50], Val Losses: mse: 12.4029, mae: 2.1986, huber: 1.8033, swd: 6.1062, ept: 82.9640
    Epoch [8/50], Test Losses: mse: 8.5939, mae: 1.8496, huber: 1.4444, swd: 3.9526, ept: 87.5062
      Epoch 8 composite train-obj: 1.318429
            No improvement (1.8033), counter 2/5
    Epoch [9/50], Train Losses: mse: 8.7519, mae: 1.6881, huber: 1.2971, swd: 3.8897, ept: 90.9943
    Epoch [9/50], Val Losses: mse: 12.4654, mae: 2.2263, huber: 1.8318, swd: 6.3039, ept: 82.4301
    Epoch [9/50], Test Losses: mse: 8.4437, mae: 1.8853, huber: 1.4742, swd: 3.9688, ept: 88.3766
      Epoch 9 composite train-obj: 1.297125
            No improvement (1.8318), counter 3/5
    Epoch [10/50], Train Losses: mse: 8.5780, mae: 1.6720, huber: 1.2823, swd: 3.7784, ept: 91.0469
    Epoch [10/50], Val Losses: mse: 12.1995, mae: 2.2159, huber: 1.8202, swd: 5.9341, ept: 82.7996
    Epoch [10/50], Test Losses: mse: 8.3656, mae: 1.8561, huber: 1.4487, swd: 3.8427, ept: 88.1059
      Epoch 10 composite train-obj: 1.282250
            No improvement (1.8202), counter 4/5
    Epoch [11/50], Train Losses: mse: 8.2832, mae: 1.6419, huber: 1.2536, swd: 3.5829, ept: 91.1942
    Epoch [11/50], Val Losses: mse: 13.1938, mae: 2.2849, huber: 1.8879, swd: 6.6968, ept: 81.9538
    Epoch [11/50], Test Losses: mse: 8.9326, mae: 1.9020, huber: 1.4937, swd: 4.2575, ept: 87.5836
      Epoch 11 composite train-obj: 1.253638
    Epoch [11/50], Test Losses: mse: 8.3248, mae: 1.8432, huber: 1.4380, swd: 3.7313, ept: 88.3394
    Best round's Test MSE: 8.3250, MAE: 1.8433, SWD: 3.7313
    Best round's Validation MSE: 12.2299, MAE: 2.2015, SWD: 5.9017
    Best round's Test verification MSE : 8.3248, MAE: 1.8432, SWD: 3.7313
    Time taken: 124.21 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred96_20250512_1945)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.5567 ± 0.1730
      mae: 1.8635 ± 0.0218
      huber: 1.4569 ± 0.0210
      swd: 4.1428 ± 0.3122
      ept: 87.9480 ± 0.3782
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 12.2501 ± 0.0144
      mae: 2.1905 ± 0.0082
      huber: 1.7928 ± 0.0078
      swd: 6.2537 ± 0.2489
      ept: 83.7091 ± 0.0562
      count: 49.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 416.08 seconds
    
    Experiment complete: ACL_ettm2_seq720_pred96_20250512_1945
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 31.7508, mae: 2.8609, huber: 2.4442, swd: 22.5682, target_std: 20.3711
    Epoch [1/50], Val Losses: mse: 13.3796, mae: 2.2993, huber: 1.8919, swd: 7.1480, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.9099, mae: 1.9716, huber: 1.5522, swd: 4.4059, target_std: 18.4426
      Epoch 1 composite train-obj: 2.444249
            Val objective improved inf → 1.8919, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.0645, mae: 2.0035, huber: 1.5986, swd: 6.7198, target_std: 20.3709
    Epoch [2/50], Val Losses: mse: 12.9651, mae: 2.2750, huber: 1.8678, swd: 6.7909, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 8.7820, mae: 1.9417, huber: 1.5255, swd: 4.3109, target_std: 18.4426
      Epoch 2 composite train-obj: 1.598638
            Val objective improved 1.8919 → 1.8678, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.1871, mae: 1.9181, huber: 1.5171, swd: 6.0158, target_std: 20.3708
    Epoch [3/50], Val Losses: mse: 12.9476, mae: 2.2740, huber: 1.8664, swd: 6.9265, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.6861, mae: 1.9131, huber: 1.5014, swd: 4.3671, target_std: 18.4426
      Epoch 3 composite train-obj: 1.517074
            Val objective improved 1.8678 → 1.8664, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.5929, mae: 1.8628, huber: 1.4640, swd: 5.5986, target_std: 20.3704
    Epoch [4/50], Val Losses: mse: 13.1338, mae: 2.3098, huber: 1.9023, swd: 7.4130, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.7644, mae: 1.9695, huber: 1.5560, swd: 4.6473, target_std: 18.4426
      Epoch 4 composite train-obj: 1.463995
            No improvement (1.9023), counter 1/5
    Epoch [5/50], Train Losses: mse: 10.2273, mae: 1.8229, huber: 1.4258, swd: 5.3794, target_std: 20.3721
    Epoch [5/50], Val Losses: mse: 12.5875, mae: 2.2432, huber: 1.8363, swd: 7.1166, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.4250, mae: 1.9122, huber: 1.4978, swd: 4.3826, target_std: 18.4426
      Epoch 5 composite train-obj: 1.425784
            Val objective improved 1.8664 → 1.8363, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 9.9220, mae: 1.7915, huber: 1.3954, swd: 5.1841, target_std: 20.3720
    Epoch [6/50], Val Losses: mse: 12.2471, mae: 2.2103, huber: 1.8070, swd: 6.6029, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.7777, mae: 1.8733, huber: 1.4678, swd: 4.4691, target_std: 18.4426
      Epoch 6 composite train-obj: 1.395359
            Val objective improved 1.8363 → 1.8070, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 9.7668, mae: 1.7779, huber: 1.3825, swd: 5.1419, target_std: 20.3712
    Epoch [7/50], Val Losses: mse: 11.8591, mae: 2.1732, huber: 1.7702, swd: 6.3375, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 8.4768, mae: 1.8905, huber: 1.4807, swd: 4.3605, target_std: 18.4426
      Epoch 7 composite train-obj: 1.382485
            Val objective improved 1.8070 → 1.7702, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 9.5389, mae: 1.7468, huber: 1.3526, swd: 4.9850, target_std: 20.3715
    Epoch [8/50], Val Losses: mse: 11.8486, mae: 2.1683, huber: 1.7661, swd: 6.4925, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 8.5616, mae: 1.8656, huber: 1.4598, swd: 4.4620, target_std: 18.4426
      Epoch 8 composite train-obj: 1.352608
            Val objective improved 1.7702 → 1.7661, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 9.2848, mae: 1.7155, huber: 1.3230, swd: 4.7839, target_std: 20.3719
    Epoch [9/50], Val Losses: mse: 12.2145, mae: 2.2229, huber: 1.8181, swd: 6.7561, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 8.5957, mae: 1.8867, huber: 1.4775, swd: 4.4409, target_std: 18.4426
      Epoch 9 composite train-obj: 1.322999
            No improvement (1.8181), counter 1/5
    Epoch [10/50], Train Losses: mse: 9.0140, mae: 1.6952, huber: 1.3033, swd: 4.5975, target_std: 20.3705
    Epoch [10/50], Val Losses: mse: 12.5746, mae: 2.2386, huber: 1.8331, swd: 7.0625, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 9.1541, mae: 1.9065, huber: 1.5002, swd: 4.9501, target_std: 18.4426
      Epoch 10 composite train-obj: 1.303336
            No improvement (1.8331), counter 2/5
    Epoch [11/50], Train Losses: mse: 8.7810, mae: 1.6759, huber: 1.2847, swd: 4.4385, target_std: 20.3708
    Epoch [11/50], Val Losses: mse: 12.8217, mae: 2.2690, huber: 1.8616, swd: 7.2103, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 9.3393, mae: 1.9373, huber: 1.5287, swd: 5.0404, target_std: 18.4426
      Epoch 11 composite train-obj: 1.284680
            No improvement (1.8616), counter 3/5
    Epoch [12/50], Train Losses: mse: 8.5693, mae: 1.6566, huber: 1.2662, swd: 4.2943, target_std: 20.3703
    Epoch [12/50], Val Losses: mse: 12.9701, mae: 2.2929, huber: 1.8841, swd: 7.2770, target_std: 20.6844
    Epoch [12/50], Test Losses: mse: 9.4129, mae: 1.9477, huber: 1.5396, swd: 5.0170, target_std: 18.4426
      Epoch 12 composite train-obj: 1.266211
            No improvement (1.8841), counter 4/5
    Epoch [13/50], Train Losses: mse: 8.3979, mae: 1.6399, huber: 1.2503, swd: 4.1641, target_std: 20.3710
    Epoch [13/50], Val Losses: mse: 12.5158, mae: 2.2304, huber: 1.8236, swd: 7.0160, target_std: 20.6844
    Epoch [13/50], Test Losses: mse: 9.3595, mae: 1.9403, huber: 1.5296, swd: 5.0838, target_std: 18.4426
      Epoch 13 composite train-obj: 1.250271
    Epoch [13/50], Test Losses: mse: 8.5616, mae: 1.8656, huber: 1.4598, swd: 4.4619, target_std: 18.4426
    Best round's Test MSE: 8.5616, MAE: 1.8656, SWD: 4.4620
    Best round's Validation MSE: 11.8486, MAE: 2.1683
    Best round's Test verification MSE : 8.5616, MAE: 1.8656, SWD: 4.4619
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 33.4848, mae: 2.9047, huber: 2.4878, swd: 23.2096, target_std: 20.3711
    Epoch [1/50], Val Losses: mse: 14.1277, mae: 2.3685, huber: 1.9575, swd: 7.1416, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 9.9503, mae: 2.0727, huber: 1.6519, swd: 4.8801, target_std: 18.4426
      Epoch 1 composite train-obj: 2.487795
            Val objective improved inf → 1.9575, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.2246, mae: 2.0226, huber: 1.6169, swd: 6.6178, target_std: 20.3712
    Epoch [2/50], Val Losses: mse: 15.7928, mae: 2.5060, huber: 2.0932, swd: 8.3404, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 11.9811, mae: 2.2507, huber: 1.8289, swd: 6.3521, target_std: 18.4426
      Epoch 2 composite train-obj: 1.616940
            No improvement (2.0932), counter 1/5
    Epoch [3/50], Train Losses: mse: 11.2158, mae: 1.9367, huber: 1.5344, swd: 5.8654, target_std: 20.3712
    Epoch [3/50], Val Losses: mse: 12.9849, mae: 2.2686, huber: 1.8626, swd: 6.6866, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.8035, mae: 1.9111, huber: 1.5009, swd: 4.2199, target_std: 18.4426
      Epoch 3 composite train-obj: 1.534437
            Val objective improved 1.9575 → 1.8626, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.5947, mae: 1.8775, huber: 1.4779, swd: 5.4596, target_std: 20.3715
    Epoch [4/50], Val Losses: mse: 12.7654, mae: 2.2712, huber: 1.8654, swd: 6.6766, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.5430, mae: 1.8873, huber: 1.4793, swd: 4.1012, target_std: 18.4426
      Epoch 4 composite train-obj: 1.477946
            No improvement (1.8654), counter 1/5
    Epoch [5/50], Train Losses: mse: 10.1551, mae: 1.8271, huber: 1.4292, swd: 5.1862, target_std: 20.3707
    Epoch [5/50], Val Losses: mse: 12.6304, mae: 2.2413, huber: 1.8370, swd: 6.6094, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.5581, mae: 1.9012, huber: 1.4913, swd: 4.1104, target_std: 18.4426
      Epoch 5 composite train-obj: 1.429223
            Val objective improved 1.8626 → 1.8370, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 9.8861, mae: 1.7996, huber: 1.4032, swd: 5.0540, target_std: 20.3711
    Epoch [6/50], Val Losses: mse: 12.5073, mae: 2.2329, huber: 1.8292, swd: 6.5125, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.6780, mae: 1.9039, huber: 1.4931, swd: 4.2110, target_std: 18.4426
      Epoch 6 composite train-obj: 1.403212
            Val objective improved 1.8370 → 1.8292, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 9.6165, mae: 1.7637, huber: 1.3687, swd: 4.8966, target_std: 20.3712
    Epoch [7/50], Val Losses: mse: 13.0584, mae: 2.2863, huber: 1.8823, swd: 6.9209, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 9.0079, mae: 1.9257, huber: 1.5167, swd: 4.5335, target_std: 18.4426
      Epoch 7 composite train-obj: 1.368694
            No improvement (1.8823), counter 1/5
    Epoch [8/50], Train Losses: mse: 9.3868, mae: 1.7376, huber: 1.3441, swd: 4.7314, target_std: 20.3715
    Epoch [8/50], Val Losses: mse: 12.4412, mae: 2.2522, huber: 1.8472, swd: 6.4945, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 8.7099, mae: 1.8956, huber: 1.4881, swd: 4.3421, target_std: 18.4426
      Epoch 8 composite train-obj: 1.344067
            No improvement (1.8472), counter 2/5
    Epoch [9/50], Train Losses: mse: 9.0743, mae: 1.7137, huber: 1.3210, swd: 4.5054, target_std: 20.3711
    Epoch [9/50], Val Losses: mse: 13.0354, mae: 2.3188, huber: 1.9135, swd: 7.0908, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 8.9799, mae: 1.9548, huber: 1.5438, swd: 4.6743, target_std: 18.4426
      Epoch 9 composite train-obj: 1.320983
            No improvement (1.9135), counter 3/5
    Epoch [10/50], Train Losses: mse: 8.9880, mae: 1.7023, huber: 1.3099, swd: 4.4841, target_std: 20.3716
    Epoch [10/50], Val Losses: mse: 13.7465, mae: 2.3642, huber: 1.9569, swd: 7.5515, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 9.7557, mae: 1.9962, huber: 1.5853, swd: 5.2214, target_std: 18.4426
      Epoch 10 composite train-obj: 1.309902
            No improvement (1.9569), counter 4/5
    Epoch [11/50], Train Losses: mse: 8.7258, mae: 1.6834, huber: 1.2918, swd: 4.2910, target_std: 20.3709
    Epoch [11/50], Val Losses: mse: 13.3802, mae: 2.3416, huber: 1.9340, swd: 7.2936, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 8.9258, mae: 1.9359, huber: 1.5264, swd: 4.5567, target_std: 18.4426
      Epoch 11 composite train-obj: 1.291789
    Epoch [11/50], Test Losses: mse: 8.6777, mae: 1.9039, huber: 1.4931, swd: 4.2107, target_std: 18.4426
    Best round's Test MSE: 8.6780, MAE: 1.9039, SWD: 4.2110
    Best round's Validation MSE: 12.5073, MAE: 2.2329
    Best round's Test verification MSE : 8.6777, MAE: 1.9039, SWD: 4.2107
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 32.9548, mae: 2.8944, huber: 2.4782, swd: 21.2080, target_std: 20.3723
    Epoch [1/50], Val Losses: mse: 14.5866, mae: 2.4014, huber: 1.9933, swd: 7.2203, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 10.2890, mae: 2.0980, huber: 1.6778, swd: 4.9228, target_std: 18.4426
      Epoch 1 composite train-obj: 2.478203
            Val objective improved inf → 1.9933, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.1521, mae: 2.0132, huber: 1.6084, swd: 6.0933, target_std: 20.3708
    Epoch [2/50], Val Losses: mse: 13.5666, mae: 2.3256, huber: 1.9167, swd: 6.4386, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 9.3561, mae: 1.9992, huber: 1.5838, swd: 4.2136, target_std: 18.4426
      Epoch 2 composite train-obj: 1.608420
            Val objective improved 1.9933 → 1.9167, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.2652, mae: 1.9361, huber: 1.5346, swd: 5.4566, target_std: 20.3711
    Epoch [3/50], Val Losses: mse: 13.5965, mae: 2.3331, huber: 1.9285, swd: 6.8580, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 9.3027, mae: 2.0421, huber: 1.6253, swd: 4.4343, target_std: 18.4426
      Epoch 3 composite train-obj: 1.534598
            No improvement (1.9285), counter 1/5
    Epoch [4/50], Train Losses: mse: 11.1810, mae: 1.9311, huber: 1.5305, swd: 5.4288, target_std: 20.3710
    Epoch [4/50], Val Losses: mse: 13.5801, mae: 2.3164, huber: 1.9114, swd: 6.7518, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 9.5020, mae: 1.9986, huber: 1.5849, swd: 4.4871, target_std: 18.4426
      Epoch 4 composite train-obj: 1.530516
            Val objective improved 1.9167 → 1.9114, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 10.3705, mae: 1.8492, huber: 1.4514, swd: 4.9154, target_std: 20.3714
    Epoch [5/50], Val Losses: mse: 12.6134, mae: 2.2264, huber: 1.8229, swd: 6.2222, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.6058, mae: 1.8811, huber: 1.4724, swd: 3.8719, target_std: 18.4426
      Epoch 5 composite train-obj: 1.451417
            Val objective improved 1.9114 → 1.8229, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 10.0851, mae: 1.8174, huber: 1.4209, swd: 4.8110, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 12.3805, mae: 2.2119, huber: 1.8094, swd: 6.2007, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.3918, mae: 1.8657, huber: 1.4572, swd: 3.8214, target_std: 18.4426
      Epoch 6 composite train-obj: 1.420894
            Val objective improved 1.8229 → 1.8094, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 9.8011, mae: 1.7766, huber: 1.3819, swd: 4.6420, target_std: 20.3706
    Epoch [7/50], Val Losses: mse: 12.5017, mae: 2.2085, huber: 1.8065, swd: 6.5542, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 8.5495, mae: 1.9081, huber: 1.4957, swd: 4.0361, target_std: 18.4426
      Epoch 7 composite train-obj: 1.381942
            Val objective improved 1.8094 → 1.8065, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 9.6072, mae: 1.7598, huber: 1.3657, swd: 4.5586, target_std: 20.3711
    Epoch [8/50], Val Losses: mse: 12.7768, mae: 2.2578, huber: 1.8553, swd: 6.5100, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 9.0994, mae: 1.9281, huber: 1.5189, swd: 4.3047, target_std: 18.4426
      Epoch 8 composite train-obj: 1.365710
            No improvement (1.8553), counter 1/5
    Epoch [9/50], Train Losses: mse: 9.4423, mae: 1.7431, huber: 1.3499, swd: 4.4828, target_std: 20.3721
    Epoch [9/50], Val Losses: mse: 12.8182, mae: 2.2616, huber: 1.8601, swd: 6.4550, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 9.0756, mae: 1.9280, huber: 1.5188, swd: 4.3239, target_std: 18.4426
      Epoch 9 composite train-obj: 1.349924
            No improvement (1.8601), counter 2/5
    Epoch [10/50], Train Losses: mse: 9.1423, mae: 1.7038, huber: 1.3124, swd: 4.2764, target_std: 20.3722
    Epoch [10/50], Val Losses: mse: 12.1352, mae: 2.2024, huber: 1.8006, swd: 6.0419, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 8.5147, mae: 1.8870, huber: 1.4764, swd: 3.9910, target_std: 18.4426
      Epoch 10 composite train-obj: 1.312352
            Val objective improved 1.8065 → 1.8006, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 9.0611, mae: 1.6981, huber: 1.3068, swd: 4.2527, target_std: 20.3708
    Epoch [11/50], Val Losses: mse: 13.5155, mae: 2.3192, huber: 1.9163, swd: 6.9809, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 9.7637, mae: 1.9802, huber: 1.5713, swd: 4.7864, target_std: 18.4426
      Epoch 11 composite train-obj: 1.306839
            No improvement (1.9163), counter 1/5
    Epoch [12/50], Train Losses: mse: 8.9382, mae: 1.6828, huber: 1.2922, swd: 4.1637, target_std: 20.3717
    Epoch [12/50], Val Losses: mse: 12.9248, mae: 2.2618, huber: 1.8603, swd: 6.4920, target_std: 20.6844
    Epoch [12/50], Test Losses: mse: 9.0896, mae: 1.9191, huber: 1.5109, swd: 4.3407, target_std: 18.4426
      Epoch 12 composite train-obj: 1.292226
            No improvement (1.8603), counter 2/5
    Epoch [13/50], Train Losses: mse: 8.8238, mae: 1.6679, huber: 1.2783, swd: 4.0957, target_std: 20.3708
    Epoch [13/50], Val Losses: mse: 12.7220, mae: 2.2560, huber: 1.8535, swd: 6.2854, target_std: 20.6844
    Epoch [13/50], Test Losses: mse: 8.9280, mae: 1.9117, huber: 1.5026, swd: 4.2084, target_std: 18.4426
      Epoch 13 composite train-obj: 1.278250
            No improvement (1.8535), counter 3/5
    Epoch [14/50], Train Losses: mse: 8.6311, mae: 1.6439, huber: 1.2554, swd: 3.9855, target_std: 20.3713
    Epoch [14/50], Val Losses: mse: 12.7972, mae: 2.2588, huber: 1.8564, swd: 6.4404, target_std: 20.6844
    Epoch [14/50], Test Losses: mse: 9.3157, mae: 1.9524, huber: 1.5423, swd: 4.5480, target_std: 18.4426
      Epoch 14 composite train-obj: 1.255394
            No improvement (1.8564), counter 4/5
    Epoch [15/50], Train Losses: mse: 8.5228, mae: 1.6327, huber: 1.2448, swd: 3.9260, target_std: 20.3710
    Epoch [15/50], Val Losses: mse: 12.6998, mae: 2.2449, huber: 1.8420, swd: 6.3496, target_std: 20.6844
    Epoch [15/50], Test Losses: mse: 9.1898, mae: 1.9383, huber: 1.5287, swd: 4.4563, target_std: 18.4426
      Epoch 15 composite train-obj: 1.244785
    Epoch [15/50], Test Losses: mse: 8.5146, mae: 1.8870, huber: 1.4764, swd: 3.9910, target_std: 18.4426
    Best round's Test MSE: 8.5147, MAE: 1.8870, SWD: 3.9910
    Best round's Validation MSE: 12.1352, MAE: 2.2024
    Best round's Test verification MSE : 8.5146, MAE: 1.8870, SWD: 3.9910
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred96_20250501_1405)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.5848 ± 0.0686
      mae: 1.8855 ± 0.0156
      huber: 1.4764 ± 0.0136
      swd: 4.2213 ± 0.1924
      target_std: 18.4426 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 12.1637 ± 0.2697
      mae: 2.2012 ± 0.0264
      huber: 1.7986 ± 0.0258
      swd: 6.3490 ± 0.2173
      target_std: 20.6844 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq720_pred96_20250501_1405
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 39.5013, mae: 3.2140, huber: 2.7919, swd: 27.1989, ept: 150.2843
    Epoch [1/50], Val Losses: mse: 22.2635, mae: 2.9914, huber: 2.5711, swd: 10.9116, ept: 146.0327
    Epoch [1/50], Test Losses: mse: 13.4481, mae: 2.3965, huber: 1.9694, swd: 5.8739, ept: 163.0269
      Epoch 1 composite train-obj: 2.791892
            Val objective improved inf → 2.5711, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 18.6272, mae: 2.4845, huber: 2.0694, swd: 9.6829, ept: 164.1583
    Epoch [2/50], Val Losses: mse: 18.3592, mae: 2.6870, huber: 2.2698, swd: 9.5523, ept: 152.0514
    Epoch [2/50], Test Losses: mse: 11.1917, mae: 2.2135, huber: 1.7876, swd: 5.3862, ept: 166.6479
      Epoch 2 composite train-obj: 2.069355
            Val objective improved 2.5711 → 2.2698, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 17.0396, mae: 2.3378, huber: 1.9258, swd: 9.4139, ept: 169.1295
    Epoch [3/50], Val Losses: mse: 17.6138, mae: 2.6236, huber: 2.2091, swd: 9.2427, ept: 152.6356
    Epoch [3/50], Test Losses: mse: 10.7364, mae: 2.1424, huber: 1.7210, swd: 5.1715, ept: 167.5644
      Epoch 3 composite train-obj: 1.925795
            Val objective improved 2.2698 → 2.2091, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 15.5598, mae: 2.2099, huber: 1.8018, swd: 8.2452, ept: 171.5640
    Epoch [4/50], Val Losses: mse: 17.4688, mae: 2.6263, huber: 2.2119, swd: 9.2203, ept: 151.2753
    Epoch [4/50], Test Losses: mse: 10.7115, mae: 2.1249, huber: 1.7065, swd: 5.1444, ept: 167.1769
      Epoch 4 composite train-obj: 1.801754
            No improvement (2.2119), counter 1/5
    Epoch [5/50], Train Losses: mse: 14.8604, mae: 2.1577, huber: 1.7513, swd: 7.7156, ept: 172.2854
    Epoch [5/50], Val Losses: mse: 18.0724, mae: 2.6738, huber: 2.2598, swd: 9.6275, ept: 149.8960
    Epoch [5/50], Test Losses: mse: 12.3355, mae: 2.2522, huber: 1.8336, swd: 6.5657, ept: 161.3037
      Epoch 5 composite train-obj: 1.751300
            No improvement (2.2598), counter 2/5
    Epoch [6/50], Train Losses: mse: 14.2826, mae: 2.1050, huber: 1.7007, swd: 7.2849, ept: 173.1231
    Epoch [6/50], Val Losses: mse: 16.9319, mae: 2.6022, huber: 2.1931, swd: 8.7277, ept: 150.4154
    Epoch [6/50], Test Losses: mse: 10.8970, mae: 2.1363, huber: 1.7203, swd: 5.4114, ept: 164.1302
      Epoch 6 composite train-obj: 1.700672
            Val objective improved 2.2091 → 2.1931, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 14.0378, mae: 2.0841, huber: 1.6808, swd: 7.1428, ept: 173.3983
    Epoch [7/50], Val Losses: mse: 16.9363, mae: 2.6046, huber: 2.1996, swd: 8.8517, ept: 150.7180
    Epoch [7/50], Test Losses: mse: 10.6606, mae: 2.1003, huber: 1.6871, swd: 5.2919, ept: 166.4233
      Epoch 7 composite train-obj: 1.680764
            No improvement (2.1996), counter 1/5
    Epoch [8/50], Train Losses: mse: 13.7720, mae: 2.0606, huber: 1.6587, swd: 6.9697, ept: 173.7704
    Epoch [8/50], Val Losses: mse: 16.9139, mae: 2.6082, huber: 2.2049, swd: 9.0499, ept: 151.1953
    Epoch [8/50], Test Losses: mse: 10.4408, mae: 2.1003, huber: 1.6851, swd: 5.1736, ept: 167.0776
      Epoch 8 composite train-obj: 1.658689
            No improvement (2.2049), counter 2/5
    Epoch [9/50], Train Losses: mse: 13.4627, mae: 2.0295, huber: 1.6286, swd: 6.7596, ept: 174.2998
    Epoch [9/50], Val Losses: mse: 17.1528, mae: 2.6147, huber: 2.2117, swd: 9.1823, ept: 150.3818
    Epoch [9/50], Test Losses: mse: 10.8277, mae: 2.1060, huber: 1.6943, swd: 5.4824, ept: 165.9570
      Epoch 9 composite train-obj: 1.628585
            No improvement (2.2117), counter 3/5
    Epoch [10/50], Train Losses: mse: 13.2680, mae: 2.0177, huber: 1.6177, swd: 6.7078, ept: 174.4644
    Epoch [10/50], Val Losses: mse: 18.1612, mae: 2.7144, huber: 2.3094, swd: 10.0426, ept: 148.6870
    Epoch [10/50], Test Losses: mse: 10.9178, mae: 2.1122, huber: 1.7002, swd: 5.5182, ept: 163.4890
      Epoch 10 composite train-obj: 1.617674
            No improvement (2.3094), counter 4/5
    Epoch [11/50], Train Losses: mse: 13.1000, mae: 2.0018, huber: 1.6023, swd: 6.5991, ept: 174.7740
    Epoch [11/50], Val Losses: mse: 18.2346, mae: 2.7013, huber: 2.2961, swd: 10.1570, ept: 147.6127
    Epoch [11/50], Test Losses: mse: 11.5542, mae: 2.2062, huber: 1.7870, swd: 6.1040, ept: 162.2939
      Epoch 11 composite train-obj: 1.602271
    Epoch [11/50], Test Losses: mse: 10.8970, mae: 2.1363, huber: 1.7203, swd: 5.4114, ept: 164.1301
    Best round's Test MSE: 10.8970, MAE: 2.1363, SWD: 5.4114
    Best round's Validation MSE: 16.9319, MAE: 2.6022, SWD: 8.7277
    Best round's Test verification MSE : 10.8970, MAE: 2.1363, SWD: 5.4114
    Time taken: 126.47 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 40.9491, mae: 3.2531, huber: 2.8309, swd: 29.4616, ept: 149.6004
    Epoch [1/50], Val Losses: mse: 20.9237, mae: 2.8899, huber: 2.4710, swd: 9.8304, ept: 147.6276
    Epoch [1/50], Test Losses: mse: 12.7910, mae: 2.3417, huber: 1.9174, swd: 5.3365, ept: 163.3329
      Epoch 1 composite train-obj: 2.830931
            Val objective improved inf → 2.4710, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 17.4223, mae: 2.3727, huber: 1.9598, swd: 9.5822, ept: 167.9398
    Epoch [2/50], Val Losses: mse: 17.5228, mae: 2.6215, huber: 2.2053, swd: 9.3474, ept: 154.8180
    Epoch [2/50], Test Losses: mse: 10.5848, mae: 2.1302, huber: 1.7090, swd: 5.1412, ept: 167.5797
      Epoch 2 composite train-obj: 1.959787
            Val objective improved 2.4710 → 2.2053, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 15.8911, mae: 2.2369, huber: 1.8277, swd: 8.8159, ept: 171.2379
    Epoch [3/50], Val Losses: mse: 16.8008, mae: 2.5846, huber: 2.1717, swd: 8.8511, ept: 154.0338
    Epoch [3/50], Test Losses: mse: 10.6327, mae: 2.1213, huber: 1.7008, swd: 5.1737, ept: 166.7551
      Epoch 3 composite train-obj: 1.827712
            Val objective improved 2.2053 → 2.1717, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 14.9852, mae: 2.1681, huber: 1.7619, swd: 8.0639, ept: 172.0184
    Epoch [4/50], Val Losses: mse: 17.2240, mae: 2.6074, huber: 2.1969, swd: 9.2038, ept: 152.1460
    Epoch [4/50], Test Losses: mse: 10.7601, mae: 2.1049, huber: 1.6888, swd: 5.3616, ept: 166.7854
      Epoch 4 composite train-obj: 1.761931
            No improvement (2.1969), counter 1/5
    Epoch [5/50], Train Losses: mse: 14.4315, mae: 2.1262, huber: 1.7215, swd: 7.6565, ept: 172.5126
    Epoch [5/50], Val Losses: mse: 17.3720, mae: 2.6652, huber: 2.2566, swd: 9.8709, ept: 151.0894
    Epoch [5/50], Test Losses: mse: 10.6197, mae: 2.1536, huber: 1.7352, swd: 5.5700, ept: 169.3521
      Epoch 5 composite train-obj: 1.721482
            No improvement (2.2566), counter 2/5
    Epoch [6/50], Train Losses: mse: 14.1948, mae: 2.0983, huber: 1.6947, swd: 7.4781, ept: 172.8989
    Epoch [6/50], Val Losses: mse: 17.8922, mae: 2.6394, huber: 2.2300, swd: 9.8005, ept: 150.6982
    Epoch [6/50], Test Losses: mse: 11.1114, mae: 2.1313, huber: 1.7176, swd: 5.7632, ept: 165.9241
      Epoch 6 composite train-obj: 1.694698
            No improvement (2.2300), counter 3/5
    Epoch [7/50], Train Losses: mse: 13.9977, mae: 2.0796, huber: 1.6766, swd: 7.3777, ept: 173.3697
    Epoch [7/50], Val Losses: mse: 17.6322, mae: 2.6344, huber: 2.2258, swd: 9.7440, ept: 150.1170
    Epoch [7/50], Test Losses: mse: 11.1613, mae: 2.1307, huber: 1.7181, swd: 5.9332, ept: 165.4429
      Epoch 7 composite train-obj: 1.676600
            No improvement (2.2258), counter 4/5
    Epoch [8/50], Train Losses: mse: 13.7166, mae: 2.0501, huber: 1.6481, swd: 7.1938, ept: 173.8574
    Epoch [8/50], Val Losses: mse: 17.3426, mae: 2.6377, huber: 2.2285, swd: 9.5277, ept: 150.5785
    Epoch [8/50], Test Losses: mse: 10.6569, mae: 2.0988, huber: 1.6841, swd: 5.4446, ept: 167.3447
      Epoch 8 composite train-obj: 1.648055
    Epoch [8/50], Test Losses: mse: 10.6328, mae: 2.1213, huber: 1.7008, swd: 5.1738, ept: 166.7572
    Best round's Test MSE: 10.6327, MAE: 2.1213, SWD: 5.1737
    Best round's Validation MSE: 16.8008, MAE: 2.5846, SWD: 8.8511
    Best round's Test verification MSE : 10.6328, MAE: 2.1213, SWD: 5.1738
    Time taken: 92.54 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 39.2604, mae: 3.1787, huber: 2.7572, swd: 23.8380, ept: 152.4168
    Epoch [1/50], Val Losses: mse: 22.0098, mae: 2.9739, huber: 2.5546, swd: 9.7370, ept: 147.1268
    Epoch [1/50], Test Losses: mse: 13.7281, mae: 2.4238, huber: 1.9948, swd: 5.5841, ept: 163.8335
      Epoch 1 composite train-obj: 2.757204
            Val objective improved inf → 2.5546, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 18.2649, mae: 2.4663, huber: 2.0516, swd: 8.0528, ept: 164.4760
    Epoch [2/50], Val Losses: mse: 18.7698, mae: 2.7288, huber: 2.3119, swd: 7.9012, ept: 149.4407
    Epoch [2/50], Test Losses: mse: 11.7742, mae: 2.2398, huber: 1.8163, swd: 4.6127, ept: 162.8448
      Epoch 2 composite train-obj: 2.051587
            Val objective improved 2.5546 → 2.3119, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 16.0489, mae: 2.2543, huber: 1.8444, swd: 7.3217, ept: 169.7785
    Epoch [3/50], Val Losses: mse: 18.1837, mae: 2.6877, huber: 2.2702, swd: 8.1345, ept: 151.8589
    Epoch [3/50], Test Losses: mse: 12.1979, mae: 2.2665, huber: 1.8441, swd: 5.5359, ept: 161.8273
      Epoch 3 composite train-obj: 1.844376
            Val objective improved 2.3119 → 2.2702, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 15.0087, mae: 2.1624, huber: 1.7560, swd: 6.8066, ept: 172.0880
    Epoch [4/50], Val Losses: mse: 16.8331, mae: 2.6062, huber: 2.1901, swd: 7.4553, ept: 153.1883
    Epoch [4/50], Test Losses: mse: 10.5033, mae: 2.1013, huber: 1.6836, swd: 4.3644, ept: 165.9312
      Epoch 4 composite train-obj: 1.756048
            Val objective improved 2.2702 → 2.1901, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 14.2294, mae: 2.1111, huber: 1.7062, swd: 6.3502, ept: 172.8511
    Epoch [5/50], Val Losses: mse: 16.5859, mae: 2.5775, huber: 2.1643, swd: 7.3636, ept: 153.4235
    Epoch [5/50], Test Losses: mse: 10.6632, mae: 2.1009, huber: 1.6851, swd: 4.5774, ept: 166.9485
      Epoch 5 composite train-obj: 1.706169
            Val objective improved 2.1901 → 2.1643, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 13.6144, mae: 2.0517, huber: 1.6489, swd: 5.9671, ept: 173.6433
    Epoch [6/50], Val Losses: mse: 17.3553, mae: 2.6376, huber: 2.2249, swd: 8.0078, ept: 150.9120
    Epoch [6/50], Test Losses: mse: 11.0083, mae: 2.1301, huber: 1.7155, swd: 4.8548, ept: 164.8404
      Epoch 6 composite train-obj: 1.648898
            No improvement (2.2249), counter 1/5
    Epoch [7/50], Train Losses: mse: 13.4275, mae: 2.0355, huber: 1.6335, swd: 5.9175, ept: 174.0735
    Epoch [7/50], Val Losses: mse: 17.4418, mae: 2.6541, huber: 2.2433, swd: 8.1956, ept: 151.0227
    Epoch [7/50], Test Losses: mse: 11.1273, mae: 2.1333, huber: 1.7197, swd: 4.9474, ept: 164.1989
      Epoch 7 composite train-obj: 1.633475
            No improvement (2.2433), counter 2/5
    Epoch [8/50], Train Losses: mse: 12.9665, mae: 1.9931, huber: 1.5924, swd: 5.6223, ept: 174.7205
    Epoch [8/50], Val Losses: mse: 17.6593, mae: 2.6566, huber: 2.2467, swd: 8.3924, ept: 150.5834
    Epoch [8/50], Test Losses: mse: 11.6086, mae: 2.1610, huber: 1.7487, swd: 5.3163, ept: 163.8101
      Epoch 8 composite train-obj: 1.592446
            No improvement (2.2467), counter 3/5
    Epoch [9/50], Train Losses: mse: 12.5270, mae: 1.9614, huber: 1.5620, swd: 5.3391, ept: 175.1660
    Epoch [9/50], Val Losses: mse: 17.6740, mae: 2.6383, huber: 2.2309, swd: 8.6580, ept: 151.7881
    Epoch [9/50], Test Losses: mse: 11.0556, mae: 2.1392, huber: 1.7248, swd: 4.9852, ept: 165.3721
      Epoch 9 composite train-obj: 1.561956
            No improvement (2.2309), counter 4/5
    Epoch [10/50], Train Losses: mse: 12.1262, mae: 1.9365, huber: 1.5377, swd: 5.0803, ept: 175.4629
    Epoch [10/50], Val Losses: mse: 18.5991, mae: 2.7043, huber: 2.2988, swd: 9.3885, ept: 149.8682
    Epoch [10/50], Test Losses: mse: 11.6102, mae: 2.1850, huber: 1.7722, swd: 5.5095, ept: 164.4379
      Epoch 10 composite train-obj: 1.537675
    Epoch [10/50], Test Losses: mse: 10.6634, mae: 2.1009, huber: 1.6851, swd: 4.5776, ept: 166.9505
    Best round's Test MSE: 10.6632, MAE: 2.1009, SWD: 4.5774
    Best round's Validation MSE: 16.5859, MAE: 2.5775, SWD: 7.3636
    Best round's Test verification MSE : 10.6634, MAE: 2.1009, SWD: 4.5776
    Time taken: 116.41 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred196_20250512_1952)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.7310 ± 0.1181
      mae: 2.1195 ± 0.0145
      huber: 1.7021 ± 0.0144
      swd: 5.0542 ± 0.3508
      ept: 165.9446 ± 1.2854
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 16.7729 ± 0.1426
      mae: 2.5881 ± 0.0104
      huber: 2.1764 ± 0.0122
      swd: 8.3142 ± 0.6740
      ept: 152.6243 ± 1.5816
      count: 48.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 335.51 seconds
    
    Experiment complete: ACL_ettm2_seq720_pred196_20250512_1952
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 40.2700, mae: 3.2476, huber: 2.8258, swd: 28.1085, target_std: 20.3719
    Epoch [1/50], Val Losses: mse: 19.7979, mae: 2.7984, huber: 2.3817, swd: 10.1258, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 12.0607, mae: 2.2855, huber: 1.8605, swd: 5.5746, target_std: 18.4106
      Epoch 1 composite train-obj: 2.825802
            Val objective improved inf → 2.3817, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 16.9774, mae: 2.3284, huber: 1.9175, swd: 9.4229, target_std: 20.3718
    Epoch [2/50], Val Losses: mse: 18.5734, mae: 2.7024, huber: 2.2856, swd: 10.0352, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 12.8031, mae: 2.3161, huber: 1.8957, swd: 7.0501, target_std: 18.4106
      Epoch 2 composite train-obj: 1.917489
            Val objective improved 2.3817 → 2.2856, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 15.6443, mae: 2.2149, huber: 1.8077, swd: 8.4510, target_std: 20.3717
    Epoch [3/50], Val Losses: mse: 16.9793, mae: 2.5793, huber: 2.1665, swd: 9.0241, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.7108, mae: 2.1229, huber: 1.7061, swd: 5.2382, target_std: 18.4106
      Epoch 3 composite train-obj: 1.807678
            Val objective improved 2.2856 → 2.1665, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 14.7580, mae: 2.1527, huber: 1.7474, swd: 7.7162, target_std: 20.3720
    Epoch [4/50], Val Losses: mse: 16.6688, mae: 2.5752, huber: 2.1604, swd: 8.7069, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.7279, mae: 2.1561, huber: 1.7312, swd: 5.2838, target_std: 18.4106
      Epoch 4 composite train-obj: 1.747370
            Val objective improved 2.1665 → 2.1604, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 14.3265, mae: 2.1246, huber: 1.7198, swd: 7.4337, target_std: 20.3719
    Epoch [5/50], Val Losses: mse: 16.5625, mae: 2.5746, huber: 2.1628, swd: 8.6633, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 10.6229, mae: 2.1115, huber: 1.6960, swd: 5.2138, target_std: 18.4106
      Epoch 5 composite train-obj: 1.719840
            No improvement (2.1628), counter 1/5
    Epoch [6/50], Train Losses: mse: 13.9447, mae: 2.0892, huber: 1.6858, swd: 7.1956, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 16.4709, mae: 2.5822, huber: 2.1702, swd: 8.4477, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 10.7792, mae: 2.1161, huber: 1.7007, swd: 5.2747, target_std: 18.4106
      Epoch 6 composite train-obj: 1.685756
            No improvement (2.1702), counter 2/5
    Epoch [7/50], Train Losses: mse: 13.5370, mae: 2.0473, huber: 1.6450, swd: 6.9076, target_std: 20.3719
    Epoch [7/50], Val Losses: mse: 16.2229, mae: 2.5784, huber: 2.1650, swd: 8.4634, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.2362, mae: 2.0616, huber: 1.6488, swd: 4.8913, target_std: 18.4106
      Epoch 7 composite train-obj: 1.645030
            No improvement (2.1650), counter 3/5
    Epoch [8/50], Train Losses: mse: 13.1161, mae: 2.0048, huber: 1.6037, swd: 6.5974, target_std: 20.3719
    Epoch [8/50], Val Losses: mse: 15.8383, mae: 2.5511, huber: 2.1373, swd: 8.2808, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.6431, mae: 2.1282, huber: 1.7096, swd: 5.4215, target_std: 18.4106
      Epoch 8 composite train-obj: 1.603739
            Val objective improved 2.1604 → 2.1373, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 12.9559, mae: 1.9908, huber: 1.5903, swd: 6.5156, target_std: 20.3720
    Epoch [9/50], Val Losses: mse: 16.3722, mae: 2.5866, huber: 2.1730, swd: 8.6440, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 10.7103, mae: 2.1139, huber: 1.6980, swd: 5.2944, target_std: 18.4106
      Epoch 9 composite train-obj: 1.590303
            No improvement (2.1730), counter 1/5
    Epoch [10/50], Train Losses: mse: 12.5889, mae: 1.9554, huber: 1.5562, swd: 6.2545, target_std: 20.3718
    Epoch [10/50], Val Losses: mse: 16.2721, mae: 2.5763, huber: 2.1614, swd: 8.4128, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 10.7746, mae: 2.1043, huber: 1.6905, swd: 5.4137, target_std: 18.4106
      Epoch 10 composite train-obj: 1.556225
            No improvement (2.1614), counter 2/5
    Epoch [11/50], Train Losses: mse: 12.2819, mae: 1.9264, huber: 1.5280, swd: 6.0296, target_std: 20.3718
    Epoch [11/50], Val Losses: mse: 17.0296, mae: 2.6310, huber: 2.2151, swd: 9.0656, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 11.3482, mae: 2.1666, huber: 1.7505, swd: 5.8941, target_std: 18.4106
      Epoch 11 composite train-obj: 1.527969
            No improvement (2.2151), counter 3/5
    Epoch [12/50], Train Losses: mse: 11.9742, mae: 1.9000, huber: 1.5026, swd: 5.8064, target_std: 20.3718
    Epoch [12/50], Val Losses: mse: 16.9928, mae: 2.6598, huber: 2.2432, swd: 9.0594, target_std: 20.7091
    Epoch [12/50], Test Losses: mse: 11.5231, mae: 2.1458, huber: 1.7322, swd: 6.0013, target_std: 18.4106
      Epoch 12 composite train-obj: 1.502629
            No improvement (2.2432), counter 4/5
    Epoch [13/50], Train Losses: mse: 11.5522, mae: 1.8668, huber: 1.4705, swd: 5.5154, target_std: 20.3719
    Epoch [13/50], Val Losses: mse: 17.3182, mae: 2.7202, huber: 2.3024, swd: 9.5819, target_std: 20.7091
    Epoch [13/50], Test Losses: mse: 11.4070, mae: 2.1929, huber: 1.7762, swd: 6.0540, target_std: 18.4106
      Epoch 13 composite train-obj: 1.470476
    Epoch [13/50], Test Losses: mse: 10.6431, mae: 2.1282, huber: 1.7096, swd: 5.4213, target_std: 18.4106
    Best round's Test MSE: 10.6431, MAE: 2.1282, SWD: 5.4215
    Best round's Validation MSE: 15.8383, MAE: 2.5511
    Best round's Test verification MSE : 10.6431, MAE: 2.1282, SWD: 5.4213
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 37.7195, mae: 3.1440, huber: 2.7234, swd: 27.7762, target_std: 20.3721
    Epoch [1/50], Val Losses: mse: 18.5575, mae: 2.7005, huber: 2.2830, swd: 10.1217, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 11.1573, mae: 2.2043, huber: 1.7797, swd: 5.4950, target_std: 18.4106
      Epoch 1 composite train-obj: 2.723356
            Val objective improved inf → 2.2830, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 16.4050, mae: 2.2766, huber: 1.8668, swd: 9.3266, target_std: 20.3719
    Epoch [2/50], Val Losses: mse: 17.8045, mae: 2.6648, huber: 2.2455, swd: 9.5529, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 11.3968, mae: 2.1982, huber: 1.7771, swd: 5.7809, target_std: 18.4106
      Epoch 2 composite train-obj: 1.866850
            Val objective improved 2.2830 → 2.2455, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 15.3618, mae: 2.2073, huber: 1.8001, swd: 8.5007, target_std: 20.3720
    Epoch [3/50], Val Losses: mse: 16.7671, mae: 2.6197, huber: 2.2017, swd: 8.9541, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.4979, mae: 2.1091, huber: 1.6901, swd: 5.1400, target_std: 18.4106
      Epoch 3 composite train-obj: 1.800127
            Val objective improved 2.2455 → 2.2017, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 14.5300, mae: 2.1425, huber: 1.7374, swd: 7.8582, target_std: 20.3719
    Epoch [4/50], Val Losses: mse: 17.0723, mae: 2.6395, huber: 2.2227, swd: 9.3299, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.4107, mae: 2.1022, huber: 1.6843, swd: 5.1576, target_std: 18.4106
      Epoch 4 composite train-obj: 1.737429
            No improvement (2.2227), counter 1/5
    Epoch [5/50], Train Losses: mse: 13.9594, mae: 2.0902, huber: 1.6867, swd: 7.4165, target_std: 20.3719
    Epoch [5/50], Val Losses: mse: 17.8613, mae: 2.6787, huber: 2.2613, swd: 9.8229, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 11.6034, mae: 2.1703, huber: 1.7551, swd: 6.1988, target_std: 18.4106
      Epoch 5 composite train-obj: 1.686680
            No improvement (2.2613), counter 2/5
    Epoch [6/50], Train Losses: mse: 13.5563, mae: 2.0522, huber: 1.6502, swd: 7.1635, target_std: 20.3719
    Epoch [6/50], Val Losses: mse: 17.0625, mae: 2.6314, huber: 2.2167, swd: 9.1829, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 10.5337, mae: 2.0792, huber: 1.6662, swd: 5.2535, target_std: 18.4106
      Epoch 6 composite train-obj: 1.650245
            No improvement (2.2167), counter 3/5
    Epoch [7/50], Train Losses: mse: 13.2440, mae: 2.0232, huber: 1.6222, swd: 6.9779, target_std: 20.3723
    Epoch [7/50], Val Losses: mse: 17.3218, mae: 2.6293, huber: 2.2169, swd: 9.5415, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.8691, mae: 2.0883, huber: 1.6761, swd: 5.5343, target_std: 18.4106
      Epoch 7 composite train-obj: 1.622171
            No improvement (2.2169), counter 4/5
    Epoch [8/50], Train Losses: mse: 12.7948, mae: 1.9754, huber: 1.5757, swd: 6.6289, target_std: 20.3720
    Epoch [8/50], Val Losses: mse: 16.5787, mae: 2.6068, huber: 2.1942, swd: 9.1999, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.7055, mae: 2.1368, huber: 1.7175, swd: 5.5367, target_std: 18.4106
      Epoch 8 composite train-obj: 1.575747
            Val objective improved 2.2017 → 2.1942, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 12.6394, mae: 1.9652, huber: 1.5658, swd: 6.5524, target_std: 20.3719
    Epoch [9/50], Val Losses: mse: 16.9256, mae: 2.6095, huber: 2.1969, swd: 9.5132, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 11.1010, mae: 2.1385, huber: 1.7214, swd: 5.8882, target_std: 18.4106
      Epoch 9 composite train-obj: 1.565778
            No improvement (2.1969), counter 1/5
    Epoch [10/50], Train Losses: mse: 12.2915, mae: 1.9294, huber: 1.5312, swd: 6.2773, target_std: 20.3718
    Epoch [10/50], Val Losses: mse: 17.2229, mae: 2.6752, huber: 2.2598, swd: 10.0167, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 10.9851, mae: 2.1471, huber: 1.7287, swd: 5.8247, target_std: 18.4106
      Epoch 10 composite train-obj: 1.531245
            No improvement (2.2598), counter 2/5
    Epoch [11/50], Train Losses: mse: 11.9145, mae: 1.8951, huber: 1.4980, swd: 5.9836, target_std: 20.3720
    Epoch [11/50], Val Losses: mse: 17.3253, mae: 2.6569, huber: 2.2420, swd: 9.6533, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 11.5148, mae: 2.1941, huber: 1.7750, swd: 6.2265, target_std: 18.4106
      Epoch 11 composite train-obj: 1.498025
            No improvement (2.2420), counter 3/5
    Epoch [12/50], Train Losses: mse: 11.5370, mae: 1.8641, huber: 1.4684, swd: 5.6796, target_std: 20.3717
    Epoch [12/50], Val Losses: mse: 17.4138, mae: 2.6803, huber: 2.2666, swd: 9.9962, target_std: 20.7091
    Epoch [12/50], Test Losses: mse: 12.1229, mae: 2.2062, huber: 1.7913, swd: 6.7736, target_std: 18.4106
      Epoch 12 composite train-obj: 1.468426
            No improvement (2.2666), counter 4/5
    Epoch [13/50], Train Losses: mse: 11.1098, mae: 1.8455, huber: 1.4504, swd: 5.3293, target_std: 20.3719
    Epoch [13/50], Val Losses: mse: 17.9710, mae: 2.7127, huber: 2.2977, swd: 10.7871, target_std: 20.7091
    Epoch [13/50], Test Losses: mse: 11.8053, mae: 2.2321, huber: 1.8125, swd: 6.5976, target_std: 18.4106
      Epoch 13 composite train-obj: 1.450407
    Epoch [13/50], Test Losses: mse: 10.7056, mae: 2.1369, huber: 1.7175, swd: 5.5367, target_std: 18.4106
    Best round's Test MSE: 10.7055, MAE: 2.1368, SWD: 5.5367
    Best round's Validation MSE: 16.5787, MAE: 2.6068
    Best round's Test verification MSE : 10.7056, MAE: 2.1369, SWD: 5.5367
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.5653, mae: 3.1962, huber: 2.7744, swd: 23.9448, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 18.8980, mae: 2.7257, huber: 2.3100, swd: 8.4041, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 11.5856, mae: 2.2255, huber: 1.8017, swd: 4.6933, target_std: 18.4106
      Epoch 1 composite train-obj: 2.774377
            Val objective improved inf → 2.3100, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 16.6906, mae: 2.3055, huber: 1.8948, swd: 8.0585, target_std: 20.3717
    Epoch [2/50], Val Losses: mse: 17.4658, mae: 2.6311, huber: 2.2133, swd: 8.1873, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 10.6098, mae: 2.1209, huber: 1.7014, swd: 4.4934, target_std: 18.4106
      Epoch 2 composite train-obj: 1.894831
            Val objective improved 2.3100 → 2.2133, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 15.4245, mae: 2.2179, huber: 1.8100, swd: 7.2553, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 17.2337, mae: 2.6169, huber: 2.1992, swd: 8.0014, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.8529, mae: 2.1389, huber: 1.7200, swd: 4.7401, target_std: 18.4106
      Epoch 3 composite train-obj: 1.809965
            Val objective improved 2.2133 → 2.1992, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 14.4006, mae: 2.1364, huber: 1.7311, swd: 6.5460, target_std: 20.3721
    Epoch [4/50], Val Losses: mse: 17.1075, mae: 2.6279, huber: 2.2117, swd: 7.8438, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.6756, mae: 2.1046, huber: 1.6896, swd: 4.5466, target_std: 18.4106
      Epoch 4 composite train-obj: 1.731088
            No improvement (2.2117), counter 1/5
    Epoch [5/50], Train Losses: mse: 13.8935, mae: 2.0855, huber: 1.6821, swd: 6.2568, target_std: 20.3719
    Epoch [5/50], Val Losses: mse: 17.1080, mae: 2.6293, huber: 2.2136, swd: 7.9642, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 10.4594, mae: 2.0877, huber: 1.6734, swd: 4.4242, target_std: 18.4106
      Epoch 5 composite train-obj: 1.682130
            No improvement (2.2136), counter 2/5
    Epoch [6/50], Train Losses: mse: 13.6543, mae: 2.0682, huber: 1.6654, swd: 6.1491, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 17.3447, mae: 2.6107, huber: 2.1961, swd: 8.2991, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 11.0057, mae: 2.1285, huber: 1.7114, swd: 4.8963, target_std: 18.4106
      Epoch 6 composite train-obj: 1.665406
            Val objective improved 2.1992 → 2.1961, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 13.1945, mae: 2.0172, huber: 1.6163, swd: 5.8736, target_std: 20.3720
    Epoch [7/50], Val Losses: mse: 16.6778, mae: 2.6140, huber: 2.2018, swd: 8.2940, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.6384, mae: 2.1487, huber: 1.7319, swd: 4.9123, target_std: 18.4106
      Epoch 7 composite train-obj: 1.616274
            No improvement (2.2018), counter 1/5
    Epoch [8/50], Train Losses: mse: 13.0523, mae: 2.0047, huber: 1.6045, swd: 5.8449, target_std: 20.3721
    Epoch [8/50], Val Losses: mse: 16.2581, mae: 2.5742, huber: 2.1616, swd: 7.8325, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.7088, mae: 2.1206, huber: 1.7067, swd: 4.8238, target_std: 18.4106
      Epoch 8 composite train-obj: 1.604488
            Val objective improved 2.1961 → 2.1616, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 12.6607, mae: 1.9712, huber: 1.5719, swd: 5.5980, target_std: 20.3719
    Epoch [9/50], Val Losses: mse: 17.5868, mae: 2.6746, huber: 2.2602, swd: 8.6949, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 10.8908, mae: 2.1285, huber: 1.7150, swd: 4.9943, target_std: 18.4106
      Epoch 9 composite train-obj: 1.571932
            No improvement (2.2602), counter 1/5
    Epoch [10/50], Train Losses: mse: 12.4615, mae: 1.9590, huber: 1.5601, swd: 5.4496, target_std: 20.3721
    Epoch [10/50], Val Losses: mse: 16.9074, mae: 2.5846, huber: 2.1722, swd: 8.1312, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 11.2047, mae: 2.1393, huber: 1.7234, swd: 5.1873, target_std: 18.4106
      Epoch 10 composite train-obj: 1.560069
            No improvement (2.1722), counter 2/5
    Epoch [11/50], Train Losses: mse: 12.1460, mae: 1.9350, huber: 1.5372, swd: 5.2461, target_std: 20.3722
    Epoch [11/50], Val Losses: mse: 16.7709, mae: 2.6061, huber: 2.1931, swd: 8.0964, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 10.8355, mae: 2.1449, huber: 1.7266, swd: 4.9840, target_std: 18.4106
      Epoch 11 composite train-obj: 1.537167
            No improvement (2.1931), counter 3/5
    Epoch [12/50], Train Losses: mse: 11.8426, mae: 1.9112, huber: 1.5141, swd: 5.0326, target_std: 20.3721
    Epoch [12/50], Val Losses: mse: 17.1574, mae: 2.6264, huber: 2.2131, swd: 8.3727, target_std: 20.7091
    Epoch [12/50], Test Losses: mse: 10.7853, mae: 2.1262, huber: 1.7100, swd: 4.9159, target_std: 18.4106
      Epoch 12 composite train-obj: 1.514137
            No improvement (2.2131), counter 4/5
    Epoch [13/50], Train Losses: mse: 11.4574, mae: 1.8705, huber: 1.4749, swd: 4.7806, target_std: 20.3717
    Epoch [13/50], Val Losses: mse: 18.1575, mae: 2.7019, huber: 2.2887, swd: 8.9064, target_std: 20.7091
    Epoch [13/50], Test Losses: mse: 11.5499, mae: 2.1607, huber: 1.7473, swd: 5.2559, target_std: 18.4106
      Epoch 13 composite train-obj: 1.474892
    Epoch [13/50], Test Losses: mse: 10.7088, mae: 2.1206, huber: 1.7067, swd: 4.8238, target_std: 18.4106
    Best round's Test MSE: 10.7088, MAE: 2.1206, SWD: 4.8238
    Best round's Validation MSE: 16.2581, MAE: 2.5742
    Best round's Test verification MSE : 10.7088, MAE: 2.1206, SWD: 4.8238
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred196_20250501_1609)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.6858 ± 0.0302
      mae: 2.1286 ± 0.0066
      huber: 1.7113 ± 0.0046
      swd: 5.2607 ± 0.3125
      target_std: 18.4106 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 16.2250 ± 0.3032
      mae: 2.5774 ± 0.0228
      huber: 2.1643 ± 0.0233
      swd: 8.4377 ± 0.5692
      target_std: 20.7091 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq720_pred196_20250501_1609
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 45.0716, mae: 3.4655, huber: 3.0402, swd: 30.7138, ept: 231.8206
    Epoch [1/50], Val Losses: mse: 26.3582, mae: 3.3098, huber: 2.8834, swd: 12.3967, ept: 218.3838
    Epoch [1/50], Test Losses: mse: 15.9823, mae: 2.6177, huber: 2.1863, swd: 7.4277, ept: 251.3254
      Epoch 1 composite train-obj: 3.040207
            Val objective improved inf → 2.8834, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 23.4355, mae: 2.7626, huber: 2.3430, swd: 11.4023, ept: 253.5714
    Epoch [2/50], Val Losses: mse: 23.3952, mae: 3.0923, huber: 2.6665, swd: 9.6723, ept: 215.2328
    Epoch [2/50], Test Losses: mse: 15.1532, mae: 2.5462, huber: 2.1168, swd: 6.5722, ept: 244.5005
      Epoch 2 composite train-obj: 2.342969
            Val objective improved 2.8834 → 2.6665, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 21.2269, mae: 2.6062, huber: 2.1886, swd: 10.4639, ept: 260.7431
    Epoch [3/50], Val Losses: mse: 20.7446, mae: 2.9262, huber: 2.4968, swd: 8.9281, ept: 225.8164
    Epoch [3/50], Test Losses: mse: 13.7356, mae: 2.4356, huber: 2.0046, swd: 6.6516, ept: 253.7767
      Epoch 3 composite train-obj: 2.188615
            Val objective improved 2.6665 → 2.4968, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 19.3556, mae: 2.4497, huber: 2.0357, swd: 9.5404, ept: 270.0528
    Epoch [4/50], Val Losses: mse: 20.0595, mae: 2.8990, huber: 2.4715, swd: 8.6447, ept: 229.0693
    Epoch [4/50], Test Losses: mse: 12.8747, mae: 2.3147, huber: 1.8921, swd: 6.0362, ept: 256.6120
      Epoch 4 composite train-obj: 2.035680
            Val objective improved 2.4968 → 2.4715, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 18.4817, mae: 2.3788, huber: 1.9671, swd: 8.9329, ept: 272.3633
    Epoch [5/50], Val Losses: mse: 19.9219, mae: 2.9318, huber: 2.5064, swd: 8.4931, ept: 229.9794
    Epoch [5/50], Test Losses: mse: 12.7670, mae: 2.3000, huber: 1.8799, swd: 5.9585, ept: 257.1230
      Epoch 5 composite train-obj: 1.967052
            No improvement (2.5064), counter 1/5
    Epoch [6/50], Train Losses: mse: 18.0537, mae: 2.3409, huber: 1.9306, swd: 8.6338, ept: 273.3386
    Epoch [6/50], Val Losses: mse: 20.5084, mae: 2.9612, huber: 2.5375, swd: 9.0995, ept: 229.5573
    Epoch [6/50], Test Losses: mse: 12.5186, mae: 2.2864, huber: 1.8674, swd: 5.8763, ept: 258.3157
      Epoch 6 composite train-obj: 1.930584
            No improvement (2.5375), counter 2/5
    Epoch [7/50], Train Losses: mse: 17.6190, mae: 2.3040, huber: 1.8949, swd: 8.3542, ept: 274.6176
    Epoch [7/50], Val Losses: mse: 21.1479, mae: 3.0529, huber: 2.6291, swd: 9.6744, ept: 226.4113
    Epoch [7/50], Test Losses: mse: 12.8574, mae: 2.3259, huber: 1.9052, swd: 6.0724, ept: 257.5639
      Epoch 7 composite train-obj: 1.894945
            No improvement (2.6291), counter 3/5
    Epoch [8/50], Train Losses: mse: 17.2430, mae: 2.2732, huber: 1.8653, swd: 8.1069, ept: 275.6641
    Epoch [8/50], Val Losses: mse: 20.4221, mae: 2.9439, huber: 2.5240, swd: 9.2336, ept: 228.3949
    Epoch [8/50], Test Losses: mse: 13.0220, mae: 2.3637, huber: 1.9376, swd: 6.3822, ept: 258.8567
      Epoch 8 composite train-obj: 1.865332
            No improvement (2.5240), counter 4/5
    Epoch [9/50], Train Losses: mse: 16.9603, mae: 2.2527, huber: 1.8460, swd: 7.9601, ept: 276.3777
    Epoch [9/50], Val Losses: mse: 24.6030, mae: 3.2019, huber: 2.7844, swd: 12.1350, ept: 216.9075
    Epoch [9/50], Test Losses: mse: 16.9396, mae: 2.6359, huber: 2.2151, swd: 9.6153, ept: 242.5370
      Epoch 9 composite train-obj: 1.845962
    Epoch [9/50], Test Losses: mse: 12.8747, mae: 2.3147, huber: 1.8921, swd: 6.0362, ept: 256.6054
    Best round's Test MSE: 12.8747, MAE: 2.3147, SWD: 6.0362
    Best round's Validation MSE: 20.0595, MAE: 2.8990, SWD: 8.6447
    Best round's Test verification MSE : 12.8747, MAE: 2.3147, SWD: 6.0362
    Time taken: 114.61 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 43.7320, mae: 3.4072, huber: 2.9823, swd: 30.3461, ept: 233.7231
    Epoch [1/50], Val Losses: mse: 27.5776, mae: 3.3912, huber: 2.9666, swd: 14.5105, ept: 214.6023
    Epoch [1/50], Test Losses: mse: 16.8779, mae: 2.6832, huber: 2.2515, swd: 8.9340, ept: 249.1610
      Epoch 1 composite train-obj: 2.982290
            Val objective improved inf → 2.9666, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 22.6713, mae: 2.7167, huber: 2.2975, swd: 11.3199, ept: 254.6300
    Epoch [2/50], Val Losses: mse: 22.6526, mae: 3.0681, huber: 2.6424, swd: 9.5792, ept: 215.8930
    Epoch [2/50], Test Losses: mse: 14.6631, mae: 2.5018, huber: 2.0748, swd: 6.6516, ept: 240.4663
      Epoch 2 composite train-obj: 2.297496
            Val objective improved 2.9666 → 2.6424, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 20.2899, mae: 2.5466, huber: 2.1301, swd: 10.1433, ept: 260.5935
    Epoch [3/50], Val Losses: mse: 21.1849, mae: 2.9533, huber: 2.5267, swd: 9.5796, ept: 222.7809
    Epoch [3/50], Test Losses: mse: 14.2459, mae: 2.4342, huber: 2.0091, swd: 7.3360, ept: 248.9837
      Epoch 3 composite train-obj: 2.130076
            Val objective improved 2.6424 → 2.5267, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 18.5713, mae: 2.3989, huber: 1.9860, swd: 9.2196, ept: 270.8133
    Epoch [4/50], Val Losses: mse: 20.1177, mae: 2.8990, huber: 2.4694, swd: 8.9387, ept: 226.3775
    Epoch [4/50], Test Losses: mse: 13.2086, mae: 2.3685, huber: 1.9412, swd: 6.5759, ept: 253.7697
      Epoch 4 composite train-obj: 1.986001
            Val objective improved 2.5267 → 2.4694, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 17.8149, mae: 2.3342, huber: 1.9231, swd: 8.7537, ept: 273.7316
    Epoch [5/50], Val Losses: mse: 19.9862, mae: 2.8876, huber: 2.4606, swd: 9.0007, ept: 228.2264
    Epoch [5/50], Test Losses: mse: 13.4393, mae: 2.3878, huber: 1.9609, swd: 6.9614, ept: 253.3178
      Epoch 5 composite train-obj: 1.923140
            Val objective improved 2.4694 → 2.4606, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 17.2372, mae: 2.2840, huber: 1.8748, swd: 8.3582, ept: 275.4771
    Epoch [6/50], Val Losses: mse: 20.2339, mae: 2.9291, huber: 2.5055, swd: 9.6555, ept: 230.1739
    Epoch [6/50], Test Losses: mse: 13.3729, mae: 2.3828, huber: 1.9585, swd: 6.9645, ept: 258.3512
      Epoch 6 composite train-obj: 1.874813
            No improvement (2.5055), counter 1/5
    Epoch [7/50], Train Losses: mse: 16.8313, mae: 2.2567, huber: 1.8482, swd: 8.1045, ept: 276.5046
    Epoch [7/50], Val Losses: mse: 20.3962, mae: 2.8907, huber: 2.4725, swd: 9.6436, ept: 229.5027
    Epoch [7/50], Test Losses: mse: 13.8301, mae: 2.4043, huber: 1.9827, swd: 7.4967, ept: 253.3050
      Epoch 7 composite train-obj: 1.848238
            No improvement (2.4725), counter 2/5
    Epoch [8/50], Train Losses: mse: 16.1544, mae: 2.2066, huber: 1.7998, swd: 7.5962, ept: 277.9858
    Epoch [8/50], Val Losses: mse: 21.7303, mae: 3.0083, huber: 2.5891, swd: 10.6872, ept: 227.0342
    Epoch [8/50], Test Losses: mse: 14.5540, mae: 2.4297, huber: 2.0104, swd: 7.9546, ept: 252.7179
      Epoch 8 composite train-obj: 1.799802
            No improvement (2.5891), counter 3/5
    Epoch [9/50], Train Losses: mse: 15.6530, mae: 2.1744, huber: 1.7686, swd: 7.1991, ept: 278.9187
    Epoch [9/50], Val Losses: mse: 21.0152, mae: 2.9532, huber: 2.5381, swd: 10.4353, ept: 229.9901
    Epoch [9/50], Test Losses: mse: 14.5871, mae: 2.4279, huber: 2.0083, swd: 8.1676, ept: 254.4007
      Epoch 9 composite train-obj: 1.768567
            No improvement (2.5381), counter 4/5
    Epoch [10/50], Train Losses: mse: 15.0447, mae: 2.1293, huber: 1.7248, swd: 6.7288, ept: 280.4636
    Epoch [10/50], Val Losses: mse: 22.7995, mae: 3.0411, huber: 2.6298, swd: 11.8180, ept: 224.2957
    Epoch [10/50], Test Losses: mse: 16.0726, mae: 2.5360, huber: 2.1163, swd: 9.4057, ept: 250.1361
      Epoch 10 composite train-obj: 1.724815
    Epoch [10/50], Test Losses: mse: 13.4387, mae: 2.3877, huber: 1.9608, swd: 6.9607, ept: 253.2781
    Best round's Test MSE: 13.4393, MAE: 2.3878, SWD: 6.9614
    Best round's Validation MSE: 19.9862, MAE: 2.8876, SWD: 9.0007
    Best round's Test verification MSE : 13.4387, MAE: 2.3877, SWD: 6.9607
    Time taken: 130.53 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 42.0766, mae: 3.3681, huber: 2.9434, swd: 26.7728, ept: 235.4261
    Epoch [1/50], Val Losses: mse: 24.5323, mae: 3.1892, huber: 2.7652, swd: 9.6963, ept: 222.9795
    Epoch [1/50], Test Losses: mse: 14.9367, mae: 2.5495, huber: 2.1186, swd: 5.9183, ept: 255.5699
      Epoch 1 composite train-obj: 2.943441
            Val objective improved inf → 2.7652, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 22.0549, mae: 2.6699, huber: 2.2514, swd: 10.4684, ept: 257.6742
    Epoch [2/50], Val Losses: mse: 20.7732, mae: 2.9167, huber: 2.4925, swd: 8.6810, ept: 226.9453
    Epoch [2/50], Test Losses: mse: 13.3201, mae: 2.4055, huber: 1.9762, swd: 5.9548, ept: 254.1941
      Epoch 2 composite train-obj: 2.251378
            Val objective improved 2.7652 → 2.4925, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 19.6027, mae: 2.4685, huber: 2.0540, swd: 9.5297, ept: 269.8797
    Epoch [3/50], Val Losses: mse: 20.3797, mae: 2.8704, huber: 2.4468, swd: 8.6043, ept: 230.4715
    Epoch [3/50], Test Losses: mse: 13.7113, mae: 2.4029, huber: 1.9770, swd: 6.4235, ept: 253.7045
      Epoch 3 composite train-obj: 2.054048
            Val objective improved 2.4925 → 2.4468, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 18.4869, mae: 2.3865, huber: 1.9745, swd: 8.7389, ept: 272.9728
    Epoch [4/50], Val Losses: mse: 19.3060, mae: 2.8515, huber: 2.4259, swd: 7.8222, ept: 232.9651
    Epoch [4/50], Test Losses: mse: 12.7091, mae: 2.3334, huber: 1.9074, swd: 5.7771, ept: 257.5649
      Epoch 4 composite train-obj: 1.974509
            Val objective improved 2.4468 → 2.4259, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 18.0276, mae: 2.3593, huber: 1.9486, swd: 8.4648, ept: 273.4508
    Epoch [5/50], Val Losses: mse: 21.0149, mae: 3.0278, huber: 2.6044, swd: 9.7066, ept: 228.6772
    Epoch [5/50], Test Losses: mse: 13.3262, mae: 2.4393, huber: 2.0105, swd: 6.5928, ept: 260.9000
      Epoch 5 composite train-obj: 1.948627
            No improvement (2.6044), counter 1/5
    Epoch [6/50], Train Losses: mse: 17.1140, mae: 2.2799, huber: 1.8712, swd: 7.7403, ept: 276.2105
    Epoch [6/50], Val Losses: mse: 19.7008, mae: 2.8744, huber: 2.4553, swd: 8.4435, ept: 231.9439
    Epoch [6/50], Test Losses: mse: 13.1751, mae: 2.4100, huber: 1.9792, swd: 6.3923, ept: 259.7860
      Epoch 6 composite train-obj: 1.871183
            No improvement (2.4553), counter 2/5
    Epoch [7/50], Train Losses: mse: 16.7382, mae: 2.2536, huber: 1.8458, swd: 7.5029, ept: 276.8734
    Epoch [7/50], Val Losses: mse: 20.0656, mae: 2.8979, huber: 2.4824, swd: 8.6064, ept: 228.7157
    Epoch [7/50], Test Losses: mse: 13.0081, mae: 2.3604, huber: 1.9363, swd: 6.2029, ept: 260.3280
      Epoch 7 composite train-obj: 1.845794
            No improvement (2.4824), counter 3/5
    Epoch [8/50], Train Losses: mse: 16.3602, mae: 2.2212, huber: 1.8142, swd: 7.2714, ept: 278.0435
    Epoch [8/50], Val Losses: mse: 19.7534, mae: 2.8593, huber: 2.4457, swd: 8.7642, ept: 232.5597
    Epoch [8/50], Test Losses: mse: 13.3560, mae: 2.3569, huber: 1.9384, swd: 6.4770, ept: 260.6687
      Epoch 8 composite train-obj: 1.814151
            No improvement (2.4457), counter 4/5
    Epoch [9/50], Train Losses: mse: 15.8855, mae: 2.1849, huber: 1.7791, swd: 6.9466, ept: 278.9830
    Epoch [9/50], Val Losses: mse: 20.8071, mae: 2.9353, huber: 2.5182, swd: 9.3414, ept: 229.3520
    Epoch [9/50], Test Losses: mse: 13.6673, mae: 2.3850, huber: 1.9628, swd: 6.6419, ept: 257.1890
      Epoch 9 composite train-obj: 1.779119
    Epoch [9/50], Test Losses: mse: 12.7090, mae: 2.3334, huber: 1.9074, swd: 5.7770, ept: 257.5658
    Best round's Test MSE: 12.7091, MAE: 2.3334, SWD: 5.7771
    Best round's Validation MSE: 19.3060, MAE: 2.8515, SWD: 7.8222
    Best round's Test verification MSE : 12.7090, MAE: 2.3334, SWD: 5.7770
    Time taken: 117.71 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred336_20250512_1958)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 13.0077 ± 0.3126
      mae: 2.3453 ± 0.0310
      huber: 1.9201 ± 0.0295
      swd: 6.2582 ± 0.5083
      ept: 255.8316 ± 1.8195
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 19.7839 ± 0.3392
      mae: 2.8794 ± 0.0203
      huber: 2.4527 ± 0.0195
      swd: 8.4892 ± 0.4935
      ept: 230.0869 ± 2.0641
      count: 47.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 362.95 seconds
    
    Experiment complete: ACL_ettm2_seq720_pred336_20250512_1958
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 44.4868, mae: 3.4821, huber: 3.0571, swd: 29.8106, target_std: 20.3729
    Epoch [1/50], Val Losses: mse: 23.5249, mae: 3.1181, huber: 2.6945, swd: 9.9087, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 14.5445, mae: 2.4994, huber: 2.0706, swd: 6.2777, target_std: 18.3950
      Epoch 1 composite train-obj: 3.057056
            Val objective improved inf → 2.6945, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.2667, mae: 2.5615, huber: 2.1462, swd: 10.9849, target_std: 20.3731
    Epoch [2/50], Val Losses: mse: 20.4864, mae: 2.9516, huber: 2.5275, swd: 9.4494, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.6113, mae: 2.3152, huber: 1.8921, swd: 5.9762, target_std: 18.3950
      Epoch 2 composite train-obj: 2.146191
            Val objective improved 2.6945 → 2.5275, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 19.4348, mae: 2.4466, huber: 2.0343, swd: 9.8386, target_std: 20.3733
    Epoch [3/50], Val Losses: mse: 19.6941, mae: 2.8915, huber: 2.4684, swd: 8.7271, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.5707, mae: 2.3223, huber: 1.8987, swd: 5.9101, target_std: 18.3950
      Epoch 3 composite train-obj: 2.034348
            Val objective improved 2.5275 → 2.4684, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 18.4112, mae: 2.3836, huber: 1.9733, swd: 9.0934, target_std: 20.3732
    Epoch [4/50], Val Losses: mse: 20.6697, mae: 2.9029, huber: 2.4831, swd: 9.2967, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 13.5449, mae: 2.3638, huber: 1.9436, swd: 6.6201, target_std: 18.3950
      Epoch 4 composite train-obj: 1.973344
            No improvement (2.4831), counter 1/5
    Epoch [5/50], Train Losses: mse: 17.6303, mae: 2.3269, huber: 1.9185, swd: 8.5211, target_std: 20.3736
    Epoch [5/50], Val Losses: mse: 21.7594, mae: 3.0039, huber: 2.5835, swd: 10.3837, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 14.4327, mae: 2.4200, huber: 2.0024, swd: 7.5023, target_std: 18.3950
      Epoch 5 composite train-obj: 1.918495
            No improvement (2.5835), counter 2/5
    Epoch [6/50], Train Losses: mse: 17.1422, mae: 2.2956, huber: 1.8884, swd: 8.1656, target_std: 20.3734
    Epoch [6/50], Val Losses: mse: 21.8001, mae: 3.0314, huber: 2.6099, swd: 10.1055, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 13.8509, mae: 2.4017, huber: 1.9807, swd: 6.8509, target_std: 18.3950
      Epoch 6 composite train-obj: 1.888352
            No improvement (2.6099), counter 3/5
    Epoch [7/50], Train Losses: mse: 16.6124, mae: 2.2521, huber: 1.8459, swd: 7.7867, target_std: 20.3732
    Epoch [7/50], Val Losses: mse: 20.3077, mae: 2.9217, huber: 2.5031, swd: 9.1125, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 13.1977, mae: 2.3512, huber: 1.9295, swd: 6.5505, target_std: 18.3950
      Epoch 7 composite train-obj: 1.845933
            No improvement (2.5031), counter 4/5
    Epoch [8/50], Train Losses: mse: 15.9145, mae: 2.1900, huber: 1.7858, swd: 7.2990, target_std: 20.3731
    Epoch [8/50], Val Losses: mse: 20.9747, mae: 2.9483, huber: 2.5314, swd: 9.7522, target_std: 20.7022
    Epoch [8/50], Test Losses: mse: 13.7657, mae: 2.3798, huber: 1.9586, swd: 6.9515, target_std: 18.3950
      Epoch 8 composite train-obj: 1.785829
    Epoch [8/50], Test Losses: mse: 12.5707, mae: 2.3223, huber: 1.8987, swd: 5.9102, target_std: 18.3950
    Best round's Test MSE: 12.5707, MAE: 2.3223, SWD: 5.9101
    Best round's Validation MSE: 19.6941, MAE: 2.8915
    Best round's Test verification MSE : 12.5707, MAE: 2.3223, SWD: 5.9102
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 42.5914, mae: 3.4074, huber: 2.9827, swd: 30.3335, target_std: 20.3734
    Epoch [1/50], Val Losses: mse: 23.1458, mae: 3.1020, huber: 2.6782, swd: 9.9660, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 14.5631, mae: 2.4958, huber: 2.0687, swd: 6.6558, target_std: 18.3950
      Epoch 1 composite train-obj: 2.982749
            Val objective improved inf → 2.6782, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.0693, mae: 2.5678, huber: 2.1519, swd: 11.3801, target_std: 20.3733
    Epoch [2/50], Val Losses: mse: 20.3623, mae: 2.9130, huber: 2.4872, swd: 9.6031, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.6126, mae: 2.3122, huber: 1.8894, swd: 6.2458, target_std: 18.3950
      Epoch 2 composite train-obj: 2.151893
            Val objective improved 2.6782 → 2.4872, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 19.0606, mae: 2.4312, huber: 2.0190, swd: 9.9113, target_std: 20.3735
    Epoch [3/50], Val Losses: mse: 20.9452, mae: 2.9970, huber: 2.5728, swd: 10.9132, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 13.2086, mae: 2.4259, huber: 1.9983, swd: 7.2358, target_std: 18.3950
      Epoch 3 composite train-obj: 2.018975
            No improvement (2.5728), counter 1/5
    Epoch [4/50], Train Losses: mse: 18.2167, mae: 2.3660, huber: 1.9559, swd: 9.2563, target_std: 20.3733
    Epoch [4/50], Val Losses: mse: 20.2233, mae: 2.9469, huber: 2.5260, swd: 9.9487, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 13.0503, mae: 2.3530, huber: 1.9345, swd: 6.7671, target_std: 18.3950
      Epoch 4 composite train-obj: 1.955897
            No improvement (2.5260), counter 2/5
    Epoch [5/50], Train Losses: mse: 17.6182, mae: 2.3290, huber: 1.9198, swd: 8.8187, target_std: 20.3737
    Epoch [5/50], Val Losses: mse: 20.0444, mae: 2.8751, huber: 2.4532, swd: 9.4022, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 13.0384, mae: 2.3102, huber: 1.8927, swd: 6.6588, target_std: 18.3950
      Epoch 5 composite train-obj: 1.919845
            Val objective improved 2.4872 → 2.4532, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 16.9098, mae: 2.2764, huber: 1.8686, swd: 8.2756, target_std: 20.3730
    Epoch [6/50], Val Losses: mse: 20.2116, mae: 2.8569, huber: 2.4372, swd: 9.5043, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 13.1850, mae: 2.3573, huber: 1.9353, swd: 6.7913, target_std: 18.3950
      Epoch 6 composite train-obj: 1.868559
            Val objective improved 2.4532 → 2.4372, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 16.3701, mae: 2.2366, huber: 1.8297, swd: 7.8906, target_std: 20.3739
    Epoch [7/50], Val Losses: mse: 21.3073, mae: 2.9386, huber: 2.5172, swd: 10.5603, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 14.3519, mae: 2.4295, huber: 2.0063, swd: 7.9145, target_std: 18.3950
      Epoch 7 composite train-obj: 1.829653
            No improvement (2.5172), counter 1/5
    Epoch [8/50], Train Losses: mse: 16.0318, mae: 2.2082, huber: 1.8019, swd: 7.6922, target_std: 20.3730
    Epoch [8/50], Val Losses: mse: 20.0500, mae: 2.9142, huber: 2.4914, swd: 9.7326, target_std: 20.7022
    Epoch [8/50], Test Losses: mse: 13.1059, mae: 2.3368, huber: 1.9166, swd: 6.7536, target_std: 18.3950
      Epoch 8 composite train-obj: 1.801948
            No improvement (2.4914), counter 2/5
    Epoch [9/50], Train Losses: mse: 15.2536, mae: 2.1472, huber: 1.7424, swd: 7.1439, target_std: 20.3733
    Epoch [9/50], Val Losses: mse: 20.3463, mae: 2.8746, huber: 2.4563, swd: 9.9586, target_std: 20.7022
    Epoch [9/50], Test Losses: mse: 13.8043, mae: 2.3853, huber: 1.9643, swd: 7.4089, target_std: 18.3950
      Epoch 9 composite train-obj: 1.742447
            No improvement (2.4563), counter 3/5
    Epoch [10/50], Train Losses: mse: 14.7729, mae: 2.1184, huber: 1.7143, swd: 6.8103, target_std: 20.3737
    Epoch [10/50], Val Losses: mse: 20.6782, mae: 2.9590, huber: 2.5366, swd: 10.3815, target_std: 20.7022
    Epoch [10/50], Test Losses: mse: 14.2127, mae: 2.4371, huber: 2.0158, swd: 7.6291, target_std: 18.3950
      Epoch 10 composite train-obj: 1.714317
            No improvement (2.5366), counter 4/5
    Epoch [11/50], Train Losses: mse: 14.1832, mae: 2.0760, huber: 1.6729, swd: 6.4159, target_std: 20.3733
    Epoch [11/50], Val Losses: mse: 21.3098, mae: 2.9693, huber: 2.5495, swd: 10.8824, target_std: 20.7022
    Epoch [11/50], Test Losses: mse: 14.2803, mae: 2.4338, huber: 2.0114, swd: 7.4803, target_std: 18.3950
      Epoch 11 composite train-obj: 1.672888
    Epoch [11/50], Test Losses: mse: 13.1855, mae: 2.3573, huber: 1.9354, swd: 6.7917, target_std: 18.3950
    Best round's Test MSE: 13.1850, MAE: 2.3573, SWD: 6.7913
    Best round's Validation MSE: 20.2116, MAE: 2.8569
    Best round's Test verification MSE : 13.1855, MAE: 2.3573, SWD: 6.7917
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 42.8253, mae: 3.4008, huber: 2.9761, swd: 27.6977, target_std: 20.3731
    Epoch [1/50], Val Losses: mse: 23.3986, mae: 3.1206, huber: 2.6985, swd: 10.4622, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 14.4807, mae: 2.5106, huber: 2.0804, swd: 6.6884, target_std: 18.3950
      Epoch 1 composite train-obj: 2.976078
            Val objective improved inf → 2.6985, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 20.9375, mae: 2.5704, huber: 2.1546, swd: 10.5456, target_std: 20.3733
    Epoch [2/50], Val Losses: mse: 20.1385, mae: 2.8724, huber: 2.4490, swd: 8.6282, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.8238, mae: 2.3547, huber: 1.9271, swd: 5.9114, target_std: 18.3950
      Epoch 2 composite train-obj: 2.154630
            Val objective improved 2.6985 → 2.4490, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 19.3718, mae: 2.4427, huber: 2.0304, swd: 9.5536, target_std: 20.3739
    Epoch [3/50], Val Losses: mse: 19.7878, mae: 2.8777, huber: 2.4531, swd: 8.3800, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.7910, mae: 2.3410, huber: 1.9163, swd: 5.8633, target_std: 18.3950
      Epoch 3 composite train-obj: 2.030424
            No improvement (2.4531), counter 1/5
    Epoch [4/50], Train Losses: mse: 18.4629, mae: 2.3717, huber: 1.9615, swd: 8.8285, target_std: 20.3733
    Epoch [4/50], Val Losses: mse: 20.1262, mae: 2.9068, huber: 2.4823, swd: 8.6136, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 13.0216, mae: 2.3298, huber: 1.9095, swd: 5.9833, target_std: 18.3950
      Epoch 4 composite train-obj: 1.961535
            No improvement (2.4823), counter 2/5
    Epoch [5/50], Train Losses: mse: 17.9362, mae: 2.3428, huber: 1.9334, swd: 8.4629, target_std: 20.3733
    Epoch [5/50], Val Losses: mse: 20.8937, mae: 2.9021, huber: 2.4819, swd: 9.1657, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 14.0493, mae: 2.3951, huber: 1.9750, swd: 6.7781, target_std: 18.3950
      Epoch 5 composite train-obj: 1.933371
            No improvement (2.4819), counter 3/5
    Epoch [6/50], Train Losses: mse: 17.2919, mae: 2.2973, huber: 1.8889, swd: 8.0162, target_std: 20.3737
    Epoch [6/50], Val Losses: mse: 20.3619, mae: 2.9317, huber: 2.5118, swd: 9.1288, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 12.8299, mae: 2.3247, huber: 1.9061, swd: 6.0090, target_std: 18.3950
      Epoch 6 composite train-obj: 1.888880
            No improvement (2.5118), counter 4/5
    Epoch [7/50], Train Losses: mse: 16.4709, mae: 2.2287, huber: 1.8223, swd: 7.4461, target_std: 20.3740
    Epoch [7/50], Val Losses: mse: 20.2710, mae: 2.9067, huber: 2.4862, swd: 8.7784, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 13.6822, mae: 2.3478, huber: 1.9306, swd: 6.5471, target_std: 18.3950
      Epoch 7 composite train-obj: 1.822283
    Epoch [7/50], Test Losses: mse: 12.8238, mae: 2.3547, huber: 1.9270, swd: 5.9114, target_std: 18.3950
    Best round's Test MSE: 12.8238, MAE: 2.3547, SWD: 5.9114
    Best round's Validation MSE: 20.1385, MAE: 2.8724
    Best round's Test verification MSE : 12.8238, MAE: 2.3547, SWD: 5.9114
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred336_20250501_1743)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.8598 ± 0.2521
      mae: 2.3448 ± 0.0159
      huber: 1.9204 ± 0.0157
      swd: 6.2043 ± 0.4151
      target_std: 18.3950 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 20.0147 ± 0.2287
      mae: 2.8736 ± 0.0142
      huber: 2.4515 ± 0.0129
      swd: 8.9532 ± 0.3918
      target_std: 20.7022 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq720_pred336_20250501_1743
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 48.4727, mae: 3.7145, huber: 3.2843, swd: 29.9034, ept: 406.7400
    Epoch [1/50], Val Losses: mse: 28.6741, mae: 3.5698, huber: 3.1343, swd: 10.4836, ept: 369.4933
    Epoch [1/50], Test Losses: mse: 17.9050, mae: 2.8001, huber: 2.3644, swd: 6.8375, ept: 436.1561
      Epoch 1 composite train-obj: 3.284260
            Val objective improved inf → 3.1343, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.5770, mae: 3.0689, huber: 2.6433, swd: 13.5945, ept: 446.5440
    Epoch [2/50], Val Losses: mse: 28.3912, mae: 3.5840, huber: 3.1490, swd: 13.3063, ept: 369.5016
    Epoch [2/50], Test Losses: mse: 17.7588, mae: 2.8038, huber: 2.3678, swd: 8.7617, ept: 436.0294
      Epoch 2 composite train-obj: 2.643299
            No improvement (3.1490), counter 1/5
    Epoch [3/50], Train Losses: mse: 26.4731, mae: 2.8364, huber: 2.4144, swd: 12.1930, ept: 481.0246
    Epoch [3/50], Val Losses: mse: 24.3586, mae: 3.2782, huber: 2.8434, swd: 8.9572, ept: 389.0643
    Epoch [3/50], Test Losses: mse: 15.8247, mae: 2.5991, huber: 2.1674, swd: 6.8836, ept: 444.6999
      Epoch 3 composite train-obj: 2.414358
            Val objective improved 3.1343 → 2.8434, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 25.3329, mae: 2.7490, huber: 2.3289, swd: 11.4283, ept: 491.4619
    Epoch [4/50], Val Losses: mse: 24.4604, mae: 3.3335, huber: 2.8957, swd: 8.8714, ept: 387.1286
    Epoch [4/50], Test Losses: mse: 15.6790, mae: 2.5874, huber: 2.1563, swd: 6.7231, ept: 439.0486
      Epoch 4 composite train-obj: 2.328867
            No improvement (2.8957), counter 1/5
    Epoch [5/50], Train Losses: mse: 24.5753, mae: 2.6885, huber: 2.2698, swd: 10.8841, ept: 495.2871
    Epoch [5/50], Val Losses: mse: 25.3565, mae: 3.3597, huber: 2.9263, swd: 9.9358, ept: 387.8912
    Epoch [5/50], Test Losses: mse: 15.5580, mae: 2.6097, huber: 2.1777, swd: 6.8936, ept: 448.4432
      Epoch 5 composite train-obj: 2.269825
            No improvement (2.9263), counter 2/5
    Epoch [6/50], Train Losses: mse: 23.9642, mae: 2.6432, huber: 2.2264, swd: 10.4378, ept: 496.9822
    Epoch [6/50], Val Losses: mse: 25.7347, mae: 3.3767, huber: 2.9509, swd: 10.0207, ept: 386.1420
    Epoch [6/50], Test Losses: mse: 15.5447, mae: 2.5737, huber: 2.1461, swd: 6.8017, ept: 443.4502
      Epoch 6 composite train-obj: 2.226395
            No improvement (2.9509), counter 3/5
    Epoch [7/50], Train Losses: mse: 23.5790, mae: 2.6180, huber: 2.2018, swd: 10.2047, ept: 497.5672
    Epoch [7/50], Val Losses: mse: 26.6014, mae: 3.4116, huber: 2.9866, swd: 10.7742, ept: 379.5037
    Epoch [7/50], Test Losses: mse: 16.9155, mae: 2.6511, huber: 2.2251, swd: 7.8891, ept: 435.6572
      Epoch 7 composite train-obj: 2.201846
            No improvement (2.9866), counter 4/5
    Epoch [8/50], Train Losses: mse: 23.1488, mae: 2.5831, huber: 2.1680, swd: 9.8989, ept: 499.8420
    Epoch [8/50], Val Losses: mse: 26.1098, mae: 3.4457, huber: 3.0217, swd: 10.9148, ept: 389.3496
    Epoch [8/50], Test Losses: mse: 16.1446, mae: 2.6132, huber: 2.1896, swd: 7.3535, ept: 449.7162
      Epoch 8 composite train-obj: 2.168039
    Epoch [8/50], Test Losses: mse: 15.8246, mae: 2.5990, huber: 2.1673, swd: 6.8835, ept: 444.7028
    Best round's Test MSE: 15.8247, MAE: 2.5991, SWD: 6.8836
    Best round's Validation MSE: 24.3586, MAE: 3.2782, SWD: 8.9572
    Best round's Test verification MSE : 15.8246, MAE: 2.5990, SWD: 6.8835
    Time taken: 103.77 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 50.1060, mae: 3.7521, huber: 3.3217, swd: 28.9899, ept: 404.4582
    Epoch [1/50], Val Losses: mse: 29.8163, mae: 3.6493, huber: 3.2120, swd: 11.4233, ept: 372.2009
    Epoch [1/50], Test Losses: mse: 18.3016, mae: 2.8263, huber: 2.3904, swd: 7.1839, ept: 433.7634
      Epoch 1 composite train-obj: 3.321689
            Val objective improved inf → 3.2120, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.0993, mae: 3.0458, huber: 2.6204, swd: 12.3079, ept: 447.3465
    Epoch [2/50], Val Losses: mse: 25.7011, mae: 3.4089, huber: 2.9745, swd: 9.3435, ept: 381.0209
    Epoch [2/50], Test Losses: mse: 16.1905, mae: 2.6261, huber: 2.1958, swd: 6.3886, ept: 430.5866
      Epoch 2 composite train-obj: 2.620438
            Val objective improved 3.2120 → 2.9745, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 26.2988, mae: 2.8273, huber: 2.4052, swd: 11.1124, ept: 481.0713
    Epoch [3/50], Val Losses: mse: 24.8542, mae: 3.3211, huber: 2.8812, swd: 8.3911, ept: 385.1861
    Epoch [3/50], Test Losses: mse: 16.2267, mae: 2.6516, huber: 2.2167, swd: 6.5928, ept: 438.9416
      Epoch 3 composite train-obj: 2.405152
            Val objective improved 2.9745 → 2.8812, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 25.0605, mae: 2.7331, huber: 2.3133, swd: 10.2865, ept: 492.1245
    Epoch [4/50], Val Losses: mse: 24.8004, mae: 3.3589, huber: 2.9240, swd: 8.5691, ept: 384.6363
    Epoch [4/50], Test Losses: mse: 15.5165, mae: 2.5677, huber: 2.1366, swd: 6.0580, ept: 448.8862
      Epoch 4 composite train-obj: 2.313294
            No improvement (2.9240), counter 1/5
    Epoch [5/50], Train Losses: mse: 24.3593, mae: 2.6787, huber: 2.2602, swd: 9.8495, ept: 495.5365
    Epoch [5/50], Val Losses: mse: 24.6572, mae: 3.3280, huber: 2.8986, swd: 8.4086, ept: 387.2907
    Epoch [5/50], Test Losses: mse: 16.0546, mae: 2.6202, huber: 2.1884, swd: 6.7202, ept: 440.1956
      Epoch 5 composite train-obj: 2.260247
            No improvement (2.8986), counter 2/5
    Epoch [6/50], Train Losses: mse: 23.9228, mae: 2.6470, huber: 2.2292, swd: 9.6192, ept: 495.9732
    Epoch [6/50], Val Losses: mse: 24.7256, mae: 3.2995, huber: 2.8703, swd: 8.4002, ept: 389.7444
    Epoch [6/50], Test Losses: mse: 16.3393, mae: 2.6281, huber: 2.1969, swd: 6.7243, ept: 441.6754
      Epoch 6 composite train-obj: 2.229195
            Val objective improved 2.8812 → 2.8703, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 23.2582, mae: 2.5922, huber: 2.1758, swd: 9.1880, ept: 500.6778
    Epoch [7/50], Val Losses: mse: 25.7243, mae: 3.3638, huber: 2.9355, swd: 9.2860, ept: 385.7967
    Epoch [7/50], Test Losses: mse: 16.5169, mae: 2.5991, huber: 2.1721, swd: 6.8358, ept: 446.7655
      Epoch 7 composite train-obj: 2.175832
            No improvement (2.9355), counter 1/5
    Epoch [8/50], Train Losses: mse: 22.6809, mae: 2.5503, huber: 2.1353, swd: 8.7942, ept: 502.7025
    Epoch [8/50], Val Losses: mse: 25.9783, mae: 3.3497, huber: 2.9220, swd: 9.1904, ept: 383.7359
    Epoch [8/50], Test Losses: mse: 17.7470, mae: 2.7191, huber: 2.2900, swd: 7.6552, ept: 438.7071
      Epoch 8 composite train-obj: 2.135340
            No improvement (2.9220), counter 2/5
    Epoch [9/50], Train Losses: mse: 22.1809, mae: 2.5174, huber: 2.1036, swd: 8.4747, ept: 504.2643
    Epoch [9/50], Val Losses: mse: 26.8690, mae: 3.5054, huber: 3.0772, swd: 11.1074, ept: 382.2383
    Epoch [9/50], Test Losses: mse: 17.3807, mae: 2.7115, huber: 2.2828, swd: 7.8655, ept: 451.1416
      Epoch 9 composite train-obj: 2.103564
            No improvement (3.0772), counter 3/5
    Epoch [10/50], Train Losses: mse: 21.7928, mae: 2.4887, huber: 2.0757, swd: 8.2187, ept: 506.3711
    Epoch [10/50], Val Losses: mse: 27.9589, mae: 3.5159, huber: 3.0882, swd: 10.4107, ept: 368.6239
    Epoch [10/50], Test Losses: mse: 18.4947, mae: 2.7858, huber: 2.3547, swd: 8.2450, ept: 428.0325
      Epoch 10 composite train-obj: 2.075739
            No improvement (3.0882), counter 4/5
    Epoch [11/50], Train Losses: mse: 21.4725, mae: 2.4663, huber: 2.0541, swd: 8.0653, ept: 506.8947
    Epoch [11/50], Val Losses: mse: 26.3682, mae: 3.4162, huber: 2.9909, swd: 9.8852, ept: 381.9495
    Epoch [11/50], Test Losses: mse: 17.6359, mae: 2.6824, huber: 2.2560, swd: 7.7603, ept: 444.1195
      Epoch 11 composite train-obj: 2.054069
    Epoch [11/50], Test Losses: mse: 16.3395, mae: 2.6281, huber: 2.1969, swd: 6.7246, ept: 441.6860
    Best round's Test MSE: 16.3393, MAE: 2.6281, SWD: 6.7243
    Best round's Validation MSE: 24.7256, MAE: 3.2995, SWD: 8.4002
    Best round's Test verification MSE : 16.3395, MAE: 2.6281, SWD: 6.7246
    Time taken: 134.65 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 48.8418, mae: 3.6991, huber: 3.2688, swd: 31.5177, ept: 412.7971
    Epoch [1/50], Val Losses: mse: 28.5735, mae: 3.5768, huber: 3.1393, swd: 10.8635, ept: 370.4537
    Epoch [1/50], Test Losses: mse: 17.7144, mae: 2.7590, huber: 2.3263, swd: 7.1153, ept: 439.0568
      Epoch 1 composite train-obj: 3.268794
            Val objective improved inf → 3.1393, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.3528, mae: 3.0545, huber: 2.6290, swd: 14.0336, ept: 446.3903
    Epoch [2/50], Val Losses: mse: 25.8911, mae: 3.4053, huber: 2.9712, swd: 9.7149, ept: 373.1501
    Epoch [2/50], Test Losses: mse: 16.6613, mae: 2.6573, huber: 2.2276, swd: 7.1631, ept: 421.3750
      Epoch 2 composite train-obj: 2.628981
            Val objective improved 3.1393 → 2.9712, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 26.4764, mae: 2.8388, huber: 2.4173, swd: 12.5985, ept: 472.3618
    Epoch [3/50], Val Losses: mse: 24.7916, mae: 3.2886, huber: 2.8584, swd: 9.9378, ept: 386.3275
    Epoch [3/50], Test Losses: mse: 15.7324, mae: 2.5898, huber: 2.1604, swd: 7.1745, ept: 441.9812
      Epoch 3 composite train-obj: 2.417309
            Val objective improved 2.9712 → 2.8584, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 25.2880, mae: 2.7494, huber: 2.3298, swd: 11.9858, ept: 490.8531
    Epoch [4/50], Val Losses: mse: 25.2218, mae: 3.2888, huber: 2.8585, swd: 10.0878, ept: 388.9456
    Epoch [4/50], Test Losses: mse: 16.1903, mae: 2.6534, huber: 2.2198, swd: 7.5504, ept: 437.2434
      Epoch 4 composite train-obj: 2.329757
            No improvement (2.8585), counter 1/5
    Epoch [5/50], Train Losses: mse: 24.4127, mae: 2.6837, huber: 2.2653, swd: 11.3284, ept: 495.4681
    Epoch [5/50], Val Losses: mse: 25.3698, mae: 3.3600, huber: 2.9273, swd: 10.6155, ept: 395.1795
    Epoch [5/50], Test Losses: mse: 16.3789, mae: 2.7197, huber: 2.2821, swd: 8.0488, ept: 445.0877
      Epoch 5 composite train-obj: 2.265251
            No improvement (2.9273), counter 2/5
    Epoch [6/50], Train Losses: mse: 23.7657, mae: 2.6341, huber: 2.2170, swd: 10.8402, ept: 498.4471
    Epoch [6/50], Val Losses: mse: 25.4803, mae: 3.3436, huber: 2.9147, swd: 10.4974, ept: 395.2216
    Epoch [6/50], Test Losses: mse: 16.3238, mae: 2.6555, huber: 2.2216, swd: 7.9043, ept: 444.6860
      Epoch 6 composite train-obj: 2.217007
            No improvement (2.9147), counter 3/5
    Epoch [7/50], Train Losses: mse: 23.2216, mae: 2.5951, huber: 2.1791, swd: 10.4437, ept: 499.4696
    Epoch [7/50], Val Losses: mse: 25.7577, mae: 3.3585, huber: 2.9338, swd: 10.8655, ept: 397.3740
    Epoch [7/50], Test Losses: mse: 16.9793, mae: 2.6561, huber: 2.2285, swd: 8.4572, ept: 440.9187
      Epoch 7 composite train-obj: 2.179067
            No improvement (2.9338), counter 4/5
    Epoch [8/50], Train Losses: mse: 22.7827, mae: 2.5644, huber: 2.1490, swd: 10.1160, ept: 501.7403
    Epoch [8/50], Val Losses: mse: 26.2021, mae: 3.3785, huber: 2.9551, swd: 11.2175, ept: 395.9705
    Epoch [8/50], Test Losses: mse: 17.3289, mae: 2.6875, huber: 2.2605, swd: 8.7726, ept: 437.8988
      Epoch 8 composite train-obj: 2.148951
    Epoch [8/50], Test Losses: mse: 15.7325, mae: 2.5898, huber: 2.1604, swd: 7.1745, ept: 441.9761
    Best round's Test MSE: 15.7324, MAE: 2.5898, SWD: 7.1745
    Best round's Validation MSE: 24.7916, MAE: 3.2886, SWD: 9.9378
    Best round's Test verification MSE : 15.7325, MAE: 2.5898, SWD: 7.1745
    Time taken: 92.87 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred720_20250512_2004)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 15.9655 ± 0.2670
      mae: 2.6057 ± 0.0163
      huber: 2.1749 ± 0.0158
      swd: 6.9275 ± 0.1864
      ept: 442.7855 ± 1.3594
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 24.6253 ± 0.1905
      mae: 3.2888 ± 0.0087
      huber: 2.8573 ± 0.0110
      swd: 9.0984 ± 0.6356
      ept: 388.3787 ± 1.4768
      count: 44.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 331.42 seconds
    
    Experiment complete: ACL_ettm2_seq720_pred720_20250512_2004
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.enable_magnitudes = [False, True]
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 51.1326, mae: 3.7730, huber: 3.3429, swd: 32.9119, target_std: 20.3782
    Epoch [1/50], Val Losses: mse: 28.7645, mae: 3.5675, huber: 3.1289, swd: 10.2081, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 18.5071, mae: 2.8300, huber: 2.3958, swd: 7.3354, target_std: 18.3805
      Epoch 1 composite train-obj: 3.342933
            Val objective improved inf → 3.1289, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 28.2942, mae: 2.9675, huber: 2.5441, swd: 13.2273, target_std: 20.3782
    Epoch [2/50], Val Losses: mse: 25.7938, mae: 3.3723, huber: 2.9351, swd: 9.9258, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 17.1327, mae: 2.7127, huber: 2.2791, swd: 7.8546, target_std: 18.3805
      Epoch 2 composite train-obj: 2.544106
            Val objective improved 3.1289 → 2.9351, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 25.9417, mae: 2.7857, huber: 2.3657, swd: 11.8487, target_std: 20.3786
    Epoch [3/50], Val Losses: mse: 24.5093, mae: 3.3117, huber: 2.8804, swd: 9.4364, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 15.4204, mae: 2.5753, huber: 2.1448, swd: 6.6403, target_std: 18.3805
      Epoch 3 composite train-obj: 2.365731
            Val objective improved 2.9351 → 2.8804, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 24.8865, mae: 2.7107, huber: 2.2926, swd: 11.1206, target_std: 20.3783
    Epoch [4/50], Val Losses: mse: 24.9384, mae: 3.3142, huber: 2.8847, swd: 9.5477, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 15.9636, mae: 2.5989, huber: 2.1719, swd: 6.9970, target_std: 18.3805
      Epoch 4 composite train-obj: 2.292633
            No improvement (2.8847), counter 1/5
    Epoch [5/50], Train Losses: mse: 24.0851, mae: 2.6499, huber: 2.2344, swd: 10.5569, target_std: 20.3783
    Epoch [5/50], Val Losses: mse: 26.5018, mae: 3.4180, huber: 2.9845, swd: 10.5380, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 16.6926, mae: 2.7041, huber: 2.2699, swd: 7.4201, target_std: 18.3805
      Epoch 5 composite train-obj: 2.234406
            No improvement (2.9845), counter 2/5
    Epoch [6/50], Train Losses: mse: 23.5167, mae: 2.6105, huber: 2.1963, swd: 10.1763, target_std: 20.3782
    Epoch [6/50], Val Losses: mse: 25.3795, mae: 3.3516, huber: 2.9263, swd: 9.8858, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 16.0527, mae: 2.5971, huber: 2.1714, swd: 6.8990, target_std: 18.3805
      Epoch 6 composite train-obj: 2.196283
            No improvement (2.9263), counter 3/5
    Epoch [7/50], Train Losses: mse: 22.8002, mae: 2.5673, huber: 2.1538, swd: 9.6465, target_std: 20.3786
    Epoch [7/50], Val Losses: mse: 27.2421, mae: 3.4186, huber: 2.9919, swd: 11.1541, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 17.6865, mae: 2.6957, huber: 2.2693, swd: 8.3185, target_std: 18.3805
      Epoch 7 composite train-obj: 2.153789
            No improvement (2.9919), counter 4/5
    Epoch [8/50], Train Losses: mse: 22.0133, mae: 2.5119, huber: 2.0995, swd: 9.0877, target_std: 20.3787
    Epoch [8/50], Val Losses: mse: 26.4237, mae: 3.3651, huber: 2.9417, swd: 10.4374, target_std: 20.6733
    Epoch [8/50], Test Losses: mse: 16.9034, mae: 2.6819, huber: 2.2542, swd: 7.7749, target_std: 18.3805
      Epoch 8 composite train-obj: 2.099483
    Epoch [8/50], Test Losses: mse: 15.4203, mae: 2.5752, huber: 2.1448, swd: 6.6401, target_std: 18.3805
    Best round's Test MSE: 15.4204, MAE: 2.5753, SWD: 6.6403
    Best round's Validation MSE: 24.5093, MAE: 3.3117
    Best round's Test verification MSE : 15.4203, MAE: 2.5752, SWD: 6.6401
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 49.6432, mae: 3.7640, huber: 3.3342, swd: 29.2872, target_std: 20.3780
    Epoch [1/50], Val Losses: mse: 29.8539, mae: 3.6264, huber: 3.1899, swd: 9.8446, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 19.7328, mae: 2.9381, huber: 2.5030, swd: 7.5804, target_std: 18.3805
      Epoch 1 composite train-obj: 3.334245
            Val objective improved inf → 3.1899, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 27.7203, mae: 2.9465, huber: 2.5233, swd: 11.8506, target_std: 20.3782
    Epoch [2/50], Val Losses: mse: 26.3724, mae: 3.4032, huber: 2.9616, swd: 9.5088, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 17.2658, mae: 2.7333, huber: 2.2984, swd: 7.3519, target_std: 18.3805
      Epoch 2 composite train-obj: 2.523277
            Val objective improved 3.1899 → 2.9616, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 25.2142, mae: 2.7518, huber: 2.3320, swd: 10.5691, target_std: 20.3782
    Epoch [3/50], Val Losses: mse: 24.5147, mae: 3.2888, huber: 2.8547, swd: 8.1903, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 16.1207, mae: 2.6222, huber: 2.1918, swd: 6.5750, target_std: 18.3805
      Epoch 3 composite train-obj: 2.332034
            Val objective improved 2.9616 → 2.8547, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 24.2629, mae: 2.6786, huber: 2.2609, swd: 9.9236, target_std: 20.3785
    Epoch [4/50], Val Losses: mse: 25.8507, mae: 3.3009, huber: 2.8740, swd: 9.2370, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 17.3095, mae: 2.6798, huber: 2.2533, swd: 7.4530, target_std: 18.3805
      Epoch 4 composite train-obj: 2.260933
            No improvement (2.8740), counter 1/5
    Epoch [5/50], Train Losses: mse: 23.3864, mae: 2.6157, huber: 2.1999, swd: 9.3213, target_std: 20.3782
    Epoch [5/50], Val Losses: mse: 24.5715, mae: 3.2878, huber: 2.8591, swd: 8.6738, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 16.6061, mae: 2.6455, huber: 2.2165, swd: 7.0729, target_std: 18.3805
      Epoch 5 composite train-obj: 2.199914
            No improvement (2.8591), counter 2/5
    Epoch [6/50], Train Losses: mse: 22.8065, mae: 2.5683, huber: 2.1537, swd: 8.9703, target_std: 20.3783
    Epoch [6/50], Val Losses: mse: 24.6854, mae: 3.3167, huber: 2.8878, swd: 9.1061, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 16.5246, mae: 2.6373, huber: 2.2134, swd: 7.0731, target_std: 18.3805
      Epoch 6 composite train-obj: 2.153714
            No improvement (2.8878), counter 3/5
    Epoch [7/50], Train Losses: mse: 22.1281, mae: 2.5145, huber: 2.1015, swd: 8.5457, target_std: 20.3783
    Epoch [7/50], Val Losses: mse: 25.4648, mae: 3.2963, huber: 2.8705, swd: 9.0397, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 18.7575, mae: 2.7495, huber: 2.3247, swd: 8.6035, target_std: 18.3805
      Epoch 7 composite train-obj: 2.101525
            No improvement (2.8705), counter 4/5
    Epoch [8/50], Train Losses: mse: 21.5081, mae: 2.4734, huber: 2.0614, swd: 8.2173, target_std: 20.3782
    Epoch [8/50], Val Losses: mse: 25.8043, mae: 3.3359, huber: 2.9080, swd: 9.0959, target_std: 20.6733
    Epoch [8/50], Test Losses: mse: 17.9285, mae: 2.7069, huber: 2.2800, swd: 7.8713, target_std: 18.3805
      Epoch 8 composite train-obj: 2.061401
    Epoch [8/50], Test Losses: mse: 16.1225, mae: 2.6224, huber: 2.1919, swd: 6.5765, target_std: 18.3805
    Best round's Test MSE: 16.1207, MAE: 2.6222, SWD: 6.5750
    Best round's Validation MSE: 24.5147, MAE: 3.2888
    Best round's Test verification MSE : 16.1225, MAE: 2.6224, SWD: 6.5765
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 51.5066, mae: 3.7988, huber: 3.3683, swd: 34.1530, target_std: 20.3782
    Epoch [1/50], Val Losses: mse: 30.1697, mae: 3.7112, huber: 3.2722, swd: 12.7415, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 18.2513, mae: 2.7899, huber: 2.3594, swd: 7.7970, target_std: 18.3805
      Epoch 1 composite train-obj: 3.368307
            Val objective improved inf → 3.2722, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 28.8309, mae: 3.0060, huber: 2.5817, swd: 13.8320, target_std: 20.3783
    Epoch [2/50], Val Losses: mse: 24.7717, mae: 3.3286, huber: 2.8921, swd: 9.6321, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 16.0478, mae: 2.7109, huber: 2.2714, swd: 7.4518, target_std: 18.3805
      Epoch 2 composite train-obj: 2.581687
            Val objective improved 3.2722 → 2.8921, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 26.1156, mae: 2.8093, huber: 2.3892, swd: 12.6114, target_std: 20.3781
    Epoch [3/50], Val Losses: mse: 27.4616, mae: 3.4700, huber: 3.0341, swd: 11.5436, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 19.0396, mae: 2.8383, huber: 2.4088, swd: 9.7783, target_std: 18.3805
      Epoch 3 composite train-obj: 2.389179
            No improvement (3.0341), counter 1/5
    Epoch [4/50], Train Losses: mse: 24.9676, mae: 2.7189, huber: 2.3009, swd: 11.7891, target_std: 20.3782
    Epoch [4/50], Val Losses: mse: 25.6165, mae: 3.3504, huber: 2.9192, swd: 10.1631, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 16.6528, mae: 2.6383, huber: 2.2122, swd: 7.8706, target_std: 18.3805
      Epoch 4 composite train-obj: 2.300944
            No improvement (2.9192), counter 2/5
    Epoch [5/50], Train Losses: mse: 24.2457, mae: 2.6658, huber: 2.2493, swd: 11.2777, target_std: 20.3783
    Epoch [5/50], Val Losses: mse: 24.7306, mae: 3.3274, huber: 2.8950, swd: 10.0023, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 16.1735, mae: 2.6383, huber: 2.2083, swd: 7.8516, target_std: 18.3805
      Epoch 5 composite train-obj: 2.249302
            No improvement (2.8950), counter 3/5
    Epoch [6/50], Train Losses: mse: 23.7904, mae: 2.6371, huber: 2.2213, swd: 10.9809, target_std: 20.3784
    Epoch [6/50], Val Losses: mse: 24.7324, mae: 3.3279, huber: 2.8970, swd: 9.6114, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 16.5565, mae: 2.6143, huber: 2.1879, swd: 7.9851, target_std: 18.3805
      Epoch 6 composite train-obj: 2.221261
            No improvement (2.8970), counter 4/5
    Epoch [7/50], Train Losses: mse: 23.1389, mae: 2.5883, huber: 2.1733, swd: 10.4418, target_std: 20.3784
    Epoch [7/50], Val Losses: mse: 25.6571, mae: 3.3831, huber: 2.9542, swd: 10.3616, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 16.7296, mae: 2.6313, huber: 2.2042, swd: 8.0726, target_std: 18.3805
      Epoch 7 composite train-obj: 2.173279
    Epoch [7/50], Test Losses: mse: 16.0481, mae: 2.7110, huber: 2.2715, swd: 7.4520, target_std: 18.3805
    Best round's Test MSE: 16.0478, MAE: 2.7109, SWD: 7.4518
    Best round's Validation MSE: 24.7717, MAE: 3.3286
    Best round's Test verification MSE : 16.0481, MAE: 2.7110, SWD: 7.4520
    
    ==================================================
    Experiment Summary (ACL_ettm2_seq720_pred720_20250501_1427)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 15.8630 ± 0.3143
      mae: 2.6361 ± 0.0563
      huber: 2.2027 ± 0.0523
      swd: 6.8890 ± 0.3988
      target_std: 18.3805 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 24.5986 ± 0.1225
      mae: 3.3097 ± 0.0163
      huber: 2.8757 ± 0.0156
      swd: 9.0863 ± 0.6385
      target_std: 20.6733 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm2_seq720_pred720_20250501_1427
    Model: ACL
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([modules_to_reload_list])
cfg = train_config.FlatACLConfig(  
    seq_len=336,
    pred_len=336,
    channels=data_mgr.datasets['lorenz']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=True,
    householder_reflects_latent = 4,
    householder_reflects_data = 8,
    mixing_strategy='convex',
    # single_magnitude_for_shift=True,

)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
exp = execute_model_evaluation('lorenz', cfg, data_mgr, scale=False)
```

### Timemixer

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.2892, mae: 1.7649, huber: 1.3754, swd: 5.5942, target_std: 20.3714
    Epoch [1/50], Val Losses: mse: 12.9865, mae: 2.1926, huber: 1.7887, swd: 7.3600, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.3803, mae: 1.8149, huber: 1.4127, swd: 4.4415, target_std: 18.4426
      Epoch 1 composite train-obj: 1.375417
            Val objective improved inf → 1.7887, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9182, mae: 1.4626, huber: 1.0821, swd: 3.2707, target_std: 20.3714
    Epoch [2/50], Val Losses: mse: 13.7715, mae: 2.2598, huber: 1.8532, swd: 7.8784, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 9.1656, mae: 1.9185, huber: 1.5133, swd: 4.9928, target_std: 18.4426
      Epoch 2 composite train-obj: 1.082087
            No improvement (1.8532), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.7843, mae: 1.2169, huber: 0.8462, swd: 1.9283, target_std: 20.3706
    Epoch [3/50], Val Losses: mse: 13.7695, mae: 2.2889, huber: 1.8810, swd: 7.7532, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 10.1331, mae: 2.0232, huber: 1.6155, swd: 5.5596, target_std: 18.4426
      Epoch 3 composite train-obj: 0.846178
            No improvement (1.8810), counter 2/5
    Epoch [4/50], Train Losses: mse: 3.5593, mae: 1.0612, huber: 0.7001, swd: 1.2894, target_std: 20.3710
    Epoch [4/50], Val Losses: mse: 13.8921, mae: 2.2960, huber: 1.8866, swd: 7.7450, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 9.6537, mae: 1.9837, huber: 1.5760, swd: 5.1677, target_std: 18.4426
      Epoch 4 composite train-obj: 0.700062
            No improvement (1.8866), counter 3/5
    Epoch [5/50], Train Losses: mse: 2.8638, mae: 0.9730, huber: 0.6190, swd: 0.9639, target_std: 20.3716
    Epoch [5/50], Val Losses: mse: 13.6585, mae: 2.2799, huber: 1.8709, swd: 7.5270, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 9.8404, mae: 2.0007, huber: 1.5924, swd: 5.2483, target_std: 18.4426
      Epoch 5 composite train-obj: 0.619038
            No improvement (1.8709), counter 4/5
    Epoch [6/50], Train Losses: mse: 2.5132, mae: 0.9094, huber: 0.5622, swd: 0.8166, target_std: 20.3707
    Epoch [6/50], Val Losses: mse: 13.5268, mae: 2.2706, huber: 1.8614, swd: 7.4442, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 9.6706, mae: 1.9987, huber: 1.5894, swd: 5.1348, target_std: 18.4426
      Epoch 6 composite train-obj: 0.562250
    Epoch [6/50], Test Losses: mse: 8.3803, mae: 1.8149, huber: 1.4127, swd: 4.4415, target_std: 18.4426
    Best round's Test MSE: 8.3803, MAE: 1.8149, SWD: 4.4415
    Best round's Validation MSE: 12.9865, MAE: 2.1926
    Best round's Test verification MSE : 8.3803, MAE: 1.8149, SWD: 4.4415
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.5569, mae: 1.7800, huber: 1.3897, swd: 5.4214, target_std: 20.3707
    Epoch [1/50], Val Losses: mse: 12.8039, mae: 2.1802, huber: 1.7764, swd: 6.9219, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.5796, mae: 1.8266, huber: 1.4246, swd: 4.3888, target_std: 18.4426
      Epoch 1 composite train-obj: 1.389661
            Val objective improved inf → 1.7764, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.8425, mae: 1.4528, huber: 1.0723, swd: 3.1019, target_std: 20.3724
    Epoch [2/50], Val Losses: mse: 13.3568, mae: 2.2623, huber: 1.8556, swd: 7.2587, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 9.3910, mae: 1.9393, huber: 1.5341, swd: 4.9207, target_std: 18.4426
      Epoch 2 composite train-obj: 1.072320
            No improvement (1.8556), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.9531, mae: 1.2430, huber: 0.8710, swd: 1.9549, target_std: 20.3712
    Epoch [3/50], Val Losses: mse: 13.5201, mae: 2.2539, huber: 1.8469, swd: 7.2583, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 9.5091, mae: 1.9443, huber: 1.5386, swd: 4.9345, target_std: 18.4426
      Epoch 3 composite train-obj: 0.870957
            No improvement (1.8469), counter 2/5
    Epoch [4/50], Train Losses: mse: 3.9855, mae: 1.1075, huber: 0.7435, swd: 1.4631, target_std: 20.3709
    Epoch [4/50], Val Losses: mse: 13.9990, mae: 2.3091, huber: 1.8989, swd: 7.4375, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 9.6494, mae: 1.9831, huber: 1.5752, swd: 4.9074, target_std: 18.4426
      Epoch 4 composite train-obj: 0.743496
            No improvement (1.8989), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.3705, mae: 1.0219, huber: 0.6644, swd: 1.1706, target_std: 20.3709
    Epoch [5/50], Val Losses: mse: 13.7757, mae: 2.2826, huber: 1.8734, swd: 7.2682, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 9.1784, mae: 1.9329, huber: 1.5259, swd: 4.5482, target_std: 18.4426
      Epoch 5 composite train-obj: 0.664418
            No improvement (1.8734), counter 4/5
    Epoch [6/50], Train Losses: mse: 2.8832, mae: 0.9575, huber: 0.6056, swd: 0.9387, target_std: 20.3708
    Epoch [6/50], Val Losses: mse: 13.8857, mae: 2.3053, huber: 1.8943, swd: 7.3114, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 9.4003, mae: 1.9734, huber: 1.5643, swd: 4.6908, target_std: 18.4426
      Epoch 6 composite train-obj: 0.605571
    Epoch [6/50], Test Losses: mse: 8.5796, mae: 1.8266, huber: 1.4246, swd: 4.3888, target_std: 18.4426
    Best round's Test MSE: 8.5796, MAE: 1.8266, SWD: 4.3888
    Best round's Validation MSE: 12.8039, MAE: 2.1802
    Best round's Test verification MSE : 8.5796, MAE: 1.8266, SWD: 4.3888
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.5955, mae: 1.7856, huber: 1.3957, swd: 5.2915, target_std: 20.3716
    Epoch [1/50], Val Losses: mse: 11.9992, mae: 2.1225, huber: 1.7203, swd: 6.0279, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.2333, mae: 1.8033, huber: 1.4013, swd: 3.9220, target_std: 18.4426
      Epoch 1 composite train-obj: 1.395705
            Val objective improved inf → 1.7203, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.3535, mae: 1.4949, huber: 1.1137, swd: 3.2597, target_std: 20.3717
    Epoch [2/50], Val Losses: mse: 13.3761, mae: 2.2294, huber: 1.8230, swd: 6.8136, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 9.1964, mae: 1.9065, huber: 1.5015, swd: 4.4347, target_std: 18.4426
      Epoch 2 composite train-obj: 1.113710
            No improvement (1.8230), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.1449, mae: 1.2580, huber: 0.8856, swd: 1.9521, target_std: 20.3706
    Epoch [3/50], Val Losses: mse: 13.1800, mae: 2.2318, huber: 1.8251, swd: 6.4373, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 9.5364, mae: 1.9525, huber: 1.5462, swd: 4.4923, target_std: 18.4426
      Epoch 3 composite train-obj: 0.885614
            No improvement (1.8251), counter 2/5
    Epoch [4/50], Train Losses: mse: 3.8653, mae: 1.0962, huber: 0.7330, swd: 1.3277, target_std: 20.3712
    Epoch [4/50], Val Losses: mse: 13.7914, mae: 2.2832, huber: 1.8743, swd: 6.9916, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 9.5905, mae: 1.9770, huber: 1.5690, swd: 4.5197, target_std: 18.4426
      Epoch 4 composite train-obj: 0.733026
            No improvement (1.8743), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.1186, mae: 0.9992, huber: 0.6433, swd: 1.0190, target_std: 20.3712
    Epoch [5/50], Val Losses: mse: 14.0318, mae: 2.3088, huber: 1.8980, swd: 7.0503, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 9.8011, mae: 1.9967, huber: 1.5883, swd: 4.6415, target_std: 18.4426
      Epoch 5 composite train-obj: 0.643278
            No improvement (1.8980), counter 4/5
    Epoch [6/50], Train Losses: mse: 2.7101, mae: 0.9363, huber: 0.5863, swd: 0.8529, target_std: 20.3720
    Epoch [6/50], Val Losses: mse: 13.5139, mae: 2.2856, huber: 1.8745, swd: 6.7230, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 9.5160, mae: 1.9806, huber: 1.5715, swd: 4.4571, target_std: 18.4426
      Epoch 6 composite train-obj: 0.586333
    Epoch [6/50], Test Losses: mse: 8.2333, mae: 1.8033, huber: 1.4013, swd: 3.9220, target_std: 18.4426
    Best round's Test MSE: 8.2333, MAE: 1.8033, SWD: 3.9220
    Best round's Validation MSE: 11.9992, MAE: 2.1225
    Best round's Test verification MSE : 8.2333, MAE: 1.8033, SWD: 3.9220
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq720_pred96_20250501_1448)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.3978 ± 0.1419
      mae: 1.8149 ± 0.0095
      huber: 1.4128 ± 0.0095
      swd: 4.2508 ± 0.2335
      target_std: 18.4426 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 12.5966 ± 0.4289
      mae: 2.1651 ± 0.0306
      huber: 1.7618 ± 0.0298
      swd: 6.7699 ± 0.5544
      target_std: 20.6844 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq720_pred96_20250501_1448
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 15.0862, mae: 2.0950, huber: 1.6963, swd: 7.9605, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 16.8820, mae: 2.5285, huber: 2.1140, swd: 9.3777, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 10.5603, mae: 2.0794, huber: 1.6682, swd: 5.5861, target_std: 18.4106
      Epoch 1 composite train-obj: 1.696336
            Val objective improved inf → 2.1140, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 10.3557, mae: 1.7438, huber: 1.3525, swd: 4.8512, target_std: 20.3718
    Epoch [2/50], Val Losses: mse: 19.3641, mae: 2.7092, huber: 2.2908, swd: 11.2623, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 12.0380, mae: 2.2028, huber: 1.7898, swd: 6.5640, target_std: 18.4106
      Epoch 2 composite train-obj: 1.352546
            No improvement (2.2908), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.4536, mae: 1.4737, huber: 1.0898, swd: 3.0389, target_std: 20.3718
    Epoch [3/50], Val Losses: mse: 18.6449, mae: 2.6934, huber: 2.2736, swd: 10.4288, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 12.7613, mae: 2.2777, huber: 1.8626, swd: 6.8859, target_std: 18.4106
      Epoch 3 composite train-obj: 1.089806
            No improvement (2.2736), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.7328, mae: 1.2820, huber: 0.9063, swd: 2.1667, target_std: 20.3720
    Epoch [4/50], Val Losses: mse: 18.5367, mae: 2.6777, huber: 2.2589, swd: 10.1367, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 12.9191, mae: 2.2819, huber: 1.8671, swd: 6.7638, target_std: 18.4106
      Epoch 4 composite train-obj: 0.906253
            No improvement (2.2589), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.5969, mae: 1.1489, huber: 0.7809, swd: 1.6144, target_std: 20.3720
    Epoch [5/50], Val Losses: mse: 18.4944, mae: 2.6856, huber: 2.2663, swd: 10.0188, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 12.7838, mae: 2.2846, huber: 1.8688, swd: 6.7293, target_std: 18.4106
      Epoch 5 composite train-obj: 0.780943
            No improvement (2.2663), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.8202, mae: 1.0596, huber: 0.6981, swd: 1.3273, target_std: 20.3720
    Epoch [6/50], Val Losses: mse: 18.3019, mae: 2.6737, huber: 2.2536, swd: 9.7953, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 12.6041, mae: 2.2690, huber: 1.8535, swd: 6.5465, target_std: 18.4106
      Epoch 6 composite train-obj: 0.698071
    Epoch [6/50], Test Losses: mse: 10.5603, mae: 2.0794, huber: 1.6682, swd: 5.5861, target_std: 18.4106
    Best round's Test MSE: 10.5603, MAE: 2.0794, SWD: 5.5861
    Best round's Validation MSE: 16.8820, MAE: 2.5285
    Best round's Test verification MSE : 10.5603, MAE: 2.0794, SWD: 5.5861
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 14.6935, mae: 2.0695, huber: 1.6710, swd: 7.7100, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 17.3996, mae: 2.6098, huber: 2.1932, swd: 9.9060, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 11.1522, mae: 2.1225, huber: 1.7111, swd: 5.9669, target_std: 18.4106
      Epoch 1 composite train-obj: 1.670985
            Val objective improved inf → 2.1932, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.1980, mae: 1.6439, huber: 1.2553, swd: 4.2175, target_std: 20.3719
    Epoch [2/50], Val Losses: mse: 19.6251, mae: 2.7359, huber: 2.3163, swd: 11.6070, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 12.3924, mae: 2.2322, huber: 1.8186, swd: 6.7884, target_std: 18.4106
      Epoch 2 composite train-obj: 1.255323
            No improvement (2.3163), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.7228, mae: 1.3946, huber: 1.0140, swd: 2.7699, target_std: 20.3718
    Epoch [3/50], Val Losses: mse: 19.2456, mae: 2.7280, huber: 2.3086, swd: 10.9328, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 12.3614, mae: 2.2399, huber: 1.8258, swd: 6.5285, target_std: 18.4106
      Epoch 3 composite train-obj: 1.013958
            No improvement (2.3086), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.3949, mae: 1.2376, huber: 0.8645, swd: 2.1416, target_std: 20.3720
    Epoch [4/50], Val Losses: mse: 19.4803, mae: 2.7439, huber: 2.3239, swd: 11.1081, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 12.8110, mae: 2.2841, huber: 1.8688, swd: 6.8118, target_std: 18.4106
      Epoch 4 composite train-obj: 0.864464
            No improvement (2.3239), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.5406, mae: 1.1332, huber: 0.7668, swd: 1.7761, target_std: 20.3721
    Epoch [5/50], Val Losses: mse: 19.9666, mae: 2.7849, huber: 2.3639, swd: 11.4143, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 12.7579, mae: 2.2902, huber: 1.8740, swd: 6.8426, target_std: 18.4106
      Epoch 5 composite train-obj: 0.766830
            No improvement (2.3639), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.8605, mae: 1.0609, huber: 0.6998, swd: 1.4826, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 19.1330, mae: 2.7332, huber: 2.3126, swd: 10.7312, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 12.5289, mae: 2.2693, huber: 1.8537, swd: 6.6615, target_std: 18.4106
      Epoch 6 composite train-obj: 0.699841
    Epoch [6/50], Test Losses: mse: 11.1522, mae: 2.1225, huber: 1.7111, swd: 5.9669, target_std: 18.4106
    Best round's Test MSE: 11.1522, MAE: 2.1225, SWD: 5.9669
    Best round's Validation MSE: 17.3996, MAE: 2.6098
    Best round's Test verification MSE : 11.1522, MAE: 2.1225, SWD: 5.9669
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 14.4782, mae: 2.0402, huber: 1.6435, swd: 6.9328, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 18.2831, mae: 2.6101, huber: 2.1961, swd: 9.1700, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 10.8547, mae: 2.0933, huber: 1.6831, swd: 5.0215, target_std: 18.4106
      Epoch 1 composite train-obj: 1.643518
            Val objective improved inf → 2.1961, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 9.4459, mae: 1.6645, huber: 1.2757, swd: 3.7533, target_std: 20.3720
    Epoch [2/50], Val Losses: mse: 19.2999, mae: 2.6893, huber: 2.2710, swd: 9.7451, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 12.5258, mae: 2.2174, huber: 1.8041, swd: 6.0146, target_std: 18.4106
      Epoch 2 composite train-obj: 1.275717
            No improvement (2.2710), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.9892, mae: 1.3424, huber: 0.9637, swd: 1.9789, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 20.8525, mae: 2.7834, huber: 2.3643, swd: 10.5128, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 12.9466, mae: 2.2600, huber: 1.8465, swd: 6.0100, target_std: 18.4106
      Epoch 3 composite train-obj: 0.963684
            No improvement (2.3643), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.2903, mae: 1.1490, huber: 0.7804, swd: 1.3377, target_std: 20.3720
    Epoch [4/50], Val Losses: mse: 20.4425, mae: 2.7674, huber: 2.3478, swd: 10.1306, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 13.0109, mae: 2.2828, huber: 1.8673, swd: 6.0360, target_std: 18.4106
      Epoch 4 composite train-obj: 0.780397
            No improvement (2.3478), counter 3/5
    Epoch [5/50], Train Losses: mse: 3.6320, mae: 1.0437, huber: 0.6832, swd: 1.1545, target_std: 20.3718
    Epoch [5/50], Val Losses: mse: 19.2742, mae: 2.7062, huber: 2.2869, swd: 9.3535, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 12.3941, mae: 2.2342, huber: 1.8193, swd: 5.6153, target_std: 18.4106
      Epoch 5 composite train-obj: 0.683216
            No improvement (2.2869), counter 4/5
    Epoch [6/50], Train Losses: mse: 3.2794, mae: 0.9777, huber: 0.6236, swd: 1.0607, target_std: 20.3722
    Epoch [6/50], Val Losses: mse: 19.7553, mae: 2.7369, huber: 2.3170, swd: 9.6767, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 12.4782, mae: 2.2469, huber: 1.8315, swd: 5.7029, target_std: 18.4106
      Epoch 6 composite train-obj: 0.623597
    Epoch [6/50], Test Losses: mse: 10.8547, mae: 2.0933, huber: 1.6831, swd: 5.0215, target_std: 18.4106
    Best round's Test MSE: 10.8547, MAE: 2.0933, SWD: 5.0215
    Best round's Validation MSE: 18.2831, MAE: 2.6101
    Best round's Test verification MSE : 10.8547, MAE: 2.0933, SWD: 5.0215
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq720_pred196_20250501_1618)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.8557 ± 0.2416
      mae: 2.0984 ± 0.0180
      huber: 1.6875 ± 0.0178
      swd: 5.5249 ± 0.3884
      target_std: 18.4106 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 17.5216 ± 0.5785
      mae: 2.5828 ± 0.0384
      huber: 2.1678 ± 0.0380
      swd: 9.4846 ± 0.3099
      target_std: 20.7091 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq720_pred196_20250501_1618
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 18.8316, mae: 2.3172, huber: 1.9135, swd: 9.5720, target_std: 20.3733
    Epoch [1/50], Val Losses: mse: 23.2145, mae: 3.0005, huber: 2.5774, swd: 12.2778, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 13.9292, mae: 2.3428, huber: 1.9257, swd: 7.2409, target_std: 18.3950
      Epoch 1 composite train-obj: 1.913544
            Val objective improved inf → 2.5774, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.5193, mae: 1.8850, huber: 1.4888, swd: 5.4370, target_std: 20.3736
    Epoch [2/50], Val Losses: mse: 22.9779, mae: 3.0167, huber: 2.5910, swd: 11.8949, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 15.6182, mae: 2.4834, huber: 2.0642, swd: 8.2973, target_std: 18.3950
      Epoch 2 composite train-obj: 1.488839
            No improvement (2.5910), counter 1/5
    Epoch [3/50], Train Losses: mse: 8.8265, mae: 1.5633, huber: 1.1751, swd: 3.4253, target_std: 20.3734
    Epoch [3/50], Val Losses: mse: 23.5082, mae: 3.0849, huber: 2.6554, swd: 11.8422, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 16.5438, mae: 2.5245, huber: 2.1055, swd: 8.5237, target_std: 18.3950
      Epoch 3 composite train-obj: 1.175143
            No improvement (2.6554), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.6699, mae: 1.3588, huber: 0.9783, swd: 2.3709, target_std: 20.3733
    Epoch [4/50], Val Losses: mse: 23.1927, mae: 3.0771, huber: 2.6486, swd: 11.4072, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 16.5639, mae: 2.5677, huber: 2.1475, swd: 8.3602, target_std: 18.3950
      Epoch 4 composite train-obj: 0.978250
            No improvement (2.6486), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.5926, mae: 1.2288, huber: 0.8552, swd: 1.9986, target_std: 20.3734
    Epoch [5/50], Val Losses: mse: 22.6348, mae: 3.0506, huber: 2.6217, swd: 10.7587, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 16.0892, mae: 2.5398, huber: 2.1192, swd: 7.9394, target_std: 18.3950
      Epoch 5 composite train-obj: 0.855209
            No improvement (2.6217), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.9547, mae: 1.1474, huber: 0.7791, swd: 1.8268, target_std: 20.3734
    Epoch [6/50], Val Losses: mse: 22.4682, mae: 3.0374, huber: 2.6088, swd: 10.7005, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 16.0855, mae: 2.5418, huber: 2.1207, swd: 8.0413, target_std: 18.3950
      Epoch 6 composite train-obj: 0.779083
    Epoch [6/50], Test Losses: mse: 13.9292, mae: 2.3428, huber: 1.9257, swd: 7.2409, target_std: 18.3950
    Best round's Test MSE: 13.9292, MAE: 2.3428, SWD: 7.2409
    Best round's Validation MSE: 23.2145, MAE: 3.0005
    Best round's Test verification MSE : 13.9292, MAE: 2.3428, SWD: 7.2409
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 18.9327, mae: 2.3319, huber: 1.9273, swd: 9.4898, target_std: 20.3734
    Epoch [1/50], Val Losses: mse: 22.7183, mae: 3.0082, huber: 2.5852, swd: 12.2481, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 14.1831, mae: 2.3955, huber: 1.9773, swd: 7.7482, target_std: 18.3950
      Epoch 1 composite train-obj: 1.927258
            Val objective improved inf → 2.5852, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.6924, mae: 1.8258, huber: 1.4309, swd: 5.0807, target_std: 20.3731
    Epoch [2/50], Val Losses: mse: 23.6051, mae: 3.0620, huber: 2.6378, swd: 12.7164, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 15.8120, mae: 2.4814, huber: 2.0634, swd: 8.4980, target_std: 18.3950
      Epoch 2 composite train-obj: 1.430892
            No improvement (2.6378), counter 1/5
    Epoch [3/50], Train Losses: mse: 8.3876, mae: 1.5194, huber: 1.1331, swd: 3.3514, target_std: 20.3734
    Epoch [3/50], Val Losses: mse: 23.2483, mae: 3.0858, huber: 2.6593, swd: 11.9378, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 16.7637, mae: 2.5606, huber: 2.1408, swd: 8.7966, target_std: 18.3950
      Epoch 3 composite train-obj: 1.133138
            No improvement (2.6593), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.5802, mae: 1.3370, huber: 0.9583, swd: 2.5376, target_std: 20.3737
    Epoch [4/50], Val Losses: mse: 22.7924, mae: 3.0668, huber: 2.6399, swd: 11.4780, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 15.9466, mae: 2.5261, huber: 2.1057, swd: 8.1061, target_std: 18.3950
      Epoch 4 composite train-obj: 0.958315
            No improvement (2.6399), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.4711, mae: 1.2159, huber: 0.8437, swd: 2.1050, target_std: 20.3741
    Epoch [5/50], Val Losses: mse: 22.9100, mae: 3.0766, huber: 2.6485, swd: 11.6072, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 16.0309, mae: 2.5400, huber: 2.1191, swd: 8.2519, target_std: 18.3950
      Epoch 5 composite train-obj: 0.843727
            No improvement (2.6485), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.8475, mae: 1.1360, huber: 0.7691, swd: 1.9266, target_std: 20.3733
    Epoch [6/50], Val Losses: mse: 23.1798, mae: 3.0940, huber: 2.6656, swd: 11.7734, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 15.8914, mae: 2.5367, huber: 2.1152, swd: 8.0823, target_std: 18.3950
      Epoch 6 composite train-obj: 0.769069
    Epoch [6/50], Test Losses: mse: 14.1831, mae: 2.3955, huber: 1.9773, swd: 7.7482, target_std: 18.3950
    Best round's Test MSE: 14.1831, MAE: 2.3955, SWD: 7.7482
    Best round's Validation MSE: 22.7183, MAE: 3.0082
    Best round's Test verification MSE : 14.1831, MAE: 2.3955, SWD: 7.7482
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 19.0026, mae: 2.3199, huber: 1.9165, swd: 9.5194, target_std: 20.3732
    Epoch [1/50], Val Losses: mse: 24.0465, mae: 2.9927, huber: 2.5716, swd: 12.1880, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 13.3767, mae: 2.2943, huber: 1.8801, swd: 6.5148, target_std: 18.3950
      Epoch 1 composite train-obj: 1.916494
            Val objective improved inf → 2.5716, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.2882, mae: 1.8695, huber: 1.4738, swd: 5.0881, target_std: 20.3733
    Epoch [2/50], Val Losses: mse: 23.3502, mae: 3.0196, huber: 2.5940, swd: 11.5945, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 15.0042, mae: 2.4491, huber: 2.0306, swd: 7.3661, target_std: 18.3950
      Epoch 2 composite train-obj: 1.473784
            No improvement (2.5940), counter 1/5
    Epoch [3/50], Train Losses: mse: 7.7422, mae: 1.4783, huber: 1.0927, swd: 2.6796, target_std: 20.3730
    Epoch [3/50], Val Losses: mse: 23.2347, mae: 3.0500, huber: 2.6238, swd: 11.0418, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 15.8538, mae: 2.5116, huber: 2.0928, swd: 7.5495, target_std: 18.3950
      Epoch 3 composite train-obj: 1.092715
            No improvement (2.6238), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.6914, mae: 1.2588, huber: 0.8829, swd: 1.9925, target_std: 20.3734
    Epoch [4/50], Val Losses: mse: 24.2515, mae: 3.1219, huber: 2.6949, swd: 11.5325, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 16.0265, mae: 2.5429, huber: 2.1221, swd: 7.5063, target_std: 18.3950
      Epoch 4 composite train-obj: 0.882925
            No improvement (2.6949), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.8679, mae: 1.1420, huber: 0.7738, swd: 1.7818, target_std: 20.3735
    Epoch [5/50], Val Losses: mse: 24.4818, mae: 3.1227, huber: 2.6958, swd: 11.6780, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 15.9828, mae: 2.5468, huber: 2.1258, swd: 7.5132, target_std: 18.3950
      Epoch 5 composite train-obj: 0.773794
            No improvement (2.6958), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.4240, mae: 1.0652, huber: 0.7035, swd: 1.6650, target_std: 20.3736
    Epoch [6/50], Val Losses: mse: 24.3331, mae: 3.1227, huber: 2.6956, swd: 11.5413, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 15.5311, mae: 2.5139, huber: 2.0931, swd: 7.2213, target_std: 18.3950
      Epoch 6 composite train-obj: 0.703480
    Epoch [6/50], Test Losses: mse: 13.3767, mae: 2.2943, huber: 1.8801, swd: 6.5148, target_std: 18.3950
    Best round's Test MSE: 13.3767, MAE: 2.2943, SWD: 6.5148
    Best round's Validation MSE: 24.0465, MAE: 2.9927
    Best round's Test verification MSE : 13.3767, MAE: 2.2943, SWD: 6.5148
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq720_pred336_20250501_1634)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 13.8297 ± 0.3366
      mae: 2.3442 ± 0.0413
      huber: 1.9277 ± 0.0397
      swd: 7.1679 ± 0.5062
      target_std: 18.3950 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 23.3264 ± 0.5480
      mae: 3.0005 ± 0.0064
      huber: 2.5781 ± 0.0056
      swd: 12.2379 ± 0.0374
      target_std: 20.7022 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq720_pred336_20250501_1634
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.3317, mae: 2.7270, huber: 2.3133, swd: 12.2870, target_std: 20.3781
    Epoch [1/50], Val Losses: mse: 28.0048, mae: 3.3876, huber: 2.9555, swd: 12.8458, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 16.8077, mae: 2.6058, huber: 2.1858, swd: 7.9882, target_std: 18.3805
      Epoch 1 composite train-obj: 2.313256
            Val objective improved inf → 2.9555, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 18.9960, mae: 2.2595, huber: 1.8530, swd: 7.8925, target_std: 20.3782
    Epoch [2/50], Val Losses: mse: 29.7505, mae: 3.5315, huber: 3.0955, swd: 13.4463, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 19.8648, mae: 2.8394, huber: 2.4150, swd: 9.7011, target_std: 18.3805
      Epoch 2 composite train-obj: 1.852999
            No improvement (3.0955), counter 1/5
    Epoch [3/50], Train Losses: mse: 13.0097, mae: 1.8376, huber: 1.4389, swd: 4.8730, target_std: 20.3782
    Epoch [3/50], Val Losses: mse: 29.6769, mae: 3.5753, huber: 3.1376, swd: 12.7451, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 21.2961, mae: 2.9013, huber: 2.4759, swd: 10.0495, target_std: 18.3805
      Epoch 3 composite train-obj: 1.438866
            No improvement (3.1376), counter 2/5
    Epoch [4/50], Train Losses: mse: 9.8847, mae: 1.5516, huber: 1.1613, swd: 3.7891, target_std: 20.3785
    Epoch [4/50], Val Losses: mse: 29.9889, mae: 3.5951, huber: 3.1565, swd: 12.5371, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 21.4709, mae: 2.9450, huber: 2.5173, swd: 9.7931, target_std: 18.3805
      Epoch 4 composite train-obj: 1.161291
            No improvement (3.1565), counter 3/5
    Epoch [5/50], Train Losses: mse: 8.4227, mae: 1.3862, huber: 1.0031, swd: 3.4841, target_std: 20.3784
    Epoch [5/50], Val Losses: mse: 29.3233, mae: 3.5618, huber: 3.1238, swd: 12.3254, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 20.6092, mae: 2.9035, huber: 2.4767, swd: 9.0317, target_std: 18.3805
      Epoch 5 composite train-obj: 1.003143
            No improvement (3.1238), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.6081, mae: 1.2820, huber: 0.9051, swd: 3.3066, target_std: 20.3782
    Epoch [6/50], Val Losses: mse: 29.2551, mae: 3.5607, huber: 3.1221, swd: 12.1803, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 20.8584, mae: 2.9285, huber: 2.5004, swd: 9.2105, target_std: 18.3805
      Epoch 6 composite train-obj: 0.905096
    Epoch [6/50], Test Losses: mse: 16.8077, mae: 2.6058, huber: 2.1858, swd: 7.9882, target_std: 18.3805
    Best round's Test MSE: 16.8077, MAE: 2.6058, SWD: 7.9882
    Best round's Validation MSE: 28.0048, MAE: 3.3876
    Best round's Test verification MSE : 16.8077, MAE: 2.6058, SWD: 7.9882
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.6277, mae: 2.7448, huber: 2.3313, swd: 11.2900, target_std: 20.3787
    Epoch [1/50], Val Losses: mse: 27.5922, mae: 3.3814, huber: 2.9478, swd: 10.9925, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 16.5947, mae: 2.5740, huber: 2.1547, swd: 7.1792, target_std: 18.3805
      Epoch 1 composite train-obj: 2.331303
            Val objective improved inf → 2.9478, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 19.4191, mae: 2.2864, huber: 1.8794, swd: 7.5554, target_std: 20.3786
    Epoch [2/50], Val Losses: mse: 28.7161, mae: 3.4622, huber: 3.0267, swd: 11.6232, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 19.4169, mae: 2.7927, huber: 2.3692, swd: 8.4770, target_std: 18.3805
      Epoch 2 composite train-obj: 1.879415
            No improvement (3.0267), counter 1/5
    Epoch [3/50], Train Losses: mse: 14.2438, mae: 1.9204, huber: 1.5200, swd: 5.0910, target_std: 20.3784
    Epoch [3/50], Val Losses: mse: 29.9118, mae: 3.5353, huber: 3.0988, swd: 12.0404, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 21.5360, mae: 2.9135, huber: 2.4889, swd: 9.5131, target_std: 18.3805
      Epoch 3 composite train-obj: 1.520030
            No improvement (3.0988), counter 2/5
    Epoch [4/50], Train Losses: mse: 10.8390, mae: 1.6467, huber: 1.2534, swd: 3.7135, target_std: 20.3786
    Epoch [4/50], Val Losses: mse: 29.2791, mae: 3.5424, huber: 3.1055, swd: 11.6702, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 20.4036, mae: 2.8721, huber: 2.4474, swd: 8.4878, target_std: 18.3805
      Epoch 4 composite train-obj: 1.253386
            No improvement (3.1055), counter 3/5
    Epoch [5/50], Train Losses: mse: 9.1232, mae: 1.4604, huber: 1.0744, swd: 3.3207, target_std: 20.3781
    Epoch [5/50], Val Losses: mse: 28.9085, mae: 3.5317, huber: 3.0943, swd: 11.1682, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 20.1468, mae: 2.8734, huber: 2.4466, swd: 8.1653, target_std: 18.3805
      Epoch 5 composite train-obj: 1.074353
            No improvement (3.0943), counter 4/5
    Epoch [6/50], Train Losses: mse: 8.1497, mae: 1.3443, huber: 0.9640, swd: 3.1342, target_std: 20.3781
    Epoch [6/50], Val Losses: mse: 29.1356, mae: 3.5386, huber: 3.1013, swd: 11.3060, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 19.8758, mae: 2.8518, huber: 2.4253, swd: 7.9856, target_std: 18.3805
      Epoch 6 composite train-obj: 0.963967
    Epoch [6/50], Test Losses: mse: 16.5947, mae: 2.5740, huber: 2.1547, swd: 7.1792, target_std: 18.3805
    Best round's Test MSE: 16.5947, MAE: 2.5740, SWD: 7.1792
    Best round's Validation MSE: 27.5922, MAE: 3.3814
    Best round's Test verification MSE : 16.5947, MAE: 2.5740, SWD: 7.1792
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.5931, mae: 2.7492, huber: 2.3354, swd: 13.2442, target_std: 20.3782
    Epoch [1/50], Val Losses: mse: 27.2455, mae: 3.3322, huber: 2.9003, swd: 12.5126, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 16.6075, mae: 2.5785, huber: 2.1598, swd: 8.3107, target_std: 18.3805
      Epoch 1 composite train-obj: 2.335443
            Val objective improved inf → 2.9003, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 20.1759, mae: 2.3484, huber: 1.9405, swd: 8.7744, target_std: 20.3782
    Epoch [2/50], Val Losses: mse: 28.5979, mae: 3.4434, huber: 3.0098, swd: 13.6024, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 19.0826, mae: 2.7713, huber: 2.3484, swd: 9.7220, target_std: 18.3805
      Epoch 2 composite train-obj: 1.940547
            No improvement (3.0098), counter 1/5
    Epoch [3/50], Train Losses: mse: 13.7521, mae: 1.9200, huber: 1.5192, swd: 5.1103, target_std: 20.3790
    Epoch [3/50], Val Losses: mse: 27.1729, mae: 3.4210, huber: 2.9875, swd: 11.9595, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 19.8298, mae: 2.8115, huber: 2.3882, swd: 9.6859, target_std: 18.3805
      Epoch 3 composite train-obj: 1.519192
            No improvement (2.9875), counter 2/5
    Epoch [4/50], Train Losses: mse: 10.1566, mae: 1.5877, huber: 1.1962, swd: 3.9959, target_std: 20.3782
    Epoch [4/50], Val Losses: mse: 27.2003, mae: 3.4233, huber: 2.9887, swd: 11.3603, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 20.0580, mae: 2.8334, huber: 2.4087, swd: 9.5042, target_std: 18.3805
      Epoch 4 composite train-obj: 1.196188
            No improvement (2.9887), counter 3/5
    Epoch [5/50], Train Losses: mse: 8.4296, mae: 1.3938, huber: 1.0106, swd: 3.6156, target_std: 20.3779
    Epoch [5/50], Val Losses: mse: 26.8535, mae: 3.4204, huber: 2.9849, swd: 11.1907, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 19.4626, mae: 2.8142, huber: 2.3880, swd: 8.9834, target_std: 18.3805
      Epoch 5 composite train-obj: 1.010640
            No improvement (2.9849), counter 4/5
    Epoch [6/50], Train Losses: mse: 7.6129, mae: 1.2815, huber: 0.9054, swd: 3.4378, target_std: 20.3779
    Epoch [6/50], Val Losses: mse: 27.1950, mae: 3.4331, huber: 2.9977, swd: 11.3857, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 19.5290, mae: 2.8122, huber: 2.3859, swd: 9.0046, target_std: 18.3805
      Epoch 6 composite train-obj: 0.905425
    Epoch [6/50], Test Losses: mse: 16.6075, mae: 2.5785, huber: 2.1598, swd: 8.3107, target_std: 18.3805
    Best round's Test MSE: 16.6075, MAE: 2.5785, SWD: 8.3107
    Best round's Validation MSE: 27.2455, MAE: 3.3322
    Best round's Test verification MSE : 16.6075, MAE: 2.5785, SWD: 8.3107
    
    ==================================================
    Experiment Summary (TimeMixer_ettm2_seq720_pred720_20250501_1649)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 16.6700 ± 0.0975
      mae: 2.5861 ± 0.0141
      huber: 2.1668 ± 0.0136
      swd: 7.8261 ± 0.4759
      target_std: 18.3805 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 27.6142 ± 0.3104
      mae: 3.3671 ± 0.0248
      huber: 2.9345 ± 0.0244
      swd: 12.1170 ± 0.8067
      target_std: 20.6733 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm2_seq720_pred720_20250501_1649
    Model: TimeMixer
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### PatchTST

#### pred=96


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 15.7315, mae: 2.2020, huber: 1.7970, swd: 6.9627, target_std: 20.3723
    Epoch [1/50], Val Losses: mse: 12.1428, mae: 2.1501, huber: 1.7435, swd: 6.6250, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 7.9966, mae: 1.7898, huber: 1.3878, swd: 4.0868, target_std: 18.4426
      Epoch 1 composite train-obj: 1.797027
            Val objective improved inf → 1.7435, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.8827, mae: 1.8985, huber: 1.5015, swd: 5.7309, target_std: 20.3717
    Epoch [2/50], Val Losses: mse: 11.6241, mae: 2.1299, huber: 1.7236, swd: 6.1620, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 7.8401, mae: 1.7766, huber: 1.3750, swd: 3.9730, target_std: 18.4426
      Epoch 2 composite train-obj: 1.501503
            Val objective improved 1.7435 → 1.7236, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.2654, mae: 1.8509, huber: 1.4556, swd: 5.3153, target_std: 20.3715
    Epoch [3/50], Val Losses: mse: 11.7222, mae: 2.1222, huber: 1.7156, swd: 6.1692, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.1062, mae: 1.7837, huber: 1.3825, swd: 4.1250, target_std: 18.4426
      Epoch 3 composite train-obj: 1.455564
            Val objective improved 1.7236 → 1.7156, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 10.6873, mae: 1.8062, huber: 1.4123, swd: 4.9171, target_std: 20.3709
    Epoch [4/50], Val Losses: mse: 12.2107, mae: 2.1910, huber: 1.7795, swd: 6.1596, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.5250, mae: 1.8678, huber: 1.4617, swd: 4.2223, target_std: 18.4426
      Epoch 4 composite train-obj: 1.412282
            No improvement (1.7795), counter 1/5
    Epoch [5/50], Train Losses: mse: 10.2215, mae: 1.7638, huber: 1.3716, swd: 4.5758, target_std: 20.3727
    Epoch [5/50], Val Losses: mse: 12.7264, mae: 2.2504, huber: 1.8353, swd: 6.3573, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.7759, mae: 1.8935, huber: 1.4843, swd: 4.3267, target_std: 18.4426
      Epoch 5 composite train-obj: 1.371566
            No improvement (1.8353), counter 2/5
    Epoch [6/50], Train Losses: mse: 9.7923, mae: 1.7278, huber: 1.3366, swd: 4.2517, target_std: 20.3711
    Epoch [6/50], Val Losses: mse: 15.8495, mae: 2.5792, huber: 2.1522, swd: 6.3179, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 11.2565, mae: 2.2044, huber: 1.7838, swd: 4.5061, target_std: 18.4426
      Epoch 6 composite train-obj: 1.336607
            No improvement (2.1522), counter 3/5
    Epoch [7/50], Train Losses: mse: 9.3691, mae: 1.6889, huber: 1.2989, swd: 3.9056, target_std: 20.3710
    Epoch [7/50], Val Losses: mse: 13.4267, mae: 2.3128, huber: 1.8967, swd: 6.5307, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 9.5971, mae: 1.9971, huber: 1.5852, swd: 4.7426, target_std: 18.4426
      Epoch 7 composite train-obj: 1.298890
            No improvement (1.8967), counter 4/5
    Epoch [8/50], Train Losses: mse: 9.0332, mae: 1.6535, huber: 1.2648, swd: 3.6450, target_std: 20.3717
    Epoch [8/50], Val Losses: mse: 17.2749, mae: 2.6805, huber: 2.2514, swd: 7.2702, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 12.1021, mae: 2.2721, huber: 1.8498, swd: 5.1214, target_std: 18.4426
      Epoch 8 composite train-obj: 1.264820
    Epoch [8/50], Test Losses: mse: 8.1062, mae: 1.7837, huber: 1.3825, swd: 4.1250, target_std: 18.4426
    Best round's Test MSE: 8.1062, MAE: 1.7837, SWD: 4.1250
    Best round's Validation MSE: 11.7222, MAE: 2.1222
    Best round's Test verification MSE : 8.1062, MAE: 1.7837, SWD: 4.1250
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 14.9971, mae: 2.1422, huber: 1.7391, swd: 6.5023, target_std: 20.3713
    Epoch [1/50], Val Losses: mse: 11.8046, mae: 2.1483, huber: 1.7403, swd: 6.0895, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 7.7240, mae: 1.7784, huber: 1.3756, swd: 3.6840, target_std: 18.4426
      Epoch 1 composite train-obj: 1.739087
            Val objective improved inf → 1.7403, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.8676, mae: 1.8912, huber: 1.4958, swd: 5.5203, target_std: 20.3704
    Epoch [2/50], Val Losses: mse: 11.6232, mae: 2.1110, huber: 1.7071, swd: 5.9848, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 7.7128, mae: 1.7607, huber: 1.3605, swd: 3.6764, target_std: 18.4426
      Epoch 2 composite train-obj: 1.495847
            Val objective improved 1.7403 → 1.7071, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.2324, mae: 1.8426, huber: 1.4487, swd: 5.1413, target_std: 20.3715
    Epoch [3/50], Val Losses: mse: 12.0257, mae: 2.1721, huber: 1.7630, swd: 6.2769, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 7.6557, mae: 1.7739, huber: 1.3704, swd: 3.6389, target_std: 18.4426
      Epoch 3 composite train-obj: 1.448707
            No improvement (1.7630), counter 1/5
    Epoch [4/50], Train Losses: mse: 10.8095, mae: 1.8052, huber: 1.4124, swd: 4.8645, target_std: 20.3710
    Epoch [4/50], Val Losses: mse: 11.8186, mae: 2.1292, huber: 1.7236, swd: 6.1179, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 7.7105, mae: 1.7656, huber: 1.3642, swd: 3.7478, target_std: 18.4426
      Epoch 4 composite train-obj: 1.412408
            No improvement (1.7236), counter 2/5
    Epoch [5/50], Train Losses: mse: 10.2835, mae: 1.7627, huber: 1.3708, swd: 4.4881, target_std: 20.3716
    Epoch [5/50], Val Losses: mse: 12.2930, mae: 2.1892, huber: 1.7776, swd: 6.1833, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.2454, mae: 1.8580, huber: 1.4512, swd: 4.0069, target_std: 18.4426
      Epoch 5 composite train-obj: 1.370774
            No improvement (1.7776), counter 3/5
    Epoch [6/50], Train Losses: mse: 9.8255, mae: 1.7219, huber: 1.3311, swd: 4.1507, target_std: 20.3713
    Epoch [6/50], Val Losses: mse: 12.5531, mae: 2.2069, huber: 1.7950, swd: 6.3995, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.3099, mae: 1.8400, huber: 1.4345, swd: 4.0094, target_std: 18.4426
      Epoch 6 composite train-obj: 1.331114
            No improvement (1.7950), counter 4/5
    Epoch [7/50], Train Losses: mse: 9.3165, mae: 1.6805, huber: 1.2905, swd: 3.7496, target_std: 20.3714
    Epoch [7/50], Val Losses: mse: 14.1176, mae: 2.3844, huber: 1.9645, swd: 7.1825, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 9.3192, mae: 1.9482, huber: 1.5377, swd: 4.5591, target_std: 18.4426
      Epoch 7 composite train-obj: 1.290547
    Epoch [7/50], Test Losses: mse: 7.7128, mae: 1.7607, huber: 1.3605, swd: 3.6764, target_std: 18.4426
    Best round's Test MSE: 7.7128, MAE: 1.7607, SWD: 3.6764
    Best round's Validation MSE: 11.6232, MAE: 2.1110
    Best round's Test verification MSE : 7.7128, MAE: 1.7607, SWD: 3.6764
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 15.1077, mae: 2.1395, huber: 1.7365, swd: 6.1643, target_std: 20.3718
    Epoch [1/50], Val Losses: mse: 11.4765, mae: 2.1319, huber: 1.7234, swd: 5.5262, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 7.8680, mae: 1.8012, huber: 1.3976, swd: 3.6041, target_std: 18.4426
      Epoch 1 composite train-obj: 1.736462
            Val objective improved inf → 1.7234, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 11.7566, mae: 1.8875, huber: 1.4917, swd: 5.0917, target_std: 20.3699
    Epoch [2/50], Val Losses: mse: 11.8130, mae: 2.1751, huber: 1.7654, swd: 5.7661, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 7.8158, mae: 1.7826, huber: 1.3802, swd: 3.5386, target_std: 18.4426
      Epoch 2 composite train-obj: 1.491681
            No improvement (1.7654), counter 1/5
    Epoch [3/50], Train Losses: mse: 11.1995, mae: 1.8407, huber: 1.4467, swd: 4.7683, target_std: 20.3713
    Epoch [3/50], Val Losses: mse: 11.6985, mae: 2.1361, huber: 1.7293, swd: 5.6612, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 7.6672, mae: 1.7510, huber: 1.3505, swd: 3.4513, target_std: 18.4426
      Epoch 3 composite train-obj: 1.446721
            No improvement (1.7293), counter 2/5
    Epoch [4/50], Train Losses: mse: 10.6871, mae: 1.8024, huber: 1.4094, swd: 4.4329, target_std: 20.3711
    Epoch [4/50], Val Losses: mse: 11.5272, mae: 2.1075, huber: 1.7016, swd: 5.6093, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 7.7119, mae: 1.7636, huber: 1.3620, swd: 3.5023, target_std: 18.4426
      Epoch 4 composite train-obj: 1.409406
            Val objective improved 1.7234 → 1.7016, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 10.1392, mae: 1.7599, huber: 1.3680, swd: 4.0499, target_std: 20.3711
    Epoch [5/50], Val Losses: mse: 12.8488, mae: 2.2637, huber: 1.8483, swd: 6.2220, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.8419, mae: 1.9388, huber: 1.5268, swd: 4.0950, target_std: 18.4426
      Epoch 5 composite train-obj: 1.367956
            No improvement (1.8483), counter 1/5
    Epoch [6/50], Train Losses: mse: 9.7262, mae: 1.7211, huber: 1.3304, swd: 3.7711, target_std: 20.3721
    Epoch [6/50], Val Losses: mse: 12.9380, mae: 2.2621, huber: 1.8483, swd: 5.8327, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.8948, mae: 1.9180, huber: 1.5088, swd: 3.7669, target_std: 18.4426
      Epoch 6 composite train-obj: 1.330360
            No improvement (1.8483), counter 2/5
    Epoch [7/50], Train Losses: mse: 9.3320, mae: 1.6823, huber: 1.2928, swd: 3.5073, target_std: 20.3715
    Epoch [7/50], Val Losses: mse: 13.6758, mae: 2.3447, huber: 1.9282, swd: 5.9144, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 9.5986, mae: 2.0007, huber: 1.5893, swd: 4.0281, target_std: 18.4426
      Epoch 7 composite train-obj: 1.292752
            No improvement (1.9282), counter 3/5
    Epoch [8/50], Train Losses: mse: 8.9999, mae: 1.6479, huber: 1.2595, swd: 3.2960, target_std: 20.3713
    Epoch [8/50], Val Losses: mse: 14.6920, mae: 2.4352, huber: 2.0136, swd: 6.8051, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 10.2519, mae: 2.0420, huber: 1.6289, swd: 4.6845, target_std: 18.4426
      Epoch 8 composite train-obj: 1.259546
            No improvement (2.0136), counter 4/5
    Epoch [9/50], Train Losses: mse: 8.7080, mae: 1.6153, huber: 1.2282, swd: 3.0972, target_std: 20.3714
    Epoch [9/50], Val Losses: mse: 13.4353, mae: 2.3097, huber: 1.8944, swd: 6.1667, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 9.5649, mae: 1.9824, huber: 1.5719, swd: 4.2800, target_std: 18.4426
      Epoch 9 composite train-obj: 1.228180
    Epoch [9/50], Test Losses: mse: 7.7119, mae: 1.7636, huber: 1.3620, swd: 3.5023, target_std: 18.4426
    Best round's Test MSE: 7.7119, MAE: 1.7636, SWD: 3.5023
    Best round's Validation MSE: 11.5272, MAE: 2.1075
    Best round's Test verification MSE : 7.7119, MAE: 1.7636, SWD: 3.5023
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq720_pred96_20250501_1433)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.8437 ± 0.1857
      mae: 1.7694 ± 0.0102
      huber: 1.3684 ± 0.0101
      swd: 3.7679 ± 0.2623
      target_std: 18.4426 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 11.6242 ± 0.0796
      mae: 2.1136 ± 0.0063
      huber: 1.7081 ± 0.0057
      swd: 5.9211 ± 0.2330
      target_std: 20.6844 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq720_pred96_20250501_1433
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 20.3868, mae: 2.5000, huber: 2.0890, swd: 9.4809, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 16.4139, mae: 2.5308, huber: 2.1136, swd: 8.8656, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 9.8610, mae: 2.0169, huber: 1.6073, swd: 4.9237, target_std: 18.4106
      Epoch 1 composite train-obj: 2.088986
            Val objective improved inf → 2.1136, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 15.3465, mae: 2.1613, huber: 1.7569, swd: 7.4287, target_std: 20.3719
    Epoch [2/50], Val Losses: mse: 16.3371, mae: 2.5245, huber: 2.1073, swd: 8.7762, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 9.9321, mae: 2.0146, huber: 1.6048, swd: 5.0512, target_std: 18.4106
      Epoch 2 composite train-obj: 1.756916
            Val objective improved 2.1136 → 2.1073, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 14.2594, mae: 2.0891, huber: 1.6864, swd: 6.6060, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 16.7249, mae: 2.5650, huber: 2.1457, swd: 8.6770, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 9.9684, mae: 2.0186, huber: 1.6079, swd: 4.9180, target_std: 18.4106
      Epoch 3 composite train-obj: 1.686407
            No improvement (2.1457), counter 1/5
    Epoch [4/50], Train Losses: mse: 13.4206, mae: 2.0257, huber: 1.6240, swd: 5.9656, target_std: 20.3719
    Epoch [4/50], Val Losses: mse: 18.6343, mae: 2.7178, huber: 2.2927, swd: 8.8821, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 11.6393, mae: 2.1791, huber: 1.7631, swd: 5.4731, target_std: 18.4106
      Epoch 4 composite train-obj: 1.624045
            No improvement (2.2927), counter 2/5
    Epoch [5/50], Train Losses: mse: 12.7320, mae: 1.9671, huber: 1.5669, swd: 5.4406, target_std: 20.3720
    Epoch [5/50], Val Losses: mse: 17.9618, mae: 2.6443, huber: 2.2233, swd: 9.1785, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 11.6884, mae: 2.1828, huber: 1.7677, swd: 5.9948, target_std: 18.4106
      Epoch 5 composite train-obj: 1.566941
            No improvement (2.2233), counter 3/5
    Epoch [6/50], Train Losses: mse: 12.1287, mae: 1.9125, huber: 1.5138, swd: 4.9836, target_std: 20.3720
    Epoch [6/50], Val Losses: mse: 20.6045, mae: 2.8583, huber: 2.4299, swd: 10.0524, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 12.9334, mae: 2.3007, huber: 1.8812, swd: 5.9777, target_std: 18.4106
      Epoch 6 composite train-obj: 1.513778
            No improvement (2.4299), counter 4/5
    Epoch [7/50], Train Losses: mse: 11.5387, mae: 1.8595, huber: 1.4622, swd: 4.5373, target_std: 20.3719
    Epoch [7/50], Val Losses: mse: 20.6257, mae: 2.8931, huber: 2.4641, swd: 9.5789, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 14.1678, mae: 2.4362, huber: 2.0131, swd: 6.9322, target_std: 18.4106
      Epoch 7 composite train-obj: 1.462158
    Epoch [7/50], Test Losses: mse: 9.9321, mae: 2.0146, huber: 1.6048, swd: 5.0512, target_std: 18.4106
    Best round's Test MSE: 9.9321, MAE: 2.0146, SWD: 5.0512
    Best round's Validation MSE: 16.3371, MAE: 2.5245
    Best round's Test verification MSE : 9.9321, MAE: 2.0146, SWD: 5.0512
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 19.4599, mae: 2.4177, huber: 2.0084, swd: 9.6066, target_std: 20.3718
    Epoch [1/50], Val Losses: mse: 16.4309, mae: 2.5545, huber: 2.1361, swd: 8.9842, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 9.6302, mae: 1.9832, huber: 1.5733, swd: 4.8084, target_std: 18.4106
      Epoch 1 composite train-obj: 2.008385
            Val objective improved inf → 2.1361, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 15.6148, mae: 2.1595, huber: 1.7563, swd: 8.0089, target_std: 20.3718
    Epoch [2/50], Val Losses: mse: 15.6965, mae: 2.5115, huber: 2.0936, swd: 8.6376, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 9.7728, mae: 2.0216, huber: 1.6109, swd: 5.0496, target_std: 18.4106
      Epoch 2 composite train-obj: 1.756347
            Val objective improved 2.1361 → 2.0936, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 14.5353, mae: 2.0870, huber: 1.6855, swd: 7.1577, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 16.3207, mae: 2.5306, huber: 2.1138, swd: 8.9514, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 9.8896, mae: 2.0152, huber: 1.6053, swd: 5.1097, target_std: 18.4106
      Epoch 3 composite train-obj: 1.685490
            No improvement (2.1138), counter 1/5
    Epoch [4/50], Train Losses: mse: 13.5327, mae: 2.0206, huber: 1.6199, swd: 6.3069, target_std: 20.3717
    Epoch [4/50], Val Losses: mse: 16.9983, mae: 2.5961, huber: 2.1760, swd: 9.3827, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.6281, mae: 2.0879, huber: 1.6754, swd: 5.6554, target_std: 18.4106
      Epoch 4 composite train-obj: 1.619857
            No improvement (2.1760), counter 2/5
    Epoch [5/50], Train Losses: mse: 12.5563, mae: 1.9468, huber: 1.5474, swd: 5.4778, target_std: 20.3720
    Epoch [5/50], Val Losses: mse: 17.5399, mae: 2.6136, huber: 2.1946, swd: 9.9653, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 11.1668, mae: 2.1346, huber: 1.7213, swd: 6.0951, target_std: 18.4106
      Epoch 5 composite train-obj: 1.547448
            No improvement (2.1946), counter 3/5
    Epoch [6/50], Train Losses: mse: 11.9075, mae: 1.8882, huber: 1.4902, swd: 4.9626, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 18.3550, mae: 2.6784, huber: 2.2572, swd: 10.3494, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 11.9585, mae: 2.2173, huber: 1.8017, swd: 6.5686, target_std: 18.4106
      Epoch 6 composite train-obj: 1.490154
            No improvement (2.2572), counter 4/5
    Epoch [7/50], Train Losses: mse: 11.3800, mae: 1.8392, huber: 1.4422, swd: 4.5630, target_std: 20.3716
    Epoch [7/50], Val Losses: mse: 18.7979, mae: 2.7429, huber: 2.3183, swd: 10.4243, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 12.7664, mae: 2.3120, huber: 1.8927, swd: 7.1639, target_std: 18.4106
      Epoch 7 composite train-obj: 1.442156
    Epoch [7/50], Test Losses: mse: 9.7728, mae: 2.0216, huber: 1.6109, swd: 5.0496, target_std: 18.4106
    Best round's Test MSE: 9.7728, MAE: 2.0216, SWD: 5.0496
    Best round's Validation MSE: 15.6965, MAE: 2.5115
    Best round's Test verification MSE : 9.7728, MAE: 2.0216, SWD: 5.0496
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 19.4254, mae: 2.4236, huber: 2.0144, swd: 8.0496, target_std: 20.3721
    Epoch [1/50], Val Losses: mse: 16.2820, mae: 2.5474, huber: 2.1281, swd: 7.8910, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 9.9291, mae: 2.0413, huber: 1.6300, swd: 4.5028, target_std: 18.4106
      Epoch 1 composite train-obj: 2.014355
            Val objective improved inf → 2.1281, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 15.6137, mae: 2.1635, huber: 1.7596, swd: 6.8440, target_std: 20.3720
    Epoch [2/50], Val Losses: mse: 16.8331, mae: 2.5707, huber: 2.1509, swd: 7.8819, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 10.0684, mae: 2.0099, huber: 1.6001, swd: 4.3638, target_std: 18.4106
      Epoch 2 composite train-obj: 1.759617
            No improvement (2.1509), counter 1/5
    Epoch [3/50], Train Losses: mse: 14.4374, mae: 2.0859, huber: 1.6837, swd: 6.0268, target_std: 20.3718
    Epoch [3/50], Val Losses: mse: 16.7155, mae: 2.5623, huber: 2.1435, swd: 7.8687, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.2485, mae: 2.0344, huber: 1.6236, swd: 4.6345, target_std: 18.4106
      Epoch 3 composite train-obj: 1.683717
            No improvement (2.1435), counter 2/5
    Epoch [4/50], Train Losses: mse: 13.3987, mae: 2.0193, huber: 1.6181, swd: 5.2489, target_std: 20.3718
    Epoch [4/50], Val Losses: mse: 16.9404, mae: 2.6018, huber: 2.1822, swd: 7.7533, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.8825, mae: 2.1030, huber: 1.6890, swd: 4.9001, target_std: 18.4106
      Epoch 4 composite train-obj: 1.618112
            No improvement (2.1822), counter 3/5
    Epoch [5/50], Train Losses: mse: 12.6645, mae: 1.9589, huber: 1.5592, swd: 4.7317, target_std: 20.3720
    Epoch [5/50], Val Losses: mse: 17.8512, mae: 2.7069, huber: 2.2807, swd: 8.0681, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 11.5255, mae: 2.1798, huber: 1.7638, swd: 5.1855, target_std: 18.4106
      Epoch 5 composite train-obj: 1.559212
            No improvement (2.2807), counter 4/5
    Epoch [6/50], Train Losses: mse: 12.0284, mae: 1.9007, huber: 1.5026, swd: 4.3163, target_std: 20.3722
    Epoch [6/50], Val Losses: mse: 18.1652, mae: 2.7433, huber: 2.3180, swd: 7.9461, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 12.1350, mae: 2.2544, huber: 1.8364, swd: 5.4417, target_std: 18.4106
      Epoch 6 composite train-obj: 1.502566
    Epoch [6/50], Test Losses: mse: 9.9291, mae: 2.0413, huber: 1.6300, swd: 4.5028, target_std: 18.4106
    Best round's Test MSE: 9.9291, MAE: 2.0413, SWD: 4.5028
    Best round's Validation MSE: 16.2820, MAE: 2.5474
    Best round's Test verification MSE : 9.9291, MAE: 2.0413, SWD: 4.5028
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq720_pred196_20250501_1706)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.8780 ± 0.0744
      mae: 2.0258 ± 0.0113
      huber: 1.6152 ± 0.0107
      swd: 4.8679 ± 0.2582
      target_std: 18.4106 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 16.1052 ± 0.2899
      mae: 2.5278 ± 0.0148
      huber: 2.1097 ± 0.0142
      swd: 8.4349 ± 0.3888
      target_std: 20.7091 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq720_pred196_20250501_1706
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 24.3103, mae: 2.6976, huber: 2.2827, swd: 11.1576, target_std: 20.3733
    Epoch [1/50], Val Losses: mse: 19.6403, mae: 2.8034, huber: 2.3827, swd: 9.3295, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 11.9716, mae: 2.2152, huber: 1.8018, swd: 5.8491, target_std: 18.3950
      Epoch 1 composite train-obj: 2.282701
            Val objective improved inf → 2.3827, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 18.6411, mae: 2.3698, huber: 1.9610, swd: 8.5621, target_std: 20.3736
    Epoch [2/50], Val Losses: mse: 20.0285, mae: 2.8591, huber: 2.4349, swd: 9.4330, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.2671, mae: 2.2417, huber: 1.8282, swd: 6.0709, target_std: 18.3950
      Epoch 2 composite train-obj: 1.960969
            No improvement (2.4349), counter 1/5
    Epoch [3/50], Train Losses: mse: 17.1940, mae: 2.2790, huber: 1.8716, swd: 7.4215, target_std: 20.3730
    Epoch [3/50], Val Losses: mse: 20.8511, mae: 2.9016, huber: 2.4759, swd: 9.8915, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.7229, mae: 2.2732, huber: 1.8587, swd: 6.4335, target_std: 18.3950
      Epoch 3 composite train-obj: 1.871611
            No improvement (2.4759), counter 2/5
    Epoch [4/50], Train Losses: mse: 16.1457, mae: 2.2017, huber: 1.7951, swd: 6.6467, target_std: 20.3732
    Epoch [4/50], Val Losses: mse: 22.2552, mae: 2.9905, huber: 2.5633, swd: 10.9792, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 14.1496, mae: 2.3850, huber: 1.9679, swd: 7.4939, target_std: 18.3950
      Epoch 4 composite train-obj: 1.795141
            No improvement (2.5633), counter 3/5
    Epoch [5/50], Train Losses: mse: 15.2687, mae: 2.1290, huber: 1.7239, swd: 6.0181, target_std: 20.3735
    Epoch [5/50], Val Losses: mse: 26.5674, mae: 3.3319, huber: 2.8949, swd: 11.4424, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 16.7434, mae: 2.6110, huber: 2.1856, swd: 7.8576, target_std: 18.3950
      Epoch 5 composite train-obj: 1.723939
            No improvement (2.8949), counter 4/5
    Epoch [6/50], Train Losses: mse: 14.5399, mae: 2.0690, huber: 1.6649, swd: 5.5119, target_std: 20.3733
    Epoch [6/50], Val Losses: mse: 26.1069, mae: 3.2633, huber: 2.8301, swd: 12.3376, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 16.1901, mae: 2.5753, huber: 2.1514, swd: 8.0840, target_std: 18.3950
      Epoch 6 composite train-obj: 1.664894
    Epoch [6/50], Test Losses: mse: 11.9716, mae: 2.2152, huber: 1.8018, swd: 5.8491, target_std: 18.3950
    Best round's Test MSE: 11.9716, MAE: 2.2152, SWD: 5.8491
    Best round's Validation MSE: 19.6403, MAE: 2.8034
    Best round's Test verification MSE : 11.9716, MAE: 2.2152, SWD: 5.8491
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 23.9472, mae: 2.6645, huber: 2.2501, swd: 11.7614, target_std: 20.3735
    Epoch [1/50], Val Losses: mse: 20.1173, mae: 2.8643, huber: 2.4396, swd: 10.2276, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 11.7254, mae: 2.2173, huber: 1.8024, swd: 6.0088, target_std: 18.3950
      Epoch 1 composite train-obj: 2.250072
            Val objective improved inf → 2.4396, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 19.3924, mae: 2.4063, huber: 1.9965, swd: 9.5869, target_std: 20.3738
    Epoch [2/50], Val Losses: mse: 19.7444, mae: 2.8522, huber: 2.4264, swd: 9.5301, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.1318, mae: 2.2423, huber: 1.8265, swd: 6.2373, target_std: 18.3950
      Epoch 2 composite train-obj: 1.996459
            Val objective improved 2.4396 → 2.4264, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 17.7242, mae: 2.3168, huber: 1.9083, swd: 8.1366, target_std: 20.3735
    Epoch [3/50], Val Losses: mse: 20.8670, mae: 2.9518, huber: 2.5224, swd: 10.4339, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.6002, mae: 2.3099, huber: 1.8920, swd: 6.6719, target_std: 18.3950
      Epoch 3 composite train-obj: 1.908261
            No improvement (2.5224), counter 1/5
    Epoch [4/50], Train Losses: mse: 16.6627, mae: 2.2408, huber: 1.8333, swd: 7.2860, target_std: 20.3733
    Epoch [4/50], Val Losses: mse: 21.2915, mae: 2.9543, huber: 2.5274, swd: 10.6437, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 12.9434, mae: 2.3194, huber: 1.9021, swd: 6.9547, target_std: 18.3950
      Epoch 4 composite train-obj: 1.833256
            No improvement (2.5274), counter 2/5
    Epoch [5/50], Train Losses: mse: 15.8115, mae: 2.1741, huber: 1.7674, swd: 6.6301, target_std: 20.3731
    Epoch [5/50], Val Losses: mse: 22.1463, mae: 3.0355, huber: 2.6049, swd: 11.0344, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 14.0651, mae: 2.4315, huber: 2.0106, swd: 7.4850, target_std: 18.3950
      Epoch 5 composite train-obj: 1.767448
            No improvement (2.6049), counter 3/5
    Epoch [6/50], Train Losses: mse: 15.0242, mae: 2.1088, huber: 1.7032, swd: 6.0717, target_std: 20.3731
    Epoch [6/50], Val Losses: mse: 23.1727, mae: 3.1266, huber: 2.6921, swd: 10.6258, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 15.0288, mae: 2.4926, huber: 2.0691, swd: 7.6163, target_std: 18.3950
      Epoch 6 composite train-obj: 1.703239
            No improvement (2.6921), counter 4/5
    Epoch [7/50], Train Losses: mse: 14.3571, mae: 2.0496, huber: 1.6455, swd: 5.6209, target_std: 20.3737
    Epoch [7/50], Val Losses: mse: 27.2340, mae: 3.4553, huber: 3.0122, swd: 12.7851, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 16.8297, mae: 2.6748, huber: 2.2449, swd: 7.9186, target_std: 18.3950
      Epoch 7 composite train-obj: 1.645458
    Epoch [7/50], Test Losses: mse: 12.1318, mae: 2.2423, huber: 1.8265, swd: 6.2373, target_std: 18.3950
    Best round's Test MSE: 12.1318, MAE: 2.2423, SWD: 6.2373
    Best round's Validation MSE: 19.7444, MAE: 2.8522
    Best round's Test verification MSE : 12.1318, MAE: 2.2423, SWD: 6.2373
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 23.8197, mae: 2.6618, huber: 2.2476, swd: 10.7522, target_std: 20.3733
    Epoch [1/50], Val Losses: mse: 20.7629, mae: 2.8657, huber: 2.4425, swd: 9.4853, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 11.9797, mae: 2.1954, huber: 1.7809, swd: 5.5581, target_std: 18.3950
      Epoch 1 composite train-obj: 2.247585
            Val objective improved inf → 2.4425, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 19.1793, mae: 2.3884, huber: 1.9792, swd: 8.7659, target_std: 20.3733
    Epoch [2/50], Val Losses: mse: 20.6057, mae: 2.8682, huber: 2.4428, swd: 9.1460, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.5092, mae: 2.2352, huber: 1.8199, swd: 5.9351, target_std: 18.3950
      Epoch 2 composite train-obj: 1.979150
            No improvement (2.4428), counter 1/5
    Epoch [3/50], Train Losses: mse: 17.6790, mae: 2.3000, huber: 1.8924, swd: 7.5719, target_std: 20.3737
    Epoch [3/50], Val Losses: mse: 21.0781, mae: 2.9040, huber: 2.4755, swd: 9.5634, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.5418, mae: 2.2605, huber: 1.8445, swd: 5.9851, target_std: 18.3950
      Epoch 3 composite train-obj: 1.892370
            No improvement (2.4755), counter 2/5
    Epoch [4/50], Train Losses: mse: 16.5302, mae: 2.2237, huber: 1.8172, swd: 6.7194, target_std: 20.3737
    Epoch [4/50], Val Losses: mse: 21.9665, mae: 2.9454, huber: 2.5188, swd: 10.2254, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 12.9549, mae: 2.2981, huber: 1.8809, swd: 6.2234, target_std: 18.3950
      Epoch 4 composite train-obj: 1.817152
            No improvement (2.5188), counter 3/5
    Epoch [5/50], Train Losses: mse: 15.7059, mae: 2.1649, huber: 1.7589, swd: 6.1551, target_std: 20.3735
    Epoch [5/50], Val Losses: mse: 23.5926, mae: 3.0780, huber: 2.6474, swd: 10.5723, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 14.1456, mae: 2.4163, huber: 1.9953, swd: 6.6176, target_std: 18.3950
      Epoch 5 composite train-obj: 1.758906
            No improvement (2.6474), counter 4/5
    Epoch [6/50], Train Losses: mse: 14.9194, mae: 2.0997, huber: 1.6950, swd: 5.6330, target_std: 20.3736
    Epoch [6/50], Val Losses: mse: 24.0352, mae: 3.1299, huber: 2.6979, swd: 10.7752, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 14.4363, mae: 2.4573, huber: 2.0344, swd: 6.7970, target_std: 18.3950
      Epoch 6 composite train-obj: 1.695003
    Epoch [6/50], Test Losses: mse: 11.9797, mae: 2.1954, huber: 1.7809, swd: 5.5581, target_std: 18.3950
    Best round's Test MSE: 11.9797, MAE: 2.1954, SWD: 5.5581
    Best round's Validation MSE: 20.7629, MAE: 2.8657
    Best round's Test verification MSE : 11.9797, MAE: 2.1954, SWD: 5.5581
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq720_pred336_20250501_1719)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.0277 ± 0.0737
      mae: 2.2176 ± 0.0193
      huber: 1.8031 ± 0.0187
      swd: 5.8815 ± 0.2782
      target_std: 18.3950 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 20.0492 ± 0.5064
      mae: 2.8404 ± 0.0267
      huber: 2.4172 ± 0.0253
      swd: 9.4483 ± 0.0859
      target_std: 20.7022 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq720_pred336_20250501_1719
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    enc_in=data_mgr.datasets['ettm2']['channels'],
    dec_in=data_mgr.datasets['ettm2']['channels'],
    c_out=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 31.6909, mae: 3.0707, huber: 2.6481, swd: 14.0014, target_std: 20.3779
    Epoch [1/50], Val Losses: mse: 26.0532, mae: 3.3090, huber: 2.8748, swd: 10.4676, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 15.3441, mae: 2.5227, huber: 2.1011, swd: 6.6584, target_std: 18.3805
      Epoch 1 composite train-obj: 2.648075
            Val objective improved inf → 2.8748, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 25.5285, mae: 2.7275, huber: 2.3100, swd: 11.0149, target_std: 20.3785
    Epoch [2/50], Val Losses: mse: 26.0335, mae: 3.3148, huber: 2.8780, swd: 10.3290, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 15.5687, mae: 2.5334, huber: 2.1121, swd: 7.0535, target_std: 18.3805
      Epoch 2 composite train-obj: 2.310001
            No improvement (2.8780), counter 1/5
    Epoch [3/50], Train Losses: mse: 23.6815, mae: 2.6158, huber: 2.1996, swd: 9.7335, target_std: 20.3778
    Epoch [3/50], Val Losses: mse: 26.0726, mae: 3.3415, huber: 2.9027, swd: 10.9881, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 17.1716, mae: 2.7091, huber: 2.2848, swd: 8.4394, target_std: 18.3805
      Epoch 3 composite train-obj: 2.199593
            No improvement (2.9027), counter 2/5
    Epoch [4/50], Train Losses: mse: 22.0885, mae: 2.5114, huber: 2.0968, swd: 8.7269, target_std: 20.3777
    Epoch [4/50], Val Losses: mse: 27.3656, mae: 3.3895, huber: 2.9528, swd: 11.7308, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 18.2039, mae: 2.7423, huber: 2.3183, swd: 9.0988, target_std: 18.3805
      Epoch 4 composite train-obj: 2.096831
            No improvement (2.9528), counter 3/5
    Epoch [5/50], Train Losses: mse: 20.7285, mae: 2.4304, huber: 2.0167, swd: 7.8655, target_std: 20.3779
    Epoch [5/50], Val Losses: mse: 28.5462, mae: 3.4480, huber: 3.0098, swd: 11.9539, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 19.9202, mae: 2.8606, huber: 2.4343, swd: 9.9737, target_std: 18.3805
      Epoch 5 composite train-obj: 2.016739
            No improvement (3.0098), counter 4/5
    Epoch [6/50], Train Losses: mse: 19.7281, mae: 2.3658, huber: 1.9532, swd: 7.2931, target_std: 20.3779
    Epoch [6/50], Val Losses: mse: 32.1455, mae: 3.7281, huber: 3.2826, swd: 12.1113, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 22.1693, mae: 3.0372, huber: 2.6048, swd: 9.9193, target_std: 18.3805
      Epoch 6 composite train-obj: 1.953248
    Epoch [6/50], Test Losses: mse: 15.3441, mae: 2.5227, huber: 2.1011, swd: 6.6584, target_std: 18.3805
    Best round's Test MSE: 15.3441, MAE: 2.5227, SWD: 6.6584
    Best round's Validation MSE: 26.0532, MAE: 3.3090
    Best round's Test verification MSE : 15.3441, MAE: 2.5227, SWD: 6.6584
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 30.5850, mae: 3.0148, huber: 2.5927, swd: 12.4940, target_std: 20.3781
    Epoch [1/50], Val Losses: mse: 25.8042, mae: 3.3093, huber: 2.8749, swd: 9.6835, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 16.0744, mae: 2.5964, huber: 2.1733, swd: 7.0803, target_std: 18.3805
      Epoch 1 composite train-obj: 2.592694
            Val objective improved inf → 2.8749, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 25.4534, mae: 2.7155, huber: 2.2972, swd: 10.1255, target_std: 20.3785
    Epoch [2/50], Val Losses: mse: 26.2516, mae: 3.3434, huber: 2.9058, swd: 10.0989, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 16.8437, mae: 2.6837, huber: 2.2585, swd: 7.6817, target_std: 18.3805
      Epoch 2 composite train-obj: 2.297208
            No improvement (2.9058), counter 1/5
    Epoch [3/50], Train Losses: mse: 24.2287, mae: 2.6300, huber: 2.2130, swd: 9.3623, target_std: 20.3784
    Epoch [3/50], Val Losses: mse: 27.1008, mae: 3.3639, huber: 2.9248, swd: 10.4389, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 16.8995, mae: 2.6506, huber: 2.2267, swd: 7.2774, target_std: 18.3805
      Epoch 3 composite train-obj: 2.213039
            No improvement (2.9248), counter 2/5
    Epoch [4/50], Train Losses: mse: 22.9595, mae: 2.5406, huber: 2.1252, swd: 8.6201, target_std: 20.3781
    Epoch [4/50], Val Losses: mse: 28.0128, mae: 3.3798, huber: 2.9397, swd: 11.2282, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 18.1908, mae: 2.7815, huber: 2.3548, swd: 8.2364, target_std: 18.3805
      Epoch 4 composite train-obj: 2.125239
            No improvement (2.9397), counter 3/5
    Epoch [5/50], Train Losses: mse: 21.8743, mae: 2.4667, huber: 2.0526, swd: 8.0347, target_std: 20.3782
    Epoch [5/50], Val Losses: mse: 28.7677, mae: 3.4281, huber: 2.9888, swd: 11.6782, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 19.5384, mae: 2.8826, huber: 2.4555, swd: 9.1052, target_std: 18.3805
      Epoch 5 composite train-obj: 2.052570
            No improvement (2.9888), counter 4/5
    Epoch [6/50], Train Losses: mse: 20.7146, mae: 2.3930, huber: 1.9801, swd: 7.3965, target_std: 20.3784
    Epoch [6/50], Val Losses: mse: 29.2669, mae: 3.4874, huber: 3.0465, swd: 11.5407, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 19.4121, mae: 2.8593, huber: 2.4317, swd: 8.5762, target_std: 18.3805
      Epoch 6 composite train-obj: 1.980109
    Epoch [6/50], Test Losses: mse: 16.0744, mae: 2.5964, huber: 2.1733, swd: 7.0803, target_std: 18.3805
    Best round's Test MSE: 16.0744, MAE: 2.5964, SWD: 7.0803
    Best round's Validation MSE: 25.8042, MAE: 3.3093
    Best round's Test verification MSE : 16.0744, MAE: 2.5964, SWD: 7.0803
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 31.2363, mae: 3.0508, huber: 2.6289, swd: 14.4364, target_std: 20.3783
    Epoch [1/50], Val Losses: mse: 25.3661, mae: 3.2790, huber: 2.8435, swd: 10.3861, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 14.9736, mae: 2.5047, huber: 2.0832, swd: 6.7602, target_std: 18.3805
      Epoch 1 composite train-obj: 2.628900
            Val objective improved inf → 2.8435, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 25.7060, mae: 2.7380, huber: 2.3211, swd: 11.7395, target_std: 20.3785
    Epoch [2/50], Val Losses: mse: 25.1067, mae: 3.2750, huber: 2.8422, swd: 10.7216, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 15.3607, mae: 2.5489, huber: 2.1279, swd: 7.4580, target_std: 18.3805
      Epoch 2 composite train-obj: 2.321081
            Val objective improved 2.8435 → 2.8422, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 24.2568, mae: 2.6356, huber: 2.2203, swd: 10.7208, target_std: 20.3787
    Epoch [3/50], Val Losses: mse: 26.1132, mae: 3.3010, huber: 2.8653, swd: 11.0752, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 16.0415, mae: 2.5994, huber: 2.1766, swd: 7.9672, target_std: 18.3805
      Epoch 3 composite train-obj: 2.220330
            No improvement (2.8653), counter 1/5
    Epoch [4/50], Train Losses: mse: 22.9150, mae: 2.5474, huber: 2.1335, swd: 9.8154, target_std: 20.3787
    Epoch [4/50], Val Losses: mse: 27.1028, mae: 3.3340, huber: 2.8985, swd: 11.9060, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 16.6816, mae: 2.6425, huber: 2.2185, swd: 8.4562, target_std: 18.3805
      Epoch 4 composite train-obj: 2.133454
            No improvement (2.8985), counter 2/5
    Epoch [5/50], Train Losses: mse: 21.5704, mae: 2.4661, huber: 2.0534, swd: 8.9065, target_std: 20.3784
    Epoch [5/50], Val Losses: mse: 29.1016, mae: 3.4643, huber: 3.0273, swd: 13.1371, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 18.9893, mae: 2.7747, huber: 2.3485, swd: 9.9022, target_std: 18.3805
      Epoch 5 composite train-obj: 2.053441
            No improvement (3.0273), counter 3/5
    Epoch [6/50], Train Losses: mse: 20.4634, mae: 2.4092, huber: 1.9973, swd: 8.1764, target_std: 20.3785
    Epoch [6/50], Val Losses: mse: 31.8731, mae: 3.6449, huber: 3.2050, swd: 13.4064, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 20.6138, mae: 2.8910, huber: 2.4617, swd: 9.6612, target_std: 18.3805
      Epoch 6 composite train-obj: 1.997273
            No improvement (3.2050), counter 4/5
    Epoch [7/50], Train Losses: mse: 19.3114, mae: 2.3463, huber: 1.9352, swd: 7.3334, target_std: 20.3782
    Epoch [7/50], Val Losses: mse: 31.8285, mae: 3.6516, huber: 3.2112, swd: 14.7210, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 19.6245, mae: 2.8400, huber: 2.4112, swd: 9.7349, target_std: 18.3805
      Epoch 7 composite train-obj: 1.935218
    Epoch [7/50], Test Losses: mse: 15.3607, mae: 2.5489, huber: 2.1279, swd: 7.4580, target_std: 18.3805
    Best round's Test MSE: 15.3607, MAE: 2.5489, SWD: 7.4580
    Best round's Validation MSE: 25.1067, MAE: 3.2750
    Best round's Test verification MSE : 15.3607, MAE: 2.5489, SWD: 7.4580
    
    ==================================================
    Experiment Summary (PatchTST_ettm2_seq720_pred720_20250501_1731)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 15.5931 ± 0.3404
      mae: 2.5560 ± 0.0305
      huber: 2.1341 ± 0.0298
      swd: 7.0656 ± 0.3266
      target_std: 18.3805 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 25.6547 ± 0.4006
      mae: 3.2978 ± 0.0161
      huber: 2.8640 ± 0.0154
      swd: 10.2909 ± 0.4418
      target_std: 20.6733 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: PatchTST_ettm2_seq720_pred720_20250501_1731
    Model: PatchTST
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### pred=96


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 23.1693, mae: 2.4577, huber: 2.0483, swd: 10.8663, target_std: 20.3717
    Epoch [1/50], Val Losses: mse: 13.8193, mae: 2.2658, huber: 1.8590, swd: 7.7063, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.7912, mae: 1.9244, huber: 1.5121, swd: 4.2150, target_std: 18.4426
      Epoch 1 composite train-obj: 2.048330
            Val objective improved inf → 1.8590, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.2910, mae: 1.9662, huber: 1.5648, swd: 6.7979, target_std: 20.3710
    Epoch [2/50], Val Losses: mse: 13.1738, mae: 2.2148, huber: 1.8103, swd: 7.2301, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 8.7186, mae: 1.8844, huber: 1.4757, swd: 4.2492, target_std: 18.4426
      Epoch 2 composite train-obj: 1.564758
            Val objective improved 1.8590 → 1.8103, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.9264, mae: 1.9356, huber: 1.5356, swd: 6.5200, target_std: 20.3724
    Epoch [3/50], Val Losses: mse: 12.8429, mae: 2.1962, huber: 1.7922, swd: 7.0987, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.6314, mae: 1.9095, huber: 1.4992, swd: 4.3059, target_std: 18.4426
      Epoch 3 composite train-obj: 1.535558
            Val objective improved 1.8103 → 1.7922, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 11.7462, mae: 1.9229, huber: 1.5230, swd: 6.3830, target_std: 20.3706
    Epoch [4/50], Val Losses: mse: 12.8147, mae: 2.1888, huber: 1.7855, swd: 6.8332, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.5665, mae: 1.8837, huber: 1.4744, swd: 4.0976, target_std: 18.4426
      Epoch 4 composite train-obj: 1.522996
            Val objective improved 1.7922 → 1.7855, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 11.7122, mae: 1.9234, huber: 1.5234, swd: 6.3212, target_std: 20.3713
    Epoch [5/50], Val Losses: mse: 12.9219, mae: 2.2052, huber: 1.8004, swd: 6.7859, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.8772, mae: 1.8937, huber: 1.4847, swd: 4.2847, target_std: 18.4426
      Epoch 5 composite train-obj: 1.523435
            No improvement (1.8004), counter 1/5
    Epoch [6/50], Train Losses: mse: 11.6570, mae: 1.9178, huber: 1.5181, swd: 6.2799, target_std: 20.3722
    Epoch [6/50], Val Losses: mse: 12.8174, mae: 2.1928, huber: 1.7890, swd: 6.6217, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.5973, mae: 1.8808, huber: 1.4718, swd: 4.0368, target_std: 18.4426
      Epoch 6 composite train-obj: 1.518142
            No improvement (1.7890), counter 2/5
    Epoch [7/50], Train Losses: mse: 11.6804, mae: 1.9222, huber: 1.5223, swd: 6.2958, target_std: 20.3716
    Epoch [7/50], Val Losses: mse: 12.6295, mae: 2.1801, huber: 1.7763, swd: 6.6039, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 8.5660, mae: 1.8922, huber: 1.4828, swd: 4.0575, target_std: 18.4426
      Epoch 7 composite train-obj: 1.522274
            Val objective improved 1.7855 → 1.7763, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 11.5972, mae: 1.9133, huber: 1.5138, swd: 6.2531, target_std: 20.3708
    Epoch [8/50], Val Losses: mse: 12.6943, mae: 2.1876, huber: 1.7828, swd: 6.5874, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 8.6930, mae: 1.8848, huber: 1.4742, swd: 4.0968, target_std: 18.4426
      Epoch 8 composite train-obj: 1.513755
            No improvement (1.7828), counter 1/5
    Epoch [9/50], Train Losses: mse: 11.6711, mae: 1.9213, huber: 1.5215, swd: 6.2766, target_std: 20.3703
    Epoch [9/50], Val Losses: mse: 12.4938, mae: 2.1723, huber: 1.7681, swd: 6.7129, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 8.4573, mae: 1.8834, huber: 1.4724, swd: 4.1586, target_std: 18.4426
      Epoch 9 composite train-obj: 1.521493
            Val objective improved 1.7763 → 1.7681, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 11.6312, mae: 1.9177, huber: 1.5180, swd: 6.2621, target_std: 20.3720
    Epoch [10/50], Val Losses: mse: 12.6429, mae: 2.1923, huber: 1.7864, swd: 6.5957, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 8.7363, mae: 1.9245, huber: 1.5103, swd: 4.2242, target_std: 18.4426
      Epoch 10 composite train-obj: 1.517978
            No improvement (1.7864), counter 1/5
    Epoch [11/50], Train Losses: mse: 11.6384, mae: 1.9207, huber: 1.5207, swd: 6.2462, target_std: 20.3711
    Epoch [11/50], Val Losses: mse: 12.3825, mae: 2.1520, huber: 1.7496, swd: 6.5549, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 8.4521, mae: 1.8748, huber: 1.4653, swd: 4.0695, target_std: 18.4426
      Epoch 11 composite train-obj: 1.520704
            Val objective improved 1.7681 → 1.7496, saving checkpoint.
    Epoch [12/50], Train Losses: mse: 11.6184, mae: 1.9152, huber: 1.5156, swd: 6.2542, target_std: 20.3712
    Epoch [12/50], Val Losses: mse: 12.5067, mae: 2.1641, huber: 1.7604, swd: 6.4858, target_std: 20.6844
    Epoch [12/50], Test Losses: mse: 8.9185, mae: 1.9234, huber: 1.5138, swd: 4.2910, target_std: 18.4426
      Epoch 12 composite train-obj: 1.515596
            No improvement (1.7604), counter 1/5
    Epoch [13/50], Train Losses: mse: 11.6917, mae: 1.9274, huber: 1.5273, swd: 6.2814, target_std: 20.3709
    Epoch [13/50], Val Losses: mse: 12.3187, mae: 2.1483, huber: 1.7456, swd: 6.4397, target_std: 20.6844
    Epoch [13/50], Test Losses: mse: 8.5549, mae: 1.9070, huber: 1.4947, swd: 4.1451, target_std: 18.4426
      Epoch 13 composite train-obj: 1.527300
            Val objective improved 1.7496 → 1.7456, saving checkpoint.
    Epoch [14/50], Train Losses: mse: 11.6455, mae: 1.9200, huber: 1.5203, swd: 6.2798, target_std: 20.3713
    Epoch [14/50], Val Losses: mse: 12.4440, mae: 2.1584, huber: 1.7562, swd: 6.6960, target_std: 20.6844
    Epoch [14/50], Test Losses: mse: 8.4329, mae: 1.8600, huber: 1.4520, swd: 4.1100, target_std: 18.4426
      Epoch 14 composite train-obj: 1.520334
            No improvement (1.7562), counter 1/5
    Epoch [15/50], Train Losses: mse: 11.5702, mae: 1.9090, huber: 1.5096, swd: 6.2209, target_std: 20.3724
    Epoch [15/50], Val Losses: mse: 12.3683, mae: 2.1493, huber: 1.7470, swd: 6.5565, target_std: 20.6844
    Epoch [15/50], Test Losses: mse: 8.4790, mae: 1.8735, huber: 1.4658, swd: 4.1274, target_std: 18.4426
      Epoch 15 composite train-obj: 1.509609
            No improvement (1.7470), counter 2/5
    Epoch [16/50], Train Losses: mse: 11.6398, mae: 1.9184, huber: 1.5186, swd: 6.2619, target_std: 20.3718
    Epoch [16/50], Val Losses: mse: 12.2338, mae: 2.1454, huber: 1.7423, swd: 6.4110, target_std: 20.6844
    Epoch [16/50], Test Losses: mse: 8.3876, mae: 1.8572, huber: 1.4491, swd: 4.0180, target_std: 18.4426
      Epoch 16 composite train-obj: 1.518627
            Val objective improved 1.7456 → 1.7423, saving checkpoint.
    Epoch [17/50], Train Losses: mse: 11.6100, mae: 1.9169, huber: 1.5171, swd: 6.2504, target_std: 20.3710
    Epoch [17/50], Val Losses: mse: 12.3915, mae: 2.1554, huber: 1.7519, swd: 6.4872, target_std: 20.6844
    Epoch [17/50], Test Losses: mse: 8.4533, mae: 1.8658, huber: 1.4567, swd: 4.0207, target_std: 18.4426
      Epoch 17 composite train-obj: 1.517131
            No improvement (1.7519), counter 1/5
    Epoch [18/50], Train Losses: mse: 11.6322, mae: 1.9180, huber: 1.5182, swd: 6.2712, target_std: 20.3714
    Epoch [18/50], Val Losses: mse: 12.5561, mae: 2.1723, huber: 1.7694, swd: 6.6109, target_std: 20.6844
    Epoch [18/50], Test Losses: mse: 8.5541, mae: 1.8916, huber: 1.4829, swd: 4.0751, target_std: 18.4426
      Epoch 18 composite train-obj: 1.518212
            No improvement (1.7694), counter 2/5
    Epoch [19/50], Train Losses: mse: 11.6535, mae: 1.9226, huber: 1.5228, swd: 6.2522, target_std: 20.3710
    Epoch [19/50], Val Losses: mse: 12.4185, mae: 2.1601, huber: 1.7562, swd: 6.5396, target_std: 20.6844
    Epoch [19/50], Test Losses: mse: 8.4304, mae: 1.8602, huber: 1.4505, swd: 4.0740, target_std: 18.4426
      Epoch 19 composite train-obj: 1.522796
            No improvement (1.7562), counter 3/5
    Epoch [20/50], Train Losses: mse: 11.6234, mae: 1.9192, huber: 1.5194, swd: 6.2481, target_std: 20.3713
    Epoch [20/50], Val Losses: mse: 12.4526, mae: 2.1653, huber: 1.7626, swd: 6.4439, target_std: 20.6844
    Epoch [20/50], Test Losses: mse: 8.4594, mae: 1.8662, huber: 1.4579, swd: 4.0168, target_std: 18.4426
      Epoch 20 composite train-obj: 1.519413
            No improvement (1.7626), counter 4/5
    Epoch [21/50], Train Losses: mse: 11.5998, mae: 1.9133, huber: 1.5137, swd: 6.2483, target_std: 20.3725
    Epoch [21/50], Val Losses: mse: 12.4021, mae: 2.1579, huber: 1.7546, swd: 6.6137, target_std: 20.6844
    Epoch [21/50], Test Losses: mse: 8.4995, mae: 1.8820, huber: 1.4733, swd: 4.0782, target_std: 18.4426
      Epoch 21 composite train-obj: 1.513672
    Epoch [21/50], Test Losses: mse: 8.3876, mae: 1.8572, huber: 1.4491, swd: 4.0180, target_std: 18.4426
    Best round's Test MSE: 8.3876, MAE: 1.8572, SWD: 4.0180
    Best round's Validation MSE: 12.2338, MAE: 2.1454
    Best round's Test verification MSE : 8.3876, MAE: 1.8572, SWD: 4.0180
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 22.3858, mae: 2.4477, huber: 2.0380, swd: 10.3108, target_std: 20.3712
    Epoch [1/50], Val Losses: mse: 13.7900, mae: 2.2705, huber: 1.8638, swd: 7.7169, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.7337, mae: 1.9296, huber: 1.5176, swd: 4.1802, target_std: 18.4426
      Epoch 1 composite train-obj: 2.037979
            Val objective improved inf → 1.8638, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.2251, mae: 1.9570, huber: 1.5558, swd: 6.5262, target_std: 20.3709
    Epoch [2/50], Val Losses: mse: 13.0260, mae: 2.2037, huber: 1.7989, swd: 6.9229, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 8.4906, mae: 1.8818, huber: 1.4705, swd: 3.9397, target_std: 18.4426
      Epoch 2 composite train-obj: 1.555816
            Val objective improved 1.8638 → 1.7989, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.8763, mae: 1.9295, huber: 1.5296, swd: 6.2693, target_std: 20.3706
    Epoch [3/50], Val Losses: mse: 12.5344, mae: 2.1672, huber: 1.7636, swd: 6.5199, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.4114, mae: 1.8586, huber: 1.4498, swd: 3.8779, target_std: 18.4426
      Epoch 3 composite train-obj: 1.529617
            Val objective improved 1.7989 → 1.7636, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 11.7515, mae: 1.9237, huber: 1.5239, swd: 6.1380, target_std: 20.3712
    Epoch [4/50], Val Losses: mse: 12.4287, mae: 2.1546, huber: 1.7517, swd: 6.4674, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.3713, mae: 1.8734, huber: 1.4645, swd: 3.9283, target_std: 18.4426
      Epoch 4 composite train-obj: 1.523915
            Val objective improved 1.7636 → 1.7517, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 11.7146, mae: 1.9232, huber: 1.5234, swd: 6.1313, target_std: 20.3710
    Epoch [5/50], Val Losses: mse: 12.4584, mae: 2.1587, huber: 1.7565, swd: 6.4583, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.4732, mae: 1.8726, huber: 1.4637, swd: 3.9230, target_std: 18.4426
      Epoch 5 composite train-obj: 1.523388
            No improvement (1.7565), counter 1/5
    Epoch [6/50], Train Losses: mse: 11.7050, mae: 1.9234, huber: 1.5234, swd: 6.1067, target_std: 20.3716
    Epoch [6/50], Val Losses: mse: 12.7444, mae: 2.1823, huber: 1.7780, swd: 6.3997, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.5944, mae: 1.8772, huber: 1.4681, swd: 3.8831, target_std: 18.4426
      Epoch 6 composite train-obj: 1.523433
            No improvement (1.7780), counter 2/5
    Epoch [7/50], Train Losses: mse: 11.6178, mae: 1.9146, huber: 1.5151, swd: 6.0604, target_std: 20.3712
    Epoch [7/50], Val Losses: mse: 12.6914, mae: 2.1802, huber: 1.7776, swd: 6.4259, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 8.7603, mae: 1.9183, huber: 1.5067, swd: 3.9797, target_std: 18.4426
      Epoch 7 composite train-obj: 1.515087
            No improvement (1.7776), counter 3/5
    Epoch [8/50], Train Losses: mse: 11.6742, mae: 1.9218, huber: 1.5220, swd: 6.0872, target_std: 20.3711
    Epoch [8/50], Val Losses: mse: 12.3303, mae: 2.1487, huber: 1.7451, swd: 6.3244, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 8.4161, mae: 1.8699, huber: 1.4605, swd: 3.8789, target_std: 18.4426
      Epoch 8 composite train-obj: 1.522028
            Val objective improved 1.7517 → 1.7451, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 11.6277, mae: 1.9176, huber: 1.5177, swd: 6.0631, target_std: 20.3715
    Epoch [9/50], Val Losses: mse: 12.3333, mae: 2.1482, huber: 1.7446, swd: 6.3627, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 8.3809, mae: 1.8669, huber: 1.4577, swd: 3.8995, target_std: 18.4426
      Epoch 9 composite train-obj: 1.517739
            Val objective improved 1.7451 → 1.7446, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 11.6604, mae: 1.9222, huber: 1.5223, swd: 6.0637, target_std: 20.3712
    Epoch [10/50], Val Losses: mse: 12.3662, mae: 2.1526, huber: 1.7491, swd: 6.2707, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 8.6547, mae: 1.9126, huber: 1.5018, swd: 4.0553, target_std: 18.4426
      Epoch 10 composite train-obj: 1.522288
            No improvement (1.7491), counter 1/5
    Epoch [11/50], Train Losses: mse: 11.6579, mae: 1.9228, huber: 1.5227, swd: 6.0843, target_std: 20.3718
    Epoch [11/50], Val Losses: mse: 12.5848, mae: 2.1718, huber: 1.7685, swd: 6.3595, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 8.5774, mae: 1.8696, huber: 1.4614, swd: 3.9061, target_std: 18.4426
      Epoch 11 composite train-obj: 1.522718
            No improvement (1.7685), counter 2/5
    Epoch [12/50], Train Losses: mse: 11.6734, mae: 1.9249, huber: 1.5249, swd: 6.0834, target_std: 20.3719
    Epoch [12/50], Val Losses: mse: 12.7130, mae: 2.1939, huber: 1.7901, swd: 6.5021, target_std: 20.6844
    Epoch [12/50], Test Losses: mse: 8.8336, mae: 1.8999, huber: 1.4903, swd: 4.1649, target_std: 18.4426
      Epoch 12 composite train-obj: 1.524912
            No improvement (1.7901), counter 3/5
    Epoch [13/50], Train Losses: mse: 11.5932, mae: 1.9147, huber: 1.5149, swd: 6.0442, target_std: 20.3715
    Epoch [13/50], Val Losses: mse: 12.2577, mae: 2.1475, huber: 1.7440, swd: 6.3193, target_std: 20.6844
    Epoch [13/50], Test Losses: mse: 8.3401, mae: 1.8693, huber: 1.4578, swd: 3.8822, target_std: 18.4426
      Epoch 13 composite train-obj: 1.514853
            Val objective improved 1.7446 → 1.7440, saving checkpoint.
    Epoch [14/50], Train Losses: mse: 11.6406, mae: 1.9193, huber: 1.5196, swd: 6.0673, target_std: 20.3719
    Epoch [14/50], Val Losses: mse: 12.4028, mae: 2.1590, huber: 1.7560, swd: 6.3407, target_std: 20.6844
    Epoch [14/50], Test Losses: mse: 8.5955, mae: 1.8983, huber: 1.4891, swd: 3.9276, target_std: 18.4426
      Epoch 14 composite train-obj: 1.519596
            No improvement (1.7560), counter 1/5
    Epoch [15/50], Train Losses: mse: 11.6243, mae: 1.9164, huber: 1.5169, swd: 6.0644, target_std: 20.3714
    Epoch [15/50], Val Losses: mse: 12.5716, mae: 2.1721, huber: 1.7694, swd: 6.3282, target_std: 20.6844
    Epoch [15/50], Test Losses: mse: 8.6593, mae: 1.8796, huber: 1.4716, swd: 3.8755, target_std: 18.4426
      Epoch 15 composite train-obj: 1.516861
            No improvement (1.7694), counter 2/5
    Epoch [16/50], Train Losses: mse: 11.6007, mae: 1.9132, huber: 1.5137, swd: 6.0461, target_std: 20.3713
    Epoch [16/50], Val Losses: mse: 12.2001, mae: 2.1340, huber: 1.7321, swd: 6.2583, target_std: 20.6844
    Epoch [16/50], Test Losses: mse: 8.2957, mae: 1.8525, huber: 1.4456, swd: 3.8479, target_std: 18.4426
      Epoch 16 composite train-obj: 1.513702
            Val objective improved 1.7440 → 1.7321, saving checkpoint.
    Epoch [17/50], Train Losses: mse: 11.6650, mae: 1.9231, huber: 1.5230, swd: 6.0403, target_std: 20.3711
    Epoch [17/50], Val Losses: mse: 12.4598, mae: 2.1631, huber: 1.7604, swd: 6.3505, target_std: 20.6844
    Epoch [17/50], Test Losses: mse: 8.5302, mae: 1.8629, huber: 1.4548, swd: 3.9427, target_std: 18.4426
      Epoch 17 composite train-obj: 1.523035
            No improvement (1.7604), counter 1/5
    Epoch [18/50], Train Losses: mse: 11.5997, mae: 1.9149, huber: 1.5154, swd: 6.0319, target_std: 20.3706
    Epoch [18/50], Val Losses: mse: 12.4682, mae: 2.1567, huber: 1.7529, swd: 6.3432, target_std: 20.6844
    Epoch [18/50], Test Losses: mse: 8.7256, mae: 1.9007, huber: 1.4904, swd: 3.9993, target_std: 18.4426
      Epoch 18 composite train-obj: 1.515355
            No improvement (1.7529), counter 2/5
    Epoch [19/50], Train Losses: mse: 11.5695, mae: 1.9117, huber: 1.5121, swd: 6.0227, target_std: 20.3712
    Epoch [19/50], Val Losses: mse: 12.3668, mae: 2.1569, huber: 1.7541, swd: 6.3048, target_std: 20.6844
    Epoch [19/50], Test Losses: mse: 8.4164, mae: 1.8794, huber: 1.4696, swd: 3.9341, target_std: 18.4426
      Epoch 19 composite train-obj: 1.512064
            No improvement (1.7541), counter 3/5
    Epoch [20/50], Train Losses: mse: 11.6099, mae: 1.9181, huber: 1.5183, swd: 6.0363, target_std: 20.3713
    Epoch [20/50], Val Losses: mse: 12.4389, mae: 2.1550, huber: 1.7522, swd: 6.3297, target_std: 20.6844
    Epoch [20/50], Test Losses: mse: 8.4225, mae: 1.8714, huber: 1.4618, swd: 3.8963, target_std: 18.4426
      Epoch 20 composite train-obj: 1.518335
            No improvement (1.7522), counter 4/5
    Epoch [21/50], Train Losses: mse: 11.6750, mae: 1.9243, huber: 1.5244, swd: 6.0702, target_std: 20.3712
    Epoch [21/50], Val Losses: mse: 12.2918, mae: 2.1508, huber: 1.7469, swd: 6.2703, target_std: 20.6844
    Epoch [21/50], Test Losses: mse: 8.3690, mae: 1.8631, huber: 1.4529, swd: 3.8560, target_std: 18.4426
      Epoch 21 composite train-obj: 1.524449
    Epoch [21/50], Test Losses: mse: 8.2957, mae: 1.8525, huber: 1.4456, swd: 3.8479, target_std: 18.4426
    Best round's Test MSE: 8.2957, MAE: 1.8525, SWD: 3.8479
    Best round's Validation MSE: 12.2001, MAE: 2.1340
    Best round's Test verification MSE : 8.2957, MAE: 1.8525, SWD: 3.8479
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 22.4657, mae: 2.4376, huber: 2.0282, swd: 9.4239, target_std: 20.3715
    Epoch [1/50], Val Losses: mse: 13.6714, mae: 2.2530, huber: 1.8462, swd: 7.0223, target_std: 20.6844
    Epoch [1/50], Test Losses: mse: 8.7607, mae: 1.9358, huber: 1.5229, swd: 3.8809, target_std: 18.4426
      Epoch 1 composite train-obj: 2.028177
            Val objective improved inf → 1.8462, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 12.2541, mae: 1.9619, huber: 1.5608, swd: 6.1130, target_std: 20.3710
    Epoch [2/50], Val Losses: mse: 12.8457, mae: 2.1878, huber: 1.7838, swd: 6.3079, target_std: 20.6844
    Epoch [2/50], Test Losses: mse: 8.4952, mae: 1.8729, huber: 1.4634, swd: 3.6436, target_std: 18.4426
      Epoch 2 composite train-obj: 1.560766
            Val objective improved 1.8462 → 1.7838, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 11.8823, mae: 1.9333, huber: 1.5331, swd: 5.8529, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 12.7773, mae: 2.1823, huber: 1.7786, swd: 6.3340, target_std: 20.6844
    Epoch [3/50], Test Losses: mse: 8.7282, mae: 1.9208, huber: 1.5104, swd: 3.9602, target_std: 18.4426
      Epoch 3 composite train-obj: 1.533065
            Val objective improved 1.7838 → 1.7786, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 11.7456, mae: 1.9253, huber: 1.5251, swd: 5.7639, target_std: 20.3706
    Epoch [4/50], Val Losses: mse: 12.4315, mae: 2.1546, huber: 1.7514, swd: 6.0068, target_std: 20.6844
    Epoch [4/50], Test Losses: mse: 8.4020, mae: 1.8676, huber: 1.4580, swd: 3.6237, target_std: 18.4426
      Epoch 4 composite train-obj: 1.525112
            Val objective improved 1.7786 → 1.7514, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 11.7262, mae: 1.9246, huber: 1.5246, swd: 5.7361, target_std: 20.3712
    Epoch [5/50], Val Losses: mse: 12.5491, mae: 2.1682, huber: 1.7649, swd: 6.0684, target_std: 20.6844
    Epoch [5/50], Test Losses: mse: 8.5385, mae: 1.8730, huber: 1.4650, swd: 3.7160, target_std: 18.4426
      Epoch 5 composite train-obj: 1.524590
            No improvement (1.7649), counter 1/5
    Epoch [6/50], Train Losses: mse: 11.6695, mae: 1.9197, huber: 1.5201, swd: 5.7167, target_std: 20.3716
    Epoch [6/50], Val Losses: mse: 12.7748, mae: 2.1863, huber: 1.7833, swd: 6.3889, target_std: 20.6844
    Epoch [6/50], Test Losses: mse: 8.6300, mae: 1.9135, huber: 1.5029, swd: 3.9275, target_std: 18.4426
      Epoch 6 composite train-obj: 1.520073
            No improvement (1.7833), counter 2/5
    Epoch [7/50], Train Losses: mse: 11.6701, mae: 1.9229, huber: 1.5228, swd: 5.6867, target_std: 20.3713
    Epoch [7/50], Val Losses: mse: 12.6060, mae: 2.1695, huber: 1.7668, swd: 6.0656, target_std: 20.6844
    Epoch [7/50], Test Losses: mse: 8.4469, mae: 1.8684, huber: 1.4604, swd: 3.6603, target_std: 18.4426
      Epoch 7 composite train-obj: 1.522795
            No improvement (1.7668), counter 3/5
    Epoch [8/50], Train Losses: mse: 11.6077, mae: 1.9123, huber: 1.5129, swd: 5.6594, target_std: 20.3716
    Epoch [8/50], Val Losses: mse: 12.3642, mae: 2.1518, huber: 1.7492, swd: 5.9085, target_std: 20.6844
    Epoch [8/50], Test Losses: mse: 8.4682, mae: 1.8698, huber: 1.4615, swd: 3.6966, target_std: 18.4426
      Epoch 8 composite train-obj: 1.512871
            Val objective improved 1.7514 → 1.7492, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 11.6977, mae: 1.9258, huber: 1.5260, swd: 5.6857, target_std: 20.3721
    Epoch [9/50], Val Losses: mse: 12.3566, mae: 2.1500, huber: 1.7471, swd: 5.9845, target_std: 20.6844
    Epoch [9/50], Test Losses: mse: 8.4867, mae: 1.8738, huber: 1.4643, swd: 3.7846, target_std: 18.4426
      Epoch 9 composite train-obj: 1.526011
            Val objective improved 1.7492 → 1.7471, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 11.6060, mae: 1.9159, huber: 1.5161, swd: 5.6465, target_std: 20.3712
    Epoch [10/50], Val Losses: mse: 12.4480, mae: 2.1620, huber: 1.7582, swd: 5.9695, target_std: 20.6844
    Epoch [10/50], Test Losses: mse: 8.4068, mae: 1.8617, huber: 1.4521, swd: 3.6692, target_std: 18.4426
      Epoch 10 composite train-obj: 1.516111
            No improvement (1.7582), counter 1/5
    Epoch [11/50], Train Losses: mse: 11.6241, mae: 1.9189, huber: 1.5190, swd: 5.6546, target_std: 20.3715
    Epoch [11/50], Val Losses: mse: 12.5762, mae: 2.1662, huber: 1.7639, swd: 5.9833, target_std: 20.6844
    Epoch [11/50], Test Losses: mse: 8.5444, mae: 1.8778, huber: 1.4694, swd: 3.6860, target_std: 18.4426
      Epoch 11 composite train-obj: 1.519010
            No improvement (1.7639), counter 2/5
    Epoch [12/50], Train Losses: mse: 11.5937, mae: 1.9112, huber: 1.5118, swd: 5.6584, target_std: 20.3718
    Epoch [12/50], Val Losses: mse: 12.4759, mae: 2.1617, huber: 1.7572, swd: 5.9619, target_std: 20.6844
    Epoch [12/50], Test Losses: mse: 8.5228, mae: 1.8874, huber: 1.4770, swd: 3.7163, target_std: 18.4426
      Epoch 12 composite train-obj: 1.511835
            No improvement (1.7572), counter 3/5
    Epoch [13/50], Train Losses: mse: 11.5865, mae: 1.9108, huber: 1.5116, swd: 5.6515, target_std: 20.3713
    Epoch [13/50], Val Losses: mse: 12.3492, mae: 2.1482, huber: 1.7455, swd: 5.9244, target_std: 20.6844
    Epoch [13/50], Test Losses: mse: 8.3658, mae: 1.8547, huber: 1.4458, swd: 3.6606, target_std: 18.4426
      Epoch 13 composite train-obj: 1.511560
            Val objective improved 1.7471 → 1.7455, saving checkpoint.
    Epoch [14/50], Train Losses: mse: 11.6593, mae: 1.9241, huber: 1.5239, swd: 5.6786, target_std: 20.3714
    Epoch [14/50], Val Losses: mse: 12.5024, mae: 2.1626, huber: 1.7599, swd: 5.8871, target_std: 20.6844
    Epoch [14/50], Test Losses: mse: 8.4960, mae: 1.8732, huber: 1.4647, swd: 3.6331, target_std: 18.4426
      Epoch 14 composite train-obj: 1.523912
            No improvement (1.7599), counter 1/5
    Epoch [15/50], Train Losses: mse: 11.6066, mae: 1.9148, huber: 1.5151, swd: 5.6657, target_std: 20.3720
    Epoch [15/50], Val Losses: mse: 12.5443, mae: 2.1772, huber: 1.7728, swd: 6.0843, target_std: 20.6844
    Epoch [15/50], Test Losses: mse: 8.6230, mae: 1.9050, huber: 1.4944, swd: 3.7828, target_std: 18.4426
      Epoch 15 composite train-obj: 1.515083
            No improvement (1.7728), counter 2/5
    Epoch [16/50], Train Losses: mse: 11.6292, mae: 1.9192, huber: 1.5193, swd: 5.6570, target_std: 20.3713
    Epoch [16/50], Val Losses: mse: 12.5718, mae: 2.1817, huber: 1.7780, swd: 6.1236, target_std: 20.6844
    Epoch [16/50], Test Losses: mse: 8.5478, mae: 1.8893, huber: 1.4788, swd: 3.7468, target_std: 18.4426
      Epoch 16 composite train-obj: 1.519337
            No improvement (1.7780), counter 3/5
    Epoch [17/50], Train Losses: mse: 11.6364, mae: 1.9184, huber: 1.5186, swd: 5.6629, target_std: 20.3707
    Epoch [17/50], Val Losses: mse: 12.2717, mae: 2.1460, huber: 1.7420, swd: 5.8586, target_std: 20.6844
    Epoch [17/50], Test Losses: mse: 8.4364, mae: 1.8811, huber: 1.4703, swd: 3.6625, target_std: 18.4426
      Epoch 17 composite train-obj: 1.518630
            Val objective improved 1.7455 → 1.7420, saving checkpoint.
    Epoch [18/50], Train Losses: mse: 11.6075, mae: 1.9168, huber: 1.5170, swd: 5.6494, target_std: 20.3718
    Epoch [18/50], Val Losses: mse: 12.4734, mae: 2.1684, huber: 1.7652, swd: 5.9893, target_std: 20.6844
    Epoch [18/50], Test Losses: mse: 8.6789, mae: 1.8955, huber: 1.4850, swd: 3.7306, target_std: 18.4426
      Epoch 18 composite train-obj: 1.517014
            No improvement (1.7652), counter 1/5
    Epoch [19/50], Train Losses: mse: 11.6607, mae: 1.9248, huber: 1.5246, swd: 5.6587, target_std: 20.3715
    Epoch [19/50], Val Losses: mse: 12.4378, mae: 2.1652, huber: 1.7616, swd: 5.9118, target_std: 20.6844
    Epoch [19/50], Test Losses: mse: 8.4105, mae: 1.8634, huber: 1.4547, swd: 3.5985, target_std: 18.4426
      Epoch 19 composite train-obj: 1.524611
            No improvement (1.7616), counter 2/5
    Epoch [20/50], Train Losses: mse: 11.6398, mae: 1.9208, huber: 1.5210, swd: 5.6548, target_std: 20.3714
    Epoch [20/50], Val Losses: mse: 12.8708, mae: 2.1892, huber: 1.7870, swd: 6.2365, target_std: 20.6844
    Epoch [20/50], Test Losses: mse: 8.8049, mae: 1.8909, huber: 1.4846, swd: 3.9022, target_std: 18.4426
      Epoch 20 composite train-obj: 1.520961
            No improvement (1.7870), counter 3/5
    Epoch [21/50], Train Losses: mse: 11.6023, mae: 1.9154, huber: 1.5159, swd: 5.6539, target_std: 20.3710
    Epoch [21/50], Val Losses: mse: 12.2868, mae: 2.1423, huber: 1.7404, swd: 5.8327, target_std: 20.6844
    Epoch [21/50], Test Losses: mse: 8.3893, mae: 1.8584, huber: 1.4511, swd: 3.6473, target_std: 18.4426
      Epoch 21 composite train-obj: 1.515938
            Val objective improved 1.7420 → 1.7404, saving checkpoint.
    Epoch [22/50], Train Losses: mse: 11.6136, mae: 1.9173, huber: 1.5176, swd: 5.6580, target_std: 20.3707
    Epoch [22/50], Val Losses: mse: 12.5115, mae: 2.1676, huber: 1.7642, swd: 5.9637, target_std: 20.6844
    Epoch [22/50], Test Losses: mse: 8.6216, mae: 1.9039, huber: 1.4937, swd: 3.7045, target_std: 18.4426
      Epoch 22 composite train-obj: 1.517568
            No improvement (1.7642), counter 1/5
    Epoch [23/50], Train Losses: mse: 11.5976, mae: 1.9148, huber: 1.5152, swd: 5.6454, target_std: 20.3717
    Epoch [23/50], Val Losses: mse: 12.6925, mae: 2.1914, huber: 1.7877, swd: 6.0144, target_std: 20.6844
    Epoch [23/50], Test Losses: mse: 8.6248, mae: 1.8744, huber: 1.4663, swd: 3.7062, target_std: 18.4426
      Epoch 23 composite train-obj: 1.515170
            No improvement (1.7877), counter 2/5
    Epoch [24/50], Train Losses: mse: 11.6054, mae: 1.9156, huber: 1.5159, swd: 5.6387, target_std: 20.3717
    Epoch [24/50], Val Losses: mse: 12.5143, mae: 2.1699, huber: 1.7665, swd: 5.9072, target_std: 20.6844
    Epoch [24/50], Test Losses: mse: 8.4624, mae: 1.8617, huber: 1.4537, swd: 3.6632, target_std: 18.4426
      Epoch 24 composite train-obj: 1.515855
            No improvement (1.7665), counter 3/5
    Epoch [25/50], Train Losses: mse: 11.6796, mae: 1.9267, huber: 1.5268, swd: 5.6711, target_std: 20.3714
    Epoch [25/50], Val Losses: mse: 12.6056, mae: 2.1710, huber: 1.7683, swd: 6.0239, target_std: 20.6844
    Epoch [25/50], Test Losses: mse: 8.5057, mae: 1.8765, huber: 1.4678, swd: 3.6849, target_std: 18.4426
      Epoch 25 composite train-obj: 1.526756
            No improvement (1.7683), counter 4/5
    Epoch [26/50], Train Losses: mse: 11.6313, mae: 1.9191, huber: 1.5191, swd: 5.6649, target_std: 20.3714
    Epoch [26/50], Val Losses: mse: 12.2206, mae: 2.1398, huber: 1.7372, swd: 5.9129, target_std: 20.6844
    Epoch [26/50], Test Losses: mse: 8.4605, mae: 1.8974, huber: 1.4859, swd: 3.7504, target_std: 18.4426
      Epoch 26 composite train-obj: 1.519150
            Val objective improved 1.7404 → 1.7372, saving checkpoint.
    Epoch [27/50], Train Losses: mse: 11.6130, mae: 1.9156, huber: 1.5160, swd: 5.6529, target_std: 20.3709
    Epoch [27/50], Val Losses: mse: 12.2245, mae: 2.1463, huber: 1.7432, swd: 5.8544, target_std: 20.6844
    Epoch [27/50], Test Losses: mse: 8.3073, mae: 1.8383, huber: 1.4311, swd: 3.6000, target_std: 18.4426
      Epoch 27 composite train-obj: 1.516017
            No improvement (1.7432), counter 1/5
    Epoch [28/50], Train Losses: mse: 11.5937, mae: 1.9162, huber: 1.5165, swd: 5.6450, target_std: 20.3714
    Epoch [28/50], Val Losses: mse: 12.3851, mae: 2.1557, huber: 1.7523, swd: 6.0115, target_std: 20.6844
    Epoch [28/50], Test Losses: mse: 8.4087, mae: 1.8652, huber: 1.4549, swd: 3.6894, target_std: 18.4426
      Epoch 28 composite train-obj: 1.516486
            No improvement (1.7523), counter 2/5
    Epoch [29/50], Train Losses: mse: 11.6270, mae: 1.9183, huber: 1.5184, swd: 5.6573, target_std: 20.3717
    Epoch [29/50], Val Losses: mse: 12.5492, mae: 2.1614, huber: 1.7594, swd: 5.9281, target_std: 20.6844
    Epoch [29/50], Test Losses: mse: 8.5328, mae: 1.8766, huber: 1.4681, swd: 3.6938, target_std: 18.4426
      Epoch 29 composite train-obj: 1.518444
            No improvement (1.7594), counter 3/5
    Epoch [30/50], Train Losses: mse: 11.6019, mae: 1.9153, huber: 1.5157, swd: 5.6424, target_std: 20.3715
    Epoch [30/50], Val Losses: mse: 12.3740, mae: 2.1504, huber: 1.7476, swd: 5.9036, target_std: 20.6844
    Epoch [30/50], Test Losses: mse: 8.4595, mae: 1.8612, huber: 1.4541, swd: 3.6695, target_std: 18.4426
      Epoch 30 composite train-obj: 1.515669
            No improvement (1.7476), counter 4/5
    Epoch [31/50], Train Losses: mse: 11.5990, mae: 1.9150, huber: 1.5155, swd: 5.6353, target_std: 20.3716
    Epoch [31/50], Val Losses: mse: 12.4810, mae: 2.1686, huber: 1.7656, swd: 5.9777, target_std: 20.6844
    Epoch [31/50], Test Losses: mse: 8.4861, mae: 1.8549, huber: 1.4477, swd: 3.6942, target_std: 18.4426
      Epoch 31 composite train-obj: 1.515465
    Epoch [31/50], Test Losses: mse: 8.4605, mae: 1.8974, huber: 1.4859, swd: 3.7504, target_std: 18.4426
    Best round's Test MSE: 8.4605, MAE: 1.8974, SWD: 3.7504
    Best round's Validation MSE: 12.2206, MAE: 2.1398
    Best round's Test verification MSE : 8.4605, MAE: 1.8974, SWD: 3.7504
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq720_pred96_20250501_1418)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.3813 ± 0.0674
      mae: 1.8690 ± 0.0202
      huber: 1.4602 ± 0.0182
      swd: 3.8721 ± 0.1106
      target_std: 18.4426 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 12.2182 ± 0.0139
      mae: 2.1397 ± 0.0047
      huber: 1.7372 ± 0.0042
      swd: 6.1941 ± 0.2084
      target_std: 20.6844 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq720_pred96_20250501_1418
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### pred=196


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.2560, mae: 2.6986, huber: 2.2839, swd: 12.8837, target_std: 20.3720
    Epoch [1/50], Val Losses: mse: 18.9323, mae: 2.6805, huber: 2.2639, swd: 10.6574, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 10.8871, mae: 2.1508, huber: 1.7326, swd: 5.1460, target_std: 18.4106
      Epoch 1 composite train-obj: 2.283873
            Val objective improved inf → 2.2639, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 17.1683, mae: 2.2841, huber: 1.8759, swd: 9.6034, target_std: 20.3720
    Epoch [2/50], Val Losses: mse: 18.3028, mae: 2.6219, huber: 2.2077, swd: 10.0945, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 10.7306, mae: 2.1320, huber: 1.7150, swd: 5.0664, target_std: 18.4106
      Epoch 2 composite train-obj: 1.875942
            Val objective improved 2.2639 → 2.2077, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 16.7673, mae: 2.2526, huber: 1.8454, swd: 9.3299, target_std: 20.3718
    Epoch [3/50], Val Losses: mse: 18.2870, mae: 2.6240, huber: 2.2095, swd: 10.0908, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.7348, mae: 2.1188, huber: 1.7021, swd: 5.0809, target_std: 18.4106
      Epoch 3 composite train-obj: 1.845369
            No improvement (2.2095), counter 1/5
    Epoch [4/50], Train Losses: mse: 16.6625, mae: 2.2499, huber: 1.8426, swd: 9.2238, target_std: 20.3718
    Epoch [4/50], Val Losses: mse: 18.1022, mae: 2.5920, huber: 2.1792, swd: 10.1643, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.7031, mae: 2.1232, huber: 1.7071, swd: 5.2248, target_std: 18.4106
      Epoch 4 composite train-obj: 1.842580
            Val objective improved 2.2077 → 2.1792, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 16.6160, mae: 2.2481, huber: 1.8407, swd: 9.1869, target_std: 20.3719
    Epoch [5/50], Val Losses: mse: 18.2596, mae: 2.6168, huber: 2.2028, swd: 10.0003, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 10.8791, mae: 2.1154, huber: 1.6981, swd: 5.2127, target_std: 18.4106
      Epoch 5 composite train-obj: 1.840741
            No improvement (2.2028), counter 1/5
    Epoch [6/50], Train Losses: mse: 16.6972, mae: 2.2570, huber: 1.8495, swd: 9.1955, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 17.7953, mae: 2.5827, huber: 2.1678, swd: 9.6853, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 10.4991, mae: 2.0896, huber: 1.6729, swd: 5.0631, target_std: 18.4106
      Epoch 6 composite train-obj: 1.849543
            Val objective improved 2.1792 → 2.1678, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 16.5751, mae: 2.2481, huber: 1.8407, swd: 9.1624, target_std: 20.3718
    Epoch [7/50], Val Losses: mse: 17.7587, mae: 2.5837, huber: 2.1701, swd: 9.8080, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.4663, mae: 2.0779, huber: 1.6635, swd: 5.0398, target_std: 18.4106
      Epoch 7 composite train-obj: 1.840691
            No improvement (2.1701), counter 1/5
    Epoch [8/50], Train Losses: mse: 16.6328, mae: 2.2540, huber: 1.8465, swd: 9.1587, target_std: 20.3721
    Epoch [8/50], Val Losses: mse: 18.0346, mae: 2.5942, huber: 2.1810, swd: 9.8574, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.6446, mae: 2.1014, huber: 1.6853, swd: 5.0367, target_std: 18.4106
      Epoch 8 composite train-obj: 1.846494
            No improvement (2.1810), counter 2/5
    Epoch [9/50], Train Losses: mse: 16.5588, mae: 2.2434, huber: 1.8362, swd: 9.1507, target_std: 20.3721
    Epoch [9/50], Val Losses: mse: 17.6378, mae: 2.5664, huber: 2.1535, swd: 9.6455, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 10.5857, mae: 2.0810, huber: 1.6664, swd: 5.1040, target_std: 18.4106
      Epoch 9 composite train-obj: 1.836238
            Val objective improved 2.1678 → 2.1535, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 16.5433, mae: 2.2444, huber: 1.8371, swd: 9.1118, target_std: 20.3720
    Epoch [10/50], Val Losses: mse: 17.5204, mae: 2.5490, huber: 2.1364, swd: 9.5939, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 10.5214, mae: 2.0960, huber: 1.6804, swd: 5.1187, target_std: 18.4106
      Epoch 10 composite train-obj: 1.837122
            Val objective improved 2.1535 → 2.1364, saving checkpoint.
    Epoch [11/50], Train Losses: mse: 16.5422, mae: 2.2446, huber: 1.8372, swd: 9.1082, target_std: 20.3719
    Epoch [11/50], Val Losses: mse: 17.8427, mae: 2.5926, huber: 2.1775, swd: 9.5823, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 10.9812, mae: 2.1438, huber: 1.7252, swd: 5.1636, target_std: 18.4106
      Epoch 11 composite train-obj: 1.837249
            No improvement (2.1775), counter 1/5
    Epoch [12/50], Train Losses: mse: 16.5759, mae: 2.2502, huber: 1.8429, swd: 9.1201, target_std: 20.3720
    Epoch [12/50], Val Losses: mse: 17.8729, mae: 2.5811, huber: 2.1685, swd: 9.9958, target_std: 20.7091
    Epoch [12/50], Test Losses: mse: 10.5801, mae: 2.1117, huber: 1.6957, swd: 5.1843, target_std: 18.4106
      Epoch 12 composite train-obj: 1.842863
            No improvement (2.1685), counter 2/5
    Epoch [13/50], Train Losses: mse: 16.5155, mae: 2.2414, huber: 1.8343, swd: 9.1060, target_std: 20.3719
    Epoch [13/50], Val Losses: mse: 17.6365, mae: 2.5662, huber: 2.1531, swd: 9.5861, target_std: 20.7091
    Epoch [13/50], Test Losses: mse: 10.5202, mae: 2.0940, huber: 1.6788, swd: 5.0487, target_std: 18.4106
      Epoch 13 composite train-obj: 1.834283
            No improvement (2.1531), counter 3/5
    Epoch [14/50], Train Losses: mse: 16.5374, mae: 2.2434, huber: 1.8363, swd: 9.1149, target_std: 20.3719
    Epoch [14/50], Val Losses: mse: 17.8769, mae: 2.5862, huber: 2.1723, swd: 9.5881, target_std: 20.7091
    Epoch [14/50], Test Losses: mse: 10.8780, mae: 2.1172, huber: 1.7015, swd: 5.1332, target_std: 18.4106
      Epoch 14 composite train-obj: 1.836271
            No improvement (2.1723), counter 4/5
    Epoch [15/50], Train Losses: mse: 16.5355, mae: 2.2433, huber: 1.8362, swd: 9.1088, target_std: 20.3721
    Epoch [15/50], Val Losses: mse: 17.9112, mae: 2.5949, huber: 2.1807, swd: 9.8490, target_std: 20.7091
    Epoch [15/50], Test Losses: mse: 10.9088, mae: 2.1582, huber: 1.7396, swd: 5.2890, target_std: 18.4106
      Epoch 15 composite train-obj: 1.836180
    Epoch [15/50], Test Losses: mse: 10.5214, mae: 2.0960, huber: 1.6804, swd: 5.1187, target_std: 18.4106
    Best round's Test MSE: 10.5214, MAE: 2.0960, SWD: 5.1187
    Best round's Validation MSE: 17.5204, MAE: 2.5490
    Best round's Test verification MSE : 10.5214, MAE: 2.0960, SWD: 5.1187
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.4711, mae: 2.7027, huber: 2.2881, swd: 13.3208, target_std: 20.3719
    Epoch [1/50], Val Losses: mse: 18.3964, mae: 2.6357, huber: 2.2199, swd: 10.7156, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 10.9679, mae: 2.1583, huber: 1.7398, swd: 5.4168, target_std: 18.4106
      Epoch 1 composite train-obj: 2.288087
            Val objective improved inf → 2.2199, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 17.1210, mae: 2.2800, huber: 1.8720, swd: 9.9579, target_std: 20.3719
    Epoch [2/50], Val Losses: mse: 18.1408, mae: 2.6021, huber: 2.1885, swd: 10.2288, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 10.7509, mae: 2.1023, huber: 1.6878, swd: 5.1500, target_std: 18.4106
      Epoch 2 composite train-obj: 1.871978
            Val objective improved 2.2199 → 2.1885, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 16.7709, mae: 2.2544, huber: 1.8471, swd: 9.6752, target_std: 20.3720
    Epoch [3/50], Val Losses: mse: 17.9720, mae: 2.5860, huber: 2.1733, swd: 10.4043, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.6238, mae: 2.1179, huber: 1.7022, swd: 5.3727, target_std: 18.4106
      Epoch 3 composite train-obj: 1.847145
            Val objective improved 2.1885 → 2.1733, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 16.7094, mae: 2.2554, huber: 1.8480, swd: 9.5908, target_std: 20.3721
    Epoch [4/50], Val Losses: mse: 17.9762, mae: 2.5921, huber: 2.1788, swd: 10.5349, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.4353, mae: 2.0911, huber: 1.6751, swd: 5.2309, target_std: 18.4106
      Epoch 4 composite train-obj: 1.847970
            No improvement (2.1788), counter 1/5
    Epoch [5/50], Train Losses: mse: 16.6993, mae: 2.2537, huber: 1.8464, swd: 9.5742, target_std: 20.3720
    Epoch [5/50], Val Losses: mse: 18.0545, mae: 2.6041, huber: 2.1899, swd: 10.2090, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 10.8041, mae: 2.1011, huber: 1.6856, swd: 5.3713, target_std: 18.4106
      Epoch 5 composite train-obj: 1.846368
            No improvement (2.1899), counter 2/5
    Epoch [6/50], Train Losses: mse: 16.6066, mae: 2.2467, huber: 1.8396, swd: 9.5028, target_std: 20.3720
    Epoch [6/50], Val Losses: mse: 18.1120, mae: 2.6047, huber: 2.1909, swd: 10.1214, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 10.6950, mae: 2.0925, huber: 1.6781, swd: 5.2297, target_std: 18.4106
      Epoch 6 composite train-obj: 1.839626
            No improvement (2.1909), counter 3/5
    Epoch [7/50], Train Losses: mse: 16.5726, mae: 2.2464, huber: 1.8390, swd: 9.4738, target_std: 20.3719
    Epoch [7/50], Val Losses: mse: 17.6810, mae: 2.5628, huber: 2.1499, swd: 10.1191, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.4196, mae: 2.0858, huber: 1.6701, swd: 5.2097, target_std: 18.4106
      Epoch 7 composite train-obj: 1.838989
            Val objective improved 2.1733 → 2.1499, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 16.5302, mae: 2.2395, huber: 1.8324, swd: 9.4667, target_std: 20.3720
    Epoch [8/50], Val Losses: mse: 17.7652, mae: 2.5763, huber: 2.1638, swd: 10.0788, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.5740, mae: 2.1051, huber: 1.6887, swd: 5.1970, target_std: 18.4106
      Epoch 8 composite train-obj: 1.832394
            No improvement (2.1638), counter 1/5
    Epoch [9/50], Train Losses: mse: 16.5751, mae: 2.2470, huber: 1.8397, swd: 9.4564, target_std: 20.3719
    Epoch [9/50], Val Losses: mse: 17.6810, mae: 2.5697, huber: 2.1549, swd: 9.9316, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 11.0159, mae: 2.1577, huber: 1.7385, swd: 5.5828, target_std: 18.4106
      Epoch 9 composite train-obj: 1.839673
            No improvement (2.1549), counter 2/5
    Epoch [10/50], Train Losses: mse: 16.5196, mae: 2.2422, huber: 1.8349, swd: 9.4534, target_std: 20.3720
    Epoch [10/50], Val Losses: mse: 17.9155, mae: 2.5947, huber: 2.1796, swd: 10.0017, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 10.7316, mae: 2.1047, huber: 1.6873, swd: 5.2034, target_std: 18.4106
      Epoch 10 composite train-obj: 1.834898
            No improvement (2.1796), counter 3/5
    Epoch [11/50], Train Losses: mse: 16.5353, mae: 2.2445, huber: 1.8371, swd: 9.4359, target_std: 20.3719
    Epoch [11/50], Val Losses: mse: 17.6238, mae: 2.5716, huber: 2.1569, swd: 10.0096, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 10.4645, mae: 2.0972, huber: 1.6787, swd: 5.2080, target_std: 18.4106
      Epoch 11 composite train-obj: 1.837061
            No improvement (2.1569), counter 4/5
    Epoch [12/50], Train Losses: mse: 16.5059, mae: 2.2418, huber: 1.8347, swd: 9.4275, target_std: 20.3720
    Epoch [12/50], Val Losses: mse: 17.8117, mae: 2.5882, huber: 2.1736, swd: 10.0671, target_std: 20.7091
    Epoch [12/50], Test Losses: mse: 10.6187, mae: 2.1097, huber: 1.6918, swd: 5.1563, target_std: 18.4106
      Epoch 12 composite train-obj: 1.834729
    Epoch [12/50], Test Losses: mse: 10.4196, mae: 2.0858, huber: 1.6701, swd: 5.2097, target_std: 18.4106
    Best round's Test MSE: 10.4196, MAE: 2.0858, SWD: 5.2097
    Best round's Validation MSE: 17.6810, MAE: 2.5628
    Best round's Test verification MSE : 10.4196, MAE: 2.0858, SWD: 5.2097
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 26.9509, mae: 2.7055, huber: 2.2908, swd: 11.3630, target_std: 20.3719
    Epoch [1/50], Val Losses: mse: 18.7269, mae: 2.6700, huber: 2.2530, swd: 9.2663, target_std: 20.7091
    Epoch [1/50], Test Losses: mse: 10.7474, mae: 2.1187, huber: 1.7018, swd: 4.4749, target_std: 18.4106
      Epoch 1 composite train-obj: 2.290779
            Val objective improved inf → 2.2530, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 17.1477, mae: 2.2820, huber: 1.8739, swd: 8.4533, target_std: 20.3722
    Epoch [2/50], Val Losses: mse: 18.4372, mae: 2.6299, huber: 2.2161, swd: 8.9955, target_std: 20.7091
    Epoch [2/50], Test Losses: mse: 10.7155, mae: 2.1147, huber: 1.6990, swd: 4.4354, target_std: 18.4106
      Epoch 2 composite train-obj: 1.873927
            Val objective improved 2.2530 → 2.2161, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 16.7913, mae: 2.2559, huber: 1.8486, swd: 8.2144, target_std: 20.3719
    Epoch [3/50], Val Losses: mse: 17.7976, mae: 2.5705, huber: 2.1574, swd: 8.6623, target_std: 20.7091
    Epoch [3/50], Test Losses: mse: 10.5284, mae: 2.0850, huber: 1.6705, swd: 4.4727, target_std: 18.4106
      Epoch 3 composite train-obj: 1.848577
            Val objective improved 2.2161 → 2.1574, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 16.7436, mae: 2.2561, huber: 1.8487, swd: 8.1480, target_std: 20.3720
    Epoch [4/50], Val Losses: mse: 17.9524, mae: 2.5858, huber: 2.1719, swd: 8.5741, target_std: 20.7091
    Epoch [4/50], Test Losses: mse: 10.6097, mae: 2.0949, huber: 1.6786, swd: 4.4103, target_std: 18.4106
      Epoch 4 composite train-obj: 1.848731
            No improvement (2.1719), counter 1/5
    Epoch [5/50], Train Losses: mse: 16.5907, mae: 2.2435, huber: 1.8364, swd: 8.0605, target_std: 20.3718
    Epoch [5/50], Val Losses: mse: 17.5466, mae: 2.5573, huber: 2.1447, swd: 8.4017, target_std: 20.7091
    Epoch [5/50], Test Losses: mse: 10.5144, mae: 2.0965, huber: 1.6806, swd: 4.4913, target_std: 18.4106
      Epoch 5 composite train-obj: 1.836378
            Val objective improved 2.1574 → 2.1447, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 16.5843, mae: 2.2456, huber: 1.8385, swd: 8.0524, target_std: 20.3718
    Epoch [6/50], Val Losses: mse: 17.5608, mae: 2.5541, huber: 2.1409, swd: 8.4660, target_std: 20.7091
    Epoch [6/50], Test Losses: mse: 10.6935, mae: 2.1070, huber: 1.6911, swd: 4.5897, target_std: 18.4106
      Epoch 6 composite train-obj: 1.838453
            Val objective improved 2.1447 → 2.1409, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 16.5537, mae: 2.2432, huber: 1.8361, swd: 8.0310, target_std: 20.3719
    Epoch [7/50], Val Losses: mse: 17.7727, mae: 2.5815, huber: 2.1679, swd: 8.5336, target_std: 20.7091
    Epoch [7/50], Test Losses: mse: 10.6722, mae: 2.0999, huber: 1.6843, swd: 4.3705, target_std: 18.4106
      Epoch 7 composite train-obj: 1.836108
            No improvement (2.1679), counter 1/5
    Epoch [8/50], Train Losses: mse: 16.5518, mae: 2.2444, huber: 1.8371, swd: 8.0137, target_std: 20.3717
    Epoch [8/50], Val Losses: mse: 17.6831, mae: 2.5644, huber: 2.1512, swd: 8.4519, target_std: 20.7091
    Epoch [8/50], Test Losses: mse: 10.6019, mae: 2.1024, huber: 1.6872, swd: 4.5077, target_std: 18.4106
      Epoch 8 composite train-obj: 1.837109
            No improvement (2.1512), counter 2/5
    Epoch [9/50], Train Losses: mse: 16.5401, mae: 2.2437, huber: 1.8364, swd: 8.0018, target_std: 20.3719
    Epoch [9/50], Val Losses: mse: 18.1910, mae: 2.6182, huber: 2.2039, swd: 9.0129, target_std: 20.7091
    Epoch [9/50], Test Losses: mse: 10.8299, mae: 2.1558, huber: 1.7369, swd: 4.7155, target_std: 18.4106
      Epoch 9 composite train-obj: 1.836393
            No improvement (2.2039), counter 3/5
    Epoch [10/50], Train Losses: mse: 16.6180, mae: 2.2546, huber: 1.8470, swd: 8.0404, target_std: 20.3720
    Epoch [10/50], Val Losses: mse: 17.7902, mae: 2.5784, huber: 2.1651, swd: 8.4650, target_std: 20.7091
    Epoch [10/50], Test Losses: mse: 10.7299, mae: 2.1215, huber: 1.7056, swd: 4.5290, target_std: 18.4106
      Epoch 10 composite train-obj: 1.846981
            No improvement (2.1651), counter 4/5
    Epoch [11/50], Train Losses: mse: 16.5068, mae: 2.2413, huber: 1.8341, swd: 7.9913, target_std: 20.3720
    Epoch [11/50], Val Losses: mse: 17.8631, mae: 2.5801, huber: 2.1667, swd: 8.6204, target_std: 20.7091
    Epoch [11/50], Test Losses: mse: 10.6316, mae: 2.1027, huber: 1.6867, swd: 4.4883, target_std: 18.4106
      Epoch 11 composite train-obj: 1.834125
    Epoch [11/50], Test Losses: mse: 10.6935, mae: 2.1070, huber: 1.6911, swd: 4.5897, target_std: 18.4106
    Best round's Test MSE: 10.6935, MAE: 2.1070, SWD: 4.5897
    Best round's Validation MSE: 17.5608, MAE: 2.5541
    Best round's Test verification MSE : 10.6935, MAE: 2.1070, SWD: 4.5897
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq720_pred196_20250501_1423)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5448 ± 0.1130
      mae: 2.0963 ± 0.0086
      huber: 1.6805 ± 0.0086
      swd: 4.9727 ± 0.2733
      target_std: 18.4106 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 17.5874 ± 0.0682
      mae: 2.5553 ± 0.0057
      huber: 2.1424 ± 0.0056
      swd: 9.3930 ± 0.6896
      target_std: 20.7091 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq720_pred196_20250501_1423
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### pred=336


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 31.4408, mae: 2.9524, huber: 2.5334, swd: 14.5502, target_std: 20.3733
    Epoch [1/50], Val Losses: mse: 22.6413, mae: 3.0098, huber: 2.5864, swd: 11.5027, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 12.8417, mae: 2.3311, huber: 1.9092, swd: 5.9590, target_std: 18.3950
      Epoch 1 composite train-obj: 2.533444
            Val objective improved inf → 2.5864, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.9069, mae: 2.5542, huber: 2.1407, swd: 11.7718, target_std: 20.3733
    Epoch [2/50], Val Losses: mse: 21.7375, mae: 2.9203, huber: 2.4981, swd: 10.8009, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.7048, mae: 2.3134, huber: 1.8911, swd: 5.8503, target_std: 18.3950
      Epoch 2 composite train-obj: 2.140689
            Val objective improved 2.5864 → 2.4981, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 21.6334, mae: 2.5363, huber: 2.1234, swd: 11.5776, target_std: 20.3734
    Epoch [3/50], Val Losses: mse: 22.3372, mae: 2.9694, huber: 2.5472, swd: 11.2549, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.6148, mae: 2.2995, huber: 1.8787, swd: 5.7851, target_std: 18.3950
      Epoch 3 composite train-obj: 2.123357
            No improvement (2.5472), counter 1/5
    Epoch [4/50], Train Losses: mse: 21.5112, mae: 2.5298, huber: 2.1167, swd: 11.4931, target_std: 20.3732
    Epoch [4/50], Val Losses: mse: 22.0261, mae: 2.9369, huber: 2.5164, swd: 11.1412, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 12.6282, mae: 2.3203, huber: 1.8992, swd: 5.9680, target_std: 18.3950
      Epoch 4 composite train-obj: 2.116733
            No improvement (2.5164), counter 2/5
    Epoch [5/50], Train Losses: mse: 21.4829, mae: 2.5298, huber: 2.1167, swd: 11.4341, target_std: 20.3737
    Epoch [5/50], Val Losses: mse: 22.1286, mae: 2.9443, huber: 2.5229, swd: 11.2757, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 12.4874, mae: 2.2935, huber: 1.8731, swd: 5.8508, target_std: 18.3950
      Epoch 5 composite train-obj: 2.116679
            No improvement (2.5229), counter 3/5
    Epoch [6/50], Train Losses: mse: 21.4728, mae: 2.5273, huber: 2.1143, swd: 11.4290, target_std: 20.3733
    Epoch [6/50], Val Losses: mse: 21.7944, mae: 2.9216, huber: 2.4999, swd: 10.8595, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 12.5555, mae: 2.2976, huber: 1.8765, swd: 5.8426, target_std: 18.3950
      Epoch 6 composite train-obj: 2.114296
            No improvement (2.4999), counter 4/5
    Epoch [7/50], Train Losses: mse: 21.4924, mae: 2.5340, huber: 2.1207, swd: 11.4231, target_std: 20.3732
    Epoch [7/50], Val Losses: mse: 22.3068, mae: 2.9627, huber: 2.5403, swd: 11.1137, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 12.5675, mae: 2.2914, huber: 1.8701, swd: 5.8130, target_std: 18.3950
      Epoch 7 composite train-obj: 2.120727
    Epoch [7/50], Test Losses: mse: 12.7048, mae: 2.3134, huber: 1.8911, swd: 5.8503, target_std: 18.3950
    Best round's Test MSE: 12.7048, MAE: 2.3134, SWD: 5.8503
    Best round's Validation MSE: 21.7375, MAE: 2.9203
    Best round's Test verification MSE : 12.7048, MAE: 2.3134, SWD: 5.8503
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 31.1843, mae: 2.9410, huber: 2.5220, swd: 15.2863, target_std: 20.3734
    Epoch [1/50], Val Losses: mse: 22.5048, mae: 2.9922, huber: 2.5692, swd: 11.5864, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 12.7006, mae: 2.3160, huber: 1.8955, swd: 6.0481, target_std: 18.3950
      Epoch 1 composite train-obj: 2.522005
            Val objective improved inf → 2.5692, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 21.9051, mae: 2.5507, huber: 2.1375, swd: 12.3255, target_std: 20.3732
    Epoch [2/50], Val Losses: mse: 21.9385, mae: 2.9403, huber: 2.5191, swd: 11.4782, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.5640, mae: 2.2946, huber: 1.8744, swd: 6.0454, target_std: 18.3950
      Epoch 2 composite train-obj: 2.137454
            Val objective improved 2.5692 → 2.5191, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 21.7037, mae: 2.5424, huber: 2.1292, swd: 12.1454, target_std: 20.3736
    Epoch [3/50], Val Losses: mse: 21.9470, mae: 2.9383, huber: 2.5174, swd: 11.3918, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.5066, mae: 2.2864, huber: 1.8658, swd: 6.0478, target_std: 18.3950
      Epoch 3 composite train-obj: 2.129231
            Val objective improved 2.5191 → 2.5174, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 21.6945, mae: 2.5448, huber: 2.1315, swd: 12.0921, target_std: 20.3730
    Epoch [4/50], Val Losses: mse: 21.8163, mae: 2.9151, huber: 2.4935, swd: 11.2300, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 12.9614, mae: 2.3367, huber: 1.9142, swd: 6.3024, target_std: 18.3950
      Epoch 4 composite train-obj: 2.131508
            Val objective improved 2.5174 → 2.4935, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 21.5132, mae: 2.5313, huber: 2.1183, swd: 11.9837, target_std: 20.3730
    Epoch [5/50], Val Losses: mse: 21.7855, mae: 2.9106, huber: 2.4898, swd: 11.2481, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 12.4874, mae: 2.2747, huber: 1.8543, swd: 6.0522, target_std: 18.3950
      Epoch 5 composite train-obj: 2.118290
            Val objective improved 2.4935 → 2.4898, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 21.5001, mae: 2.5312, huber: 2.1181, swd: 11.9464, target_std: 20.3733
    Epoch [6/50], Val Losses: mse: 21.7122, mae: 2.9078, huber: 2.4863, swd: 11.2750, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 12.7586, mae: 2.3356, huber: 1.9118, swd: 6.3729, target_std: 18.3950
      Epoch 6 composite train-obj: 2.118109
            Val objective improved 2.4898 → 2.4863, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 21.4473, mae: 2.5283, huber: 2.1152, swd: 11.9235, target_std: 20.3733
    Epoch [7/50], Val Losses: mse: 21.9219, mae: 2.9289, huber: 2.5077, swd: 11.2256, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 12.6818, mae: 2.3245, huber: 1.9010, swd: 6.0775, target_std: 18.3950
      Epoch 7 composite train-obj: 2.115230
            No improvement (2.5077), counter 1/5
    Epoch [8/50], Train Losses: mse: 21.4435, mae: 2.5288, huber: 2.1157, swd: 11.9072, target_std: 20.3737
    Epoch [8/50], Val Losses: mse: 21.8006, mae: 2.9184, huber: 2.4973, swd: 11.3123, target_std: 20.7022
    Epoch [8/50], Test Losses: mse: 12.4989, mae: 2.2815, huber: 1.8614, swd: 6.0446, target_std: 18.3950
      Epoch 8 composite train-obj: 2.115746
            No improvement (2.4973), counter 2/5
    Epoch [9/50], Train Losses: mse: 21.5006, mae: 2.5342, huber: 2.1209, swd: 11.9460, target_std: 20.3733
    Epoch [9/50], Val Losses: mse: 21.9356, mae: 2.9245, huber: 2.5039, swd: 11.2584, target_std: 20.7022
    Epoch [9/50], Test Losses: mse: 12.5670, mae: 2.2923, huber: 1.8721, swd: 5.9739, target_std: 18.3950
      Epoch 9 composite train-obj: 2.120899
            No improvement (2.5039), counter 3/5
    Epoch [10/50], Train Losses: mse: 21.4691, mae: 2.5296, huber: 2.1164, swd: 11.9383, target_std: 20.3739
    Epoch [10/50], Val Losses: mse: 22.4707, mae: 2.9723, huber: 2.5504, swd: 11.8606, target_std: 20.7022
    Epoch [10/50], Test Losses: mse: 12.6580, mae: 2.3366, huber: 1.9120, swd: 6.2033, target_std: 18.3950
      Epoch 10 composite train-obj: 2.116430
            No improvement (2.5504), counter 4/5
    Epoch [11/50], Train Losses: mse: 21.4506, mae: 2.5300, huber: 2.1168, swd: 11.9366, target_std: 20.3737
    Epoch [11/50], Val Losses: mse: 22.0466, mae: 2.9561, huber: 2.5347, swd: 11.3939, target_std: 20.7022
    Epoch [11/50], Test Losses: mse: 12.5631, mae: 2.2752, huber: 1.8560, swd: 6.0472, target_std: 18.3950
      Epoch 11 composite train-obj: 2.116753
    Epoch [11/50], Test Losses: mse: 12.7586, mae: 2.3356, huber: 1.9118, swd: 6.3729, target_std: 18.3950
    Best round's Test MSE: 12.7586, MAE: 2.3356, SWD: 6.3729
    Best round's Validation MSE: 21.7122, MAE: 2.9078
    Best round's Test verification MSE : 12.7586, MAE: 2.3356, SWD: 6.3729
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 30.9999, mae: 2.9350, huber: 2.5162, swd: 14.0266, target_std: 20.3734
    Epoch [1/50], Val Losses: mse: 22.4827, mae: 2.9929, huber: 2.5701, swd: 10.7055, target_std: 20.7022
    Epoch [1/50], Test Losses: mse: 12.9630, mae: 2.3518, huber: 1.9290, swd: 5.6758, target_std: 18.3950
      Epoch 1 composite train-obj: 2.516170
            Val objective improved inf → 2.5701, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 22.0360, mae: 2.5640, huber: 2.1504, swd: 11.4769, target_std: 20.3736
    Epoch [2/50], Val Losses: mse: 22.4595, mae: 2.9680, huber: 2.5463, swd: 11.0471, target_std: 20.7022
    Epoch [2/50], Test Losses: mse: 12.9489, mae: 2.3586, huber: 1.9347, swd: 6.0141, target_std: 18.3950
      Epoch 2 composite train-obj: 2.150442
            Val objective improved 2.5701 → 2.5463, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 21.6517, mae: 2.5394, huber: 2.1262, swd: 11.2237, target_std: 20.3730
    Epoch [3/50], Val Losses: mse: 21.9227, mae: 2.9307, huber: 2.5092, swd: 10.4615, target_std: 20.7022
    Epoch [3/50], Test Losses: mse: 12.6193, mae: 2.3060, huber: 1.8849, swd: 5.6840, target_std: 18.3950
      Epoch 3 composite train-obj: 2.126162
            Val objective improved 2.5463 → 2.5092, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 21.5549, mae: 2.5299, huber: 2.1170, swd: 11.1600, target_std: 20.3733
    Epoch [4/50], Val Losses: mse: 21.7789, mae: 2.9212, huber: 2.4999, swd: 10.4149, target_std: 20.7022
    Epoch [4/50], Test Losses: mse: 12.4938, mae: 2.3010, huber: 1.8781, swd: 5.5795, target_std: 18.3950
      Epoch 4 composite train-obj: 2.116990
            Val objective improved 2.5092 → 2.4999, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 21.5517, mae: 2.5349, huber: 2.1218, swd: 11.1398, target_std: 20.3733
    Epoch [5/50], Val Losses: mse: 22.0362, mae: 2.9464, huber: 2.5247, swd: 10.5857, target_std: 20.7022
    Epoch [5/50], Test Losses: mse: 12.4915, mae: 2.2775, huber: 1.8577, swd: 5.5489, target_std: 18.3950
      Epoch 5 composite train-obj: 2.121836
            No improvement (2.5247), counter 1/5
    Epoch [6/50], Train Losses: mse: 21.4802, mae: 2.5272, huber: 2.1143, swd: 11.0971, target_std: 20.3734
    Epoch [6/50], Val Losses: mse: 22.0659, mae: 2.9462, huber: 2.5242, swd: 10.6317, target_std: 20.7022
    Epoch [6/50], Test Losses: mse: 12.6067, mae: 2.3151, huber: 1.8925, swd: 5.5771, target_std: 18.3950
      Epoch 6 composite train-obj: 2.114264
            No improvement (2.5242), counter 2/5
    Epoch [7/50], Train Losses: mse: 21.5265, mae: 2.5361, huber: 2.1228, swd: 11.1044, target_std: 20.3732
    Epoch [7/50], Val Losses: mse: 21.5109, mae: 2.8907, huber: 2.4701, swd: 10.1670, target_std: 20.7022
    Epoch [7/50], Test Losses: mse: 12.7895, mae: 2.3099, huber: 1.8892, swd: 5.7676, target_std: 18.3950
      Epoch 7 composite train-obj: 2.122806
            Val objective improved 2.4999 → 2.4701, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 21.4333, mae: 2.5284, huber: 2.1151, swd: 11.0353, target_std: 20.3734
    Epoch [8/50], Val Losses: mse: 21.8527, mae: 2.9190, huber: 2.4983, swd: 10.5427, target_std: 20.7022
    Epoch [8/50], Test Losses: mse: 12.6918, mae: 2.3062, huber: 1.8855, swd: 5.6796, target_std: 18.3950
      Epoch 8 composite train-obj: 2.115145
            No improvement (2.4983), counter 1/5
    Epoch [9/50], Train Losses: mse: 21.4920, mae: 2.5322, huber: 2.1190, swd: 11.0645, target_std: 20.3728
    Epoch [9/50], Val Losses: mse: 21.4130, mae: 2.8937, huber: 2.4715, swd: 10.1742, target_std: 20.7022
    Epoch [9/50], Test Losses: mse: 12.5677, mae: 2.3079, huber: 1.8841, swd: 5.7101, target_std: 18.3950
      Epoch 9 composite train-obj: 2.119044
            No improvement (2.4715), counter 2/5
    Epoch [10/50], Train Losses: mse: 21.3970, mae: 2.5244, huber: 2.1113, swd: 11.0299, target_std: 20.3738
    Epoch [10/50], Val Losses: mse: 21.7555, mae: 2.9106, huber: 2.4896, swd: 10.2597, target_std: 20.7022
    Epoch [10/50], Test Losses: mse: 12.6803, mae: 2.3007, huber: 1.8806, swd: 5.6431, target_std: 18.3950
      Epoch 10 composite train-obj: 2.111347
            No improvement (2.4896), counter 3/5
    Epoch [11/50], Train Losses: mse: 21.4347, mae: 2.5289, huber: 2.1158, swd: 11.0375, target_std: 20.3735
    Epoch [11/50], Val Losses: mse: 22.0152, mae: 2.9407, huber: 2.5197, swd: 10.6697, target_std: 20.7022
    Epoch [11/50], Test Losses: mse: 12.5272, mae: 2.2980, huber: 1.8775, swd: 5.5508, target_std: 18.3950
      Epoch 11 composite train-obj: 2.115816
            No improvement (2.5197), counter 4/5
    Epoch [12/50], Train Losses: mse: 21.4586, mae: 2.5314, huber: 2.1181, swd: 11.0527, target_std: 20.3737
    Epoch [12/50], Val Losses: mse: 21.6095, mae: 2.9085, huber: 2.4864, swd: 10.2050, target_std: 20.7022
    Epoch [12/50], Test Losses: mse: 12.5095, mae: 2.2965, huber: 1.8745, swd: 5.5948, target_std: 18.3950
      Epoch 12 composite train-obj: 2.118131
    Epoch [12/50], Test Losses: mse: 12.7895, mae: 2.3099, huber: 1.8892, swd: 5.7676, target_std: 18.3950
    Best round's Test MSE: 12.7895, MAE: 2.3099, SWD: 5.7676
    Best round's Validation MSE: 21.5109, MAE: 2.8907
    Best round's Test verification MSE : 12.7895, MAE: 2.3099, SWD: 5.7676
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq720_pred336_20250501_1425)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 12.7509 ± 0.0350
      mae: 2.3196 ± 0.0113
      huber: 1.8974 ± 0.0102
      swd: 5.9969 ± 0.2680
      target_std: 18.3950 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 21.6536 ± 0.1014
      mae: 2.9063 ± 0.0121
      huber: 2.4848 ± 0.0115
      swd: 10.7476 ± 0.4539
      target_std: 20.7022 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq720_pred336_20250501_1425
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### pred=720


```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm2']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm2
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.1159, mae: 3.3052, huber: 2.8797, swd: 17.1078, target_std: 20.3782
    Epoch [1/50], Val Losses: mse: 27.2431, mae: 3.4022, huber: 2.9688, swd: 12.0263, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 15.5995, mae: 2.5929, huber: 2.1662, swd: 6.7121, target_std: 18.3805
      Epoch 1 composite train-obj: 2.879747
            Val objective improved inf → 2.9688, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.5560, mae: 2.9719, huber: 2.5507, swd: 14.7757, target_std: 20.3783
    Epoch [2/50], Val Losses: mse: 27.2858, mae: 3.3952, huber: 2.9623, swd: 11.9326, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 15.5565, mae: 2.5636, huber: 2.1381, swd: 6.5026, target_std: 18.3805
      Epoch 2 composite train-obj: 2.550694
            Val objective improved 2.9688 → 2.9623, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 29.2960, mae: 2.9523, huber: 2.5315, swd: 14.6411, target_std: 20.3781
    Epoch [3/50], Val Losses: mse: 27.0561, mae: 3.3802, huber: 2.9484, swd: 12.0199, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 15.2862, mae: 2.5505, huber: 2.1261, swd: 6.5098, target_std: 18.3805
      Epoch 3 composite train-obj: 2.531507
            Val objective improved 2.9623 → 2.9484, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 29.1820, mae: 2.9477, huber: 2.5267, swd: 14.5372, target_std: 20.3785
    Epoch [4/50], Val Losses: mse: 26.7356, mae: 3.3549, huber: 2.9229, swd: 11.8300, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 15.6555, mae: 2.5856, huber: 2.1597, swd: 6.9358, target_std: 18.3805
      Epoch 4 composite train-obj: 2.526653
            Val objective improved 2.9484 → 2.9229, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 29.1919, mae: 2.9533, huber: 2.5320, swd: 14.5231, target_std: 20.3782
    Epoch [5/50], Val Losses: mse: 26.9805, mae: 3.3700, huber: 2.9376, swd: 11.8739, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 15.7685, mae: 2.6024, huber: 2.1751, swd: 6.7946, target_std: 18.3805
      Epoch 5 composite train-obj: 2.532030
            No improvement (2.9376), counter 1/5
    Epoch [6/50], Train Losses: mse: 29.1890, mae: 2.9514, huber: 2.5301, swd: 14.5101, target_std: 20.3783
    Epoch [6/50], Val Losses: mse: 27.2130, mae: 3.3966, huber: 2.9647, swd: 11.9100, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 15.3652, mae: 2.5639, huber: 2.1384, swd: 6.3518, target_std: 18.3805
      Epoch 6 composite train-obj: 2.530082
            No improvement (2.9647), counter 2/5
    Epoch [7/50], Train Losses: mse: 29.0876, mae: 2.9463, huber: 2.5250, swd: 14.4248, target_std: 20.3778
    Epoch [7/50], Val Losses: mse: 27.1217, mae: 3.3800, huber: 2.9457, swd: 11.8169, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 15.3108, mae: 2.5692, huber: 2.1394, swd: 6.4130, target_std: 18.3805
      Epoch 7 composite train-obj: 2.525018
            No improvement (2.9457), counter 3/5
    Epoch [8/50], Train Losses: mse: 29.0089, mae: 2.9393, huber: 2.5181, swd: 14.4217, target_std: 20.3780
    Epoch [8/50], Val Losses: mse: 26.4771, mae: 3.3368, huber: 2.9045, swd: 11.7324, target_std: 20.6733
    Epoch [8/50], Test Losses: mse: 15.9278, mae: 2.6307, huber: 2.2012, swd: 7.2072, target_std: 18.3805
      Epoch 8 composite train-obj: 2.518087
            Val objective improved 2.9229 → 2.9045, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 29.1275, mae: 2.9501, huber: 2.5286, swd: 14.4436, target_std: 20.3784
    Epoch [9/50], Val Losses: mse: 27.1500, mae: 3.3911, huber: 2.9582, swd: 11.9459, target_std: 20.6733
    Epoch [9/50], Test Losses: mse: 15.3015, mae: 2.5477, huber: 2.1225, swd: 6.4293, target_std: 18.3805
      Epoch 9 composite train-obj: 2.528647
            No improvement (2.9582), counter 1/5
    Epoch [10/50], Train Losses: mse: 29.1381, mae: 2.9536, huber: 2.5321, swd: 14.4368, target_std: 20.3782
    Epoch [10/50], Val Losses: mse: 27.0068, mae: 3.3644, huber: 2.9305, swd: 11.7741, target_std: 20.6733
    Epoch [10/50], Test Losses: mse: 15.8093, mae: 2.5897, huber: 2.1629, swd: 6.9094, target_std: 18.3805
      Epoch 10 composite train-obj: 2.532098
            No improvement (2.9305), counter 2/5
    Epoch [11/50], Train Losses: mse: 29.0650, mae: 2.9463, huber: 2.5249, swd: 14.3908, target_std: 20.3788
    Epoch [11/50], Val Losses: mse: 27.4571, mae: 3.4227, huber: 2.9878, swd: 12.0956, target_std: 20.6733
    Epoch [11/50], Test Losses: mse: 15.2178, mae: 2.5478, huber: 2.1206, swd: 6.3410, target_std: 18.3805
      Epoch 11 composite train-obj: 2.524927
            No improvement (2.9878), counter 3/5
    Epoch [12/50], Train Losses: mse: 29.0573, mae: 2.9467, huber: 2.5253, swd: 14.3906, target_std: 20.3783
    Epoch [12/50], Val Losses: mse: 26.7248, mae: 3.3511, huber: 2.9178, swd: 11.6583, target_std: 20.6733
    Epoch [12/50], Test Losses: mse: 15.5652, mae: 2.5778, huber: 2.1504, swd: 6.6982, target_std: 18.3805
      Epoch 12 composite train-obj: 2.525271
            No improvement (2.9178), counter 4/5
    Epoch [13/50], Train Losses: mse: 29.0130, mae: 2.9462, huber: 2.5246, swd: 14.3724, target_std: 20.3786
    Epoch [13/50], Val Losses: mse: 27.5894, mae: 3.4015, huber: 2.9692, swd: 11.5687, target_std: 20.6733
    Epoch [13/50], Test Losses: mse: 16.5447, mae: 2.6343, huber: 2.2095, swd: 7.0730, target_std: 18.3805
      Epoch 13 composite train-obj: 2.524638
    Epoch [13/50], Test Losses: mse: 15.9278, mae: 2.6307, huber: 2.2012, swd: 7.2072, target_std: 18.3805
    Best round's Test MSE: 15.9278, MAE: 2.6307, SWD: 7.2072
    Best round's Validation MSE: 26.4771, MAE: 3.3368
    Best round's Test verification MSE : 15.9278, MAE: 2.6307, SWD: 7.2072
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.2977, mae: 3.3084, huber: 2.8831, swd: 15.8773, target_std: 20.3785
    Epoch [1/50], Val Losses: mse: 27.5335, mae: 3.4244, huber: 2.9923, swd: 11.2588, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 15.4937, mae: 2.5846, huber: 2.1580, swd: 6.0942, target_std: 18.3805
      Epoch 1 composite train-obj: 2.883080
            Val objective improved inf → 2.9923, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.5943, mae: 2.9722, huber: 2.5510, swd: 13.7173, target_std: 20.3781
    Epoch [2/50], Val Losses: mse: 27.0553, mae: 3.3764, huber: 2.9435, swd: 10.8574, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 15.3735, mae: 2.5662, huber: 2.1390, swd: 6.1351, target_std: 18.3805
      Epoch 2 composite train-obj: 2.551004
            Val objective improved 2.9923 → 2.9435, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 29.2541, mae: 2.9497, huber: 2.5288, swd: 13.4940, target_std: 20.3781
    Epoch [3/50], Val Losses: mse: 26.8322, mae: 3.3542, huber: 2.9228, swd: 10.7373, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 15.5530, mae: 2.5620, huber: 2.1371, swd: 6.2317, target_std: 18.3805
      Epoch 3 composite train-obj: 2.528811
            Val objective improved 2.9435 → 2.9228, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 29.1950, mae: 2.9485, huber: 2.5275, swd: 13.4327, target_std: 20.3782
    Epoch [4/50], Val Losses: mse: 26.8827, mae: 3.3608, huber: 2.9292, swd: 11.0100, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 15.5488, mae: 2.5755, huber: 2.1497, swd: 6.3333, target_std: 18.3805
      Epoch 4 composite train-obj: 2.527518
            No improvement (2.9292), counter 1/5
    Epoch [5/50], Train Losses: mse: 29.1681, mae: 2.9499, huber: 2.5287, swd: 13.4135, target_std: 20.3782
    Epoch [5/50], Val Losses: mse: 26.8891, mae: 3.3636, huber: 2.9318, swd: 10.9915, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 15.5958, mae: 2.5764, huber: 2.1495, swd: 6.0538, target_std: 18.3805
      Epoch 5 composite train-obj: 2.528720
            No improvement (2.9318), counter 2/5
    Epoch [6/50], Train Losses: mse: 29.1410, mae: 2.9465, huber: 2.5253, swd: 13.3905, target_std: 20.3786
    Epoch [6/50], Val Losses: mse: 26.8516, mae: 3.3546, huber: 2.9221, swd: 10.7605, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 15.6339, mae: 2.5695, huber: 2.1442, swd: 6.3078, target_std: 18.3805
      Epoch 6 composite train-obj: 2.525333
            Val objective improved 2.9228 → 2.9221, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 29.0282, mae: 2.9397, huber: 2.5186, swd: 13.3116, target_std: 20.3785
    Epoch [7/50], Val Losses: mse: 26.4717, mae: 3.3355, huber: 2.9036, swd: 10.7496, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 16.0007, mae: 2.6035, huber: 2.1775, swd: 6.5711, target_std: 18.3805
      Epoch 7 composite train-obj: 2.518617
            Val objective improved 2.9221 → 2.9036, saving checkpoint.
    Epoch [8/50], Train Losses: mse: 29.0896, mae: 2.9477, huber: 2.5264, swd: 13.3153, target_std: 20.3780
    Epoch [8/50], Val Losses: mse: 27.1802, mae: 3.4001, huber: 2.9658, swd: 11.2003, target_std: 20.6733
    Epoch [8/50], Test Losses: mse: 15.3580, mae: 2.5707, huber: 2.1434, swd: 6.2359, target_std: 18.3805
      Epoch 8 composite train-obj: 2.526363
            No improvement (2.9658), counter 1/5
    Epoch [9/50], Train Losses: mse: 29.1054, mae: 2.9489, huber: 2.5274, swd: 13.3230, target_std: 20.3788
    Epoch [9/50], Val Losses: mse: 26.8990, mae: 3.3686, huber: 2.9358, swd: 10.8354, target_std: 20.6733
    Epoch [9/50], Test Losses: mse: 15.8336, mae: 2.6146, huber: 2.1861, swd: 6.4804, target_std: 18.3805
      Epoch 9 composite train-obj: 2.527374
            No improvement (2.9358), counter 2/5
    Epoch [10/50], Train Losses: mse: 29.0834, mae: 2.9475, huber: 2.5260, swd: 13.3064, target_std: 20.3784
    Epoch [10/50], Val Losses: mse: 27.1771, mae: 3.3920, huber: 2.9594, swd: 11.0838, target_std: 20.6733
    Epoch [10/50], Test Losses: mse: 15.2296, mae: 2.5561, huber: 2.1303, swd: 6.0604, target_std: 18.3805
      Epoch 10 composite train-obj: 2.526015
            No improvement (2.9594), counter 3/5
    Epoch [11/50], Train Losses: mse: 28.9245, mae: 2.9361, huber: 2.5149, swd: 13.2390, target_std: 20.3783
    Epoch [11/50], Val Losses: mse: 26.9010, mae: 3.3662, huber: 2.9334, swd: 10.7208, target_std: 20.6733
    Epoch [11/50], Test Losses: mse: 15.4208, mae: 2.5544, huber: 2.1284, swd: 6.1597, target_std: 18.3805
      Epoch 11 composite train-obj: 2.514884
            No improvement (2.9334), counter 4/5
    Epoch [12/50], Train Losses: mse: 29.0143, mae: 2.9431, huber: 2.5218, swd: 13.2289, target_std: 20.3782
    Epoch [12/50], Val Losses: mse: 27.6180, mae: 3.4320, huber: 2.9976, swd: 11.3028, target_std: 20.6733
    Epoch [12/50], Test Losses: mse: 15.9608, mae: 2.6451, huber: 2.2152, swd: 6.6310, target_std: 18.3805
      Epoch 12 composite train-obj: 2.521810
    Epoch [12/50], Test Losses: mse: 16.0007, mae: 2.6035, huber: 2.1775, swd: 6.5711, target_std: 18.3805
    Best round's Test MSE: 16.0007, MAE: 2.6035, SWD: 6.5711
    Best round's Validation MSE: 26.4717, MAE: 3.3355
    Best round's Test verification MSE : 16.0007, MAE: 2.6035, SWD: 6.5711
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 38.3076, mae: 3.3033, huber: 2.8780, swd: 17.7389, target_std: 20.3779
    Epoch [1/50], Val Losses: mse: 27.4298, mae: 3.4089, huber: 2.9763, swd: 12.4771, target_std: 20.6733
    Epoch [1/50], Test Losses: mse: 15.4750, mae: 2.5741, huber: 2.1481, swd: 6.7663, target_std: 18.3805
      Epoch 1 composite train-obj: 2.877983
            Val objective improved inf → 2.9763, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 29.5261, mae: 2.9670, huber: 2.5459, swd: 15.4975, target_std: 20.3784
    Epoch [2/50], Val Losses: mse: 26.7720, mae: 3.3538, huber: 2.9217, swd: 12.0558, target_std: 20.6733
    Epoch [2/50], Test Losses: mse: 15.7248, mae: 2.5844, huber: 2.1582, swd: 7.3571, target_std: 18.3805
      Epoch 2 composite train-obj: 2.545880
            Val objective improved 2.9763 → 2.9217, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 29.2485, mae: 2.9502, huber: 2.5294, swd: 15.3287, target_std: 20.3786
    Epoch [3/50], Val Losses: mse: 27.6702, mae: 3.4272, huber: 2.9944, swd: 13.1166, target_std: 20.6733
    Epoch [3/50], Test Losses: mse: 15.4312, mae: 2.5892, huber: 2.1617, swd: 6.9852, target_std: 18.3805
      Epoch 3 composite train-obj: 2.529351
            No improvement (2.9944), counter 1/5
    Epoch [4/50], Train Losses: mse: 29.2555, mae: 2.9551, huber: 2.5339, swd: 15.2870, target_std: 20.3780
    Epoch [4/50], Val Losses: mse: 27.1051, mae: 3.3861, huber: 2.9523, swd: 12.5428, target_std: 20.6733
    Epoch [4/50], Test Losses: mse: 15.4975, mae: 2.6093, huber: 2.1781, swd: 7.1272, target_std: 18.3805
      Epoch 4 composite train-obj: 2.533911
            No improvement (2.9523), counter 2/5
    Epoch [5/50], Train Losses: mse: 29.1583, mae: 2.9469, huber: 2.5257, swd: 15.2301, target_std: 20.3783
    Epoch [5/50], Val Losses: mse: 27.0200, mae: 3.3843, huber: 2.9515, swd: 12.3201, target_std: 20.6733
    Epoch [5/50], Test Losses: mse: 15.8253, mae: 2.6231, huber: 2.1945, swd: 7.2881, target_std: 18.3805
      Epoch 5 composite train-obj: 2.525730
            No improvement (2.9515), counter 3/5
    Epoch [6/50], Train Losses: mse: 29.1537, mae: 2.9500, huber: 2.5287, swd: 15.2015, target_std: 20.3782
    Epoch [6/50], Val Losses: mse: 26.9381, mae: 3.3714, huber: 2.9393, swd: 12.3015, target_std: 20.6733
    Epoch [6/50], Test Losses: mse: 15.2521, mae: 2.5476, huber: 2.1222, swd: 6.8375, target_std: 18.3805
      Epoch 6 composite train-obj: 2.528680
            No improvement (2.9393), counter 4/5
    Epoch [7/50], Train Losses: mse: 29.0615, mae: 2.9437, huber: 2.5224, swd: 15.1346, target_std: 20.3787
    Epoch [7/50], Val Losses: mse: 27.4598, mae: 3.4152, huber: 2.9824, swd: 12.4290, target_std: 20.6733
    Epoch [7/50], Test Losses: mse: 15.4149, mae: 2.5748, huber: 2.1477, swd: 6.6826, target_std: 18.3805
      Epoch 7 composite train-obj: 2.522381
    Epoch [7/50], Test Losses: mse: 15.7248, mae: 2.5844, huber: 2.1582, swd: 7.3571, target_std: 18.3805
    Best round's Test MSE: 15.7248, MAE: 2.5844, SWD: 7.3571
    Best round's Validation MSE: 26.7720, MAE: 3.3538
    Best round's Test verification MSE : 15.7248, MAE: 2.5844, SWD: 7.3571
    
    ==================================================
    Experiment Summary (DLinear_ettm2_seq720_pred720_20250501_1415)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 15.8844 ± 0.1167
      mae: 2.6062 ± 0.0190
      huber: 2.1790 ± 0.0176
      swd: 7.0451 ± 0.3407
      target_std: 18.3805 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 26.5736 ± 0.1403
      mae: 3.3420 ± 0.0083
      huber: 2.9099 ± 0.0083
      swd: 11.5126 ± 0.5555
      target_std: 20.6733 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm2_seq720_pred720_20250501_1415
    Model: DLinear
    Dataset: ettm2
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


