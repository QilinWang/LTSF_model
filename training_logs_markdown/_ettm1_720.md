# data 


```python
%load_ext autoreload
%autoreload 2
import importlib
from importlib import reload  
  
import monotonic
import utils
from train import execute_model_evaluation
from train_config import FlatACLConfig
import train_config
import data_manager
from data_manager import DatasetManager
import metrics
from dataclasses import replace

reload(utils)
reload(monotonic)
reload(train_config)


%load_ext autoreload
%autoreload 2
# Initialize the data manager
data_mgr = DatasetManager(device='cuda')

# Load a synthetic dataset
data_mgr.load_csv('ettm1', './ettm1.csv')
# SCALE = False
# trajectory = utils.generate_trajectory('lorenz',steps=52200, dt=1e-2) 
# trajectory = utils.generate_hyperchaotic_rossler(steps=12000, dt=1e-3)
# trajectory_2 = utils.generate_henon(steps=52000) 
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload
    
    ==================================================
    Dataset: ettm1 (csv)
    ==================================================
    Shape: torch.Size([69680, 7])
    Channels: 7
    Length: 69680
    Source: ./ettm1.csv
    
    Sample data (first 2 rows):
    tensor([[ 5.8270,  2.0090,  1.5990,  0.4620,  4.2030,  1.3400, 30.5310],
            [ 5.7600,  2.0760,  1.4920,  0.4260,  4.2640,  1.4010, 30.4600]])
    ==================================================
    




    <data_manager.DatasetManager at 0x1787f945cd0>



# Seq=720


```python
### EigenACL
```

### EigenACL

#### 720-96 


##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.5528, mae: 1.5103, huber: 1.1400, swd: 3.1458, ept: 59.9935
    Epoch [1/50], Val Losses: mse: 6.0040, mae: 1.3091, huber: 0.9552, swd: 1.2053, ept: 66.7514
    Epoch [1/50], Test Losses: mse: 7.7980, mae: 1.5153, huber: 1.1529, swd: 1.6328, ept: 55.6643
      Epoch 1 composite train-obj: 1.140044
            Val objective improved inf → 0.9552, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1370, mae: 1.1788, huber: 0.8293, swd: 1.3138, ept: 70.3521
    Epoch [2/50], Val Losses: mse: 5.6059, mae: 1.2489, huber: 0.9021, swd: 1.1245, ept: 69.0705
    Epoch [2/50], Test Losses: mse: 7.2938, mae: 1.4259, huber: 1.0726, swd: 1.4025, ept: 59.0120
      Epoch 2 composite train-obj: 0.829300
            Val objective improved 0.9552 → 0.9021, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.8113, mae: 1.1228, huber: 0.7782, swd: 1.1904, ept: 72.3073
    Epoch [3/50], Val Losses: mse: 5.8151, mae: 1.2575, huber: 0.9121, swd: 1.2451, ept: 70.2517
    Epoch [3/50], Test Losses: mse: 7.6976, mae: 1.4344, huber: 1.0826, swd: 1.5919, ept: 60.3300
      Epoch 3 composite train-obj: 0.778182
            No improvement (0.9121), counter 1/5
    Epoch [4/50], Train Losses: mse: 3.5359, mae: 1.0801, huber: 0.7387, swd: 1.0907, ept: 73.4483
    Epoch [4/50], Val Losses: mse: 5.9569, mae: 1.2732, huber: 0.9273, swd: 1.2420, ept: 70.3104
    Epoch [4/50], Test Losses: mse: 7.9885, mae: 1.4617, huber: 1.1091, swd: 1.6917, ept: 60.3924
      Epoch 4 composite train-obj: 0.738714
            No improvement (0.9273), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.2586, mae: 1.0415, huber: 0.7026, swd: 1.0084, ept: 74.4428
    Epoch [5/50], Val Losses: mse: 5.7571, mae: 1.2514, huber: 0.9055, swd: 1.2555, ept: 71.1603
    Epoch [5/50], Test Losses: mse: 8.0998, mae: 1.4580, huber: 1.1061, swd: 1.6739, ept: 61.0088
      Epoch 5 composite train-obj: 0.702580
            No improvement (0.9055), counter 3/5
    Epoch [6/50], Train Losses: mse: 2.9394, mae: 0.9979, huber: 0.6618, swd: 0.9097, ept: 75.3045
    Epoch [6/50], Val Losses: mse: 6.3841, mae: 1.2949, huber: 0.9496, swd: 1.2439, ept: 70.3815
    Epoch [6/50], Test Losses: mse: 8.7584, mae: 1.4933, huber: 1.1423, swd: 1.6520, ept: 60.3506
      Epoch 6 composite train-obj: 0.661817
            No improvement (0.9496), counter 4/5
    Epoch [7/50], Train Losses: mse: 2.6313, mae: 0.9551, huber: 0.6214, swd: 0.8175, ept: 76.1772
    Epoch [7/50], Val Losses: mse: 6.3958, mae: 1.3094, huber: 0.9628, swd: 1.4443, ept: 70.6211
    Epoch [7/50], Test Losses: mse: 8.9606, mae: 1.5206, huber: 1.1684, swd: 1.9999, ept: 60.1392
      Epoch 7 composite train-obj: 0.621426
    Epoch [7/50], Test Losses: mse: 7.2943, mae: 1.4259, huber: 1.0727, swd: 1.4024, ept: 58.9934
    Best round's Test MSE: 7.2938, MAE: 1.4259, SWD: 1.4025
    Best round's Validation MSE: 5.6059, MAE: 1.2489, SWD: 1.1245
    Best round's Test verification MSE : 7.2943, MAE: 1.4259, SWD: 1.4024
    Time taken: 74.61 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.6204, mae: 1.5239, huber: 1.1516, swd: 3.1771, ept: 59.9533
    Epoch [1/50], Val Losses: mse: 6.1200, mae: 1.3302, huber: 0.9772, swd: 1.5202, ept: 66.2401
    Epoch [1/50], Test Losses: mse: 7.7245, mae: 1.5145, huber: 1.1534, swd: 2.0110, ept: 54.7829
      Epoch 1 composite train-obj: 1.151613
            Val objective improved inf → 0.9772, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.2134, mae: 1.1949, huber: 0.8431, swd: 1.3270, ept: 69.6650
    Epoch [2/50], Val Losses: mse: 5.7133, mae: 1.2805, huber: 0.9328, swd: 1.4159, ept: 67.4231
    Epoch [2/50], Test Losses: mse: 7.3476, mae: 1.4495, huber: 1.0936, swd: 1.7817, ept: 56.5850
      Epoch 2 composite train-obj: 0.843122
            Val objective improved 0.9772 → 0.9328, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.9028, mae: 1.1395, huber: 0.7928, swd: 1.2050, ept: 71.5467
    Epoch [3/50], Val Losses: mse: 5.5489, mae: 1.2525, huber: 0.9054, swd: 1.2436, ept: 69.6753
    Epoch [3/50], Test Losses: mse: 7.6461, mae: 1.4561, huber: 1.1017, swd: 1.7697, ept: 58.2002
      Epoch 3 composite train-obj: 0.792847
            Val objective improved 0.9328 → 0.9054, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.6710, mae: 1.1062, huber: 0.7622, swd: 1.1460, ept: 72.6181
    Epoch [4/50], Val Losses: mse: 5.5770, mae: 1.2476, huber: 0.9017, swd: 1.1978, ept: 70.0542
    Epoch [4/50], Test Losses: mse: 7.8705, mae: 1.4599, huber: 1.1060, swd: 1.7525, ept: 59.1170
      Epoch 4 composite train-obj: 0.762198
            Val objective improved 0.9054 → 0.9017, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.3987, mae: 1.0642, huber: 0.7234, swd: 1.0514, ept: 73.6262
    Epoch [5/50], Val Losses: mse: 6.0684, mae: 1.3075, huber: 0.9591, swd: 1.4324, ept: 69.6763
    Epoch [5/50], Test Losses: mse: 8.3518, mae: 1.4937, huber: 1.1400, swd: 2.0001, ept: 59.1500
      Epoch 5 composite train-obj: 0.723368
            No improvement (0.9591), counter 1/5
    Epoch [6/50], Train Losses: mse: 3.1268, mae: 1.0242, huber: 0.6863, swd: 0.9587, ept: 74.6500
    Epoch [6/50], Val Losses: mse: 6.1934, mae: 1.3132, huber: 0.9663, swd: 1.4709, ept: 69.7535
    Epoch [6/50], Test Losses: mse: 8.5462, mae: 1.5138, huber: 1.1588, swd: 2.0831, ept: 58.9837
      Epoch 6 composite train-obj: 0.686263
            No improvement (0.9663), counter 2/5
    Epoch [7/50], Train Losses: mse: 2.8763, mae: 0.9913, huber: 0.6553, swd: 0.8860, ept: 75.3713
    Epoch [7/50], Val Losses: mse: 6.2251, mae: 1.3066, huber: 0.9600, swd: 1.3383, ept: 70.1739
    Epoch [7/50], Test Losses: mse: 8.5909, mae: 1.4958, huber: 1.1435, swd: 1.8911, ept: 59.8809
      Epoch 7 composite train-obj: 0.655276
            No improvement (0.9600), counter 3/5
    Epoch [8/50], Train Losses: mse: 2.6216, mae: 0.9531, huber: 0.6197, swd: 0.7966, ept: 76.0594
    Epoch [8/50], Val Losses: mse: 6.4853, mae: 1.3361, huber: 0.9874, swd: 1.4525, ept: 70.3539
    Epoch [8/50], Test Losses: mse: 8.8208, mae: 1.5101, huber: 1.1573, swd: 1.9435, ept: 60.0018
      Epoch 8 composite train-obj: 0.619692
            No improvement (0.9874), counter 4/5
    Epoch [9/50], Train Losses: mse: 2.4183, mae: 0.9218, huber: 0.5907, swd: 0.7333, ept: 76.7183
    Epoch [9/50], Val Losses: mse: 6.3051, mae: 1.3360, huber: 0.9861, swd: 1.5778, ept: 69.8132
    Epoch [9/50], Test Losses: mse: 8.8956, mae: 1.5339, huber: 1.1767, swd: 2.0456, ept: 58.9003
      Epoch 9 composite train-obj: 0.590662
    Epoch [9/50], Test Losses: mse: 7.8713, mae: 1.4599, huber: 1.1060, swd: 1.7528, ept: 59.1164
    Best round's Test MSE: 7.8705, MAE: 1.4599, SWD: 1.7525
    Best round's Validation MSE: 5.5770, MAE: 1.2476, SWD: 1.1978
    Best round's Test verification MSE : 7.8713, MAE: 1.4599, SWD: 1.7528
    Time taken: 95.64 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.4955, mae: 1.5077, huber: 1.1367, swd: 2.9598, ept: 60.2741
    Epoch [1/50], Val Losses: mse: 6.1048, mae: 1.3396, huber: 0.9868, swd: 1.6334, ept: 66.1946
    Epoch [1/50], Test Losses: mse: 7.5251, mae: 1.5026, huber: 1.1413, swd: 1.8648, ept: 55.3416
      Epoch 1 composite train-obj: 1.136700
            Val objective improved inf → 0.9868, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.1046, mae: 1.1745, huber: 0.8244, swd: 1.1813, ept: 70.3788
    Epoch [2/50], Val Losses: mse: 5.7027, mae: 1.2726, huber: 0.9258, swd: 1.3154, ept: 69.0346
    Epoch [2/50], Test Losses: mse: 7.3339, mae: 1.4404, huber: 1.0865, swd: 1.5906, ept: 58.0485
      Epoch 2 composite train-obj: 0.824361
            Val objective improved 0.9868 → 0.9258, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.8011, mae: 1.1205, huber: 0.7756, swd: 1.0839, ept: 72.1853
    Epoch [3/50], Val Losses: mse: 5.4608, mae: 1.2444, huber: 0.8982, swd: 1.2411, ept: 70.0326
    Epoch [3/50], Test Losses: mse: 7.5182, mae: 1.4500, huber: 1.0950, swd: 1.7193, ept: 58.9808
      Epoch 3 composite train-obj: 0.775626
            Val objective improved 0.9258 → 0.8982, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.5248, mae: 1.0795, huber: 0.7378, swd: 0.9991, ept: 73.2602
    Epoch [4/50], Val Losses: mse: 5.7630, mae: 1.2550, huber: 0.9104, swd: 1.1209, ept: 69.7977
    Epoch [4/50], Test Losses: mse: 7.7927, mae: 1.4433, huber: 1.0917, swd: 1.4970, ept: 59.9039
      Epoch 4 composite train-obj: 0.737814
            No improvement (0.9104), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.2931, mae: 1.0491, huber: 0.7094, swd: 0.9449, ept: 74.3307
    Epoch [5/50], Val Losses: mse: 6.0162, mae: 1.2781, huber: 0.9339, swd: 1.1951, ept: 70.6687
    Epoch [5/50], Test Losses: mse: 8.1131, mae: 1.4648, huber: 1.1137, swd: 1.6806, ept: 59.7392
      Epoch 5 composite train-obj: 0.709385
            No improvement (0.9339), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.0183, mae: 1.0106, huber: 0.6732, swd: 0.8611, ept: 75.0715
    Epoch [6/50], Val Losses: mse: 6.1750, mae: 1.2958, huber: 0.9496, swd: 1.2594, ept: 70.3871
    Epoch [6/50], Test Losses: mse: 8.8647, mae: 1.5006, huber: 1.1484, swd: 1.6554, ept: 60.1150
      Epoch 6 composite train-obj: 0.673232
            No improvement (0.9496), counter 3/5
    Epoch [7/50], Train Losses: mse: 2.7743, mae: 0.9756, huber: 0.6405, swd: 0.7876, ept: 75.8476
    Epoch [7/50], Val Losses: mse: 6.0172, mae: 1.2982, huber: 0.9490, swd: 1.3372, ept: 70.0480
    Epoch [7/50], Test Losses: mse: 8.6670, mae: 1.4947, huber: 1.1406, swd: 1.7069, ept: 60.6320
      Epoch 7 composite train-obj: 0.640472
            No improvement (0.9490), counter 4/5
    Epoch [8/50], Train Losses: mse: 2.4987, mae: 0.9332, huber: 0.6011, swd: 0.6967, ept: 76.6129
    Epoch [8/50], Val Losses: mse: 6.5258, mae: 1.3317, huber: 0.9849, swd: 1.3917, ept: 70.6234
    Epoch [8/50], Test Losses: mse: 8.7962, mae: 1.5063, huber: 1.1530, swd: 1.7174, ept: 60.2507
      Epoch 8 composite train-obj: 0.601076
    Epoch [8/50], Test Losses: mse: 7.5187, mae: 1.4500, huber: 1.0951, swd: 1.7194, ept: 58.9811
    Best round's Test MSE: 7.5182, MAE: 1.4500, SWD: 1.7193
    Best round's Validation MSE: 5.4608, MAE: 1.2444, SWD: 1.2411
    Best round's Test verification MSE : 7.5187, MAE: 1.4500, SWD: 1.7194
    Time taken: 82.56 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred96_20250512_1456)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5609 ± 0.2374
      mae: 1.4453 ± 0.0143
      huber: 1.0912 ± 0.0139
      swd: 1.6248 ± 0.1577
      ept: 59.0366 ± 0.0582
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.5479 ± 0.0627
      mae: 1.2470 ± 0.0019
      huber: 0.9007 ± 0.0017
      swd: 1.1878 ± 0.0481
      ept: 69.7191 ± 0.4587
      count: 49.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 254.34 seconds
    
    Experiment complete: ACL_ettm1_seq720_pred96_20250512_1456
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### AB: no rotate back + outside shift


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.8362, mae: 1.4421, huber: 1.0771, swd: 2.9747, target_std: 6.4717
    Epoch [1/50], Val Losses: mse: 5.8647, mae: 1.2842, huber: 0.9347, swd: 1.2914, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.3496, mae: 1.4331, huber: 1.0804, swd: 1.5089, target_std: 4.7550
      Epoch 1 composite train-obj: 1.077065
            Val objective improved inf → 0.9347, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0431, mae: 1.1569, huber: 0.8102, swd: 1.3094, target_std: 6.4715
    Epoch [2/50], Val Losses: mse: 5.6043, mae: 1.2374, huber: 0.8920, swd: 1.1545, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.5270, mae: 1.4342, huber: 1.0835, swd: 1.5065, target_std: 4.7550
      Epoch 2 composite train-obj: 0.810227
            Val objective improved 0.9347 → 0.8920, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.7610, mae: 1.1136, huber: 0.7702, swd: 1.2203, target_std: 6.4716
    Epoch [3/50], Val Losses: mse: 5.5973, mae: 1.2565, huber: 0.9113, swd: 1.3566, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.5152, mae: 1.4408, huber: 1.0891, swd: 1.7537, target_std: 4.7550
      Epoch 3 composite train-obj: 0.770215
            No improvement (0.9113), counter 1/5
    Epoch [4/50], Train Losses: mse: 3.4778, mae: 1.0747, huber: 0.7337, swd: 1.1372, target_std: 6.4713
    Epoch [4/50], Val Losses: mse: 5.6706, mae: 1.2766, huber: 0.9276, swd: 1.5437, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 8.1861, mae: 1.4941, huber: 1.1383, swd: 2.0363, target_std: 4.7550
      Epoch 4 composite train-obj: 0.733654
            No improvement (0.9276), counter 2/5
    Epoch [5/50], Train Losses: mse: 3.1135, mae: 1.0244, huber: 0.6865, swd: 1.0255, target_std: 6.4714
    Epoch [5/50], Val Losses: mse: 5.9488, mae: 1.3226, huber: 0.9710, swd: 1.7836, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 8.5992, mae: 1.5470, huber: 1.1876, swd: 2.3168, target_std: 4.7550
      Epoch 5 composite train-obj: 0.686504
            No improvement (0.9710), counter 3/5
    Epoch [6/50], Train Losses: mse: 2.7933, mae: 0.9778, huber: 0.6435, swd: 0.9269, target_std: 6.4719
    Epoch [6/50], Val Losses: mse: 6.0244, mae: 1.3029, huber: 0.9537, swd: 1.4240, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 8.5237, mae: 1.5003, huber: 1.1472, swd: 1.8658, target_std: 4.7550
      Epoch 6 composite train-obj: 0.643468
            No improvement (0.9537), counter 4/5
    Epoch [7/50], Train Losses: mse: 2.4823, mae: 0.9320, huber: 0.6007, swd: 0.8254, target_std: 6.4716
    Epoch [7/50], Val Losses: mse: 6.4362, mae: 1.3411, huber: 0.9909, swd: 1.5787, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 8.7449, mae: 1.5165, huber: 1.1619, swd: 1.8809, target_std: 4.7550
      Epoch 7 composite train-obj: 0.600718
    Epoch [7/50], Test Losses: mse: 7.5269, mae: 1.4342, huber: 1.0835, swd: 1.5066, target_std: 4.7550
    Best round's Test MSE: 7.5270, MAE: 1.4342, SWD: 1.5065
    Best round's Validation MSE: 5.6043, MAE: 1.2374
    Best round's Test verification MSE : 7.5269, MAE: 1.4342, SWD: 1.5066
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.9916, mae: 1.4635, huber: 1.0970, swd: 2.9656, target_std: 6.4718
    Epoch [1/50], Val Losses: mse: 5.8446, mae: 1.2716, huber: 0.9256, swd: 1.3009, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.4359, mae: 1.4388, huber: 1.0866, swd: 1.6700, target_std: 4.7550
      Epoch 1 composite train-obj: 1.096987
            Val objective improved inf → 0.9256, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0351, mae: 1.1593, huber: 0.8122, swd: 1.2875, target_std: 6.4714
    Epoch [2/50], Val Losses: mse: 5.6088, mae: 1.2623, huber: 0.9157, swd: 1.4035, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.4154, mae: 1.4429, huber: 1.0904, swd: 1.8676, target_std: 4.7550
      Epoch 2 composite train-obj: 0.812183
            Val objective improved 0.9256 → 0.9157, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.7386, mae: 1.1112, huber: 0.7680, swd: 1.1849, target_std: 6.4718
    Epoch [3/50], Val Losses: mse: 5.6349, mae: 1.2616, huber: 0.9148, swd: 1.4531, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.6812, mae: 1.4650, huber: 1.1107, swd: 1.9818, target_std: 4.7550
      Epoch 3 composite train-obj: 0.767964
            Val objective improved 0.9157 → 0.9148, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.4358, mae: 1.0676, huber: 0.7275, swd: 1.0927, target_std: 6.4718
    Epoch [4/50], Val Losses: mse: 5.5093, mae: 1.2368, huber: 0.8913, swd: 1.1178, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 8.0662, mae: 1.4609, huber: 1.1080, swd: 1.6969, target_std: 4.7550
      Epoch 4 composite train-obj: 0.727489
            Val objective improved 0.9148 → 0.8913, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 3.1532, mae: 1.0305, huber: 0.6927, swd: 1.0160, target_std: 6.4713
    Epoch [5/50], Val Losses: mse: 5.8662, mae: 1.2550, huber: 0.9096, swd: 1.2792, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 8.3944, mae: 1.4895, huber: 1.1361, swd: 1.9135, target_std: 4.7550
      Epoch 5 composite train-obj: 0.692708
            No improvement (0.9096), counter 1/5
    Epoch [6/50], Train Losses: mse: 2.8512, mae: 0.9897, huber: 0.6546, swd: 0.9235, target_std: 6.4720
    Epoch [6/50], Val Losses: mse: 5.8743, mae: 1.2663, huber: 0.9204, swd: 1.2987, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 8.5072, mae: 1.4868, huber: 1.1341, swd: 1.8334, target_std: 4.7550
      Epoch 6 composite train-obj: 0.654552
            No improvement (0.9204), counter 2/5
    Epoch [7/50], Train Losses: mse: 2.6077, mae: 0.9545, huber: 0.6217, swd: 0.8535, target_std: 6.4715
    Epoch [7/50], Val Losses: mse: 6.3696, mae: 1.3391, huber: 0.9890, swd: 1.6509, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 8.5416, mae: 1.5218, huber: 1.1638, swd: 2.0793, target_std: 4.7550
      Epoch 7 composite train-obj: 0.621684
            No improvement (0.9890), counter 3/5
    Epoch [8/50], Train Losses: mse: 2.3600, mae: 0.9141, huber: 0.5843, swd: 0.7593, target_std: 6.4718
    Epoch [8/50], Val Losses: mse: 6.3061, mae: 1.3207, huber: 0.9719, swd: 1.4205, target_std: 4.3137
    Epoch [8/50], Test Losses: mse: 8.5605, mae: 1.5001, huber: 1.1468, swd: 1.8820, target_std: 4.7550
      Epoch 8 composite train-obj: 0.584327
            No improvement (0.9719), counter 4/5
    Epoch [9/50], Train Losses: mse: 2.1509, mae: 0.8764, huber: 0.5498, swd: 0.6797, target_std: 6.4716
    Epoch [9/50], Val Losses: mse: 6.5300, mae: 1.3425, huber: 0.9926, swd: 1.5188, target_std: 4.3137
    Epoch [9/50], Test Losses: mse: 8.7821, mae: 1.5162, huber: 1.1624, swd: 1.9581, target_std: 4.7550
      Epoch 9 composite train-obj: 0.549766
    Epoch [9/50], Test Losses: mse: 8.0664, mae: 1.4609, huber: 1.1080, swd: 1.6967, target_std: 4.7550
    Best round's Test MSE: 8.0662, MAE: 1.4609, SWD: 1.6969
    Best round's Validation MSE: 5.5093, MAE: 1.2368
    Best round's Test verification MSE : 8.0664, MAE: 1.4609, SWD: 1.6967
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.9489, mae: 1.4643, huber: 1.0968, swd: 2.8136, target_std: 6.4720
    Epoch [1/50], Val Losses: mse: 5.9327, mae: 1.2848, huber: 0.9364, swd: 1.1308, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.4418, mae: 1.4555, huber: 1.1007, swd: 1.5303, target_std: 4.7550
      Epoch 1 composite train-obj: 1.096826
            Val objective improved inf → 0.9364, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0860, mae: 1.1657, huber: 0.8178, swd: 1.2227, target_std: 6.4719
    Epoch [2/50], Val Losses: mse: 5.5101, mae: 1.2596, huber: 0.9086, swd: 1.1242, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.5080, mae: 1.4557, huber: 1.1000, swd: 1.5712, target_std: 4.7550
      Epoch 2 composite train-obj: 0.817811
            Val objective improved 0.9364 → 0.9086, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 3.7651, mae: 1.1151, huber: 0.7712, swd: 1.1147, target_std: 6.4718
    Epoch [3/50], Val Losses: mse: 5.4064, mae: 1.2443, huber: 0.8981, swd: 1.1901, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.5781, mae: 1.4421, huber: 1.0897, swd: 1.6364, target_std: 4.7550
      Epoch 3 composite train-obj: 0.771235
            Val objective improved 0.9086 → 0.8981, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 3.4489, mae: 1.0712, huber: 0.7303, swd: 1.0275, target_std: 6.4715
    Epoch [4/50], Val Losses: mse: 5.6600, mae: 1.2503, huber: 0.9054, swd: 1.1965, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 7.9661, mae: 1.4677, huber: 1.1145, swd: 1.7222, target_std: 4.7550
      Epoch 4 composite train-obj: 0.730337
            No improvement (0.9054), counter 1/5
    Epoch [5/50], Train Losses: mse: 3.1869, mae: 1.0373, huber: 0.6985, swd: 0.9729, target_std: 6.4720
    Epoch [5/50], Val Losses: mse: 5.9358, mae: 1.2686, huber: 0.9230, swd: 1.1954, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 8.2661, mae: 1.4728, huber: 1.1205, swd: 1.7130, target_std: 4.7550
      Epoch 5 composite train-obj: 0.698545
            No improvement (0.9230), counter 2/5
    Epoch [6/50], Train Losses: mse: 2.8243, mae: 0.9841, huber: 0.6491, swd: 0.8514, target_std: 6.4718
    Epoch [6/50], Val Losses: mse: 6.3481, mae: 1.3073, huber: 0.9587, swd: 1.2543, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 8.7584, mae: 1.5132, huber: 1.1588, swd: 1.7613, target_std: 4.7550
      Epoch 6 composite train-obj: 0.649104
            No improvement (0.9587), counter 3/5
    Epoch [7/50], Train Losses: mse: 2.5510, mae: 0.9463, huber: 0.6137, swd: 0.7764, target_std: 6.4719
    Epoch [7/50], Val Losses: mse: 6.2905, mae: 1.3254, huber: 0.9764, swd: 1.4252, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 8.6013, mae: 1.5172, huber: 1.1609, swd: 1.8920, target_std: 4.7550
      Epoch 7 composite train-obj: 0.613664
            No improvement (0.9764), counter 4/5
    Epoch [8/50], Train Losses: mse: 2.2962, mae: 0.9026, huber: 0.5734, swd: 0.6932, target_std: 6.4718
    Epoch [8/50], Val Losses: mse: 6.4297, mae: 1.3350, huber: 0.9861, swd: 1.2951, target_std: 4.3137
    Epoch [8/50], Test Losses: mse: 8.6388, mae: 1.5110, huber: 1.1573, swd: 1.7319, target_std: 4.7550
      Epoch 8 composite train-obj: 0.573449
    Epoch [8/50], Test Losses: mse: 7.5780, mae: 1.4421, huber: 1.0897, swd: 1.6364, target_std: 4.7550
    Best round's Test MSE: 7.5781, MAE: 1.4421, SWD: 1.6364
    Best round's Validation MSE: 5.4064, MAE: 1.2443
    Best round's Test verification MSE : 7.5780, MAE: 1.4421, SWD: 1.6364
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred96_20250429_2055)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.7238 ± 0.2430
      mae: 1.4457 ± 0.0112
      huber: 1.0937 ± 0.0104
      swd: 1.6133 ± 0.0794
      target_std: 4.7550 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.5067 ± 0.0808
      mae: 1.2395 ± 0.0034
      huber: 0.8938 ± 0.0030
      swd: 1.1541 ± 0.0295
      target_std: 4.3137 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred96_20250429_2055
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### Ab: normalized data


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2794, mae: 0.3624, huber: 0.1249, swd: 0.1286, target_std: 0.7915
    Epoch [1/50], Val Losses: mse: 0.2853, mae: 0.3580, huber: 0.1256, swd: 0.0973, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3280, mae: 0.3833, huber: 0.1441, swd: 0.1156, target_std: 0.8908
      Epoch 1 composite train-obj: 0.124900
            Val objective improved inf → 0.1256, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1893, mae: 0.3011, huber: 0.0880, swd: 0.0681, target_std: 0.7916
    Epoch [2/50], Val Losses: mse: 0.2950, mae: 0.3614, huber: 0.1293, swd: 0.0989, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3511, mae: 0.3945, huber: 0.1516, swd: 0.1354, target_std: 0.8908
      Epoch 2 composite train-obj: 0.088028
            No improvement (0.1293), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1533, mae: 0.2746, huber: 0.0726, swd: 0.0503, target_std: 0.7916
    Epoch [3/50], Val Losses: mse: 0.3305, mae: 0.3827, huber: 0.1431, swd: 0.1032, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3751, mae: 0.4098, huber: 0.1606, swd: 0.1399, target_std: 0.8908
      Epoch 3 composite train-obj: 0.072594
            No improvement (0.1431), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1225, mae: 0.2489, huber: 0.0589, swd: 0.0350, target_std: 0.7916
    Epoch [4/50], Val Losses: mse: 0.3449, mae: 0.4011, huber: 0.1502, swd: 0.1173, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.4048, mae: 0.4294, huber: 0.1732, swd: 0.1586, target_std: 0.8908
      Epoch 4 composite train-obj: 0.058877
            No improvement (0.1502), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1000, mae: 0.2264, huber: 0.0485, swd: 0.0245, target_std: 0.7915
    Epoch [5/50], Val Losses: mse: 0.3534, mae: 0.4126, huber: 0.1547, swd: 0.1231, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.4032, mae: 0.4320, huber: 0.1731, swd: 0.1608, target_std: 0.8908
      Epoch 5 composite train-obj: 0.048488
            No improvement (0.1547), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0861, mae: 0.2107, huber: 0.0420, swd: 0.0186, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3794, mae: 0.4332, huber: 0.1653, swd: 0.1282, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.4023, mae: 0.4339, huber: 0.1733, swd: 0.1534, target_std: 0.8908
      Epoch 6 composite train-obj: 0.041978
    Epoch [6/50], Test Losses: mse: 0.3280, mae: 0.3833, huber: 0.1441, swd: 0.1156, target_std: 0.8908
    Best round's Test MSE: 0.3280, MAE: 0.3833, SWD: 0.1156
    Best round's Validation MSE: 0.2853, MAE: 0.3580
    Best round's Test verification MSE : 0.3280, MAE: 0.3833, SWD: 0.1156
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2781, mae: 0.3620, huber: 0.1246, swd: 0.1273, target_std: 0.7915
    Epoch [1/50], Val Losses: mse: 0.2887, mae: 0.3621, huber: 0.1278, swd: 0.1013, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3295, mae: 0.3844, huber: 0.1450, swd: 0.1261, target_std: 0.8908
      Epoch 1 composite train-obj: 0.124563
            Val objective improved inf → 0.1278, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1911, mae: 0.3021, huber: 0.0888, swd: 0.0685, target_std: 0.7915
    Epoch [2/50], Val Losses: mse: 0.2932, mae: 0.3640, huber: 0.1303, swd: 0.0991, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3462, mae: 0.3954, huber: 0.1514, swd: 0.1391, target_std: 0.8908
      Epoch 2 composite train-obj: 0.088785
            No improvement (0.1303), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1563, mae: 0.2768, huber: 0.0739, swd: 0.0514, target_std: 0.7915
    Epoch [3/50], Val Losses: mse: 0.3153, mae: 0.3826, huber: 0.1394, swd: 0.1139, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3810, mae: 0.4144, huber: 0.1635, swd: 0.1600, target_std: 0.8908
      Epoch 3 composite train-obj: 0.073875
            No improvement (0.1394), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1244, mae: 0.2503, huber: 0.0597, swd: 0.0352, target_std: 0.7915
    Epoch [4/50], Val Losses: mse: 0.3282, mae: 0.3906, huber: 0.1452, swd: 0.1133, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.3952, mae: 0.4242, huber: 0.1694, swd: 0.1585, target_std: 0.8908
      Epoch 4 composite train-obj: 0.059741
            No improvement (0.1452), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1017, mae: 0.2281, huber: 0.0493, swd: 0.0246, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3546, mae: 0.4074, huber: 0.1544, swd: 0.1137, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.4011, mae: 0.4284, huber: 0.1716, swd: 0.1543, target_std: 0.8908
      Epoch 5 composite train-obj: 0.049319
            No improvement (0.1544), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0872, mae: 0.2117, huber: 0.0425, swd: 0.0185, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3453, mae: 0.4027, huber: 0.1516, swd: 0.1088, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.3977, mae: 0.4277, huber: 0.1707, swd: 0.1504, target_std: 0.8908
      Epoch 6 composite train-obj: 0.042525
    Epoch [6/50], Test Losses: mse: 0.3295, mae: 0.3844, huber: 0.1450, swd: 0.1261, target_std: 0.8908
    Best round's Test MSE: 0.3295, MAE: 0.3844, SWD: 0.1261
    Best round's Validation MSE: 0.2887, MAE: 0.3621
    Best round's Test verification MSE : 0.3295, MAE: 0.3844, SWD: 0.1261
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2752, mae: 0.3607, huber: 0.1234, swd: 0.1186, target_std: 0.7916
    Epoch [1/50], Val Losses: mse: 0.2840, mae: 0.3592, huber: 0.1261, swd: 0.0963, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3328, mae: 0.3908, huber: 0.1474, swd: 0.1236, target_std: 0.8908
      Epoch 1 composite train-obj: 0.123427
            Val objective improved inf → 0.1261, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1916, mae: 0.3036, huber: 0.0891, swd: 0.0648, target_std: 0.7916
    Epoch [2/50], Val Losses: mse: 0.3040, mae: 0.3726, huber: 0.1343, swd: 0.0921, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3593, mae: 0.4049, huber: 0.1560, swd: 0.1298, target_std: 0.8908
      Epoch 2 composite train-obj: 0.089147
            No improvement (0.1343), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1568, mae: 0.2780, huber: 0.0742, swd: 0.0489, target_std: 0.7916
    Epoch [3/50], Val Losses: mse: 0.3303, mae: 0.3871, huber: 0.1445, swd: 0.0988, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3859, mae: 0.4137, huber: 0.1647, swd: 0.1372, target_std: 0.8908
      Epoch 3 composite train-obj: 0.074192
            No improvement (0.1445), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1274, mae: 0.2538, huber: 0.0612, swd: 0.0353, target_std: 0.7916
    Epoch [4/50], Val Losses: mse: 0.3440, mae: 0.3980, huber: 0.1503, swd: 0.1044, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.3883, mae: 0.4181, huber: 0.1664, swd: 0.1415, target_std: 0.8908
      Epoch 4 composite train-obj: 0.061156
            No improvement (0.1503), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1046, mae: 0.2315, huber: 0.0507, swd: 0.0252, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3583, mae: 0.4072, huber: 0.1560, swd: 0.1136, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.4083, mae: 0.4350, huber: 0.1759, swd: 0.1589, target_std: 0.8908
      Epoch 5 composite train-obj: 0.050665
            No improvement (0.1560), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0896, mae: 0.2151, huber: 0.0437, swd: 0.0192, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3649, mae: 0.4177, huber: 0.1593, swd: 0.1143, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.4017, mae: 0.4321, huber: 0.1734, swd: 0.1521, target_std: 0.8908
      Epoch 6 composite train-obj: 0.043680
    Epoch [6/50], Test Losses: mse: 0.3328, mae: 0.3908, huber: 0.1474, swd: 0.1236, target_std: 0.8908
    Best round's Test MSE: 0.3328, MAE: 0.3908, SWD: 0.1236
    Best round's Validation MSE: 0.2840, MAE: 0.3592
    Best round's Test verification MSE : 0.3328, MAE: 0.3908, SWD: 0.1236
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred96_20250430_0041)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.3301 ± 0.0020
      mae: 0.3862 ± 0.0033
      huber: 0.1455 ± 0.0014
      swd: 0.1218 ± 0.0045
      target_std: 0.8908 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2860 ± 0.0020
      mae: 0.3598 ± 0.0017
      huber: 0.1265 ± 0.0009
      swd: 0.0983 ± 0.0021
      target_std: 0.9535 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred96_20250430_0041
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 720-196

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.6360, mae: 1.6451, huber: 1.2666, swd: 3.4157, ept: 93.1514
    Epoch [1/50], Val Losses: mse: 7.0167, mae: 1.4439, huber: 1.0842, swd: 1.2082, ept: 102.0704
    Epoch [1/50], Test Losses: mse: 9.5380, mae: 1.6880, huber: 1.3189, swd: 1.8533, ept: 79.1803
      Epoch 1 composite train-obj: 1.266634
            Val objective improved inf → 1.0842, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1692, mae: 1.3342, huber: 0.9732, swd: 1.5290, ept: 111.3074
    Epoch [2/50], Val Losses: mse: 6.8182, mae: 1.4327, huber: 1.0764, swd: 1.7793, ept: 106.8939
    Epoch [2/50], Test Losses: mse: 8.8363, mae: 1.6219, huber: 1.2567, swd: 2.1643, ept: 85.4431
      Epoch 2 composite train-obj: 0.973193
            Val objective improved 1.0842 → 1.0764, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.8403, mae: 1.2764, huber: 0.9208, swd: 1.4057, ept: 116.3796
    Epoch [3/50], Val Losses: mse: 6.5542, mae: 1.3788, huber: 1.0264, swd: 1.4688, ept: 111.1008
    Epoch [3/50], Test Losses: mse: 9.1032, mae: 1.6117, huber: 1.2493, swd: 1.9766, ept: 89.2131
      Epoch 3 composite train-obj: 0.920847
            Val objective improved 1.0764 → 1.0264, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.5756, mae: 1.2351, huber: 0.8826, swd: 1.2880, ept: 119.0550
    Epoch [4/50], Val Losses: mse: 6.5863, mae: 1.3913, huber: 1.0375, swd: 1.6521, ept: 111.7532
    Epoch [4/50], Test Losses: mse: 9.5207, mae: 1.6403, huber: 1.2766, swd: 2.2168, ept: 88.8460
      Epoch 4 composite train-obj: 0.882622
            No improvement (1.0375), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.3090, mae: 1.1991, huber: 0.8486, swd: 1.1931, ept: 120.9335
    Epoch [5/50], Val Losses: mse: 7.0740, mae: 1.4359, huber: 1.0795, swd: 1.7231, ept: 110.6542
    Epoch [5/50], Test Losses: mse: 9.5938, mae: 1.6368, huber: 1.2731, swd: 2.0545, ept: 90.8245
      Epoch 5 composite train-obj: 0.848610
            No improvement (1.0795), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.0269, mae: 1.1622, huber: 0.8136, swd: 1.0976, ept: 122.4913
    Epoch [6/50], Val Losses: mse: 6.9815, mae: 1.4091, huber: 1.0559, swd: 1.7554, ept: 113.7084
    Epoch [6/50], Test Losses: mse: 10.3215, mae: 1.6735, huber: 1.3108, swd: 2.2448, ept: 90.2707
      Epoch 6 composite train-obj: 0.813608
            No improvement (1.0559), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.7168, mae: 1.1190, huber: 0.7728, swd: 0.9733, ept: 124.2114
    Epoch [7/50], Val Losses: mse: 7.1064, mae: 1.4629, huber: 1.1059, swd: 1.8649, ept: 112.6110
    Epoch [7/50], Test Losses: mse: 10.1233, mae: 1.6752, huber: 1.3112, swd: 2.2448, ept: 90.9095
      Epoch 7 composite train-obj: 0.772811
            No improvement (1.1059), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.4316, mae: 1.0791, huber: 0.7352, swd: 0.8716, ept: 125.8476
    Epoch [8/50], Val Losses: mse: 7.4393, mae: 1.4962, huber: 1.1396, swd: 2.0045, ept: 113.5065
    Epoch [8/50], Test Losses: mse: 10.3856, mae: 1.6896, huber: 1.3265, swd: 2.2627, ept: 91.0419
      Epoch 8 composite train-obj: 0.735248
    Epoch [8/50], Test Losses: mse: 9.1034, mae: 1.6118, huber: 1.2493, swd: 1.9765, ept: 89.2153
    Best round's Test MSE: 9.1032, MAE: 1.6117, SWD: 1.9766
    Best round's Validation MSE: 6.5542, MAE: 1.3788, SWD: 1.4688
    Best round's Test verification MSE : 9.1034, MAE: 1.6118, SWD: 1.9765
    Time taken: 84.92 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.5879, mae: 1.6341, huber: 1.2570, swd: 3.5016, ept: 94.7043
    Epoch [1/50], Val Losses: mse: 6.8394, mae: 1.4229, huber: 1.0635, swd: 1.3330, ept: 105.2811
    Epoch [1/50], Test Losses: mse: 9.2394, mae: 1.6596, huber: 1.2908, swd: 1.9163, ept: 83.3561
      Epoch 1 composite train-obj: 1.256992
            Val objective improved inf → 1.0635, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.0692, mae: 1.3137, huber: 0.9553, swd: 1.5129, ept: 113.8248
    Epoch [2/50], Val Losses: mse: 6.5058, mae: 1.3738, huber: 1.0215, swd: 1.2559, ept: 109.2096
    Epoch [2/50], Test Losses: mse: 8.7939, mae: 1.5916, huber: 1.2296, swd: 1.6970, ept: 87.8761
      Epoch 2 composite train-obj: 0.955288
            Val objective improved 1.0635 → 1.0215, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.7653, mae: 1.2629, huber: 0.9087, swd: 1.3773, ept: 117.7587
    Epoch [3/50], Val Losses: mse: 6.5529, mae: 1.3877, huber: 1.0343, swd: 1.6083, ept: 110.4859
    Epoch [3/50], Test Losses: mse: 8.8646, mae: 1.6055, huber: 1.2427, swd: 2.0422, ept: 88.7297
      Epoch 3 composite train-obj: 0.908668
            No improvement (1.0343), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.5369, mae: 1.2300, huber: 0.8781, swd: 1.3092, ept: 119.9717
    Epoch [4/50], Val Losses: mse: 6.5875, mae: 1.3761, huber: 1.0224, swd: 1.4327, ept: 113.1321
    Epoch [4/50], Test Losses: mse: 9.1859, mae: 1.6078, huber: 1.2460, swd: 2.0527, ept: 91.5871
      Epoch 4 composite train-obj: 0.878126
            No improvement (1.0224), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.2570, mae: 1.1916, huber: 0.8420, swd: 1.2021, ept: 121.7619
    Epoch [5/50], Val Losses: mse: 6.7860, mae: 1.4030, huber: 1.0493, swd: 1.5714, ept: 111.8683
    Epoch [5/50], Test Losses: mse: 9.4695, mae: 1.6219, huber: 1.2589, swd: 1.9657, ept: 90.9642
      Epoch 5 composite train-obj: 0.842044
            No improvement (1.0493), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.9842, mae: 1.1561, huber: 0.8086, swd: 1.1127, ept: 123.2571
    Epoch [6/50], Val Losses: mse: 6.7577, mae: 1.4006, huber: 1.0455, swd: 1.5024, ept: 113.2746
    Epoch [6/50], Test Losses: mse: 9.8725, mae: 1.6450, huber: 1.2830, swd: 2.1341, ept: 91.2499
      Epoch 6 composite train-obj: 0.808571
            No improvement (1.0455), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.7032, mae: 1.1192, huber: 0.7734, swd: 1.0112, ept: 124.8110
    Epoch [7/50], Val Losses: mse: 6.9731, mae: 1.4314, huber: 1.0755, swd: 1.6869, ept: 113.6229
    Epoch [7/50], Test Losses: mse: 9.9450, mae: 1.6589, huber: 1.2963, swd: 2.1518, ept: 91.7234
      Epoch 7 composite train-obj: 0.773426
    Epoch [7/50], Test Losses: mse: 8.7942, mae: 1.5917, huber: 1.2297, swd: 1.6971, ept: 87.8794
    Best round's Test MSE: 8.7939, MAE: 1.5916, SWD: 1.6970
    Best round's Validation MSE: 6.5058, MAE: 1.3738, SWD: 1.2559
    Best round's Test verification MSE : 8.7942, MAE: 1.5917, SWD: 1.6971
    Time taken: 71.48 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4880, mae: 1.6323, huber: 1.2549, swd: 3.0213, ept: 94.8043
    Epoch [1/50], Val Losses: mse: 6.9877, mae: 1.4463, huber: 1.0831, swd: 1.2074, ept: 102.6772
    Epoch [1/50], Test Losses: mse: 9.5144, mae: 1.6928, huber: 1.3212, swd: 1.8524, ept: 80.4079
      Epoch 1 composite train-obj: 1.254883
            Val objective improved inf → 1.0831, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.1274, mae: 1.3227, huber: 0.9634, swd: 1.3586, ept: 113.1808
    Epoch [2/50], Val Losses: mse: 6.5429, mae: 1.3887, huber: 1.0357, swd: 1.3875, ept: 108.9134
    Epoch [2/50], Test Losses: mse: 8.7439, mae: 1.5924, huber: 1.2307, swd: 1.7151, ept: 87.8710
      Epoch 2 composite train-obj: 0.963436
            Val objective improved 1.0831 → 1.0357, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.8296, mae: 1.2701, huber: 0.9155, swd: 1.2505, ept: 117.5611
    Epoch [3/50], Val Losses: mse: 6.7261, mae: 1.4502, huber: 1.0904, swd: 1.9098, ept: 105.4948
    Epoch [3/50], Test Losses: mse: 8.9699, mae: 1.6590, huber: 1.2906, swd: 2.5008, ept: 85.0214
      Epoch 3 composite train-obj: 0.915458
            No improvement (1.0904), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.6131, mae: 1.2380, huber: 0.8856, swd: 1.1819, ept: 119.6726
    Epoch [4/50], Val Losses: mse: 6.5255, mae: 1.3678, huber: 1.0154, swd: 1.2306, ept: 113.2657
    Epoch [4/50], Test Losses: mse: 9.2034, mae: 1.6128, huber: 1.2509, swd: 1.7553, ept: 90.4739
      Epoch 4 composite train-obj: 0.885564
            Val objective improved 1.0357 → 1.0154, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.3677, mae: 1.2042, huber: 0.8538, swd: 1.1095, ept: 121.6106
    Epoch [5/50], Val Losses: mse: 6.8841, mae: 1.4112, huber: 1.0590, swd: 1.6420, ept: 112.7753
    Epoch [5/50], Test Losses: mse: 9.2900, mae: 1.6234, huber: 1.2617, swd: 2.0511, ept: 90.9360
      Epoch 5 composite train-obj: 0.853835
            No improvement (1.0590), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.1239, mae: 1.1716, huber: 0.8232, swd: 1.0245, ept: 123.0525
    Epoch [6/50], Val Losses: mse: 7.0014, mae: 1.4011, huber: 1.0485, swd: 1.4284, ept: 113.0078
    Epoch [6/50], Test Losses: mse: 9.7654, mae: 1.6291, huber: 1.2670, swd: 1.8621, ept: 92.0064
      Epoch 6 composite train-obj: 0.823225
            No improvement (1.0485), counter 2/5
    Epoch [7/50], Train Losses: mse: 3.8994, mae: 1.1444, huber: 0.7972, swd: 0.9665, ept: 124.2086
    Epoch [7/50], Val Losses: mse: 7.0202, mae: 1.4182, huber: 1.0634, swd: 1.6177, ept: 113.0329
    Epoch [7/50], Test Losses: mse: 9.9884, mae: 1.6624, huber: 1.2985, swd: 2.2202, ept: 90.5012
      Epoch 7 composite train-obj: 0.797232
            No improvement (1.0634), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.6021, mae: 1.1029, huber: 0.7580, swd: 0.8560, ept: 125.5214
    Epoch [8/50], Val Losses: mse: 7.1784, mae: 1.4302, huber: 1.0748, swd: 1.6322, ept: 114.1318
    Epoch [8/50], Test Losses: mse: 10.3701, mae: 1.6883, huber: 1.3227, swd: 2.1877, ept: 91.2614
      Epoch 8 composite train-obj: 0.757988
            No improvement (1.0748), counter 4/5
    Epoch [9/50], Train Losses: mse: 3.3367, mae: 1.0659, huber: 0.7232, swd: 0.7693, ept: 127.0104
    Epoch [9/50], Val Losses: mse: 7.3969, mae: 1.4485, huber: 1.0936, swd: 1.4955, ept: 113.9632
    Epoch [9/50], Test Losses: mse: 10.2058, mae: 1.6770, huber: 1.3136, swd: 2.0851, ept: 91.6497
      Epoch 9 composite train-obj: 0.723202
    Epoch [9/50], Test Losses: mse: 9.2034, mae: 1.6128, huber: 1.2509, swd: 1.7554, ept: 90.4826
    Best round's Test MSE: 9.2034, MAE: 1.6128, SWD: 1.7553
    Best round's Validation MSE: 6.5255, MAE: 1.3678, SWD: 1.2306
    Best round's Test verification MSE : 9.2034, MAE: 1.6128, SWD: 1.7554
    Time taken: 90.69 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred196_20250512_1500)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.0335 ± 0.1743
      mae: 1.6054 ± 0.0098
      huber: 1.2433 ± 0.0097
      swd: 1.8096 ± 0.1205
      ept: 89.1877 ± 1.0607
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.5285 ± 0.0199
      mae: 1.3735 ± 0.0045
      huber: 1.0211 ± 0.0045
      swd: 1.3184 ± 0.1068
      ept: 111.1920 ± 1.6571
      count: 48.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 247.19 seconds
    
    Experiment complete: ACL_ettm1_seq720_pred196_20250512_1500
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

##### AB: no rotate back + outside shift


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.2112, mae: 1.6024, huber: 1.2274, swd: 3.3662, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 6.6741, mae: 1.4042, huber: 1.0487, swd: 1.4539, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.0364, mae: 1.6237, huber: 1.2599, swd: 1.8541, target_std: 4.7514
      Epoch 1 composite train-obj: 1.227377
            Val objective improved inf → 1.0487, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9633, mae: 1.2891, huber: 0.9331, swd: 1.4353, target_std: 6.4712
    Epoch [2/50], Val Losses: mse: 6.3416, mae: 1.3614, huber: 1.0095, swd: 1.4788, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 8.8103, mae: 1.6015, huber: 1.2389, swd: 2.0466, target_std: 4.7514
      Epoch 2 composite train-obj: 0.933138
            Val objective improved 1.0487 → 1.0095, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6296, mae: 1.2374, huber: 0.8854, swd: 1.3114, target_std: 6.4711
    Epoch [3/50], Val Losses: mse: 6.6702, mae: 1.4270, huber: 1.0705, swd: 1.9026, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.4113, mae: 1.6736, huber: 1.3052, swd: 2.4489, target_std: 4.7514
      Epoch 3 composite train-obj: 0.885411
            No improvement (1.0705), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.3409, mae: 1.2011, huber: 0.8513, swd: 1.2333, target_std: 6.4713
    Epoch [4/50], Val Losses: mse: 6.4951, mae: 1.3817, huber: 1.0285, swd: 1.5346, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.7547, mae: 1.6411, huber: 1.2793, swd: 2.1279, target_std: 4.7514
      Epoch 4 composite train-obj: 0.851281
            No improvement (1.0285), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.0095, mae: 1.1582, huber: 0.8105, swd: 1.1217, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 6.9609, mae: 1.4381, huber: 1.0814, swd: 1.7203, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 9.6793, mae: 1.6468, huber: 1.2843, swd: 2.1535, target_std: 4.7514
      Epoch 5 composite train-obj: 0.810474
            No improvement (1.0814), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.6346, mae: 1.1073, huber: 0.7624, swd: 0.9895, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 7.2501, mae: 1.4733, huber: 1.1163, swd: 1.8916, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.2203, mae: 1.6768, huber: 1.3136, swd: 2.3094, target_std: 4.7514
      Epoch 6 composite train-obj: 0.762441
            No improvement (1.1163), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.2552, mae: 1.0534, huber: 0.7114, swd: 0.8464, target_std: 6.4713
    Epoch [7/50], Val Losses: mse: 7.4965, mae: 1.4921, huber: 1.1349, swd: 2.0342, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 10.5888, mae: 1.7150, huber: 1.3504, swd: 2.4047, target_std: 4.7514
      Epoch 7 composite train-obj: 0.711395
    Epoch [7/50], Test Losses: mse: 8.8105, mae: 1.6015, huber: 1.2389, swd: 2.0467, target_std: 4.7514
    Best round's Test MSE: 8.8103, MAE: 1.6015, SWD: 2.0466
    Best round's Validation MSE: 6.3416, MAE: 1.3614
    Best round's Test verification MSE : 8.8105, MAE: 1.6015, SWD: 2.0467
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.1977, mae: 1.5960, huber: 1.2219, swd: 3.4178, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 6.8197, mae: 1.4415, huber: 1.0810, swd: 1.8570, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 8.9515, mae: 1.6481, huber: 1.2798, swd: 2.3127, target_std: 4.7514
      Epoch 1 composite train-obj: 1.221929
            Val objective improved inf → 1.0810, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9448, mae: 1.2871, huber: 0.9313, swd: 1.4660, target_std: 6.4713
    Epoch [2/50], Val Losses: mse: 6.5469, mae: 1.3704, huber: 1.0189, swd: 1.4027, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 8.8577, mae: 1.5915, huber: 1.2305, swd: 1.8282, target_std: 4.7514
      Epoch 2 composite train-obj: 0.931288
            Val objective improved 1.0810 → 1.0189, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6658, mae: 1.2446, huber: 0.8924, swd: 1.3708, target_std: 6.4712
    Epoch [3/50], Val Losses: mse: 6.2889, mae: 1.3591, huber: 1.0068, swd: 1.6220, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.1242, mae: 1.6189, huber: 1.2553, swd: 2.1739, target_std: 4.7514
      Epoch 3 composite train-obj: 0.892356
            Val objective improved 1.0189 → 1.0068, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.3831, mae: 1.2067, huber: 0.8569, swd: 1.2899, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 6.5234, mae: 1.3800, huber: 1.0274, swd: 1.6522, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.5735, mae: 1.6423, huber: 1.2782, swd: 2.1905, target_std: 4.7514
      Epoch 4 composite train-obj: 0.856942
            No improvement (1.0274), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.0670, mae: 1.1651, huber: 0.8178, swd: 1.1910, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 6.7655, mae: 1.3923, huber: 1.0397, swd: 1.6505, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 10.0298, mae: 1.6618, huber: 1.2988, swd: 2.2103, target_std: 4.7514
      Epoch 5 composite train-obj: 0.817841
            No improvement (1.0397), counter 2/5
    Epoch [6/50], Train Losses: mse: 3.7717, mae: 1.1280, huber: 0.7824, swd: 1.1031, target_std: 6.4713
    Epoch [6/50], Val Losses: mse: 7.0573, mae: 1.4209, huber: 1.0675, swd: 1.6730, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.1377, mae: 1.6648, huber: 1.3013, swd: 2.0600, target_std: 4.7514
      Epoch 6 composite train-obj: 0.782424
            No improvement (1.0675), counter 3/5
    Epoch [7/50], Train Losses: mse: 3.4639, mae: 1.0840, huber: 0.7411, swd: 0.9938, target_std: 6.4713
    Epoch [7/50], Val Losses: mse: 6.9769, mae: 1.4288, huber: 1.0725, swd: 1.7547, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 10.5999, mae: 1.6884, huber: 1.3246, swd: 2.2026, target_std: 4.7514
      Epoch 7 composite train-obj: 0.741076
            No improvement (1.0725), counter 4/5
    Epoch [8/50], Train Losses: mse: 3.1497, mae: 1.0383, huber: 0.6980, swd: 0.8829, target_std: 6.4713
    Epoch [8/50], Val Losses: mse: 7.5586, mae: 1.4890, huber: 1.1309, swd: 1.8787, target_std: 4.3103
    Epoch [8/50], Test Losses: mse: 10.5344, mae: 1.7115, huber: 1.3455, swd: 2.1355, target_std: 4.7514
      Epoch 8 composite train-obj: 0.697951
    Epoch [8/50], Test Losses: mse: 9.1246, mae: 1.6189, huber: 1.2553, swd: 2.1745, target_std: 4.7514
    Best round's Test MSE: 9.1242, MAE: 1.6189, SWD: 2.1739
    Best round's Validation MSE: 6.2889, MAE: 1.3591
    Best round's Test verification MSE : 9.1246, MAE: 1.6189, SWD: 2.1745
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.0861, mae: 1.5922, huber: 1.2178, swd: 3.0320, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 7.0204, mae: 1.4694, huber: 1.1094, swd: 1.9357, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.2064, mae: 1.6739, huber: 1.3064, swd: 2.4011, target_std: 4.7514
      Epoch 1 composite train-obj: 1.217799
            Val objective improved inf → 1.1094, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.0181, mae: 1.2976, huber: 0.9411, swd: 1.3372, target_std: 6.4712
    Epoch [2/50], Val Losses: mse: 6.4439, mae: 1.3779, huber: 1.0249, swd: 1.4747, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 8.9085, mae: 1.6162, huber: 1.2531, swd: 1.9932, target_std: 4.7514
      Epoch 2 composite train-obj: 0.941083
            Val objective improved 1.1094 → 1.0249, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.6778, mae: 1.2473, huber: 0.8945, swd: 1.2234, target_std: 6.4713
    Epoch [3/50], Val Losses: mse: 6.7046, mae: 1.3954, huber: 1.0432, swd: 1.4770, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.2405, mae: 1.6273, huber: 1.2644, swd: 1.9912, target_std: 4.7514
      Epoch 3 composite train-obj: 0.894529
            No improvement (1.0432), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.3477, mae: 1.2025, huber: 0.8526, swd: 1.1245, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 6.6069, mae: 1.3944, huber: 1.0422, swd: 1.6509, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.7767, mae: 1.6528, huber: 1.2896, swd: 2.1435, target_std: 4.7514
      Epoch 4 composite train-obj: 0.852614
            No improvement (1.0422), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.0320, mae: 1.1621, huber: 0.8144, swd: 1.0313, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 6.8150, mae: 1.4021, huber: 1.0491, swd: 1.5655, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 10.1947, mae: 1.6768, huber: 1.3118, swd: 2.1428, target_std: 4.7514
      Epoch 5 composite train-obj: 0.814399
            No improvement (1.0491), counter 3/5
    Epoch [6/50], Train Losses: mse: 3.6564, mae: 1.1115, huber: 0.7666, swd: 0.9065, target_std: 6.4713
    Epoch [6/50], Val Losses: mse: 6.9288, mae: 1.4201, huber: 1.0666, swd: 1.7315, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.5809, mae: 1.6952, huber: 1.3306, swd: 2.2771, target_std: 4.7514
      Epoch 6 composite train-obj: 0.766579
            No improvement (1.0666), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.3442, mae: 1.0689, huber: 0.7262, swd: 0.8101, target_std: 6.4713
    Epoch [7/50], Val Losses: mse: 7.0020, mae: 1.4271, huber: 1.0728, swd: 1.5596, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 10.5784, mae: 1.7101, huber: 1.3454, swd: 2.2470, target_std: 4.7514
      Epoch 7 composite train-obj: 0.726245
    Epoch [7/50], Test Losses: mse: 8.9088, mae: 1.6162, huber: 1.2531, swd: 1.9930, target_std: 4.7514
    Best round's Test MSE: 8.9085, MAE: 1.6162, SWD: 1.9932
    Best round's Validation MSE: 6.4439, MAE: 1.3779
    Best round's Test verification MSE : 8.9088, MAE: 1.6162, SWD: 1.9930
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred196_20250429_2200)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 8.9476 ± 0.1311
      mae: 1.6122 ± 0.0076
      huber: 1.2491 ± 0.0072
      swd: 2.0712 ± 0.0758
      target_std: 4.7514 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.3581 ± 0.0644
      mae: 1.3661 ± 0.0084
      huber: 1.0137 ± 0.0080
      swd: 1.5252 ± 0.0685
      target_std: 4.3103 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred196_20250429_2200
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

##### Ab: normalized data


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3333, mae: 0.3989, huber: 0.1468, swd: 0.1463, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3336, mae: 0.3939, huber: 0.1463, swd: 0.1116, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.3875, mae: 0.4258, huber: 0.1686, swd: 0.1436, target_std: 0.8895
      Epoch 1 composite train-obj: 0.146816
            Val objective improved inf → 0.1463, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2454, mae: 0.3434, huber: 0.1121, swd: 0.0811, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3351, mae: 0.3926, huber: 0.1467, swd: 0.1027, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.3944, mae: 0.4261, huber: 0.1699, swd: 0.1422, target_std: 0.8895
      Epoch 2 composite train-obj: 0.112109
            No improvement (0.1467), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2057, mae: 0.3179, huber: 0.0960, swd: 0.0610, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3732, mae: 0.4247, huber: 0.1625, swd: 0.1226, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4218, mae: 0.4434, huber: 0.1803, swd: 0.1610, target_std: 0.8895
      Epoch 3 composite train-obj: 0.096029
            No improvement (0.1625), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1711, mae: 0.2931, huber: 0.0811, swd: 0.0441, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3902, mae: 0.4243, huber: 0.1673, swd: 0.1139, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4610, mae: 0.4648, huber: 0.1948, swd: 0.1644, target_std: 0.8895
      Epoch 4 composite train-obj: 0.081132
            No improvement (0.1673), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1441, mae: 0.2717, huber: 0.0691, swd: 0.0327, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3985, mae: 0.4316, huber: 0.1711, swd: 0.1158, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4741, mae: 0.4719, huber: 0.1995, swd: 0.1643, target_std: 0.8895
      Epoch 5 composite train-obj: 0.069148
            No improvement (0.1711), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1215, mae: 0.2511, huber: 0.0588, swd: 0.0236, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.4098, mae: 0.4439, huber: 0.1761, swd: 0.1190, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4780, mae: 0.4746, huber: 0.2010, swd: 0.1580, target_std: 0.8895
      Epoch 6 composite train-obj: 0.058819
    Epoch [6/50], Test Losses: mse: 0.3875, mae: 0.4258, huber: 0.1686, swd: 0.1436, target_std: 0.8895
    Best round's Test MSE: 0.3875, MAE: 0.4258, SWD: 0.1436
    Best round's Validation MSE: 0.3336, MAE: 0.3939
    Best round's Test verification MSE : 0.3875, MAE: 0.4258, SWD: 0.1436
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3322, mae: 0.3981, huber: 0.1463, swd: 0.1459, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3206, mae: 0.3842, huber: 0.1413, swd: 0.1059, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.3830, mae: 0.4236, huber: 0.1673, swd: 0.1458, target_std: 0.8895
      Epoch 1 composite train-obj: 0.146276
            Val objective improved inf → 0.1413, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2419, mae: 0.3408, huber: 0.1106, swd: 0.0798, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3456, mae: 0.4031, huber: 0.1504, swd: 0.1159, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.3979, mae: 0.4299, huber: 0.1721, swd: 0.1526, target_std: 0.8895
      Epoch 2 composite train-obj: 0.110605
            No improvement (0.1504), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2046, mae: 0.3167, huber: 0.0954, swd: 0.0609, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3545, mae: 0.4104, huber: 0.1545, swd: 0.1134, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4249, mae: 0.4449, huber: 0.1817, swd: 0.1676, target_std: 0.8895
      Epoch 3 composite train-obj: 0.095426
            No improvement (0.1545), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1708, mae: 0.2928, huber: 0.0810, swd: 0.0437, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3833, mae: 0.4364, huber: 0.1674, swd: 0.1333, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4557, mae: 0.4653, huber: 0.1941, swd: 0.1830, target_std: 0.8895
      Epoch 4 composite train-obj: 0.080998
            No improvement (0.1674), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1427, mae: 0.2706, huber: 0.0686, swd: 0.0315, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3884, mae: 0.4385, huber: 0.1693, swd: 0.1266, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4722, mae: 0.4741, huber: 0.1999, swd: 0.1802, target_std: 0.8895
      Epoch 5 composite train-obj: 0.068576
            No improvement (0.1693), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1217, mae: 0.2517, huber: 0.0590, swd: 0.0235, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3977, mae: 0.4441, huber: 0.1733, swd: 0.1206, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4777, mae: 0.4769, huber: 0.2014, swd: 0.1689, target_std: 0.8895
      Epoch 6 composite train-obj: 0.058999
    Epoch [6/50], Test Losses: mse: 0.3830, mae: 0.4236, huber: 0.1673, swd: 0.1458, target_std: 0.8895
    Best round's Test MSE: 0.3830, MAE: 0.4236, SWD: 0.1458
    Best round's Validation MSE: 0.3206, MAE: 0.3842
    Best round's Test verification MSE : 0.3830, MAE: 0.4236, SWD: 0.1458
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3329, mae: 0.3993, huber: 0.1468, swd: 0.1359, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3341, mae: 0.3939, huber: 0.1466, swd: 0.1089, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.3877, mae: 0.4258, huber: 0.1685, swd: 0.1360, target_std: 0.8895
      Epoch 1 composite train-obj: 0.146768
            Val objective improved inf → 0.1466, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2448, mae: 0.3432, huber: 0.1119, swd: 0.0751, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3537, mae: 0.4108, huber: 0.1547, swd: 0.1259, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.4097, mae: 0.4377, huber: 0.1768, swd: 0.1553, target_std: 0.8895
      Epoch 2 composite train-obj: 0.111869
            No improvement (0.1547), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2024, mae: 0.3161, huber: 0.0947, swd: 0.0548, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3478, mae: 0.4001, huber: 0.1510, swd: 0.1046, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4218, mae: 0.4436, huber: 0.1803, swd: 0.1540, target_std: 0.8895
      Epoch 3 composite train-obj: 0.094682
            No improvement (0.1510), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1684, mae: 0.2914, huber: 0.0801, swd: 0.0400, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3823, mae: 0.4208, huber: 0.1637, swd: 0.1075, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4600, mae: 0.4635, huber: 0.1939, swd: 0.1526, target_std: 0.8895
      Epoch 4 composite train-obj: 0.080054
            No improvement (0.1637), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1411, mae: 0.2695, huber: 0.0679, swd: 0.0293, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3970, mae: 0.4358, huber: 0.1704, swd: 0.1157, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4723, mae: 0.4729, huber: 0.1997, swd: 0.1584, target_std: 0.8895
      Epoch 5 composite train-obj: 0.067877
            No improvement (0.1704), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1197, mae: 0.2496, huber: 0.0580, swd: 0.0220, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3995, mae: 0.4417, huber: 0.1721, swd: 0.1200, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4786, mae: 0.4776, huber: 0.2022, swd: 0.1623, target_std: 0.8895
      Epoch 6 composite train-obj: 0.057985
    Epoch [6/50], Test Losses: mse: 0.3877, mae: 0.4258, huber: 0.1685, swd: 0.1360, target_std: 0.8895
    Best round's Test MSE: 0.3877, MAE: 0.4258, SWD: 0.1360
    Best round's Validation MSE: 0.3341, MAE: 0.3939
    Best round's Test verification MSE : 0.3877, MAE: 0.4258, SWD: 0.1360
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred196_20250429_2258)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.3861 ± 0.0022
      mae: 0.4251 ± 0.0010
      huber: 0.1682 ± 0.0006
      swd: 0.1418 ± 0.0042
      target_std: 0.8895 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3294 ± 0.0062
      mae: 0.3907 ± 0.0046
      huber: 0.1447 ± 0.0024
      swd: 0.1088 ± 0.0023
      target_std: 0.9533 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred196_20250429_2258
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 720-336

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4318, mae: 1.7370, huber: 1.3533, swd: 3.4575, ept: 127.3906
    Epoch [1/50], Val Losses: mse: 8.2883, mae: 1.5969, huber: 1.2314, swd: 1.9361, ept: 136.6965
    Epoch [1/50], Test Losses: mse: 10.2062, mae: 1.7993, huber: 1.4226, swd: 2.4149, ept: 107.8513
      Epoch 1 composite train-obj: 1.353313
            Val objective improved inf → 1.2314, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8513, mae: 1.4366, huber: 1.0684, swd: 1.5839, ept: 151.7548
    Epoch [2/50], Val Losses: mse: 7.8783, mae: 1.5451, huber: 1.1845, swd: 1.8436, ept: 147.3127
    Epoch [2/50], Test Losses: mse: 9.7252, mae: 1.7291, huber: 1.3575, swd: 2.1762, ept: 117.4555
      Epoch 2 composite train-obj: 1.068374
            Val objective improved 1.2314 → 1.1845, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.5101, mae: 1.3793, huber: 1.0156, swd: 1.4317, ept: 159.4703
    Epoch [3/50], Val Losses: mse: 8.0491, mae: 1.5773, huber: 1.2048, swd: 1.4535, ept: 129.3908
    Epoch [3/50], Test Losses: mse: 10.2322, mae: 1.7749, huber: 1.3944, swd: 1.7622, ept: 109.5443
      Epoch 3 composite train-obj: 1.015582
            No improvement (1.2048), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.2741, mae: 1.3422, huber: 0.9814, swd: 1.3306, ept: 163.7543
    Epoch [4/50], Val Losses: mse: 8.1760, mae: 1.5737, huber: 1.2126, swd: 1.9767, ept: 147.1964
    Epoch [4/50], Test Losses: mse: 9.9556, mae: 1.7394, huber: 1.3668, swd: 2.2154, ept: 118.3944
      Epoch 4 composite train-obj: 0.981405
            No improvement (1.2126), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9920, mae: 1.3026, huber: 0.9443, swd: 1.2252, ept: 166.5095
    Epoch [5/50], Val Losses: mse: 8.1671, mae: 1.5598, huber: 1.1994, swd: 1.8271, ept: 148.1060
    Epoch [5/50], Test Losses: mse: 10.5127, mae: 1.7408, huber: 1.3691, swd: 1.9827, ept: 120.0395
      Epoch 5 composite train-obj: 0.944346
            No improvement (1.1994), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.7075, mae: 1.2645, huber: 0.9083, swd: 1.1152, ept: 169.0884
    Epoch [6/50], Val Losses: mse: 8.2158, mae: 1.5775, huber: 1.2162, swd: 2.1635, ept: 150.3867
    Epoch [6/50], Test Losses: mse: 10.9227, mae: 1.7836, huber: 1.4109, swd: 2.4306, ept: 121.6118
      Epoch 6 composite train-obj: 0.908318
            No improvement (1.2162), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.4074, mae: 1.2231, huber: 0.8693, swd: 1.0011, ept: 171.6470
    Epoch [7/50], Val Losses: mse: 8.3054, mae: 1.5808, huber: 1.2196, swd: 2.2846, ept: 150.8688
    Epoch [7/50], Test Losses: mse: 11.7228, mae: 1.8428, huber: 1.4690, swd: 2.8748, ept: 119.5900
      Epoch 7 composite train-obj: 0.869306
    Epoch [7/50], Test Losses: mse: 9.7256, mae: 1.7291, huber: 1.3575, swd: 2.1762, ept: 117.4632
    Best round's Test MSE: 9.7252, MAE: 1.7291, SWD: 2.1762
    Best round's Validation MSE: 7.8783, MAE: 1.5451, SWD: 1.8436
    Best round's Test verification MSE : 9.7256, MAE: 1.7291, SWD: 2.1762
    Time taken: 72.85 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4922, mae: 1.7457, huber: 1.3617, swd: 3.6532, ept: 125.5064
    Epoch [1/50], Val Losses: mse: 8.2288, mae: 1.5935, huber: 1.2274, swd: 1.7486, ept: 133.0596
    Epoch [1/50], Test Losses: mse: 10.2877, mae: 1.8010, huber: 1.4241, swd: 2.2916, ept: 104.9649
      Epoch 1 composite train-obj: 1.361677
            Val objective improved inf → 1.2274, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8184, mae: 1.4311, huber: 1.0633, swd: 1.6055, ept: 151.8537
    Epoch [2/50], Val Losses: mse: 7.9776, mae: 1.5409, huber: 1.1795, swd: 1.6121, ept: 143.6680
    Epoch [2/50], Test Losses: mse: 9.9531, mae: 1.7487, huber: 1.3761, swd: 2.0733, ept: 113.9424
      Epoch 2 composite train-obj: 1.063259
            Val objective improved 1.2274 → 1.1795, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4875, mae: 1.3750, huber: 1.0118, swd: 1.4611, ept: 159.4612
    Epoch [3/50], Val Losses: mse: 7.9510, mae: 1.5245, huber: 1.1665, swd: 1.6284, ept: 147.7536
    Epoch [3/50], Test Losses: mse: 9.8688, mae: 1.7195, huber: 1.3507, swd: 2.0067, ept: 118.4504
      Epoch 3 composite train-obj: 1.011768
            Val objective improved 1.1795 → 1.1665, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.2631, mae: 1.3400, huber: 0.9795, swd: 1.3804, ept: 163.3082
    Epoch [4/50], Val Losses: mse: 7.9109, mae: 1.5373, huber: 1.1783, swd: 1.8486, ept: 147.5460
    Epoch [4/50], Test Losses: mse: 10.2138, mae: 1.7401, huber: 1.3700, swd: 2.1572, ept: 118.2554
      Epoch 4 composite train-obj: 0.979474
            No improvement (1.1783), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.9514, mae: 1.2959, huber: 0.9380, swd: 1.2377, ept: 166.6838
    Epoch [5/50], Val Losses: mse: 8.4095, mae: 1.5853, huber: 1.2239, swd: 2.1355, ept: 147.8128
    Epoch [5/50], Test Losses: mse: 10.2355, mae: 1.7580, huber: 1.3869, swd: 2.4851, ept: 119.5732
      Epoch 5 composite train-obj: 0.937967
            No improvement (1.2239), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.6472, mae: 1.2537, huber: 0.8981, swd: 1.1155, ept: 169.7390
    Epoch [6/50], Val Losses: mse: 8.0906, mae: 1.5562, huber: 1.1963, swd: 2.0733, ept: 149.7823
    Epoch [6/50], Test Losses: mse: 11.2276, mae: 1.7996, huber: 1.4288, swd: 2.5360, ept: 122.0802
      Epoch 6 composite train-obj: 0.898130
            No improvement (1.1963), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.3299, mae: 1.2085, huber: 0.8553, swd: 0.9779, ept: 172.4889
    Epoch [7/50], Val Losses: mse: 8.4877, mae: 1.5851, huber: 1.2253, swd: 2.1815, ept: 150.4546
    Epoch [7/50], Test Losses: mse: 11.1777, mae: 1.8035, huber: 1.4321, swd: 2.5116, ept: 120.8347
      Epoch 7 composite train-obj: 0.855328
            No improvement (1.2253), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.0043, mae: 1.1627, huber: 0.8122, swd: 0.8465, ept: 175.4719
    Epoch [8/50], Val Losses: mse: 8.7058, mae: 1.6007, huber: 1.2409, swd: 2.1932, ept: 155.3682
    Epoch [8/50], Test Losses: mse: 11.5115, mae: 1.8298, huber: 1.4579, swd: 2.5792, ept: 121.8822
      Epoch 8 composite train-obj: 0.812176
    Epoch [8/50], Test Losses: mse: 9.8685, mae: 1.7195, huber: 1.3507, swd: 2.0066, ept: 118.4717
    Best round's Test MSE: 9.8688, MAE: 1.7195, SWD: 2.0067
    Best round's Validation MSE: 7.9510, MAE: 1.5245, SWD: 1.6284
    Best round's Test verification MSE : 9.8685, MAE: 1.7195, SWD: 2.0066
    Time taken: 87.13 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.0868, mae: 1.7121, huber: 1.3299, swd: 3.2647, ept: 128.8948
    Epoch [1/50], Val Losses: mse: 8.0849, mae: 1.5547, huber: 1.1902, swd: 1.4451, ept: 140.3707
    Epoch [1/50], Test Losses: mse: 10.1257, mae: 1.7684, huber: 1.3937, swd: 1.9165, ept: 109.5667
      Epoch 1 composite train-obj: 1.329891
            Val objective improved inf → 1.1902, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.7682, mae: 1.4210, huber: 1.0544, swd: 1.5078, ept: 154.1674
    Epoch [2/50], Val Losses: mse: 7.5474, mae: 1.5039, huber: 1.1444, swd: 1.6947, ept: 145.0123
    Epoch [2/50], Test Losses: mse: 9.9075, mae: 1.7372, huber: 1.3663, swd: 2.4016, ept: 115.7634
      Epoch 2 composite train-obj: 1.054426
            Val objective improved 1.1902 → 1.1444, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4406, mae: 1.3662, huber: 1.0040, swd: 1.3782, ept: 161.3142
    Epoch [3/50], Val Losses: mse: 7.8964, mae: 1.5242, huber: 1.1662, swd: 1.5968, ept: 149.4202
    Epoch [3/50], Test Losses: mse: 9.7138, mae: 1.7058, huber: 1.3367, swd: 2.0951, ept: 119.7295
      Epoch 3 composite train-obj: 1.003978
            No improvement (1.1662), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.2201, mae: 1.3337, huber: 0.9739, swd: 1.3076, ept: 165.1431
    Epoch [4/50], Val Losses: mse: 7.9117, mae: 1.5315, huber: 1.1728, swd: 1.7755, ept: 149.6267
    Epoch [4/50], Test Losses: mse: 10.0534, mae: 1.7252, huber: 1.3557, swd: 2.1934, ept: 120.4048
      Epoch 4 composite train-obj: 0.973878
            No improvement (1.1728), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9422, mae: 1.2937, huber: 0.9365, swd: 1.1971, ept: 168.0275
    Epoch [5/50], Val Losses: mse: 8.3516, mae: 1.5906, huber: 1.2301, swd: 2.1732, ept: 148.9507
    Epoch [5/50], Test Losses: mse: 10.3208, mae: 1.7435, huber: 1.3737, swd: 2.4397, ept: 121.2541
      Epoch 5 composite train-obj: 0.936475
            No improvement (1.2301), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.6687, mae: 1.2586, huber: 0.9032, swd: 1.0960, ept: 170.1640
    Epoch [6/50], Val Losses: mse: 8.3515, mae: 1.5811, huber: 1.2213, swd: 2.1382, ept: 151.9903
    Epoch [6/50], Test Losses: mse: 10.9095, mae: 1.7682, huber: 1.3985, swd: 2.5834, ept: 123.1020
      Epoch 6 composite train-obj: 0.903229
            No improvement (1.2213), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.3577, mae: 1.2176, huber: 0.8642, swd: 0.9802, ept: 172.6424
    Epoch [7/50], Val Losses: mse: 8.4593, mae: 1.5967, huber: 1.2359, swd: 2.1630, ept: 151.2635
    Epoch [7/50], Test Losses: mse: 11.5255, mae: 1.8096, huber: 1.4388, swd: 2.5110, ept: 122.0772
      Epoch 7 composite train-obj: 0.864234
    Epoch [7/50], Test Losses: mse: 9.9076, mae: 1.7372, huber: 1.3664, swd: 2.4015, ept: 115.7560
    Best round's Test MSE: 9.9075, MAE: 1.7372, SWD: 2.4016
    Best round's Validation MSE: 7.5474, MAE: 1.5039, SWD: 1.6947
    Best round's Test verification MSE : 9.9076, MAE: 1.7372, SWD: 2.4015
    Time taken: 81.78 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred336_20250512_1504)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.8338 ± 0.0784
      mae: 1.7286 ± 0.0072
      huber: 1.3582 ± 0.0064
      swd: 2.1948 ± 0.1618
      ept: 117.2231 ± 1.1092
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.7922 ± 0.1757
      mae: 1.5245 ± 0.0169
      huber: 1.1651 ± 0.0164
      swd: 1.7222 ± 0.0900
      ept: 146.6929 ± 1.2019
      count: 47.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 241.85 seconds
    
    Experiment complete: ACL_ettm1_seq720_pred336_20250512_1504
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### AB: no rotate back + outside shift


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.2802, mae: 1.7233, huber: 1.3414, swd: 3.4270, target_std: 6.4709
    Epoch [1/50], Val Losses: mse: 8.1469, mae: 1.5637, huber: 1.1994, swd: 1.8496, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.4261, mae: 1.7989, huber: 1.4238, swd: 2.3977, target_std: 4.7516
      Epoch 1 composite train-obj: 1.341364
            Val objective improved inf → 1.1994, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.7490, mae: 1.4084, huber: 1.0436, swd: 1.4996, target_std: 6.4710
    Epoch [2/50], Val Losses: mse: 7.7944, mae: 1.5318, huber: 1.1719, swd: 1.8713, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 9.7315, mae: 1.7329, huber: 1.3601, swd: 2.2860, target_std: 4.7516
      Epoch 2 composite train-obj: 1.043553
            Val objective improved 1.1994 → 1.1719, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.4063, mae: 1.3541, huber: 0.9936, swd: 1.3910, target_std: 6.4708
    Epoch [3/50], Val Losses: mse: 8.0549, mae: 1.5544, huber: 1.1951, swd: 2.0496, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.0036, mae: 1.7316, huber: 1.3612, swd: 2.1384, target_std: 4.7516
      Epoch 3 composite train-obj: 0.993642
            No improvement (1.1951), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.1595, mae: 1.3189, huber: 0.9608, swd: 1.3182, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 8.0656, mae: 1.5243, huber: 1.1665, swd: 1.5860, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.1474, mae: 1.7238, huber: 1.3543, swd: 1.8573, target_std: 4.7516
      Epoch 4 composite train-obj: 0.960837
            Val objective improved 1.1719 → 1.1665, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.7863, mae: 1.2662, huber: 0.9111, swd: 1.1530, target_std: 6.4710
    Epoch [5/50], Val Losses: mse: 8.1190, mae: 1.5479, huber: 1.1882, swd: 1.8497, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.7686, mae: 1.7726, huber: 1.4013, swd: 2.0926, target_std: 4.7516
      Epoch 5 composite train-obj: 0.911098
            No improvement (1.1882), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.4735, mae: 1.2234, huber: 0.8709, swd: 1.0417, target_std: 6.4707
    Epoch [6/50], Val Losses: mse: 8.1201, mae: 1.5614, huber: 1.2018, swd: 1.9910, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.1833, mae: 1.8174, huber: 1.4444, swd: 2.4625, target_std: 4.7516
      Epoch 6 composite train-obj: 0.870854
            No improvement (1.2018), counter 2/5
    Epoch [7/50], Train Losses: mse: 4.1452, mae: 1.1789, huber: 0.8287, swd: 0.9301, target_std: 6.4711
    Epoch [7/50], Val Losses: mse: 8.1883, mae: 1.5733, huber: 1.2107, swd: 2.0411, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 11.5580, mae: 1.8460, huber: 1.4718, swd: 2.5660, target_std: 4.7516
      Epoch 7 composite train-obj: 0.828719
            No improvement (1.2107), counter 3/5
    Epoch [8/50], Train Losses: mse: 3.7604, mae: 1.1246, huber: 0.7776, swd: 0.7862, target_std: 6.4710
    Epoch [8/50], Val Losses: mse: 8.4164, mae: 1.5782, huber: 1.2181, swd: 1.9562, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 11.3993, mae: 1.8392, huber: 1.4655, swd: 2.4131, target_std: 4.7516
      Epoch 8 composite train-obj: 0.777609
            No improvement (1.2181), counter 4/5
    Epoch [9/50], Train Losses: mse: 3.4860, mae: 1.0880, huber: 0.7431, swd: 0.7141, target_std: 6.4709
    Epoch [9/50], Val Losses: mse: 8.5729, mae: 1.6041, huber: 1.2421, swd: 2.1841, target_std: 4.3126
    Epoch [9/50], Test Losses: mse: 11.7694, mae: 1.8624, huber: 1.4870, swd: 2.5167, target_std: 4.7516
      Epoch 9 composite train-obj: 0.743052
    Epoch [9/50], Test Losses: mse: 10.1472, mae: 1.7238, huber: 1.3543, swd: 1.8573, target_std: 4.7516
    Best round's Test MSE: 10.1474, MAE: 1.7238, SWD: 1.8573
    Best round's Validation MSE: 8.0656, MAE: 1.5243
    Best round's Test verification MSE : 10.1472, MAE: 1.7238, SWD: 1.8573
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.9858, mae: 1.7012, huber: 1.3200, swd: 3.5258, target_std: 6.4709
    Epoch [1/50], Val Losses: mse: 7.7610, mae: 1.5102, huber: 1.1501, swd: 1.4606, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.1752, mae: 1.7484, huber: 1.3785, swd: 2.0519, target_std: 4.7516
      Epoch 1 composite train-obj: 1.319964
            Val objective improved inf → 1.1501, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.6868, mae: 1.3993, huber: 1.0353, swd: 1.5488, target_std: 6.4710
    Epoch [2/50], Val Losses: mse: 7.6995, mae: 1.5164, huber: 1.1581, swd: 1.8123, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 9.8752, mae: 1.7194, huber: 1.3508, swd: 2.2483, target_std: 4.7516
      Epoch 2 composite train-obj: 1.035276
            No improvement (1.1581), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.3145, mae: 1.3414, huber: 0.9814, swd: 1.3909, target_std: 6.4707
    Epoch [3/50], Val Losses: mse: 7.7783, mae: 1.5332, huber: 1.1742, swd: 2.0122, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.2063, mae: 1.7419, huber: 1.3712, swd: 2.2827, target_std: 4.7516
      Epoch 3 composite train-obj: 0.981377
            No improvement (1.1742), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.0218, mae: 1.3028, huber: 0.9449, swd: 1.2962, target_std: 6.4709
    Epoch [4/50], Val Losses: mse: 8.0813, mae: 1.5867, huber: 1.2239, swd: 2.3890, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.7024, mae: 1.7747, huber: 1.4021, swd: 2.5217, target_std: 4.7516
      Epoch 4 composite train-obj: 0.944891
            No improvement (1.2239), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.6321, mae: 1.2509, huber: 0.8958, swd: 1.1184, target_std: 6.4709
    Epoch [5/50], Val Losses: mse: 8.1391, mae: 1.5789, huber: 1.2174, swd: 2.2681, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 11.0424, mae: 1.7988, huber: 1.4256, swd: 2.4760, target_std: 4.7516
      Epoch 5 composite train-obj: 0.895761
            No improvement (1.2174), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.1952, mae: 1.1925, huber: 0.8402, swd: 0.9414, target_std: 6.4709
    Epoch [6/50], Val Losses: mse: 8.3892, mae: 1.5951, huber: 1.2335, swd: 2.2925, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.3590, mae: 1.8178, huber: 1.4452, swd: 2.4914, target_std: 4.7516
      Epoch 6 composite train-obj: 0.840216
    Epoch [6/50], Test Losses: mse: 10.1751, mae: 1.7483, huber: 1.3785, swd: 2.0518, target_std: 4.7516
    Best round's Test MSE: 10.1752, MAE: 1.7484, SWD: 2.0519
    Best round's Validation MSE: 7.7610, MAE: 1.5102
    Best round's Test verification MSE : 10.1751, MAE: 1.7483, SWD: 2.0518
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.5819, mae: 1.6639, huber: 1.2853, swd: 3.1922, target_std: 6.4708
    Epoch [1/50], Val Losses: mse: 7.8648, mae: 1.5220, huber: 1.1616, swd: 1.4490, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.1126, mae: 1.7417, huber: 1.3723, swd: 2.0007, target_std: 4.7516
      Epoch 1 composite train-obj: 1.285272
            Val objective improved inf → 1.1616, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.6605, mae: 1.3934, huber: 1.0302, swd: 1.4834, target_std: 6.4708
    Epoch [2/50], Val Losses: mse: 7.3699, mae: 1.4725, huber: 1.1160, swd: 1.6122, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 9.9771, mae: 1.7105, huber: 1.3423, swd: 2.1516, target_std: 4.7516
      Epoch 2 composite train-obj: 1.030246
            Val objective improved 1.1616 → 1.1160, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3540, mae: 1.3475, huber: 0.9877, swd: 1.3771, target_std: 6.4710
    Epoch [3/50], Val Losses: mse: 7.6059, mae: 1.5024, huber: 1.1442, swd: 1.7612, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.3015, mae: 1.7389, huber: 1.3695, swd: 2.4043, target_std: 4.7516
      Epoch 3 composite train-obj: 0.987670
            No improvement (1.1442), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.0870, mae: 1.3111, huber: 0.9536, swd: 1.2856, target_std: 6.4707
    Epoch [4/50], Val Losses: mse: 7.6782, mae: 1.5280, huber: 1.1680, swd: 2.0518, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.4838, mae: 1.7630, huber: 1.3919, swd: 2.5358, target_std: 4.7516
      Epoch 4 composite train-obj: 0.953555
            No improvement (1.1680), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.7956, mae: 1.2737, huber: 0.9181, swd: 1.1846, target_std: 6.4708
    Epoch [5/50], Val Losses: mse: 8.0886, mae: 1.5679, huber: 1.2067, swd: 2.1754, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.7849, mae: 1.7849, huber: 1.4107, swd: 2.6588, target_std: 4.7516
      Epoch 5 composite train-obj: 0.918103
            No improvement (1.2067), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.4720, mae: 1.2294, huber: 0.8761, swd: 1.0612, target_std: 6.4706
    Epoch [6/50], Val Losses: mse: 8.2210, mae: 1.5621, huber: 1.2014, swd: 1.9659, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.8787, mae: 1.7710, huber: 1.4002, swd: 2.3842, target_std: 4.7516
      Epoch 6 composite train-obj: 0.876148
            No improvement (1.2014), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.1679, mae: 1.1879, huber: 0.8368, swd: 0.9523, target_std: 6.4710
    Epoch [7/50], Val Losses: mse: 8.4213, mae: 1.5903, huber: 1.2257, swd: 2.1316, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 11.3816, mae: 1.8118, huber: 1.4392, swd: 2.5577, target_std: 4.7516
      Epoch 7 composite train-obj: 0.836763
    Epoch [7/50], Test Losses: mse: 9.9772, mae: 1.7105, huber: 1.3424, swd: 2.1518, target_std: 4.7516
    Best round's Test MSE: 9.9771, MAE: 1.7105, SWD: 2.1516
    Best round's Validation MSE: 7.3699, MAE: 1.4725
    Best round's Test verification MSE : 9.9772, MAE: 1.7105, SWD: 2.1518
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred336_20250429_2153)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.0999 ± 0.0876
      mae: 1.7275 ± 0.0157
      huber: 1.3584 ± 0.0150
      swd: 2.0203 ± 0.1222
      target_std: 4.7516 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.7321 ± 0.2847
      mae: 1.5023 ± 0.0219
      huber: 1.1442 ± 0.0210
      swd: 1.5529 ± 0.0661
      target_std: 4.3126 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred336_20250429_2153
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.2138, mae: 1.8247, huber: 1.4326, swd: 4.0340, target_std: 6.4709
    Epoch [1/50], Val Losses: mse: 8.4487, mae: 1.6234, huber: 1.2564, swd: 2.3034, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.3073, mae: 1.8151, huber: 1.4373, swd: 2.8451, target_std: 4.7516
      Epoch 1 composite train-obj: 1.432579
            Val objective improved inf → 1.2564, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9724, mae: 1.4706, huber: 1.0958, swd: 1.6789, target_std: 6.4710
    Epoch [2/50], Val Losses: mse: 7.8237, mae: 1.5325, huber: 1.1723, swd: 1.8307, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 9.9903, mae: 1.7416, huber: 1.3707, swd: 2.3580, target_std: 4.7516
      Epoch 2 composite train-obj: 1.095806
            Val objective improved 1.2564 → 1.1723, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6256, mae: 1.3978, huber: 1.0315, swd: 1.4805, target_std: 6.4708
    Epoch [3/50], Val Losses: mse: 7.7020, mae: 1.5183, huber: 1.1585, swd: 1.6629, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.1275, mae: 1.7366, huber: 1.3657, swd: 2.1274, target_std: 4.7516
      Epoch 3 composite train-obj: 1.031540
            Val objective improved 1.1723 → 1.1585, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.4205, mae: 1.3663, huber: 1.0032, swd: 1.4175, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 8.1365, mae: 1.5666, huber: 1.2061, swd: 1.7936, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.3231, mae: 1.7531, huber: 1.3799, swd: 2.1032, target_std: 4.7516
      Epoch 4 composite train-obj: 1.003220
            No improvement (1.2061), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.0945, mae: 1.3189, huber: 0.9589, swd: 1.2675, target_std: 6.4710
    Epoch [5/50], Val Losses: mse: 8.0814, mae: 1.5683, huber: 1.2075, swd: 1.8178, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.4213, mae: 1.7507, huber: 1.3791, swd: 2.0002, target_std: 4.7516
      Epoch 5 composite train-obj: 0.958897
            No improvement (1.2075), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.8174, mae: 1.2828, huber: 0.9249, swd: 1.1740, target_std: 6.4707
    Epoch [6/50], Val Losses: mse: 8.4627, mae: 1.6110, huber: 1.2504, swd: 2.1680, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.4410, mae: 1.7526, huber: 1.3804, swd: 2.2629, target_std: 4.7516
      Epoch 6 composite train-obj: 0.924863
            No improvement (1.2504), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.4758, mae: 1.2361, huber: 0.8806, swd: 1.0290, target_std: 6.4711
    Epoch [7/50], Val Losses: mse: 8.7450, mae: 1.6485, huber: 1.2853, swd: 2.3531, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 11.1081, mae: 1.7964, huber: 1.4236, swd: 2.3210, target_std: 4.7516
      Epoch 7 composite train-obj: 0.880608
            No improvement (1.2853), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.1188, mae: 1.1866, huber: 0.8336, swd: 0.8869, target_std: 6.4710
    Epoch [8/50], Val Losses: mse: 8.8742, mae: 1.6659, huber: 1.3014, swd: 2.3717, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 11.2027, mae: 1.8264, huber: 1.4507, swd: 2.5641, target_std: 4.7516
      Epoch 8 composite train-obj: 0.833642
    Epoch [8/50], Test Losses: mse: 10.1296, mae: 1.7366, huber: 1.3657, swd: 2.1283, target_std: 4.7516
    Best round's Test MSE: 10.1275, MAE: 1.7366, SWD: 2.1274
    Best round's Validation MSE: 7.7020, MAE: 1.5183
    Best round's Test verification MSE : 10.1296, MAE: 1.7366, SWD: 2.1283
    Time taken: 128.46 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9801, mae: 1.8116, huber: 1.4195, swd: 3.9156, target_std: 6.4709
    Epoch [1/50], Val Losses: mse: 8.3284, mae: 1.5788, huber: 1.2151, swd: 1.7992, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.3511, mae: 1.7846, huber: 1.4113, swd: 2.3592, target_std: 4.7516
      Epoch 1 composite train-obj: 1.419531
            Val objective improved inf → 1.2151, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0482, mae: 1.4860, huber: 1.1097, swd: 1.8225, target_std: 6.4710
    Epoch [2/50], Val Losses: mse: 7.9783, mae: 1.5432, huber: 1.1818, swd: 1.8182, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.0089, mae: 1.7438, huber: 1.3727, swd: 2.3785, target_std: 4.7516
      Epoch 2 composite train-obj: 1.109665
            Val objective improved 1.2151 → 1.1818, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6173, mae: 1.3992, huber: 1.0322, swd: 1.5232, target_std: 6.4707
    Epoch [3/50], Val Losses: mse: 7.7775, mae: 1.5303, huber: 1.1706, swd: 1.8881, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.0484, mae: 1.7402, huber: 1.3690, swd: 2.3857, target_std: 4.7516
      Epoch 3 composite train-obj: 1.032224
            Val objective improved 1.1818 → 1.1706, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.3387, mae: 1.3560, huber: 0.9933, swd: 1.4186, target_std: 6.4709
    Epoch [4/50], Val Losses: mse: 7.9114, mae: 1.5576, huber: 1.1964, swd: 2.0817, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.1812, mae: 1.7529, huber: 1.3801, swd: 2.4855, target_std: 4.7516
      Epoch 4 composite train-obj: 0.993324
            No improvement (1.1964), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.0853, mae: 1.3229, huber: 0.9622, swd: 1.3354, target_std: 6.4709
    Epoch [5/50], Val Losses: mse: 8.1599, mae: 1.5811, huber: 1.2207, swd: 2.1652, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.5703, mae: 1.7651, huber: 1.3930, swd: 2.3834, target_std: 4.7516
      Epoch 5 composite train-obj: 0.962225
            No improvement (1.2207), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.7771, mae: 1.2797, huber: 0.9217, swd: 1.2007, target_std: 6.4709
    Epoch [6/50], Val Losses: mse: 8.3514, mae: 1.6062, huber: 1.2440, swd: 2.3250, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.5766, mae: 1.7669, huber: 1.3935, swd: 2.4638, target_std: 4.7516
      Epoch 6 composite train-obj: 0.921660
            No improvement (1.2440), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.4793, mae: 1.2399, huber: 0.8840, swd: 1.0840, target_std: 6.4709
    Epoch [7/50], Val Losses: mse: 8.6418, mae: 1.6368, huber: 1.2745, swd: 2.5651, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 10.9576, mae: 1.7911, huber: 1.4182, swd: 2.4978, target_std: 4.7516
      Epoch 7 composite train-obj: 0.884031
            No improvement (1.2745), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.0974, mae: 1.1867, huber: 0.8336, swd: 0.9251, target_std: 6.4710
    Epoch [8/50], Val Losses: mse: 8.5946, mae: 1.6406, huber: 1.2763, swd: 2.5710, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 11.3062, mae: 1.8178, huber: 1.4453, swd: 2.6795, target_std: 4.7516
      Epoch 8 composite train-obj: 0.833575
    Epoch [8/50], Test Losses: mse: 10.0497, mae: 1.7403, huber: 1.3692, swd: 2.3869, target_std: 4.7516
    Best round's Test MSE: 10.0484, MAE: 1.7402, SWD: 2.3857
    Best round's Validation MSE: 7.7775, MAE: 1.5303
    Best round's Test verification MSE : 10.0497, MAE: 1.7403, SWD: 2.3869
    Time taken: 124.92 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.1362, mae: 1.8275, huber: 1.4350, swd: 3.9054, target_std: 6.4708
    Epoch [1/50], Val Losses: mse: 8.4423, mae: 1.6054, huber: 1.2394, swd: 1.9083, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.4157, mae: 1.8034, huber: 1.4278, swd: 2.4418, target_std: 4.7516
      Epoch 1 composite train-obj: 1.434951
            Val objective improved inf → 1.2394, saving checkpoint.
    


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    Cell In[7], line 24
         22 cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
         23 cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
    ---> 24 exp_ACL_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
    

    File c:\proj\DL_notebook\study\train.py:398, in execute_model_evaluation(dataname, train_config, data_manager, scale)
        390 experiment = MultiSeedRunner(
        391     base_config=cfg,
        392     seeds=cfg.seeds,
        393     experiment_name=experiment_name,
        394     raw_test_data=data_manager.raw_test_data
        395 )
        397 # Execute the experiment
    --> 398 experiment.run_multiple_seeds(train_loader, val_loader, test_loader)
        400 # Print summary
        401 print(f"\nExperiment complete: {experiment_name}")
    

    File c:\proj\DL_notebook\study\train.py:614, in MultiSeedRunner.run_multiple_seeds(self, train_loader, val_loader, test_loader)
        612 for i, seed in enumerate(self.seeds):
        613     start_time = time.time()
    --> 614     result = self._run_single_seed(seed, i, train_loader, val_loader, test_loader)
        615     self.results.append(result)
        616     self._save_experiment_result(result)
    

    File c:\proj\DL_notebook\study\train.py:586, in MultiSeedRunner._run_single_seed(self, seed, seed_idx, train_loader, val_loader, test_loader)
        584 trainer = ModelTrainer(config=current_config, checkpoint_mgr=self.checkpoint_mgr)
        585 start_time = time.time()
    --> 586 best_val_losses, best_test_losses, test_data_dict  = trainer.train_model(train_loader, val_loader, test_loader)
        587 end_time = time.time()
        589 print(f"Time taken: {end_time - start_time:.2f} seconds")
    

    File c:\proj\DL_notebook\study\train.py:930, in ModelTrainer.train_model(self, train_loader, val_loader, test_loader)
        926 for epoch in range(self.cfg.epochs): 
        927     # on_epoch_begin
        928     for cb in self.callbacks: cb.on_epoch_begin(epoch)
    --> 930     dict_train = self.evaluate_phase(train_loader, "Train", epoch) 
        931     dict_val = self.evaluate_phase(val_loader, "Val", epoch)
        932     dict_test = self.evaluate_phase(test_loader, "Test", epoch)
    

    File c:\proj\DL_notebook\study\train.py:899, in ModelTrainer.evaluate_phase(self, data_loader, phase, epoch, collect_data)
        897         # on_batch_end
        898         for cb in self.callbacks: 
    --> 899             cb.on_batch_end(
        900                 phase=phase,
        901                 batch_x=batch_x,
        902                 pred=pred,
        903                 batch_y=batch_y,
        904             )
        905 # on_phase_end
        906 for cb in self.callbacks: 
    

    File c:\proj\DL_notebook\study\train.py:195, in Callback.on_batch_end(self, phase, **kwargs)
        190     """Subclasses may:
        191     - Accumulate losses for batch level logging
        192     - Compute loss to backward or validate
        193     """
        194     return None 
    --> 195 def on_batch_end(self, phase: str, **kwargs): 
        196     """
        197     - Prediction collector collect data if it is a test phase
        198     """
        199     return None 
    

    KeyboardInterrupt: 



```python
importlib.reload(monotonic)
importlib.reload(train_config)
# utils.reload_modules([modules_to_reload_list])
cfg = train_config.FlatACLConfig(  
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 6,
    mixing_strategy='convex',
    # single_magnitude_for_shift=True,

)
cfg.x_to_z_delay.enable_magnitudes = [False, False]
cfg.x_to_z_delay.spectral_flags_scale_shift = [False, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, False]
cfg.x_to_z_delay.spectral_flags_hidden = [False, False]

cfg.x_to_z_deri.enable_magnitudes = [False, False]
cfg.x_to_z_deri.spectral_flags_scale_shift = [False, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, False]
cfg.x_to_z_deri.spectral_flags_hidden = [False, False]

cfg.z_to_x_main.enable_magnitudes = [False, False]
cfg.z_to_x_main.spectral_flags_scale_shift = [False, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, False]
cfg.z_to_x_main.spectral_flags_hidden = [False, False]

cfg.z_push_to_z.enable_magnitudes = [False, False]
cfg.z_push_to_z.spectral_flags_scale_shift = [False, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, False]
cfg.z_push_to_z.spectral_flags_hidden = [False, False]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [False, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden = [True, True]
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.4548, mae: 1.8188, huber: 1.4312, swd: 4.0174, target_std: 6.4708
    Epoch [1/50], Val Losses: mse: 8.7191, mae: 1.6435, huber: 1.2745, swd: 1.9862, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.6594, mae: 1.8386, huber: 1.4591, swd: 2.3597, target_std: 4.7516
      Epoch 1 composite train-obj: 1.431152
            Val objective improved inf → 1.2745, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9314, mae: 1.4456, huber: 1.0755, swd: 1.5509, target_std: 6.4710
    Epoch [2/50], Val Losses: mse: 8.6297, mae: 1.6618, huber: 1.2967, swd: 2.3227, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.1511, mae: 1.7783, huber: 1.4072, swd: 2.4437, target_std: 4.7516
      Epoch 2 composite train-obj: 1.075527
            No improvement (1.2967), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.6198, mae: 1.3925, huber: 1.0264, swd: 1.4124, target_std: 6.4711
    Epoch [3/50], Val Losses: mse: 8.4053, mae: 1.6686, huber: 1.3017, swd: 2.6659, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.2316, mae: 1.7664, huber: 1.3942, swd: 2.5016, target_std: 4.7516
      Epoch 3 composite train-obj: 1.026371
            No improvement (1.3017), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.3766, mae: 1.3558, huber: 0.9917, swd: 1.2949, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 8.6720, mae: 1.7013, huber: 1.3347, swd: 2.8435, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.4662, mae: 1.7768, huber: 1.4050, swd: 2.4228, target_std: 4.7516
      Epoch 4 composite train-obj: 0.991723
            No improvement (1.3347), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.1205, mae: 1.3179, huber: 0.9562, swd: 1.1849, target_std: 6.4708
    Epoch [5/50], Val Losses: mse: 8.7258, mae: 1.6954, huber: 1.3265, swd: 2.7247, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.6534, mae: 1.7850, huber: 1.4126, swd: 2.5321, target_std: 4.7516
      Epoch 5 composite train-obj: 0.956185
            No improvement (1.3265), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.8255, mae: 1.2769, huber: 0.9172, swd: 1.0552, target_std: 6.4708
    Epoch [6/50], Val Losses: mse: 9.3457, mae: 1.7673, huber: 1.3989, swd: 3.2420, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.9876, mae: 1.8121, huber: 1.4400, swd: 2.6863, target_std: 4.7516
      Epoch 6 composite train-obj: 0.917241
    Epoch [6/50], Test Losses: mse: 10.6591, mae: 1.8386, huber: 1.4591, swd: 2.3591, target_std: 4.7516
    Best round's Test MSE: 10.6594, MAE: 1.8386, SWD: 2.3597
    Best round's Validation MSE: 8.7191, MAE: 1.6435
    Best round's Test verification MSE : 10.6591, MAE: 1.8386, SWD: 2.3591
    Time taken: 75.91 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.3590, mae: 1.8144, huber: 1.4270, swd: 4.1476, target_std: 6.4710
    Epoch [1/50], Val Losses: mse: 9.0794, mae: 1.6913, huber: 1.3213, swd: 2.3173, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.6915, mae: 1.8563, huber: 1.4751, swd: 2.7482, target_std: 4.7516
      Epoch 1 composite train-obj: 1.427037
            Val objective improved inf → 1.3213, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.9444, mae: 1.4490, huber: 1.0784, swd: 1.6191, target_std: 6.4707
    Epoch [2/50], Val Losses: mse: 8.5964, mae: 1.6610, huber: 1.2894, swd: 2.4278, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.2150, mae: 1.7654, huber: 1.3902, swd: 2.2189, target_std: 4.7516
      Epoch 2 composite train-obj: 1.078365
            Val objective improved 1.3213 → 1.2894, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.6547, mae: 1.3988, huber: 1.0319, swd: 1.4897, target_std: 6.4709
    Epoch [3/50], Val Losses: mse: 8.4861, mae: 1.6666, huber: 1.2983, swd: 2.7066, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.3429, mae: 1.7800, huber: 1.4058, swd: 2.5055, target_std: 4.7516
      Epoch 3 composite train-obj: 1.031896
            No improvement (1.2983), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.3274, mae: 1.3491, huber: 0.9852, swd: 1.3074, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 8.5603, mae: 1.6754, huber: 1.3077, swd: 2.7686, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.5654, mae: 1.7901, huber: 1.4161, swd: 2.6246, target_std: 4.7516
      Epoch 4 composite train-obj: 0.985175
            No improvement (1.3077), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9896, mae: 1.3005, huber: 0.9393, swd: 1.1310, target_std: 6.4708
    Epoch [5/50], Val Losses: mse: 8.6881, mae: 1.6873, huber: 1.3206, swd: 2.9213, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 11.0285, mae: 1.8260, huber: 1.4518, swd: 2.8588, target_std: 4.7516
      Epoch 5 composite train-obj: 0.939327
            No improvement (1.3206), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.6749, mae: 1.2599, huber: 0.9001, swd: 0.9875, target_std: 6.4707
    Epoch [6/50], Val Losses: mse: 8.9856, mae: 1.7225, huber: 1.3551, swd: 3.1302, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.3679, mae: 1.8446, huber: 1.4699, swd: 2.9091, target_std: 4.7516
      Epoch 6 composite train-obj: 0.900067
            No improvement (1.3551), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.2951, mae: 1.2058, huber: 0.8491, swd: 0.8114, target_std: 6.4709
    Epoch [7/50], Val Losses: mse: 9.5610, mae: 1.7603, huber: 1.3900, swd: 3.1192, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 11.7670, mae: 1.8707, huber: 1.4925, swd: 2.6974, target_std: 4.7516
      Epoch 7 composite train-obj: 0.849068
    Epoch [7/50], Test Losses: mse: 10.2155, mae: 1.7654, huber: 1.3902, swd: 2.2189, target_std: 4.7516
    Best round's Test MSE: 10.2150, MAE: 1.7654, SWD: 2.2189
    Best round's Validation MSE: 8.5964, MAE: 1.6610
    Best round's Test verification MSE : 10.2155, MAE: 1.7654, SWD: 2.2189
    Time taken: 86.34 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    


    ---------------------------------------------------------------------------

    KeyboardInterrupt                         Traceback (most recent call last)

    Cell In[9], line 49
         47 cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
         48 cfg.z_to_y_main.spectral_flags_hidden = [True, True]
    ---> 49 exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
    

    File c:\proj\DL_notebook\study\train.py:398, in execute_model_evaluation(dataname, train_config, data_manager, scale)
        390 experiment = MultiSeedRunner(
        391     base_config=cfg,
        392     seeds=cfg.seeds,
        393     experiment_name=experiment_name,
        394     raw_test_data=data_manager.raw_test_data
        395 )
        397 # Execute the experiment
    --> 398 experiment.run_multiple_seeds(train_loader, val_loader, test_loader)
        400 # Print summary
        401 print(f"\nExperiment complete: {experiment_name}")
    

    File c:\proj\DL_notebook\study\train.py:614, in MultiSeedRunner.run_multiple_seeds(self, train_loader, val_loader, test_loader)
        612 for i, seed in enumerate(self.seeds):
        613     start_time = time.time()
    --> 614     result = self._run_single_seed(seed, i, train_loader, val_loader, test_loader)
        615     self.results.append(result)
        616     self._save_experiment_result(result)
    

    File c:\proj\DL_notebook\study\train.py:586, in MultiSeedRunner._run_single_seed(self, seed, seed_idx, train_loader, val_loader, test_loader)
        584 trainer = ModelTrainer(config=current_config, checkpoint_mgr=self.checkpoint_mgr)
        585 start_time = time.time()
    --> 586 best_val_losses, best_test_losses, test_data_dict  = trainer.train_model(train_loader, val_loader, test_loader)
        587 end_time = time.time()
        589 print(f"Time taken: {end_time - start_time:.2f} seconds")
    

    File c:\proj\DL_notebook\study\train.py:930, in ModelTrainer.train_model(self, train_loader, val_loader, test_loader)
        926 for epoch in range(self.cfg.epochs): 
        927     # on_epoch_begin
        928     for cb in self.callbacks: cb.on_epoch_begin(epoch)
    --> 930     dict_train = self.evaluate_phase(train_loader, "Train", epoch) 
        931     dict_val = self.evaluate_phase(val_loader, "Val", epoch)
        932     dict_test = self.evaluate_phase(test_loader, "Test", epoch)
    

    File c:\proj\DL_notebook\study\train.py:895, in ModelTrainer.evaluate_phase(self, data_loader, phase, epoch, collect_data)
        892 batch_y = batch_y.to(self.cfg.device)
        893 # on_batch_begin
    --> 895 loss_to_use, pred = self.run_batch(batch_x, batch_y, phase=phase)
        897 # on_batch_end
        898 for cb in self.callbacks: 
    

    File c:\proj\DL_notebook\study\train.py:861, in ModelTrainer.run_batch(self, batch_x, batch_y, phase)
        859 # loss_to_use.backward()
        860 try:
    --> 861     loss_to_use.backward()
        862     # --- GRAD CHECK 3: Parameter Gradients ---
        863     grads = [p.grad.abs().max().item() for p in self.model.parameters() if p.grad is not None]
    

    File c:\Users\qilin\miniconda3\envs\ww\Lib\site-packages\torch\_tensor.py:648, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)
        638 if has_torch_function_unary(self):
        639     return handle_torch_function(
        640         Tensor.backward,
        641         (self,),
       (...)    646         inputs=inputs,
        647     )
    --> 648 torch.autograd.backward(
        649     self, gradient, retain_graph, create_graph, inputs=inputs
        650 )
    

    File c:\Users\qilin\miniconda3\envs\ww\Lib\site-packages\torch\autograd\__init__.py:353, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)
        348     retain_graph = create_graph
        350 # The reason we repeat the same comment below is that
        351 # some Python versions print out the first line of a multi-line function
        352 # calls in the traceback and some print out the last line
    --> 353 _engine_run_backward(
        354     tensors,
        355     grad_tensors_,
        356     retain_graph,
        357     create_graph,
        358     inputs,
        359     allow_unreachable=True,
        360     accumulate_grad=True,
        361 )
    

    File c:\Users\qilin\miniconda3\envs\ww\Lib\site-packages\torch\autograd\graph.py:824, in _engine_run_backward(t_outputs, *args, **kwargs)
        822     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
        823 try:
    --> 824     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
        825         t_outputs, *args, **kwargs
        826     )  # Calls into the C++ engine to run the backward pass
        827 finally:
        828     if attach_logging_hooks:
    

    KeyboardInterrupt: 


##### normalized scale


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3756, mae: 0.4255, huber: 0.1633, swd: 0.1535, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3682, mae: 0.4265, huber: 0.1618, swd: 0.1363, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4334, mae: 0.4605, huber: 0.1887, swd: 0.1706, target_std: 0.8890
      Epoch 1 composite train-obj: 0.163314
            Val objective improved inf → 0.1618, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2827, mae: 0.3709, huber: 0.1281, swd: 0.0852, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3584, mae: 0.4109, huber: 0.1564, swd: 0.1171, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.4411, mae: 0.4623, huber: 0.1906, swd: 0.1558, target_std: 0.8890
      Epoch 2 composite train-obj: 0.128064
            Val objective improved 0.1618 → 0.1564, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2395, mae: 0.3437, huber: 0.1108, swd: 0.0624, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.3868, mae: 0.4329, huber: 0.1679, swd: 0.1179, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.4751, mae: 0.4767, huber: 0.2019, swd: 0.1645, target_std: 0.8890
      Epoch 3 composite train-obj: 0.110832
            No improvement (0.1679), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2067, mae: 0.3208, huber: 0.0968, swd: 0.0471, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.3953, mae: 0.4395, huber: 0.1719, swd: 0.1240, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5129, mae: 0.4992, huber: 0.2168, swd: 0.1788, target_std: 0.8890
      Epoch 4 composite train-obj: 0.096833
            No improvement (0.1719), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1802, mae: 0.3005, huber: 0.0852, swd: 0.0365, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4153, mae: 0.4556, huber: 0.1804, swd: 0.1270, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5337, mae: 0.5111, huber: 0.2250, swd: 0.1785, target_std: 0.8890
      Epoch 5 composite train-obj: 0.085164
            No improvement (0.1804), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1592, mae: 0.2835, huber: 0.0758, swd: 0.0292, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4225, mae: 0.4602, huber: 0.1837, swd: 0.1285, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5395, mae: 0.5140, huber: 0.2269, swd: 0.1877, target_std: 0.8890
      Epoch 6 composite train-obj: 0.075786
            No improvement (0.1837), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1432, mae: 0.2699, huber: 0.0685, swd: 0.0246, target_std: 0.7920
    Epoch [7/50], Val Losses: mse: 0.4202, mae: 0.4557, huber: 0.1816, swd: 0.1151, target_std: 0.9537
    Epoch [7/50], Test Losses: mse: 0.5436, mae: 0.5156, huber: 0.2281, swd: 0.1683, target_std: 0.8890
      Epoch 7 composite train-obj: 0.068535
    Epoch [7/50], Test Losses: mse: 0.4411, mae: 0.4623, huber: 0.1906, swd: 0.1558, target_std: 0.8890
    Best round's Test MSE: 0.4411, MAE: 0.4623, SWD: 0.1558
    Best round's Validation MSE: 0.3584, MAE: 0.4109
    Best round's Test verification MSE : 0.4411, MAE: 0.4623, SWD: 0.1558
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3759, mae: 0.4250, huber: 0.1632, swd: 0.1598, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3678, mae: 0.4205, huber: 0.1609, swd: 0.1198, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4188, mae: 0.4503, huber: 0.1831, swd: 0.1469, target_std: 0.8890
      Epoch 1 composite train-obj: 0.163214
            Val objective improved inf → 0.1609, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2825, mae: 0.3702, huber: 0.1279, swd: 0.0886, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3617, mae: 0.4127, huber: 0.1583, swd: 0.1313, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.4428, mae: 0.4641, huber: 0.1917, swd: 0.1765, target_std: 0.8890
      Epoch 2 composite train-obj: 0.127868
            Val objective improved 0.1609 → 0.1583, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 0.2391, mae: 0.3436, huber: 0.1107, swd: 0.0646, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.3859, mae: 0.4309, huber: 0.1677, swd: 0.1338, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.4737, mae: 0.4788, huber: 0.2029, swd: 0.1808, target_std: 0.8890
      Epoch 3 composite train-obj: 0.110731
            No improvement (0.1677), counter 1/5
    Epoch [4/50], Train Losses: mse: 0.2046, mae: 0.3192, huber: 0.0959, swd: 0.0473, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.4242, mae: 0.4565, huber: 0.1837, swd: 0.1331, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5190, mae: 0.5018, huber: 0.2200, swd: 0.1805, target_std: 0.8890
      Epoch 4 composite train-obj: 0.095948
            No improvement (0.1837), counter 2/5
    Epoch [5/50], Train Losses: mse: 0.1764, mae: 0.2975, huber: 0.0835, swd: 0.0356, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4448, mae: 0.4754, huber: 0.1930, swd: 0.1421, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5417, mae: 0.5139, huber: 0.2280, swd: 0.1782, target_std: 0.8890
      Epoch 5 composite train-obj: 0.083486
            No improvement (0.1930), counter 3/5
    Epoch [6/50], Train Losses: mse: 0.1528, mae: 0.2786, huber: 0.0730, swd: 0.0272, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4418, mae: 0.4647, huber: 0.1892, swd: 0.1209, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5633, mae: 0.5215, huber: 0.2347, swd: 0.1665, target_std: 0.8890
      Epoch 6 composite train-obj: 0.072996
            No improvement (0.1892), counter 4/5
    Epoch [7/50], Train Losses: mse: 0.1337, mae: 0.2620, huber: 0.0644, swd: 0.0215, target_std: 0.7920
    Epoch [7/50], Val Losses: mse: 0.4400, mae: 0.4668, huber: 0.1891, swd: 0.1314, target_std: 0.9537
    Epoch [7/50], Test Losses: mse: 0.5665, mae: 0.5233, huber: 0.2356, swd: 0.1757, target_std: 0.8890
      Epoch 7 composite train-obj: 0.064363
    Epoch [7/50], Test Losses: mse: 0.4428, mae: 0.4641, huber: 0.1917, swd: 0.1765, target_std: 0.8890
    Best round's Test MSE: 0.4428, MAE: 0.4641, SWD: 0.1765
    Best round's Validation MSE: 0.3617, MAE: 0.4127
    Best round's Test verification MSE : 0.4428, MAE: 0.4641, SWD: 0.1765
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3792, mae: 0.4277, huber: 0.1647, swd: 0.1573, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3783, mae: 0.4236, huber: 0.1646, swd: 0.1109, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4234, mae: 0.4531, huber: 0.1844, swd: 0.1393, target_std: 0.8890
      Epoch 1 composite train-obj: 0.164684
            Val objective improved inf → 0.1646, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2829, mae: 0.3718, huber: 0.1283, swd: 0.0865, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.4059, mae: 0.4471, huber: 0.1767, swd: 0.1335, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.4682, mae: 0.4790, huber: 0.2018, swd: 0.1721, target_std: 0.8890
      Epoch 2 composite train-obj: 0.128315
            No improvement (0.1767), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.2403, mae: 0.3449, huber: 0.1113, swd: 0.0643, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.3909, mae: 0.4386, huber: 0.1706, swd: 0.1291, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.4862, mae: 0.4863, huber: 0.2070, swd: 0.1767, target_std: 0.8890
      Epoch 3 composite train-obj: 0.111291
            No improvement (0.1706), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.2086, mae: 0.3227, huber: 0.0978, swd: 0.0486, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.4236, mae: 0.4639, huber: 0.1852, swd: 0.1497, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5362, mae: 0.5112, huber: 0.2256, swd: 0.2045, target_std: 0.8890
      Epoch 4 composite train-obj: 0.097813
            No improvement (0.1852), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.1834, mae: 0.3032, huber: 0.0866, swd: 0.0377, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4077, mae: 0.4489, huber: 0.1774, swd: 0.1331, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5373, mae: 0.5104, huber: 0.2246, swd: 0.1887, target_std: 0.8890
      Epoch 5 composite train-obj: 0.086616
            No improvement (0.1774), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.1624, mae: 0.2864, huber: 0.0773, swd: 0.0301, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4348, mae: 0.4653, huber: 0.1884, swd: 0.1359, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5687, mae: 0.5217, huber: 0.2348, swd: 0.1921, target_std: 0.8890
      Epoch 6 composite train-obj: 0.077263
    Epoch [6/50], Test Losses: mse: 0.4234, mae: 0.4531, huber: 0.1844, swd: 0.1393, target_std: 0.8890
    Best round's Test MSE: 0.4234, MAE: 0.4531, SWD: 0.1393
    Best round's Validation MSE: 0.3783, MAE: 0.4236
    Best round's Test verification MSE : 0.4234, MAE: 0.4531, SWD: 0.1393
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred336_20250429_2325)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.4358 ± 0.0088
      mae: 0.4598 ± 0.0048
      huber: 0.1889 ± 0.0032
      swd: 0.1572 ± 0.0152
      target_std: 0.8890 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3662 ± 0.0087
      mae: 0.4157 ± 0.0056
      huber: 0.1598 ± 0.0035
      swd: 0.1198 ± 0.0085
      target_std: 0.9537 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred336_20250429_2325
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 720-720

##### huber


```python
from monotonic import DynamicTanh
import torch.nn as nn

importlib.reload(monotonic)
importlib.reload(train_config) 
cfg = train_config.FlatACLConfig(  # original householder 
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128, 
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=True, 
    ablate_shift_inside_scale=False,
    householder_reflects_latent = 2,
    householder_reflects_data = 4,
    mixing_strategy='delay_only', 
    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],
    ablate_deterministic_y0=False, 
)
cfg.x_to_z_delay.enable_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_delay.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.x_to_z_deri.enable_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]
cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]
cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]
cfg.x_to_z_deri.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_x_main.enable_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_x_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_push_to_z.enable_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]
cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]
cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]
cfg.z_push_to_z.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]

cfg.z_to_y_main.enable_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]
cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]
cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]
cfg.z_to_y_main.activations_scale_shift = ["relu6", "dynamic_tanh"]
cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]
# cfg.x_to_z_delay.scale_zeroing_threshold = 1e-4
# cfg.x_to_z_deri.scale_zeroing_threshold = 1e-4
# cfg.z_to_x_main.scale_zeroing_threshold = 1e-4
# cfg.z_push_to_z.scale_zeroing_threshold = 1e-4
# cfg.z_to_y_main.scale_zeroing_threshold = 1e-4
exp = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.9617, mae: 1.8254, huber: 1.4353, swd: 3.1752, ept: 184.7266
    Epoch [1/50], Val Losses: mse: 10.3252, mae: 1.7546, huber: 1.3841, swd: 1.7098, ept: 185.7864
    Epoch [1/50], Test Losses: mse: 10.9389, mae: 1.9033, huber: 1.5196, swd: 2.0279, ept: 164.2595
      Epoch 1 composite train-obj: 1.435274
            Val objective improved inf → 1.3841, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4746, mae: 1.5431, huber: 1.1661, swd: 1.5135, ept: 222.8522
    Epoch [2/50], Val Losses: mse: 10.0495, mae: 1.7289, huber: 1.3640, swd: 2.1379, ept: 197.0246
    Epoch [2/50], Test Losses: mse: 10.1867, mae: 1.8263, huber: 1.4471, swd: 2.0199, ept: 179.1291
      Epoch 2 composite train-obj: 1.166088
            Val objective improved 1.3841 → 1.3640, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.1036, mae: 1.4856, huber: 1.1132, swd: 1.3609, ept: 236.4272
    Epoch [3/50], Val Losses: mse: 10.0696, mae: 1.7510, huber: 1.3853, swd: 2.3619, ept: 194.9190
    Epoch [3/50], Test Losses: mse: 10.4249, mae: 1.8412, huber: 1.4612, swd: 2.0497, ept: 178.5245
      Epoch 3 composite train-obj: 1.113236
            No improvement (1.3853), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8810, mae: 1.4515, huber: 1.0812, swd: 1.2695, ept: 241.9821
    Epoch [4/50], Val Losses: mse: 9.9935, mae: 1.7623, huber: 1.3951, swd: 2.7013, ept: 198.8954
    Epoch [4/50], Test Losses: mse: 10.8350, mae: 1.8414, huber: 1.4626, swd: 2.1146, ept: 184.9504
      Epoch 4 composite train-obj: 1.081201
            No improvement (1.3951), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.6176, mae: 1.4098, huber: 1.0421, swd: 1.1352, ept: 246.8014
    Epoch [5/50], Val Losses: mse: 10.3163, mae: 1.7874, huber: 1.4203, swd: 2.7019, ept: 196.5036
    Epoch [5/50], Test Losses: mse: 11.2307, mae: 1.8659, huber: 1.4872, swd: 2.0733, ept: 181.8508
      Epoch 5 composite train-obj: 1.042117
            No improvement (1.4203), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.4067, mae: 1.3771, huber: 1.0114, swd: 1.0686, ept: 251.0249
    Epoch [6/50], Val Losses: mse: 10.1479, mae: 1.7816, huber: 1.4141, swd: 2.7965, ept: 200.6486
    Epoch [6/50], Test Losses: mse: 11.2483, mae: 1.8615, huber: 1.4805, swd: 2.1619, ept: 184.2650
      Epoch 6 composite train-obj: 1.011437
            No improvement (1.4141), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.1404, mae: 1.3364, huber: 0.9731, swd: 0.9581, ept: 255.0197
    Epoch [7/50], Val Losses: mse: 10.1956, mae: 1.8176, huber: 1.4463, swd: 3.1514, ept: 201.9170
    Epoch [7/50], Test Losses: mse: 11.7221, mae: 1.9137, huber: 1.5310, swd: 2.6287, ept: 182.8705
      Epoch 7 composite train-obj: 0.973136
    Epoch [7/50], Test Losses: mse: 10.1866, mae: 1.8263, huber: 1.4471, swd: 2.0195, ept: 179.0636
    Best round's Test MSE: 10.1867, MAE: 1.8263, SWD: 2.0199
    Best round's Validation MSE: 10.0495, MAE: 1.7289, SWD: 2.1379
    Best round's Test verification MSE : 10.1866, MAE: 1.8263, SWD: 2.0195
    Time taken: 81.09 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 10.0468, mae: 1.8245, huber: 1.4353, swd: 3.2734, ept: 186.3584
    Epoch [1/50], Val Losses: mse: 10.1032, mae: 1.7381, huber: 1.3697, swd: 1.9740, ept: 186.8319
    Epoch [1/50], Test Losses: mse: 10.5785, mae: 1.8850, huber: 1.5006, swd: 2.3001, ept: 172.0250
      Epoch 1 composite train-obj: 1.435287
            Val objective improved inf → 1.3697, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3859, mae: 1.5269, huber: 1.1516, swd: 1.3942, ept: 228.1725
    Epoch [2/50], Val Losses: mse: 9.6210, mae: 1.6796, huber: 1.3157, swd: 1.6569, ept: 195.3096
    Epoch [2/50], Test Losses: mse: 10.2969, mae: 1.8232, huber: 1.4444, swd: 1.8211, ept: 180.2570
      Epoch 2 composite train-obj: 1.151625
            Val objective improved 1.3697 → 1.3157, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0420, mae: 1.4742, huber: 1.1027, swd: 1.2588, ept: 239.6799
    Epoch [3/50], Val Losses: mse: 10.0421, mae: 1.7531, huber: 1.3873, swd: 2.4139, ept: 197.9057
    Epoch [3/50], Test Losses: mse: 10.2637, mae: 1.8269, huber: 1.4486, swd: 2.3488, ept: 186.9374
      Epoch 3 composite train-obj: 1.102728
            No improvement (1.3873), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8068, mae: 1.4393, huber: 1.0699, swd: 1.1780, ept: 244.5791
    Epoch [4/50], Val Losses: mse: 10.1122, mae: 1.7554, huber: 1.3900, swd: 2.2568, ept: 201.7053
    Epoch [4/50], Test Losses: mse: 10.6580, mae: 1.8336, huber: 1.4547, swd: 2.0467, ept: 184.1517
      Epoch 4 composite train-obj: 1.069916
            No improvement (1.3900), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.5424, mae: 1.3981, huber: 1.0313, swd: 1.0745, ept: 249.4504
    Epoch [5/50], Val Losses: mse: 9.9932, mae: 1.7550, huber: 1.3878, swd: 2.3666, ept: 202.2553
    Epoch [5/50], Test Losses: mse: 11.1799, mae: 1.8658, huber: 1.4873, swd: 2.4358, ept: 181.4177
      Epoch 5 composite train-obj: 1.031273
            No improvement (1.3878), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.2641, mae: 1.3544, huber: 0.9903, swd: 0.9644, ept: 253.9522
    Epoch [6/50], Val Losses: mse: 10.1406, mae: 1.7398, huber: 1.3744, swd: 2.2975, ept: 207.8656
    Epoch [6/50], Test Losses: mse: 11.3122, mae: 1.8703, huber: 1.4910, swd: 2.4591, ept: 186.8639
      Epoch 6 composite train-obj: 0.990317
            No improvement (1.3744), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.9345, mae: 1.3028, huber: 0.9422, swd: 0.8198, ept: 259.8265
    Epoch [7/50], Val Losses: mse: 10.2543, mae: 1.7658, huber: 1.3987, swd: 2.4357, ept: 203.5336
    Epoch [7/50], Test Losses: mse: 11.5345, mae: 1.8811, huber: 1.5000, swd: 2.4404, ept: 183.7134
      Epoch 7 composite train-obj: 0.942184
    Epoch [7/50], Test Losses: mse: 10.2968, mae: 1.8233, huber: 1.4444, swd: 1.8212, ept: 180.2582
    Best round's Test MSE: 10.2969, MAE: 1.8232, SWD: 1.8211
    Best round's Validation MSE: 9.6210, MAE: 1.6796, SWD: 1.6569
    Best round's Test verification MSE : 10.2968, MAE: 1.8233, SWD: 1.8212
    Time taken: 74.80 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8687, mae: 1.8139, huber: 1.4247, swd: 3.3572, ept: 186.5314
    Epoch [1/50], Val Losses: mse: 9.9890, mae: 1.7198, huber: 1.3521, swd: 1.8470, ept: 191.3145
    Epoch [1/50], Test Losses: mse: 10.7265, mae: 1.8752, huber: 1.4933, swd: 2.1419, ept: 170.1448
      Epoch 1 composite train-obj: 1.424674
            Val objective improved inf → 1.3521, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4123, mae: 1.5295, huber: 1.1539, swd: 1.5429, ept: 224.7981
    Epoch [2/50], Val Losses: mse: 9.8095, mae: 1.7047, huber: 1.3392, swd: 2.1780, ept: 200.1391
    Epoch [2/50], Test Losses: mse: 10.1847, mae: 1.8245, huber: 1.4449, swd: 2.1919, ept: 181.7897
      Epoch 2 composite train-obj: 1.153911
            Val objective improved 1.3521 → 1.3392, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0757, mae: 1.4797, huber: 1.1077, swd: 1.4056, ept: 236.6554
    Epoch [3/50], Val Losses: mse: 9.7359, mae: 1.7098, huber: 1.3449, swd: 2.1341, ept: 197.0159
    Epoch [3/50], Test Losses: mse: 10.5335, mae: 1.8501, huber: 1.4705, swd: 2.1363, ept: 180.1414
      Epoch 3 composite train-obj: 1.107677
            No improvement (1.3449), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.8548, mae: 1.4453, huber: 1.0754, swd: 1.3125, ept: 242.3964
    Epoch [4/50], Val Losses: mse: 9.6280, mae: 1.7313, huber: 1.3647, swd: 2.6135, ept: 197.0683
    Epoch [4/50], Test Losses: mse: 10.6562, mae: 1.8501, huber: 1.4700, swd: 2.3834, ept: 185.2317
      Epoch 4 composite train-obj: 1.075445
            No improvement (1.3647), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.5927, mae: 1.4049, huber: 1.0376, swd: 1.1799, ept: 247.7386
    Epoch [5/50], Val Losses: mse: 10.3947, mae: 1.8043, huber: 1.4369, swd: 2.9457, ept: 200.0048
    Epoch [5/50], Test Losses: mse: 10.3898, mae: 1.8407, huber: 1.4596, swd: 2.3503, ept: 186.1551
      Epoch 5 composite train-obj: 1.037611
            No improvement (1.4369), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.3480, mae: 1.3679, huber: 1.0029, swd: 1.0772, ept: 252.5715
    Epoch [6/50], Val Losses: mse: 10.1899, mae: 1.7952, huber: 1.4248, swd: 2.8550, ept: 199.3400
    Epoch [6/50], Test Losses: mse: 11.5360, mae: 1.9016, huber: 1.5207, swd: 2.6812, ept: 182.8363
      Epoch 6 composite train-obj: 1.002918
            No improvement (1.4248), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.0651, mae: 1.3244, huber: 0.9621, swd: 0.9477, ept: 258.2116
    Epoch [7/50], Val Losses: mse: 9.9249, mae: 1.7555, huber: 1.3864, swd: 2.5553, ept: 202.4555
    Epoch [7/50], Test Losses: mse: 11.9318, mae: 1.9107, huber: 1.5301, swd: 2.5535, ept: 179.9969
      Epoch 7 composite train-obj: 0.962073
    Epoch [7/50], Test Losses: mse: 10.1846, mae: 1.8246, huber: 1.4449, swd: 2.1919, ept: 181.7896
    Best round's Test MSE: 10.1847, MAE: 1.8245, SWD: 2.1919
    Best round's Validation MSE: 9.8095, MAE: 1.7047, SWD: 2.1780
    Best round's Test verification MSE : 10.1846, MAE: 1.8246, SWD: 2.1919
    Time taken: 76.34 seconds
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred720_20250512_1508)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2227 ± 0.0524
      mae: 1.8247 ± 0.0012
      huber: 1.4455 ± 0.0012
      swd: 2.0110 ± 0.1515
      ept: 180.3919 ± 1.0904
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.8267 ± 0.1754
      mae: 1.7044 ± 0.0201
      huber: 1.3396 ± 0.0197
      swd: 1.9909 ± 0.2368
      ept: 197.4911 ± 1.9990
      count: 44.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 232.34 seconds
    
    Experiment complete: ACL_ettm1_seq720_pred720_20250512_1508
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

##### AB: no rotate back + outside shift


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8119, mae: 1.8138, huber: 1.4246, swd: 3.3479, target_std: 6.4637
    Epoch [1/50], Val Losses: mse: 9.9521, mae: 1.7229, huber: 1.3527, swd: 1.9331, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 11.1126, mae: 1.9177, huber: 1.5337, swd: 2.3341, target_std: 4.7627
      Epoch 1 composite train-obj: 1.424596
            Val objective improved inf → 1.3527, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3982, mae: 1.5244, huber: 1.1496, swd: 1.4377, target_std: 6.4636
    Epoch [2/50], Val Losses: mse: 9.4453, mae: 1.6832, huber: 1.3193, swd: 2.0217, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.6698, mae: 1.8613, huber: 1.4810, swd: 2.1891, target_std: 4.7627
      Epoch 2 composite train-obj: 1.149578
            Val objective improved 1.3527 → 1.3193, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0306, mae: 1.4677, huber: 1.0972, swd: 1.3232, target_std: 6.4634
    Epoch [3/50], Val Losses: mse: 9.7523, mae: 1.7207, huber: 1.3556, swd: 2.3432, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.8623, mae: 1.8595, huber: 1.4791, swd: 2.1974, target_std: 4.7627
      Epoch 3 composite train-obj: 1.097246
            No improvement (1.3556), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.7590, mae: 1.4278, huber: 1.0598, swd: 1.2387, target_std: 6.4636
    Epoch [4/50], Val Losses: mse: 9.7454, mae: 1.7237, huber: 1.3587, swd: 2.3710, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 11.2097, mae: 1.8681, huber: 1.4873, swd: 2.0967, target_std: 4.7627
      Epoch 4 composite train-obj: 1.059777
            No improvement (1.3587), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4397, mae: 1.3795, huber: 1.0146, swd: 1.1087, target_std: 6.4637
    Epoch [5/50], Val Losses: mse: 10.0093, mae: 1.7553, huber: 1.3878, swd: 2.4793, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 12.1166, mae: 1.9344, huber: 1.5525, swd: 2.4306, target_std: 4.7627
      Epoch 5 composite train-obj: 1.014586
            No improvement (1.3878), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1585, mae: 1.3377, huber: 0.9751, swd: 1.0126, target_std: 6.4635
    Epoch [6/50], Val Losses: mse: 10.1182, mae: 1.7619, huber: 1.3936, swd: 2.5570, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 11.6865, mae: 1.9205, huber: 1.5383, swd: 2.6108, target_std: 4.7627
      Epoch 6 composite train-obj: 0.975111
            No improvement (1.3936), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8506, mae: 1.2907, huber: 0.9308, swd: 0.8881, target_std: 6.4637
    Epoch [7/50], Val Losses: mse: 10.3832, mae: 1.7829, huber: 1.4152, swd: 2.6555, target_std: 4.3111
    Epoch [7/50], Test Losses: mse: 11.9276, mae: 1.9439, huber: 1.5607, swd: 2.2950, target_std: 4.7627
      Epoch 7 composite train-obj: 0.930833
    Epoch [7/50], Test Losses: mse: 10.6695, mae: 1.8613, huber: 1.4810, swd: 2.1893, target_std: 4.7627
    Best round's Test MSE: 10.6698, MAE: 1.8613, SWD: 2.1891
    Best round's Validation MSE: 9.4453, MAE: 1.6832
    Best round's Test verification MSE : 10.6695, MAE: 1.8613, SWD: 2.1893
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8220, mae: 1.8199, huber: 1.4300, swd: 3.2502, target_std: 6.4636
    Epoch [1/50], Val Losses: mse: 9.9233, mae: 1.7186, huber: 1.3509, swd: 1.8999, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.6804, mae: 1.8907, huber: 1.5077, swd: 2.3892, target_std: 4.7627
      Epoch 1 composite train-obj: 1.429962
            Val objective improved inf → 1.3509, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3360, mae: 1.5159, huber: 1.1417, swd: 1.3427, target_std: 6.4635
    Epoch [2/50], Val Losses: mse: 9.3298, mae: 1.6663, huber: 1.3025, swd: 1.9587, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.5148, mae: 1.8386, huber: 1.4600, swd: 2.1911, target_std: 4.7627
      Epoch 2 composite train-obj: 1.141745
            Val objective improved 1.3509 → 1.3025, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0139, mae: 1.4687, huber: 1.0978, swd: 1.2570, target_std: 6.4637
    Epoch [3/50], Val Losses: mse: 9.6259, mae: 1.7080, huber: 1.3414, swd: 2.0214, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.9318, mae: 1.8678, huber: 1.4880, swd: 2.1448, target_std: 4.7627
      Epoch 3 composite train-obj: 1.097781
            No improvement (1.3414), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.7240, mae: 1.4240, huber: 1.0559, swd: 1.1478, target_std: 6.4636
    Epoch [4/50], Val Losses: mse: 9.8401, mae: 1.7299, huber: 1.3656, swd: 2.3284, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 10.6068, mae: 1.8395, huber: 1.4598, swd: 2.1784, target_std: 4.7627
      Epoch 4 composite train-obj: 1.055913
            No improvement (1.3656), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4444, mae: 1.3811, huber: 1.0157, swd: 1.0499, target_std: 6.4638
    Epoch [5/50], Val Losses: mse: 9.8051, mae: 1.7290, huber: 1.3624, swd: 2.1450, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 11.2466, mae: 1.8740, huber: 1.4933, swd: 2.1823, target_std: 4.7627
      Epoch 5 composite train-obj: 1.015683
            No improvement (1.3624), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1582, mae: 1.3372, huber: 0.9744, swd: 0.9484, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 9.9510, mae: 1.7629, huber: 1.3938, swd: 2.4401, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 11.6051, mae: 1.9114, huber: 1.5283, swd: 2.4366, target_std: 4.7627
      Epoch 6 composite train-obj: 0.974436
            No improvement (1.3938), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8265, mae: 1.2854, huber: 0.9258, swd: 0.8178, target_std: 6.4636
    Epoch [7/50], Val Losses: mse: 10.2095, mae: 1.8007, huber: 1.4302, swd: 2.6646, target_std: 4.3111
    Epoch [7/50], Test Losses: mse: 12.2611, mae: 1.9572, huber: 1.5737, swd: 2.6401, target_std: 4.7627
      Epoch 7 composite train-obj: 0.925827
    Epoch [7/50], Test Losses: mse: 10.5147, mae: 1.8386, huber: 1.4600, swd: 2.1911, target_std: 4.7627
    Best round's Test MSE: 10.5148, MAE: 1.8386, SWD: 2.1911
    Best round's Validation MSE: 9.3298, MAE: 1.6663
    Best round's Test verification MSE : 10.5147, MAE: 1.8386, SWD: 2.1911
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.8759, mae: 1.8095, huber: 1.4210, swd: 3.4093, target_std: 6.4636
    Epoch [1/50], Val Losses: mse: 9.8495, mae: 1.7188, huber: 1.3520, swd: 2.2689, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.5781, mae: 1.8787, huber: 1.4968, swd: 2.6122, target_std: 4.7627
      Epoch 1 composite train-obj: 1.420969
            Val objective improved inf → 1.3520, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3389, mae: 1.5136, huber: 1.1398, swd: 1.4874, target_std: 6.4637
    Epoch [2/50], Val Losses: mse: 9.5506, mae: 1.7154, huber: 1.3476, swd: 2.4337, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.4953, mae: 1.8620, huber: 1.4792, swd: 2.5401, target_std: 4.7627
      Epoch 2 composite train-obj: 1.139841
            Val objective improved 1.3520 → 1.3476, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.9765, mae: 1.4590, huber: 1.0890, swd: 1.3515, target_std: 6.4638
    Epoch [3/50], Val Losses: mse: 10.2474, mae: 1.8047, huber: 1.4327, swd: 2.8576, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.9267, mae: 1.8651, huber: 1.4829, swd: 2.2625, target_std: 4.7627
      Epoch 3 composite train-obj: 1.088996
            No improvement (1.4327), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.6929, mae: 1.4139, huber: 1.0471, swd: 1.2547, target_std: 6.4638
    Epoch [4/50], Val Losses: mse: 10.2237, mae: 1.7973, huber: 1.4271, swd: 2.9434, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 10.8389, mae: 1.8808, huber: 1.4965, swd: 2.6291, target_std: 4.7627
      Epoch 4 composite train-obj: 1.047069
            No improvement (1.4271), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.4106, mae: 1.3692, huber: 1.0056, swd: 1.1290, target_std: 6.4637
    Epoch [5/50], Val Losses: mse: 10.1579, mae: 1.7970, huber: 1.4283, swd: 2.9499, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 11.4596, mae: 1.8988, huber: 1.5159, swd: 2.5212, target_std: 4.7627
      Epoch 5 composite train-obj: 1.005553
            No improvement (1.4283), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1396, mae: 1.3271, huber: 0.9662, swd: 1.0233, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 10.1158, mae: 1.8080, huber: 1.4372, swd: 3.1100, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 11.6925, mae: 1.9172, huber: 1.5327, swd: 2.6947, target_std: 4.7627
      Epoch 6 composite train-obj: 0.966187
            No improvement (1.4372), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8567, mae: 1.2852, huber: 0.9267, swd: 0.9121, target_std: 6.4636
    Epoch [7/50], Val Losses: mse: 10.1721, mae: 1.8157, huber: 1.4441, swd: 3.2894, target_std: 4.3111
    Epoch [7/50], Test Losses: mse: 12.0678, mae: 1.9436, huber: 1.5592, swd: 2.8219, target_std: 4.7627
      Epoch 7 composite train-obj: 0.926679
    Epoch [7/50], Test Losses: mse: 10.4955, mae: 1.8620, huber: 1.4792, swd: 2.5400, target_std: 4.7627
    Best round's Test MSE: 10.4953, MAE: 1.8620, SWD: 2.5401
    Best round's Validation MSE: 9.5506, MAE: 1.7154
    Best round's Test verification MSE : 10.4955, MAE: 1.8620, SWD: 2.5400
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq720_pred720_20250429_2112)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5600 ± 0.0781
      mae: 1.8540 ± 0.0109
      huber: 1.4734 ± 0.0095
      swd: 2.3068 ± 0.1650
      target_std: 4.7627 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.4419 ± 0.0902
      mae: 1.6883 ± 0.0204
      huber: 1.3231 ± 0.0186
      swd: 2.1381 ± 0.2106
      target_std: 4.3111 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq720_pred720_20250429_2112
    Model: ACL
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

##### normalized scale


```python
importlib.reload(monotonic)
importlib.reload(train_config)

cfg = train_config.FlatACLConfig( 
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],# data_mgr.channels,              # ← number of features in your data
    batch_size=128,
    learning_rate=9e-4, 
    seeds=[1955, 7, 20],  
    epochs=50, 
    dim_hidden=128,
    dim_augment=128,
    ablate_no_koopman=False,
    use_complex_eigenvalues=True,
    second_delay_use_shift=True,
    ablate_rotate_back_Koopman=False, 
    ablate_shift_inside_scale=False,
)
cfg.x_to_z_delay.use_magnitude_for_scale_and_translate = [False, True]
cfg.x_to_z_deri.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_x_main.use_magnitude_for_scale_and_translate = [False, True]
cfg.z_to_y_main.use_magnitude_for_scale_and_translate = [False, True]
exp_ACL_720_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)
```

### TimeMixer

#### 720-96


##### ab:original scale


```python
utils.reload_modules([utils])
cfg_time_mixer_720_96 = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_96 = execute_model_evaluation('ettm1', cfg_time_mixer_720_96, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.1747, mae: 1.1605, huber: 0.8168, swd: 1.2785, target_std: 6.4717
    Epoch [1/50], Val Losses: mse: 5.8720, mae: 1.2395, huber: 0.8977, swd: 0.9527, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 8.0795, mae: 1.4374, huber: 1.0924, swd: 1.3869, target_std: 4.7550
      Epoch 1 composite train-obj: 0.816812
            Val objective improved inf → 0.8977, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 2.6756, mae: 0.9335, huber: 0.6047, swd: 0.7356, target_std: 6.4716
    Epoch [2/50], Val Losses: mse: 6.5754, mae: 1.3309, huber: 0.9816, swd: 1.1940, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 9.2686, mae: 1.5642, huber: 1.2121, swd: 1.9853, target_std: 4.7550
      Epoch 2 composite train-obj: 0.604737
            No improvement (0.9816), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.5883, mae: 0.7511, huber: 0.4371, swd: 0.3789, target_std: 6.4719
    Epoch [3/50], Val Losses: mse: 7.0531, mae: 1.3804, huber: 1.0272, swd: 1.2627, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 9.5070, mae: 1.5874, huber: 1.2326, swd: 1.8865, target_std: 4.7550
      Epoch 3 composite train-obj: 0.437118
            No improvement (1.0272), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.1168, mae: 0.6410, huber: 0.3419, swd: 0.2258, target_std: 6.4720
    Epoch [4/50], Val Losses: mse: 6.9085, mae: 1.3769, huber: 1.0231, swd: 1.2364, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 9.3113, mae: 1.5865, huber: 1.2292, swd: 1.8977, target_std: 4.7550
      Epoch 4 composite train-obj: 0.341854
            No improvement (1.0231), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.9165, mae: 0.5810, huber: 0.2928, swd: 0.1633, target_std: 6.4716
    Epoch [5/50], Val Losses: mse: 6.7305, mae: 1.3677, huber: 1.0127, swd: 1.1935, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 9.2167, mae: 1.5864, huber: 1.2277, swd: 1.9201, target_std: 4.7550
      Epoch 5 composite train-obj: 0.292839
            No improvement (1.0127), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.8030, mae: 0.5417, huber: 0.2621, swd: 0.1318, target_std: 6.4715
    Epoch [6/50], Val Losses: mse: 6.7512, mae: 1.3691, huber: 1.0135, swd: 1.2059, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 9.3014, mae: 1.6006, huber: 1.2403, swd: 2.0203, target_std: 4.7550
      Epoch 6 composite train-obj: 0.262138
    Epoch [6/50], Test Losses: mse: 8.0795, mae: 1.4374, huber: 1.0924, swd: 1.3869, target_std: 4.7550
    Best round's Test MSE: 8.0795, MAE: 1.4374, SWD: 1.3869
    Best round's Validation MSE: 5.8720, MAE: 1.2395
    Best round's Test verification MSE : 8.0795, MAE: 1.4374, SWD: 1.3869
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.3515, mae: 1.1810, huber: 0.8361, swd: 1.2511, target_std: 6.4719
    Epoch [1/50], Val Losses: mse: 5.7612, mae: 1.2352, huber: 0.8932, swd: 1.1328, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.7619, mae: 1.4394, huber: 1.0932, swd: 1.7444, target_std: 4.7550
      Epoch 1 composite train-obj: 0.836057
            Val objective improved inf → 0.8932, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 2.6379, mae: 0.9328, huber: 0.6033, swd: 0.7088, target_std: 6.4718
    Epoch [2/50], Val Losses: mse: 6.3268, mae: 1.3028, huber: 0.9572, swd: 1.1733, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 8.7239, mae: 1.5167, huber: 1.1667, swd: 1.8757, target_std: 4.7550
      Epoch 2 composite train-obj: 0.603305
            No improvement (0.9572), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.6239, mae: 0.7658, huber: 0.4496, swd: 0.3789, target_std: 6.4717
    Epoch [3/50], Val Losses: mse: 6.6396, mae: 1.3469, huber: 0.9973, swd: 1.1316, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 8.7803, mae: 1.5167, huber: 1.1657, swd: 1.6713, target_std: 4.7550
      Epoch 3 composite train-obj: 0.449611
            No improvement (0.9973), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.1747, mae: 0.6636, huber: 0.3598, swd: 0.2439, target_std: 6.4716
    Epoch [4/50], Val Losses: mse: 6.7681, mae: 1.3607, huber: 1.0088, swd: 1.1028, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 8.8559, mae: 1.5264, huber: 1.1740, swd: 1.6662, target_std: 4.7550
      Epoch 4 composite train-obj: 0.359843
            No improvement (1.0088), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.9612, mae: 0.6020, huber: 0.3084, swd: 0.1818, target_std: 6.4719
    Epoch [5/50], Val Losses: mse: 6.5884, mae: 1.3416, huber: 0.9901, swd: 1.1220, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 8.7834, mae: 1.5386, huber: 1.1839, swd: 1.8311, target_std: 4.7550
      Epoch 5 composite train-obj: 0.308390
            No improvement (0.9901), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.8294, mae: 0.5574, huber: 0.2729, swd: 0.1448, target_std: 6.4716
    Epoch [6/50], Val Losses: mse: 6.6088, mae: 1.3448, huber: 0.9921, swd: 1.1283, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 8.7626, mae: 1.5396, huber: 1.1840, swd: 1.8252, target_std: 4.7550
      Epoch 6 composite train-obj: 0.272866
    Epoch [6/50], Test Losses: mse: 7.7619, mae: 1.4394, huber: 1.0932, swd: 1.7444, target_std: 4.7550
    Best round's Test MSE: 7.7619, MAE: 1.4394, SWD: 1.7444
    Best round's Validation MSE: 5.7612, MAE: 1.2352
    Best round's Test verification MSE : 7.7619, MAE: 1.4394, SWD: 1.7444
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 4.3198, mae: 1.1751, huber: 0.8310, swd: 1.2358, target_std: 6.4716
    Epoch [1/50], Val Losses: mse: 5.5018, mae: 1.1946, huber: 0.8571, swd: 0.8958, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.3730, mae: 1.3757, huber: 1.0337, swd: 1.2797, target_std: 4.7550
      Epoch 1 composite train-obj: 0.830953
            Val objective improved inf → 0.8571, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.0207, mae: 0.9798, huber: 0.6482, swd: 0.7956, target_std: 6.4720
    Epoch [2/50], Val Losses: mse: 6.2198, mae: 1.3001, huber: 0.9528, swd: 0.9813, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 8.6170, mae: 1.5230, huber: 1.1729, swd: 1.6612, target_std: 4.7550
      Epoch 2 composite train-obj: 0.648153
            No improvement (0.9528), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.8037, mae: 0.7892, huber: 0.4713, swd: 0.4100, target_std: 6.4716
    Epoch [3/50], Val Losses: mse: 6.5999, mae: 1.3547, huber: 1.0026, swd: 1.0447, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 9.0917, mae: 1.5728, huber: 1.2190, swd: 1.7421, target_std: 4.7550
      Epoch 3 composite train-obj: 0.471303
            No improvement (1.0026), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.2223, mae: 0.6690, huber: 0.3653, swd: 0.2422, target_std: 6.4719
    Epoch [4/50], Val Losses: mse: 6.7513, mae: 1.3677, huber: 1.0146, swd: 1.0629, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 9.1451, mae: 1.5791, huber: 1.2228, swd: 1.6687, target_std: 4.7550
      Epoch 4 composite train-obj: 0.365325
            No improvement (1.0146), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.9654, mae: 0.5972, huber: 0.3056, swd: 0.1682, target_std: 6.4717
    Epoch [5/50], Val Losses: mse: 6.9892, mae: 1.3852, huber: 1.0299, swd: 1.0683, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 8.9832, mae: 1.5725, huber: 1.2146, swd: 1.6049, target_std: 4.7550
      Epoch 5 composite train-obj: 0.305635
            No improvement (1.0299), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.8369, mae: 0.5540, huber: 0.2715, swd: 0.1343, target_std: 6.4718
    Epoch [6/50], Val Losses: mse: 7.0210, mae: 1.3881, huber: 1.0319, swd: 1.0312, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 9.0022, mae: 1.5768, huber: 1.2172, swd: 1.5711, target_std: 4.7550
      Epoch 6 composite train-obj: 0.271478
    Epoch [6/50], Test Losses: mse: 7.3730, mae: 1.3757, huber: 1.0337, swd: 1.2797, target_std: 4.7550
    Best round's Test MSE: 7.3730, MAE: 1.3757, SWD: 1.2797
    Best round's Validation MSE: 5.5018, MAE: 1.1946
    Best round's Test verification MSE : 7.3730, MAE: 1.3757, SWD: 1.2797
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred96_20250430_0119)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.7381 ± 0.2889
      mae: 1.4175 ± 0.0296
      huber: 1.0731 ± 0.0278
      swd: 1.4703 ± 0.1987
      target_std: 4.7550 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.7117 ± 0.1551
      mae: 1.2231 ± 0.0202
      huber: 0.8827 ± 0.0182
      swd: 0.9938 ± 0.1010
      target_std: 4.3137 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred96_20250430_0119
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

##### Ab: normalized data


```python
utils.reload_modules([utils])
cfg_time_mixer_720_96 = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_96 = execute_model_evaluation('ettm1', cfg_time_mixer_720_96, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2272, mae: 0.3257, huber: 0.1037, swd: 0.0790, target_std: 0.7915
    Epoch [1/50], Val Losses: mse: 0.2826, mae: 0.3480, huber: 0.1231, swd: 0.0917, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3468, mae: 0.3866, huber: 0.1486, swd: 0.1238, target_std: 0.8908
      Epoch 1 composite train-obj: 0.103732
            Val objective improved inf → 0.1231, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1488, mae: 0.2689, huber: 0.0703, swd: 0.0475, target_std: 0.7915
    Epoch [2/50], Val Losses: mse: 0.3198, mae: 0.3782, huber: 0.1390, swd: 0.0959, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3950, mae: 0.4170, huber: 0.1674, swd: 0.1318, target_std: 0.8908
      Epoch 2 composite train-obj: 0.070289
            No improvement (0.1390), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.0951, mae: 0.2198, huber: 0.0461, swd: 0.0237, target_std: 0.7916
    Epoch [3/50], Val Losses: mse: 0.3242, mae: 0.3816, huber: 0.1408, swd: 0.0976, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3915, mae: 0.4168, huber: 0.1661, swd: 0.1287, target_std: 0.8908
      Epoch 3 composite train-obj: 0.046121
            No improvement (0.1408), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0692, mae: 0.1884, huber: 0.0340, swd: 0.0137, target_std: 0.7915
    Epoch [4/50], Val Losses: mse: 0.3341, mae: 0.3882, huber: 0.1443, swd: 0.1016, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.4002, mae: 0.4230, huber: 0.1696, swd: 0.1314, target_std: 0.8908
      Epoch 4 composite train-obj: 0.033983
            No improvement (0.1443), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0578, mae: 0.1721, huber: 0.0285, swd: 0.0099, target_std: 0.7915
    Epoch [5/50], Val Losses: mse: 0.3235, mae: 0.3844, huber: 0.1412, swd: 0.0974, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.3937, mae: 0.4197, huber: 0.1673, swd: 0.1302, target_std: 0.8908
      Epoch 5 composite train-obj: 0.028528
            No improvement (0.1412), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0511, mae: 0.1613, huber: 0.0253, swd: 0.0079, target_std: 0.7915
    Epoch [6/50], Val Losses: mse: 0.3214, mae: 0.3835, huber: 0.1405, swd: 0.0966, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.3907, mae: 0.4194, huber: 0.1666, swd: 0.1288, target_std: 0.8908
      Epoch 6 composite train-obj: 0.025254
    Epoch [6/50], Test Losses: mse: 0.3468, mae: 0.3866, huber: 0.1486, swd: 0.1238, target_std: 0.8908
    Best round's Test MSE: 0.3468, MAE: 0.3866, SWD: 0.1238
    Best round's Validation MSE: 0.2826, MAE: 0.3480
    Best round's Test verification MSE : 0.3468, MAE: 0.3866, SWD: 0.1238
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2372, mae: 0.3318, huber: 0.1077, swd: 0.0774, target_std: 0.7916
    Epoch [1/50], Val Losses: mse: 0.2857, mae: 0.3519, huber: 0.1250, swd: 0.0944, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3445, mae: 0.3904, huber: 0.1494, swd: 0.1199, target_std: 0.8908
      Epoch 1 composite train-obj: 0.107701
            Val objective improved inf → 0.1250, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1465, mae: 0.2679, huber: 0.0694, swd: 0.0451, target_std: 0.7915
    Epoch [2/50], Val Losses: mse: 0.3097, mae: 0.3720, huber: 0.1352, swd: 0.0999, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3861, mae: 0.4145, huber: 0.1648, swd: 0.1341, target_std: 0.8908
      Epoch 2 composite train-obj: 0.069432
            No improvement (0.1352), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.0969, mae: 0.2225, huber: 0.0471, swd: 0.0241, target_std: 0.7915
    Epoch [3/50], Val Losses: mse: 0.3147, mae: 0.3768, huber: 0.1375, swd: 0.0978, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3848, mae: 0.4144, huber: 0.1641, swd: 0.1271, target_std: 0.8908
      Epoch 3 composite train-obj: 0.047051
            No improvement (0.1375), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0724, mae: 0.1931, huber: 0.0355, swd: 0.0154, target_std: 0.7916
    Epoch [4/50], Val Losses: mse: 0.3185, mae: 0.3799, huber: 0.1386, swd: 0.0943, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.3910, mae: 0.4168, huber: 0.1660, swd: 0.1263, target_std: 0.8908
      Epoch 4 composite train-obj: 0.035522
            No improvement (0.1386), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0590, mae: 0.1745, huber: 0.0291, swd: 0.0110, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3192, mae: 0.3829, huber: 0.1399, swd: 0.0988, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.3908, mae: 0.4198, huber: 0.1669, swd: 0.1308, target_std: 0.8908
      Epoch 5 composite train-obj: 0.029112
            No improvement (0.1399), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0516, mae: 0.1628, huber: 0.0255, swd: 0.0088, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3180, mae: 0.3816, huber: 0.1392, swd: 0.0970, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.3858, mae: 0.4164, huber: 0.1649, swd: 0.1258, target_std: 0.8908
      Epoch 6 composite train-obj: 0.025515
    Epoch [6/50], Test Losses: mse: 0.3445, mae: 0.3904, huber: 0.1494, swd: 0.1199, target_std: 0.8908
    Best round's Test MSE: 0.3445, MAE: 0.3904, SWD: 0.1199
    Best round's Validation MSE: 0.2857, MAE: 0.3519
    Best round's Test verification MSE : 0.3445, MAE: 0.3904, SWD: 0.1199
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2357, mae: 0.3302, huber: 0.1071, swd: 0.0792, target_std: 0.7916
    Epoch [1/50], Val Losses: mse: 0.2693, mae: 0.3405, huber: 0.1186, swd: 0.0826, target_std: 0.9535
    Epoch [1/50], Test Losses: mse: 0.3182, mae: 0.3711, huber: 0.1386, swd: 0.1046, target_std: 0.8908
      Epoch 1 composite train-obj: 0.107063
            Val objective improved inf → 0.1186, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1598, mae: 0.2767, huber: 0.0749, swd: 0.0491, target_std: 0.7916
    Epoch [2/50], Val Losses: mse: 0.3062, mae: 0.3693, huber: 0.1342, swd: 0.0860, target_std: 0.9535
    Epoch [2/50], Test Losses: mse: 0.3784, mae: 0.4062, huber: 0.1602, swd: 0.1142, target_std: 0.8908
      Epoch 2 composite train-obj: 0.074907
            No improvement (0.1342), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.0988, mae: 0.2239, huber: 0.0479, swd: 0.0238, target_std: 0.7916
    Epoch [3/50], Val Losses: mse: 0.3161, mae: 0.3788, huber: 0.1382, swd: 0.0885, target_std: 0.9535
    Epoch [3/50], Test Losses: mse: 0.3951, mae: 0.4181, huber: 0.1671, swd: 0.1192, target_std: 0.8908
      Epoch 3 composite train-obj: 0.047851
            No improvement (0.1382), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0697, mae: 0.1895, huber: 0.0342, swd: 0.0133, target_std: 0.7915
    Epoch [4/50], Val Losses: mse: 0.3158, mae: 0.3787, huber: 0.1381, swd: 0.0891, target_std: 0.9535
    Epoch [4/50], Test Losses: mse: 0.3958, mae: 0.4202, huber: 0.1676, swd: 0.1182, target_std: 0.8908
      Epoch 4 composite train-obj: 0.034233
            No improvement (0.1381), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0567, mae: 0.1706, huber: 0.0280, swd: 0.0093, target_std: 0.7916
    Epoch [5/50], Val Losses: mse: 0.3227, mae: 0.3838, huber: 0.1410, swd: 0.0902, target_std: 0.9535
    Epoch [5/50], Test Losses: mse: 0.3980, mae: 0.4235, huber: 0.1689, swd: 0.1176, target_std: 0.8908
      Epoch 5 composite train-obj: 0.028002
            No improvement (0.1410), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0497, mae: 0.1589, huber: 0.0246, swd: 0.0073, target_std: 0.7916
    Epoch [6/50], Val Losses: mse: 0.3200, mae: 0.3831, huber: 0.1402, swd: 0.0890, target_std: 0.9535
    Epoch [6/50], Test Losses: mse: 0.3997, mae: 0.4257, huber: 0.1700, swd: 0.1190, target_std: 0.8908
      Epoch 6 composite train-obj: 0.024579
    Epoch [6/50], Test Losses: mse: 0.3182, mae: 0.3711, huber: 0.1386, swd: 0.1046, target_std: 0.8908
    Best round's Test MSE: 0.3182, MAE: 0.3711, SWD: 0.1046
    Best round's Validation MSE: 0.2693, MAE: 0.3405
    Best round's Test verification MSE : 0.3182, MAE: 0.3711, SWD: 0.1046
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred96_20250430_0057)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.3365 ± 0.0130
      mae: 0.3827 ± 0.0083
      huber: 0.1455 ± 0.0049
      swd: 0.1161 ± 0.0083
      target_std: 0.8908 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.2792 ± 0.0071
      mae: 0.3468 ± 0.0047
      huber: 0.1222 ± 0.0027
      swd: 0.0896 ± 0.0051
      target_std: 0.9535 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred96_20250430_0057
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    


```python

```

#### 720-196


##### Ab: original scale


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.3558, mae: 1.3227, huber: 0.9677, swd: 1.4538, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 6.5603, mae: 1.3386, huber: 0.9895, swd: 0.9971, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.1863, mae: 1.5883, huber: 1.2338, swd: 1.5770, target_std: 4.7514
      Epoch 1 composite train-obj: 0.967749
            Val objective improved inf → 0.9895, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.6031, mae: 1.0911, huber: 0.7479, swd: 0.8604, target_std: 6.4712
    Epoch [2/50], Val Losses: mse: 7.2207, mae: 1.4194, huber: 1.0644, swd: 1.1881, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 10.3988, mae: 1.7078, huber: 1.3479, swd: 2.1218, target_std: 4.7514
      Epoch 2 composite train-obj: 0.747942
            No improvement (1.0644), counter 1/5
    Epoch [3/50], Train Losses: mse: 2.3066, mae: 0.9029, huber: 0.5702, swd: 0.4613, target_std: 6.4712
    Epoch [3/50], Val Losses: mse: 7.6280, mae: 1.4777, huber: 1.1185, swd: 1.1213, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 10.7486, mae: 1.7308, huber: 1.3677, swd: 1.7786, target_std: 4.7514
      Epoch 3 composite train-obj: 0.570220
            No improvement (1.1185), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.5931, mae: 0.7712, huber: 0.4501, swd: 0.2849, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 7.8148, mae: 1.4931, huber: 1.1315, swd: 1.1869, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 10.9943, mae: 1.7668, huber: 1.4000, swd: 1.9327, target_std: 4.7514
      Epoch 4 composite train-obj: 0.450079
            No improvement (1.1315), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.2271, mae: 0.6859, huber: 0.3756, swd: 0.2005, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 7.8667, mae: 1.4980, huber: 1.1347, swd: 1.1271, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 10.8386, mae: 1.7603, huber: 1.3919, swd: 1.9022, target_std: 4.7514
      Epoch 5 composite train-obj: 0.375586
            No improvement (1.1347), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.0239, mae: 0.6268, huber: 0.3263, swd: 0.1520, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 7.9802, mae: 1.5068, huber: 1.1426, swd: 1.0916, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.8772, mae: 1.7640, huber: 1.3950, swd: 1.8082, target_std: 4.7514
      Epoch 6 composite train-obj: 0.326304
    Epoch [6/50], Test Losses: mse: 9.1863, mae: 1.5883, huber: 1.2338, swd: 1.5770, target_std: 4.7514
    Best round's Test MSE: 9.1863, MAE: 1.5883, SWD: 1.5770
    Best round's Validation MSE: 6.5603, MAE: 1.3386
    Best round's Test verification MSE : 9.1863, MAE: 1.5883, SWD: 1.5770
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.2900, mae: 1.3097, huber: 0.9552, swd: 1.3766, target_std: 6.4713
    Epoch [1/50], Val Losses: mse: 6.8014, mae: 1.3749, huber: 1.0236, swd: 0.9957, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 10.2190, mae: 1.6770, huber: 1.3201, swd: 1.7706, target_std: 4.7514
      Epoch 1 composite train-obj: 0.955194
            Val objective improved inf → 1.0236, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.0276, mae: 1.0135, huber: 0.6740, swd: 0.6771, target_std: 6.4712
    Epoch [2/50], Val Losses: mse: 7.6183, mae: 1.4763, huber: 1.1190, swd: 1.3066, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 11.3611, mae: 1.7850, huber: 1.4229, swd: 2.2822, target_std: 4.7514
      Epoch 2 composite train-obj: 0.673963
            No improvement (1.1190), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.9077, mae: 0.8375, huber: 0.5096, swd: 0.3694, target_std: 6.4713
    Epoch [3/50], Val Losses: mse: 7.6396, mae: 1.4805, huber: 1.1207, swd: 1.2523, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 11.2665, mae: 1.7709, huber: 1.4071, swd: 2.0987, target_std: 4.7514
      Epoch 3 composite train-obj: 0.509599
            No improvement (1.1207), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.3721, mae: 0.7267, huber: 0.4102, swd: 0.2419, target_std: 6.4713
    Epoch [4/50], Val Losses: mse: 7.7529, mae: 1.4944, huber: 1.1325, swd: 1.1310, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 11.1439, mae: 1.7645, huber: 1.3990, swd: 1.8911, target_std: 4.7514
      Epoch 4 composite train-obj: 0.410231
            No improvement (1.1325), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.1010, mae: 0.6532, huber: 0.3477, swd: 0.1763, target_std: 6.4713
    Epoch [5/50], Val Losses: mse: 7.7286, mae: 1.5026, huber: 1.1383, swd: 1.0933, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 10.9899, mae: 1.7570, huber: 1.3891, swd: 1.8065, target_std: 4.7514
      Epoch 5 composite train-obj: 0.347700
            No improvement (1.1383), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.9460, mae: 0.6031, huber: 0.3070, swd: 0.1403, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 7.7766, mae: 1.4972, huber: 1.1333, swd: 1.0765, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.8883, mae: 1.7527, huber: 1.3841, swd: 1.8604, target_std: 4.7514
      Epoch 6 composite train-obj: 0.306988
    Epoch [6/50], Test Losses: mse: 10.2190, mae: 1.6770, huber: 1.3201, swd: 1.7706, target_std: 4.7514
    Best round's Test MSE: 10.2190, MAE: 1.6770, SWD: 1.7706
    Best round's Validation MSE: 6.8014, MAE: 1.3749
    Best round's Test verification MSE : 10.2190, MAE: 1.6770, SWD: 1.7706
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.0603, mae: 1.2827, huber: 0.9308, swd: 1.3296, target_std: 6.4714
    Epoch [1/50], Val Losses: mse: 6.7542, mae: 1.3721, huber: 1.0223, swd: 1.1435, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.5709, mae: 1.6366, huber: 1.2794, swd: 1.9399, target_std: 4.7514
      Epoch 1 composite train-obj: 0.930769
            Val objective improved inf → 1.0223, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.1985, mae: 1.0283, huber: 0.6888, swd: 0.6866, target_std: 6.4713
    Epoch [2/50], Val Losses: mse: 7.6694, mae: 1.4675, huber: 1.1112, swd: 1.1205, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 10.8222, mae: 1.7334, huber: 1.3723, swd: 1.9164, target_std: 4.7514
      Epoch 2 composite train-obj: 0.688807
            No improvement (1.1112), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.6150, mae: 0.7755, huber: 0.4535, swd: 0.2732, target_std: 6.4712
    Epoch [3/50], Val Losses: mse: 7.9810, mae: 1.4970, huber: 1.1360, swd: 1.1199, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 10.8887, mae: 1.7435, huber: 1.3782, swd: 1.8894, target_std: 4.7514
      Epoch 3 composite train-obj: 0.453539
            No improvement (1.1360), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.0757, mae: 0.6457, huber: 0.3410, swd: 0.1534, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 7.9460, mae: 1.5004, huber: 1.1374, swd: 1.0777, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 10.7922, mae: 1.7410, huber: 1.3742, swd: 1.7924, target_std: 4.7514
      Epoch 4 composite train-obj: 0.340951
            No improvement (1.1374), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.8804, mae: 0.5801, huber: 0.2884, swd: 0.1131, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 8.0447, mae: 1.5115, huber: 1.1461, swd: 1.0378, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 10.8130, mae: 1.7525, huber: 1.3828, swd: 1.7572, target_std: 4.7514
      Epoch 5 composite train-obj: 0.288387
            No improvement (1.1461), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.7812, mae: 0.5424, huber: 0.2597, swd: 0.0950, target_std: 6.4714
    Epoch [6/50], Val Losses: mse: 7.7647, mae: 1.4894, huber: 1.1247, swd: 1.0628, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 10.6062, mae: 1.7457, huber: 1.3754, swd: 1.8815, target_std: 4.7514
      Epoch 6 composite train-obj: 0.259657
    Epoch [6/50], Test Losses: mse: 9.5709, mae: 1.6366, huber: 1.2794, swd: 1.9399, target_std: 4.7514
    Best round's Test MSE: 9.5709, MAE: 1.6366, SWD: 1.9399
    Best round's Validation MSE: 6.7542, MAE: 1.3721
    Best round's Test verification MSE : 9.5709, MAE: 1.6366, SWD: 1.9399
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred196_20250429_1948)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.6587 ± 0.4262
      mae: 1.6340 ± 0.0362
      huber: 1.2778 ± 0.0353
      swd: 1.7625 ± 0.1483
      target_std: 4.7514 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.7053 ± 0.1044
      mae: 1.3619 ± 0.0165
      huber: 1.0118 ± 0.0158
      swd: 1.0454 ± 0.0693
      target_std: 4.3103 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred196_20250429_1948
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

##### Ab: normalized scale


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2992, mae: 0.3725, huber: 0.1323, swd: 0.0905, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3075, mae: 0.3679, huber: 0.1343, swd: 0.0921, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.3806, mae: 0.4152, huber: 0.1642, swd: 0.1202, target_std: 0.8895
      Epoch 1 composite train-obj: 0.132350
            Val objective improved inf → 0.1343, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2090, mae: 0.3179, huber: 0.0966, swd: 0.0609, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3475, mae: 0.3986, huber: 0.1509, swd: 0.0967, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.4292, mae: 0.4450, huber: 0.1827, swd: 0.1242, target_std: 0.8895
      Epoch 2 composite train-obj: 0.096558
            No improvement (0.1509), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1401, mae: 0.2678, huber: 0.0673, swd: 0.0333, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3671, mae: 0.4111, huber: 0.1579, swd: 0.0978, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4552, mae: 0.4576, huber: 0.1910, swd: 0.1223, target_std: 0.8895
      Epoch 3 composite train-obj: 0.067259
            No improvement (0.1579), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0992, mae: 0.2282, huber: 0.0485, swd: 0.0191, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3739, mae: 0.4184, huber: 0.1615, swd: 0.0988, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4674, mae: 0.4675, huber: 0.1965, swd: 0.1259, target_std: 0.8895
      Epoch 4 composite train-obj: 0.048526
            No improvement (0.1615), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0780, mae: 0.2026, huber: 0.0384, swd: 0.0127, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3700, mae: 0.4160, huber: 0.1596, swd: 0.0979, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4693, mae: 0.4690, huber: 0.1971, swd: 0.1260, target_std: 0.8895
      Epoch 5 composite train-obj: 0.038417
            No improvement (0.1596), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0666, mae: 0.1866, huber: 0.0329, swd: 0.0097, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3715, mae: 0.4176, huber: 0.1606, swd: 0.0936, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4615, mae: 0.4639, huber: 0.1941, swd: 0.1189, target_std: 0.8895
      Epoch 6 composite train-obj: 0.032894
    Epoch [6/50], Test Losses: mse: 0.3806, mae: 0.4152, huber: 0.1642, swd: 0.1202, target_std: 0.8895
    Best round's Test MSE: 0.3806, MAE: 0.4152, SWD: 0.1202
    Best round's Validation MSE: 0.3075, MAE: 0.3679
    Best round's Test verification MSE : 0.3806, MAE: 0.4152, SWD: 0.1202
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2948, mae: 0.3701, huber: 0.1305, swd: 0.0867, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3191, mae: 0.3805, huber: 0.1397, swd: 0.0950, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.4084, mae: 0.4334, huber: 0.1750, swd: 0.1287, target_std: 0.8895
      Epoch 1 composite train-obj: 0.130500
            Val objective improved inf → 0.1397, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1803, mae: 0.2996, huber: 0.0849, swd: 0.0497, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3639, mae: 0.4093, huber: 0.1566, swd: 0.1055, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.4510, mae: 0.4565, huber: 0.1902, swd: 0.1278, target_std: 0.8895
      Epoch 2 composite train-obj: 0.084854
            No improvement (0.1566), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1164, mae: 0.2462, huber: 0.0565, swd: 0.0249, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3774, mae: 0.4179, huber: 0.1610, swd: 0.1056, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4717, mae: 0.4684, huber: 0.1976, swd: 0.1299, target_std: 0.8895
      Epoch 3 composite train-obj: 0.056542
            No improvement (0.1610), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0847, mae: 0.2114, huber: 0.0417, swd: 0.0150, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3840, mae: 0.4218, huber: 0.1634, swd: 0.1029, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4728, mae: 0.4689, huber: 0.1979, swd: 0.1239, target_std: 0.8895
      Epoch 4 composite train-obj: 0.041668
            No improvement (0.1634), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0689, mae: 0.1902, huber: 0.0340, swd: 0.0106, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3769, mae: 0.4193, huber: 0.1615, swd: 0.0982, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4670, mae: 0.4670, huber: 0.1962, swd: 0.1213, target_std: 0.8895
      Epoch 5 composite train-obj: 0.033984
            No improvement (0.1615), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0601, mae: 0.1771, huber: 0.0297, swd: 0.0084, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3744, mae: 0.4172, huber: 0.1605, swd: 0.0975, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4631, mae: 0.4652, huber: 0.1949, swd: 0.1228, target_std: 0.8895
      Epoch 6 composite train-obj: 0.029727
    Epoch [6/50], Test Losses: mse: 0.4084, mae: 0.4334, huber: 0.1750, swd: 0.1287, target_std: 0.8895
    Best round's Test MSE: 0.4084, MAE: 0.4334, SWD: 0.1287
    Best round's Validation MSE: 0.3191, MAE: 0.3805
    Best round's Test verification MSE : 0.4084, MAE: 0.4334, SWD: 0.1287
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.2811, mae: 0.3601, huber: 0.1251, swd: 0.0832, target_std: 0.7917
    Epoch [1/50], Val Losses: mse: 0.3172, mae: 0.3750, huber: 0.1385, swd: 0.0900, target_std: 0.9533
    Epoch [1/50], Test Losses: mse: 0.3889, mae: 0.4196, huber: 0.1676, swd: 0.1199, target_std: 0.8895
      Epoch 1 composite train-obj: 0.125069
            Val objective improved inf → 0.1385, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.1837, mae: 0.2992, huber: 0.0856, swd: 0.0477, target_std: 0.7917
    Epoch [2/50], Val Losses: mse: 0.3570, mae: 0.4059, huber: 0.1544, swd: 0.0889, target_std: 0.9533
    Epoch [2/50], Test Losses: mse: 0.4558, mae: 0.4601, huber: 0.1924, swd: 0.1186, target_std: 0.8895
      Epoch 2 composite train-obj: 0.085637
            No improvement (0.1544), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1005, mae: 0.2285, huber: 0.0490, swd: 0.0182, target_std: 0.7917
    Epoch [3/50], Val Losses: mse: 0.3697, mae: 0.4121, huber: 0.1580, swd: 0.0917, target_std: 0.9533
    Epoch [3/50], Test Losses: mse: 0.4647, mae: 0.4656, huber: 0.1956, swd: 0.1173, target_std: 0.8895
      Epoch 3 composite train-obj: 0.048963
            No improvement (0.1580), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0696, mae: 0.1905, huber: 0.0343, swd: 0.0098, target_std: 0.7917
    Epoch [4/50], Val Losses: mse: 0.3690, mae: 0.4116, huber: 0.1577, swd: 0.0935, target_std: 0.9533
    Epoch [4/50], Test Losses: mse: 0.4626, mae: 0.4647, huber: 0.1949, swd: 0.1191, target_std: 0.8895
      Epoch 4 composite train-obj: 0.034341
            No improvement (0.1577), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0578, mae: 0.1726, huber: 0.0286, swd: 0.0072, target_std: 0.7917
    Epoch [5/50], Val Losses: mse: 0.3668, mae: 0.4109, huber: 0.1571, swd: 0.0907, target_std: 0.9533
    Epoch [5/50], Test Losses: mse: 0.4609, mae: 0.4646, huber: 0.1945, swd: 0.1181, target_std: 0.8895
      Epoch 5 composite train-obj: 0.028568
            No improvement (0.1571), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0510, mae: 0.1612, huber: 0.0252, swd: 0.0057, target_std: 0.7917
    Epoch [6/50], Val Losses: mse: 0.3649, mae: 0.4100, huber: 0.1566, swd: 0.0902, target_std: 0.9533
    Epoch [6/50], Test Losses: mse: 0.4598, mae: 0.4645, huber: 0.1943, swd: 0.1194, target_std: 0.8895
      Epoch 6 composite train-obj: 0.025243
    Epoch [6/50], Test Losses: mse: 0.3889, mae: 0.4196, huber: 0.1676, swd: 0.1199, target_std: 0.8895
    Best round's Test MSE: 0.3889, MAE: 0.4196, SWD: 0.1199
    Best round's Validation MSE: 0.3172, MAE: 0.3750
    Best round's Test verification MSE : 0.3889, MAE: 0.4196, SWD: 0.1199
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred196_20250429_2308)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.3926 ± 0.0116
      mae: 0.4227 ± 0.0077
      huber: 0.1690 ± 0.0045
      swd: 0.1229 ± 0.0041
      target_std: 0.8895 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3146 ± 0.0051
      mae: 0.3745 ± 0.0051
      huber: 0.1375 ± 0.0023
      swd: 0.0924 ± 0.0021
      target_std: 0.9533 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred196_20250429_2308
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 720-336


##### Ab: original scale


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.9161, mae: 1.4118, huber: 1.0502, swd: 1.4663, target_std: 6.4708
    Epoch [1/50], Val Losses: mse: 8.0580, mae: 1.4638, huber: 1.1111, swd: 0.9224, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.4769, mae: 1.7144, huber: 1.3522, swd: 1.5279, target_std: 4.7516
      Epoch 1 composite train-obj: 1.050165
            Val objective improved inf → 1.1111, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.0442, mae: 1.1642, huber: 0.8142, swd: 0.8093, target_std: 6.4708
    Epoch [2/50], Val Losses: mse: 8.0922, mae: 1.5355, huber: 1.1761, swd: 1.3158, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 11.2348, mae: 1.8292, huber: 1.4602, swd: 2.1852, target_std: 4.7516
      Epoch 2 composite train-obj: 0.814200
            No improvement (1.1761), counter 1/5
    Epoch [3/50], Train Losses: mse: 2.5733, mae: 0.9580, huber: 0.6180, swd: 0.4336, target_std: 6.4707
    Epoch [3/50], Val Losses: mse: 8.2595, mae: 1.5828, huber: 1.2175, swd: 1.3154, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 11.8910, mae: 1.8871, huber: 1.5133, swd: 2.1772, target_std: 4.7516
      Epoch 3 composite train-obj: 0.617960
            No improvement (1.2175), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.8011, mae: 0.8248, huber: 0.4950, swd: 0.2737, target_std: 6.4709
    Epoch [4/50], Val Losses: mse: 8.4377, mae: 1.5980, huber: 1.2310, swd: 1.1940, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 11.8210, mae: 1.8845, huber: 1.5098, swd: 2.0283, target_std: 4.7516
      Epoch 4 composite train-obj: 0.494952
            No improvement (1.2310), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.4058, mae: 0.7385, huber: 0.4184, swd: 0.1975, target_std: 6.4707
    Epoch [5/50], Val Losses: mse: 8.6314, mae: 1.6142, huber: 1.2446, swd: 1.1868, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 11.8953, mae: 1.8916, huber: 1.5151, swd: 1.9791, target_std: 4.7516
      Epoch 5 composite train-obj: 0.418400
            No improvement (1.2446), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.1804, mae: 0.6798, huber: 0.3681, swd: 0.1563, target_std: 6.4709
    Epoch [6/50], Val Losses: mse: 8.7284, mae: 1.6305, huber: 1.2596, swd: 1.1941, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.8332, mae: 1.8897, huber: 1.5119, swd: 1.9866, target_std: 4.7516
      Epoch 6 composite train-obj: 0.368091
    Epoch [6/50], Test Losses: mse: 10.4769, mae: 1.7144, huber: 1.3522, swd: 1.5279, target_std: 4.7516
    Best round's Test MSE: 10.4769, MAE: 1.7144, SWD: 1.5279
    Best round's Validation MSE: 8.0580, MAE: 1.4638
    Best round's Test verification MSE : 10.4769, MAE: 1.7144, SWD: 1.5279
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.1418, mae: 1.4335, huber: 1.0704, swd: 1.4379, target_std: 6.4709
    Epoch [1/50], Val Losses: mse: 7.8494, mae: 1.4702, huber: 1.1153, swd: 1.1023, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.8413, mae: 1.7698, huber: 1.4047, swd: 1.8943, target_std: 4.7516
      Epoch 1 composite train-obj: 1.070446
            Val objective improved inf → 1.1153, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.5090, mae: 1.0987, huber: 0.7511, swd: 0.6801, target_std: 6.4709
    Epoch [2/50], Val Losses: mse: 8.4326, mae: 1.5570, huber: 1.1951, swd: 1.0999, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 11.8611, mae: 1.8654, huber: 1.4945, swd: 1.9027, target_std: 4.7516
      Epoch 2 composite train-obj: 0.751139
            No improvement (1.1951), counter 1/5
    Epoch [3/50], Train Losses: mse: 2.0870, mae: 0.8803, huber: 0.5459, swd: 0.3379, target_std: 6.4707
    Epoch [3/50], Val Losses: mse: 8.7214, mae: 1.6002, huber: 1.2341, swd: 1.2083, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 11.9540, mae: 1.8888, huber: 1.5139, swd: 1.9903, target_std: 4.7516
      Epoch 3 composite train-obj: 0.545858
            No improvement (1.2341), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.4748, mae: 0.7569, huber: 0.4345, swd: 0.2170, target_std: 6.4710
    Epoch [4/50], Val Losses: mse: 8.7334, mae: 1.6089, huber: 1.2412, swd: 1.1339, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 11.9100, mae: 1.8897, huber: 1.5138, swd: 1.8908, target_std: 4.7516
      Epoch 4 composite train-obj: 0.434537
            No improvement (1.2412), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.1919, mae: 0.6843, huber: 0.3719, swd: 0.1615, target_std: 6.4710
    Epoch [5/50], Val Losses: mse: 8.6601, mae: 1.6004, huber: 1.2313, swd: 1.0753, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 11.8504, mae: 1.8850, huber: 1.5079, swd: 1.8392, target_std: 4.7516
      Epoch 5 composite train-obj: 0.371896
            No improvement (1.2313), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.0426, mae: 0.6391, huber: 0.3343, swd: 0.1349, target_std: 6.4708
    Epoch [6/50], Val Losses: mse: 8.6891, mae: 1.6097, huber: 1.2387, swd: 1.0893, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.7833, mae: 1.8878, huber: 1.5092, swd: 1.9223, target_std: 4.7516
      Epoch 6 composite train-obj: 0.334262
    Epoch [6/50], Test Losses: mse: 10.8413, mae: 1.7698, huber: 1.4047, swd: 1.8943, target_std: 4.7516
    Best round's Test MSE: 10.8413, MAE: 1.7698, SWD: 1.8943
    Best round's Validation MSE: 7.8494, MAE: 1.4702
    Best round's Test verification MSE : 10.8413, MAE: 1.7698, SWD: 1.8943
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.8392, mae: 1.4007, huber: 1.0398, swd: 1.4701, target_std: 6.4707
    Epoch [1/50], Val Losses: mse: 8.2461, mae: 1.5041, huber: 1.1478, swd: 1.3109, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.5792, mae: 1.7363, huber: 1.3703, swd: 1.9485, target_std: 4.7516
      Epoch 1 composite train-obj: 1.039779
            Val objective improved inf → 1.1478, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 3.7172, mae: 1.1150, huber: 0.7673, swd: 0.7224, target_std: 6.4708
    Epoch [2/50], Val Losses: mse: 8.5557, mae: 1.5938, huber: 1.2285, swd: 1.3565, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 11.6458, mae: 1.8605, huber: 1.4891, swd: 2.1565, target_std: 4.7516
      Epoch 2 composite train-obj: 0.767257
            No improvement (1.2285), counter 1/5
    Epoch [3/50], Train Losses: mse: 1.8769, mae: 0.8311, huber: 0.5017, swd: 0.2723, target_std: 6.4708
    Epoch [3/50], Val Losses: mse: 8.5151, mae: 1.5947, huber: 1.2275, swd: 1.2710, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 11.9839, mae: 1.8970, huber: 1.5224, swd: 2.1208, target_std: 4.7516
      Epoch 3 composite train-obj: 0.501675
            No improvement (1.2275), counter 2/5
    Epoch [4/50], Train Losses: mse: 1.2689, mae: 0.6977, huber: 0.3839, swd: 0.1616, target_std: 6.4709
    Epoch [4/50], Val Losses: mse: 8.4389, mae: 1.5913, huber: 1.2218, swd: 1.1816, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 11.8666, mae: 1.8917, huber: 1.5155, swd: 1.9951, target_std: 4.7516
      Epoch 4 composite train-obj: 0.383874
            No improvement (1.2218), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.0263, mae: 0.6279, huber: 0.3258, swd: 0.1210, target_std: 6.4709
    Epoch [5/50], Val Losses: mse: 8.4567, mae: 1.5981, huber: 1.2260, swd: 1.2230, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 11.8152, mae: 1.8924, huber: 1.5144, swd: 2.0420, target_std: 4.7516
      Epoch 5 composite train-obj: 0.325782
            No improvement (1.2260), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.9011, mae: 0.5855, huber: 0.2921, swd: 0.1018, target_std: 6.4708
    Epoch [6/50], Val Losses: mse: 8.5393, mae: 1.6021, huber: 1.2296, swd: 1.1533, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 11.7542, mae: 1.8862, huber: 1.5073, swd: 1.8899, target_std: 4.7516
      Epoch 6 composite train-obj: 0.292097
    Epoch [6/50], Test Losses: mse: 10.5792, mae: 1.7363, huber: 1.3703, swd: 1.9485, target_std: 4.7516
    Best round's Test MSE: 10.5792, MAE: 1.7363, SWD: 1.9485
    Best round's Validation MSE: 8.2461, MAE: 1.5041
    Best round's Test verification MSE : 10.5792, MAE: 1.7363, SWD: 1.9485
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred336_20250429_2003)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.6325 ± 0.1535
      mae: 1.7402 ± 0.0228
      huber: 1.3758 ± 0.0218
      swd: 1.7902 ± 0.1868
      target_std: 4.7516 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.0512 ± 0.1621
      mae: 1.4794 ± 0.0177
      huber: 1.1248 ± 0.0164
      swd: 1.1119 ± 0.1587
      target_std: 4.3126 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred336_20250429_2003
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

##### Ab: normalized scale


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=True)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: Yes
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3395, mae: 0.3968, huber: 0.1479, swd: 0.0979, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3516, mae: 0.3932, huber: 0.1505, swd: 0.0970, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4309, mae: 0.4477, huber: 0.1847, swd: 0.1193, target_std: 0.8890
      Epoch 1 composite train-obj: 0.147851
            Val objective improved inf → 0.1505, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2249, mae: 0.3333, huber: 0.1043, swd: 0.0595, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3981, mae: 0.4321, huber: 0.1705, swd: 0.0969, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.4938, mae: 0.4914, huber: 0.2107, swd: 0.1209, target_std: 0.8890
      Epoch 2 composite train-obj: 0.104323
            No improvement (0.1705), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1463, mae: 0.2762, huber: 0.0706, swd: 0.0296, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.4159, mae: 0.4434, huber: 0.1770, swd: 0.0932, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.5153, mae: 0.5025, huber: 0.2182, swd: 0.1183, target_std: 0.8890
      Epoch 3 composite train-obj: 0.070579
            No improvement (0.1770), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.1056, mae: 0.2373, huber: 0.0517, swd: 0.0170, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.4122, mae: 0.4433, huber: 0.1765, swd: 0.0895, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5147, mae: 0.5032, huber: 0.2182, swd: 0.1111, target_std: 0.8890
      Epoch 4 composite train-obj: 0.051738
            No improvement (0.1765), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0851, mae: 0.2132, huber: 0.0419, swd: 0.0118, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4177, mae: 0.4470, huber: 0.1787, swd: 0.0893, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5219, mae: 0.5071, huber: 0.2206, swd: 0.1167, target_std: 0.8890
      Epoch 5 composite train-obj: 0.041926
            No improvement (0.1787), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0738, mae: 0.1979, huber: 0.0364, swd: 0.0093, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4217, mae: 0.4489, huber: 0.1799, swd: 0.0887, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5227, mae: 0.5082, huber: 0.2209, swd: 0.1111, target_std: 0.8890
      Epoch 6 composite train-obj: 0.036431
    Epoch [6/50], Test Losses: mse: 0.4309, mae: 0.4477, huber: 0.1847, swd: 0.1193, target_std: 0.8890
    Best round's Test MSE: 0.4309, MAE: 0.4477, SWD: 0.1193
    Best round's Validation MSE: 0.3516, MAE: 0.3932
    Best round's Test verification MSE : 0.4309, MAE: 0.4477, SWD: 0.1193
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3516, mae: 0.4050, huber: 0.1527, swd: 0.0962, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3578, mae: 0.4003, huber: 0.1537, swd: 0.1057, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4452, mae: 0.4610, huber: 0.1914, swd: 0.1330, target_std: 0.8890
      Epoch 1 composite train-obj: 0.152701
            Val objective improved inf → 0.1537, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2106, mae: 0.3250, huber: 0.0985, swd: 0.0532, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.4261, mae: 0.4410, huber: 0.1785, swd: 0.1130, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.5063, mae: 0.4955, huber: 0.2141, swd: 0.1248, target_std: 0.8890
      Epoch 2 composite train-obj: 0.098546
            No improvement (0.1785), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1324, mae: 0.2646, huber: 0.0643, swd: 0.0246, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.4407, mae: 0.4495, huber: 0.1838, swd: 0.1142, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.5194, mae: 0.5041, huber: 0.2192, swd: 0.1199, target_std: 0.8890
      Epoch 3 composite train-obj: 0.064348
            No improvement (0.1838), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0957, mae: 0.2265, huber: 0.0471, swd: 0.0143, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.4366, mae: 0.4496, huber: 0.1832, swd: 0.1103, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5254, mae: 0.5078, huber: 0.2214, swd: 0.1199, target_std: 0.8890
      Epoch 4 composite train-obj: 0.047067
            No improvement (0.1832), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0789, mae: 0.2053, huber: 0.0389, swd: 0.0105, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4310, mae: 0.4472, huber: 0.1815, swd: 0.1011, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5189, mae: 0.5045, huber: 0.2188, swd: 0.1170, target_std: 0.8890
      Epoch 5 composite train-obj: 0.038932
            No improvement (0.1815), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0696, mae: 0.1921, huber: 0.0344, swd: 0.0086, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4371, mae: 0.4499, huber: 0.1832, swd: 0.1034, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5194, mae: 0.5042, huber: 0.2187, swd: 0.1156, target_std: 0.8890
      Epoch 6 composite train-obj: 0.034379
    Epoch [6/50], Test Losses: mse: 0.4452, mae: 0.4610, huber: 0.1914, swd: 0.1330, target_std: 0.8890
    Best round's Test MSE: 0.4452, MAE: 0.4610, SWD: 0.1330
    Best round's Validation MSE: 0.3578, MAE: 0.4003
    Best round's Test verification MSE : 0.4452, MAE: 0.4610, SWD: 0.1330
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 0.3370, mae: 0.3946, huber: 0.1467, swd: 0.0988, target_std: 0.7920
    Epoch [1/50], Val Losses: mse: 0.3518, mae: 0.3960, huber: 0.1515, swd: 0.0975, target_std: 0.9537
    Epoch [1/50], Test Losses: mse: 0.4319, mae: 0.4494, huber: 0.1852, swd: 0.1237, target_std: 0.8890
      Epoch 1 composite train-obj: 0.146735
            Val objective improved inf → 0.1515, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 0.2152, mae: 0.3248, huber: 0.0996, swd: 0.0554, target_std: 0.7920
    Epoch [2/50], Val Losses: mse: 0.3964, mae: 0.4334, huber: 0.1705, swd: 0.0997, target_std: 0.9537
    Epoch [2/50], Test Losses: mse: 0.4908, mae: 0.4868, huber: 0.2080, swd: 0.1194, target_std: 0.8890
      Epoch 2 composite train-obj: 0.099613
            No improvement (0.1705), counter 1/5
    Epoch [3/50], Train Losses: mse: 0.1211, mae: 0.2518, huber: 0.0588, swd: 0.0215, target_std: 0.7920
    Epoch [3/50], Val Losses: mse: 0.4085, mae: 0.4447, huber: 0.1763, swd: 0.0944, target_std: 0.9537
    Epoch [3/50], Test Losses: mse: 0.5150, mae: 0.5011, huber: 0.2173, swd: 0.1133, target_std: 0.8890
      Epoch 3 composite train-obj: 0.058828
            No improvement (0.1763), counter 2/5
    Epoch [4/50], Train Losses: mse: 0.0864, mae: 0.2140, huber: 0.0425, swd: 0.0119, target_std: 0.7920
    Epoch [4/50], Val Losses: mse: 0.4120, mae: 0.4469, huber: 0.1778, swd: 0.0948, target_std: 0.9537
    Epoch [4/50], Test Losses: mse: 0.5163, mae: 0.5028, huber: 0.2181, swd: 0.1115, target_std: 0.8890
      Epoch 4 composite train-obj: 0.042491
            No improvement (0.1778), counter 3/5
    Epoch [5/50], Train Losses: mse: 0.0713, mae: 0.1939, huber: 0.0352, swd: 0.0085, target_std: 0.7920
    Epoch [5/50], Val Losses: mse: 0.4134, mae: 0.4485, huber: 0.1784, swd: 0.0930, target_std: 0.9537
    Epoch [5/50], Test Losses: mse: 0.5257, mae: 0.5082, huber: 0.2216, swd: 0.1126, target_std: 0.8890
      Epoch 5 composite train-obj: 0.035206
            No improvement (0.1784), counter 4/5
    Epoch [6/50], Train Losses: mse: 0.0634, mae: 0.1821, huber: 0.0314, swd: 0.0071, target_std: 0.7920
    Epoch [6/50], Val Losses: mse: 0.4096, mae: 0.4463, huber: 0.1768, swd: 0.0918, target_std: 0.9537
    Epoch [6/50], Test Losses: mse: 0.5228, mae: 0.5062, huber: 0.2204, swd: 0.1122, target_std: 0.8890
      Epoch 6 composite train-obj: 0.031356
    Epoch [6/50], Test Losses: mse: 0.4319, mae: 0.4494, huber: 0.1852, swd: 0.1237, target_std: 0.8890
    Best round's Test MSE: 0.4319, MAE: 0.4494, SWD: 0.1237
    Best round's Validation MSE: 0.3518, MAE: 0.3960
    Best round's Test verification MSE : 0.4319, MAE: 0.4494, SWD: 0.1237
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred336_20250429_2331)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 0.4360 ± 0.0065
      mae: 0.4527 ± 0.0059
      huber: 0.1871 ± 0.0031
      swd: 0.1253 ± 0.0057
      target_std: 0.8890 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 0.3537 ± 0.0029
      mae: 0.3965 ± 0.0029
      huber: 0.1519 ± 0.0013
      swd: 0.1001 ± 0.0040
      target_std: 0.9537 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred336_20250429_2331
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 720-720


##### huber

##### ab:original scale


```python
utils.reload_modules([utils])
cfg = train_config.FlatTimeMixerConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_time_mixer_720_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)

```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.9413, mae: 1.5656, huber: 1.1925, swd: 1.4949, target_std: 6.4635
    Epoch [1/50], Val Losses: mse: 10.3461, mae: 1.7434, huber: 1.3799, swd: 2.2445, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.9093, mae: 1.8757, huber: 1.4960, swd: 2.4101, target_std: 4.7627
      Epoch 1 composite train-obj: 1.192495
            Val objective improved inf → 1.3799, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.0734, mae: 1.3381, huber: 0.9736, swd: 0.9098, target_std: 6.4637
    Epoch [2/50], Val Losses: mse: 12.0968, mae: 1.8407, huber: 1.4713, swd: 1.4820, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 11.4569, mae: 1.9413, huber: 1.5576, swd: 1.9023, target_std: 4.7627
      Epoch 2 composite train-obj: 0.973615
            No improvement (1.4713), counter 1/5
    Epoch [3/50], Train Losses: mse: 3.1898, mae: 1.0780, huber: 0.7244, swd: 0.4536, target_std: 6.4637
    Epoch [3/50], Val Losses: mse: 11.2425, mae: 1.8257, huber: 1.4507, swd: 1.2546, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 12.1769, mae: 2.0074, huber: 1.6199, swd: 1.8388, target_std: 4.7627
      Epoch 3 composite train-obj: 0.724444
            No improvement (1.4507), counter 2/5
    Epoch [4/50], Train Losses: mse: 2.1446, mae: 0.9030, huber: 0.5616, swd: 0.2631, target_std: 6.4638
    Epoch [4/50], Val Losses: mse: 11.7460, mae: 1.8564, huber: 1.4790, swd: 1.1601, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 12.5409, mae: 2.0395, huber: 1.6502, swd: 1.6636, target_std: 4.7627
      Epoch 4 composite train-obj: 0.561551
            No improvement (1.4790), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.6491, mae: 0.8031, huber: 0.4712, swd: 0.1895, target_std: 6.4637
    Epoch [5/50], Val Losses: mse: 11.3208, mae: 1.8578, huber: 1.4763, swd: 1.1766, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 12.6268, mae: 2.0567, huber: 1.6636, swd: 1.7763, target_std: 4.7627
      Epoch 5 composite train-obj: 0.471151
            No improvement (1.4763), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.3717, mae: 0.7368, huber: 0.4131, swd: 0.1508, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 11.7864, mae: 1.8816, huber: 1.4993, swd: 1.2523, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 12.5743, mae: 2.0533, huber: 1.6595, swd: 1.7324, target_std: 4.7627
      Epoch 6 composite train-obj: 0.413124
    Epoch [6/50], Test Losses: mse: 10.9093, mae: 1.8757, huber: 1.4960, swd: 2.4101, target_std: 4.7627
    Best round's Test MSE: 10.9093, MAE: 1.8757, SWD: 2.4101
    Best round's Validation MSE: 10.3461, MAE: 1.7434
    Best round's Test verification MSE : 10.9093, MAE: 1.8757, SWD: 2.4101
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.1434, mae: 1.5796, huber: 1.2062, swd: 1.4241, target_std: 6.4639
    Epoch [1/50], Val Losses: mse: 9.6586, mae: 1.6463, huber: 1.2840, swd: 1.1450, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.8617, mae: 1.8431, huber: 1.4685, swd: 1.4135, target_std: 4.7627
      Epoch 1 composite train-obj: 1.206191
            Val objective improved inf → 1.2840, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.6556, mae: 1.2901, huber: 0.9271, swd: 0.7448, target_std: 6.4637
    Epoch [2/50], Val Losses: mse: 10.5310, mae: 1.7639, huber: 1.3946, swd: 1.5504, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 11.7959, mae: 1.9554, huber: 1.5721, swd: 2.0025, target_std: 4.7627
      Epoch 2 composite train-obj: 0.927110
            No improvement (1.3946), counter 1/5
    Epoch [3/50], Train Losses: mse: 2.9686, mae: 1.0477, huber: 0.6958, swd: 0.3751, target_std: 6.4636
    Epoch [3/50], Val Losses: mse: 10.9638, mae: 1.8021, huber: 1.4278, swd: 1.2079, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 12.0174, mae: 1.9712, huber: 1.5866, swd: 1.5802, target_std: 4.7627
      Epoch 3 composite train-obj: 0.695838
            No improvement (1.4278), counter 2/5
    Epoch [4/50], Train Losses: mse: 2.0005, mae: 0.8809, huber: 0.5412, swd: 0.2294, target_std: 6.4635
    Epoch [4/50], Val Losses: mse: 11.2168, mae: 1.8175, huber: 1.4424, swd: 1.2058, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 12.2085, mae: 1.9861, huber: 1.6010, swd: 1.6381, target_std: 4.7627
      Epoch 4 composite train-obj: 0.541167
            No improvement (1.4424), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.5266, mae: 0.7805, huber: 0.4511, swd: 0.1687, target_std: 6.4636
    Epoch [5/50], Val Losses: mse: 11.2524, mae: 1.8242, huber: 1.4473, swd: 1.1835, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 12.3737, mae: 2.0042, huber: 1.6172, swd: 1.5850, target_std: 4.7627
      Epoch 5 composite train-obj: 0.451139
            No improvement (1.4473), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.2812, mae: 0.7181, huber: 0.3969, swd: 0.1362, target_std: 6.4637
    Epoch [6/50], Val Losses: mse: 11.0914, mae: 1.8150, huber: 1.4368, swd: 1.1472, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 12.3126, mae: 2.0005, huber: 1.6128, swd: 1.5692, target_std: 4.7627
      Epoch 6 composite train-obj: 0.396898
    Epoch [6/50], Test Losses: mse: 10.8617, mae: 1.8431, huber: 1.4685, swd: 1.4135, target_std: 4.7627
    Best round's Test MSE: 10.8617, MAE: 1.8431, SWD: 1.4135
    Best round's Validation MSE: 9.6586, MAE: 1.6463
    Best round's Test verification MSE : 10.8617, MAE: 1.8431, SWD: 1.4135
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0385, mae: 1.5711, huber: 1.1979, swd: 1.6368, target_std: 6.4637
    Epoch [1/50], Val Losses: mse: 9.7926, mae: 1.6402, huber: 1.2786, swd: 1.3533, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.7909, mae: 1.8351, huber: 1.4605, swd: 1.5236, target_std: 4.7627
      Epoch 1 composite train-obj: 1.197948
            Val objective improved inf → 1.2786, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.2998, mae: 1.3589, huber: 0.9941, swd: 0.9953, target_std: 6.4636
    Epoch [2/50], Val Losses: mse: 10.7038, mae: 1.7576, huber: 1.3897, swd: 1.8424, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 11.4383, mae: 1.9213, huber: 1.5393, swd: 2.2500, target_std: 4.7627
      Epoch 2 composite train-obj: 0.994054
            No improvement (1.3897), counter 1/5
    Epoch [3/50], Train Losses: mse: 3.5403, mae: 1.1217, huber: 0.7662, swd: 0.5201, target_std: 6.4639
    Epoch [3/50], Val Losses: mse: 12.8591, mae: 1.8842, huber: 1.5112, swd: 1.6163, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 12.0055, mae: 1.9788, huber: 1.5919, swd: 1.8808, target_std: 4.7627
      Epoch 3 composite train-obj: 0.766206
            No improvement (1.5112), counter 2/5
    Epoch [4/50], Train Losses: mse: 2.4314, mae: 0.9455, huber: 0.6012, swd: 0.3091, target_std: 6.4637
    Epoch [4/50], Val Losses: mse: 12.3827, mae: 1.8609, huber: 1.4859, swd: 1.3116, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 12.4296, mae: 2.0126, huber: 1.6239, swd: 1.6869, target_std: 4.7627
      Epoch 4 composite train-obj: 0.601159
            No improvement (1.4859), counter 3/5
    Epoch [5/50], Train Losses: mse: 1.8237, mae: 0.8343, huber: 0.4998, swd: 0.2166, target_std: 6.4635
    Epoch [5/50], Val Losses: mse: 12.2291, mae: 1.8649, huber: 1.4883, swd: 1.3533, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 12.6435, mae: 2.0293, huber: 1.6403, swd: 1.7730, target_std: 4.7627
      Epoch 5 composite train-obj: 0.499778
            No improvement (1.4883), counter 4/5
    Epoch [6/50], Train Losses: mse: 1.4820, mae: 0.7610, huber: 0.4347, swd: 0.1684, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 12.2891, mae: 1.8745, huber: 1.4953, swd: 1.3139, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 12.8087, mae: 2.0479, huber: 1.6570, swd: 1.7564, target_std: 4.7627
      Epoch 6 composite train-obj: 0.434732
    Epoch [6/50], Test Losses: mse: 10.7909, mae: 1.8351, huber: 1.4605, swd: 1.5236, target_std: 4.7627
    Best round's Test MSE: 10.7909, MAE: 1.8351, SWD: 1.5236
    Best round's Validation MSE: 9.7926, MAE: 1.6402
    Best round's Test verification MSE : 10.7909, MAE: 1.8351, SWD: 1.5236
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq720_pred720_20250429_2022)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.8540 ± 0.0486
      mae: 1.8513 ± 0.0175
      huber: 1.4750 ± 0.0152
      swd: 1.7824 ± 0.4461
      target_std: 4.7627 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.9324 ± 0.2976
      mae: 1.6766 ± 0.0473
      huber: 1.3142 ± 0.0465
      swd: 1.5809 ± 0.4769
      target_std: 4.3111 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq720_pred720_20250429_2022
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

##### normalized scale

### PatchTST


#### 720-96



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_720_96 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0984, mae: 1.4846, huber: 1.1184, swd: 1.9197, ept: 53.9028
    Epoch [1/50], Val Losses: mse: 5.8373, mae: 1.2534, huber: 0.9031, swd: 1.3845, ept: 69.1316
    Epoch [1/50], Test Losses: mse: 8.4063, mae: 1.5672, huber: 1.2040, swd: 2.6687, ept: 57.1133
      Epoch 1 composite train-obj: 1.118407
            Val objective improved inf → 0.9031, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9326, mae: 1.2584, huber: 0.9039, swd: 1.3622, ept: 59.4181
    Epoch [2/50], Val Losses: mse: 5.4649, mae: 1.1901, huber: 0.8459, swd: 0.9444, ept: 69.7352
    Epoch [2/50], Test Losses: mse: 7.8165, mae: 1.4557, huber: 1.1005, swd: 1.6770, ept: 58.4223
      Epoch 2 composite train-obj: 0.903881
            Val objective improved 0.9031 → 0.8459, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.7822, mae: 1.2311, huber: 0.8790, swd: 1.2992, ept: 59.6492
    Epoch [3/50], Val Losses: mse: 5.6793, mae: 1.2338, huber: 0.8873, swd: 1.1629, ept: 69.4037
    Epoch [3/50], Test Losses: mse: 7.5993, mae: 1.4426, huber: 1.0876, swd: 1.7359, ept: 60.1666
      Epoch 3 composite train-obj: 0.878971
            No improvement (0.8873), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.6439, mae: 1.2097, huber: 0.8591, swd: 1.2439, ept: 59.9961
    Epoch [4/50], Val Losses: mse: 5.7218, mae: 1.2416, huber: 0.8959, swd: 0.9561, ept: 69.3008
    Epoch [4/50], Test Losses: mse: 7.5143, mae: 1.4516, huber: 1.0966, swd: 1.6712, ept: 59.8069
      Epoch 4 composite train-obj: 0.859097
            No improvement (0.8959), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.4900, mae: 1.1887, huber: 0.8393, swd: 1.1866, ept: 60.5292
    Epoch [5/50], Val Losses: mse: 5.8487, mae: 1.2765, huber: 0.9292, swd: 0.9332, ept: 68.9282
    Epoch [5/50], Test Losses: mse: 7.7996, mae: 1.4690, huber: 1.1149, swd: 1.4306, ept: 59.1882
      Epoch 5 composite train-obj: 0.839272
            No improvement (0.9292), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.2775, mae: 1.1591, huber: 0.8117, swd: 1.1142, ept: 61.2673
    Epoch [6/50], Val Losses: mse: 5.8636, mae: 1.2952, huber: 0.9418, swd: 0.9036, ept: 68.9618
    Epoch [6/50], Test Losses: mse: 8.4269, mae: 1.5524, huber: 1.1907, swd: 1.3412, ept: 57.4821
      Epoch 6 composite train-obj: 0.811718
            No improvement (0.9418), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.0530, mae: 1.1270, huber: 0.7820, swd: 1.0328, ept: 62.0455
    Epoch [7/50], Val Losses: mse: 7.2037, mae: 1.4594, huber: 1.0992, swd: 1.1648, ept: 66.6757
    Epoch [7/50], Test Losses: mse: 9.7503, mae: 1.7005, huber: 1.3348, swd: 1.4720, ept: 54.9558
      Epoch 7 composite train-obj: 0.782044
    Epoch [7/50], Test Losses: mse: 7.8165, mae: 1.4557, huber: 1.1005, swd: 1.6770, ept: 58.4223
    Best round's Test MSE: 7.8165, MAE: 1.4557, SWD: 1.6770
    Best round's Validation MSE: 5.4649, MAE: 1.1901, SWD: 0.9444
    Best round's Test verification MSE : 7.8165, MAE: 1.4557, SWD: 1.6770
    Time taken: 247.41 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.8725, mae: 1.4709, huber: 1.1046, swd: 1.8099, ept: 53.7534
    Epoch [1/50], Val Losses: mse: 5.4878, mae: 1.1944, huber: 0.8526, swd: 0.9871, ept: 70.1888
    Epoch [1/50], Test Losses: mse: 7.6919, mae: 1.4649, huber: 1.1100, swd: 1.7475, ept: 59.2726
      Epoch 1 composite train-obj: 1.104636
            Val objective improved inf → 0.8526, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9163, mae: 1.2556, huber: 0.9011, swd: 1.3274, ept: 59.3544
    Epoch [2/50], Val Losses: mse: 5.2866, mae: 1.1834, huber: 0.8401, swd: 0.9322, ept: 70.1044
    Epoch [2/50], Test Losses: mse: 7.2816, mae: 1.4161, huber: 1.0632, swd: 1.6463, ept: 60.2027
      Epoch 2 composite train-obj: 0.901076
            Val objective improved 0.8526 → 0.8401, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.7342, mae: 1.2248, huber: 0.8728, swd: 1.2605, ept: 59.9040
    Epoch [3/50], Val Losses: mse: 5.3162, mae: 1.1966, huber: 0.8514, swd: 0.9346, ept: 69.2173
    Epoch [3/50], Test Losses: mse: 7.3050, mae: 1.4119, huber: 1.0605, swd: 1.5368, ept: 60.0806
      Epoch 3 composite train-obj: 0.872758
            No improvement (0.8514), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.5407, mae: 1.1953, huber: 0.8452, swd: 1.1862, ept: 60.3608
    Epoch [4/50], Val Losses: mse: 5.4096, mae: 1.2018, huber: 0.8583, swd: 0.9920, ept: 70.3692
    Epoch [4/50], Test Losses: mse: 7.7778, mae: 1.4738, huber: 1.1204, swd: 2.0360, ept: 59.8118
      Epoch 4 composite train-obj: 0.845216
            No improvement (0.8583), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.3502, mae: 1.1679, huber: 0.8195, swd: 1.1051, ept: 60.8590
    Epoch [5/50], Val Losses: mse: 5.4610, mae: 1.2298, huber: 0.8847, swd: 0.9983, ept: 70.1965
    Epoch [5/50], Test Losses: mse: 7.8800, mae: 1.4886, huber: 1.1361, swd: 2.0221, ept: 59.8145
      Epoch 5 composite train-obj: 0.819471
            No improvement (0.8847), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.1438, mae: 1.1367, huber: 0.7907, swd: 1.0243, ept: 61.6354
    Epoch [6/50], Val Losses: mse: 5.9210, mae: 1.3054, huber: 0.9520, swd: 0.8929, ept: 67.8935
    Epoch [6/50], Test Losses: mse: 8.7096, mae: 1.5744, huber: 1.2138, swd: 1.6210, ept: 55.5982
      Epoch 6 composite train-obj: 0.790726
            No improvement (0.9520), counter 4/5
    Epoch [7/50], Train Losses: mse: 3.9448, mae: 1.1065, huber: 0.7629, swd: 0.9462, ept: 62.3679
    Epoch [7/50], Val Losses: mse: 7.3391, mae: 1.4429, huber: 1.0852, swd: 1.1187, ept: 65.5270
    Epoch [7/50], Test Losses: mse: 9.5481, mae: 1.6686, huber: 1.3035, swd: 1.8195, ept: 52.6763
      Epoch 7 composite train-obj: 0.762930
    Epoch [7/50], Test Losses: mse: 7.2816, mae: 1.4161, huber: 1.0632, swd: 1.6463, ept: 60.2027
    Best round's Test MSE: 7.2816, MAE: 1.4161, SWD: 1.6463
    Best round's Validation MSE: 5.2866, MAE: 1.1834, SWD: 0.9322
    Best round's Test verification MSE : 7.2816, MAE: 1.4161, SWD: 1.6463
    Time taken: 249.24 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.8856, mae: 1.4686, huber: 1.1032, swd: 1.7317, ept: 54.0118
    Epoch [1/50], Val Losses: mse: 5.5440, mae: 1.2229, huber: 0.8779, swd: 0.9624, ept: 68.5096
    Epoch [1/50], Test Losses: mse: 7.5369, mae: 1.4435, huber: 1.0913, swd: 1.5880, ept: 59.5028
      Epoch 1 composite train-obj: 1.103231
            Val objective improved inf → 0.8779, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.9483, mae: 1.2608, huber: 0.9067, swd: 1.2470, ept: 59.4185
    Epoch [2/50], Val Losses: mse: 5.7480, mae: 1.2362, huber: 0.8926, swd: 0.9761, ept: 69.3918
    Epoch [2/50], Test Losses: mse: 7.2660, mae: 1.4165, huber: 1.0662, swd: 1.5194, ept: 60.8944
      Epoch 2 composite train-obj: 0.906662
            No improvement (0.8926), counter 1/5
    Epoch [3/50], Train Losses: mse: 4.7830, mae: 1.2277, huber: 0.8767, swd: 1.1800, ept: 59.9598
    Epoch [3/50], Val Losses: mse: 5.7680, mae: 1.2366, huber: 0.8932, swd: 1.0186, ept: 70.3081
    Epoch [3/50], Test Losses: mse: 7.3208, mae: 1.4343, huber: 1.0827, swd: 1.7142, ept: 60.8511
      Epoch 3 composite train-obj: 0.876707
            No improvement (0.8932), counter 2/5
    Epoch [4/50], Train Losses: mse: 4.6204, mae: 1.2014, huber: 0.8518, swd: 1.1177, ept: 60.3812
    Epoch [4/50], Val Losses: mse: 5.9706, mae: 1.2928, huber: 0.9427, swd: 0.9675, ept: 68.3256
    Epoch [4/50], Test Losses: mse: 8.0735, mae: 1.5353, huber: 1.1771, swd: 1.6102, ept: 56.9750
      Epoch 4 composite train-obj: 0.851842
            No improvement (0.9427), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.4180, mae: 1.1690, huber: 0.8220, swd: 1.0447, ept: 61.3130
    Epoch [5/50], Val Losses: mse: 5.9561, mae: 1.2947, huber: 0.9456, swd: 0.9493, ept: 69.0240
    Epoch [5/50], Test Losses: mse: 8.2370, mae: 1.5613, huber: 1.2010, swd: 1.7766, ept: 56.9100
      Epoch 5 composite train-obj: 0.822016
            No improvement (0.9456), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.1638, mae: 1.1335, huber: 0.7890, swd: 0.9611, ept: 62.0953
    Epoch [6/50], Val Losses: mse: 6.2517, mae: 1.3354, huber: 0.9841, swd: 0.9303, ept: 67.7119
    Epoch [6/50], Test Losses: mse: 8.9631, mae: 1.6171, huber: 1.2565, swd: 1.6677, ept: 55.1840
      Epoch 6 composite train-obj: 0.789046
    Epoch [6/50], Test Losses: mse: 7.5369, mae: 1.4435, huber: 1.0913, swd: 1.5880, ept: 59.5028
    Best round's Test MSE: 7.5369, MAE: 1.4435, SWD: 1.5880
    Best round's Validation MSE: 5.5440, MAE: 1.2229, SWD: 0.9624
    Best round's Test verification MSE : 7.5369, MAE: 1.4435, SWD: 1.5880
    Time taken: 214.50 seconds
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq720_pred96_20250512_1657)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5450 ± 0.2185
      mae: 1.4384 ± 0.0165
      huber: 1.0850 ± 0.0159
      swd: 1.6371 ± 0.0369
      ept: 59.3759 ± 0.7324
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.4318 ± 0.1077
      mae: 1.1988 ± 0.0173
      huber: 0.8546 ± 0.0166
      swd: 0.9463 ± 0.0124
      ept: 69.4497 ± 0.6816
      count: 49.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 712.67 seconds
    
    Experiment complete: PatchTST_ettm1_seq720_pred96_20250512_1657
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 720-196



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.9437, mae: 1.5974, huber: 1.2244, swd: 2.0240, ept: 84.8023
    Epoch [1/50], Val Losses: mse: 6.4005, mae: 1.3243, huber: 0.9722, swd: 1.2344, ept: 112.0552
    Epoch [1/50], Test Losses: mse: 9.3711, mae: 1.6475, huber: 1.2824, swd: 2.3877, ept: 88.8089
      Epoch 1 composite train-obj: 1.224445
            Val objective improved inf → 0.9722, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.8004, mae: 1.3857, huber: 1.0221, swd: 1.5418, ept: 94.3140
    Epoch [2/50], Val Losses: mse: 6.3703, mae: 1.3318, huber: 0.9801, swd: 1.2241, ept: 111.3633
    Epoch [2/50], Test Losses: mse: 9.0683, mae: 1.6194, huber: 1.2544, swd: 1.9964, ept: 91.3695
      Epoch 2 composite train-obj: 1.022080
            No improvement (0.9801), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.5937, mae: 1.3547, huber: 0.9931, swd: 1.4520, ept: 94.8406
    Epoch [3/50], Val Losses: mse: 6.2827, mae: 1.3138, huber: 0.9634, swd: 0.8784, ept: 111.0639
    Epoch [3/50], Test Losses: mse: 9.0093, mae: 1.6172, huber: 1.2528, swd: 1.9060, ept: 90.5238
      Epoch 3 composite train-obj: 0.993071
            Val objective improved 0.9722 → 0.9634, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 5.3693, mae: 1.3259, huber: 0.9655, swd: 1.3485, ept: 95.5119
    Epoch [4/50], Val Losses: mse: 6.5814, mae: 1.3563, huber: 1.0033, swd: 0.8629, ept: 108.9196
    Epoch [4/50], Test Losses: mse: 9.2196, mae: 1.6091, huber: 1.2472, swd: 1.5912, ept: 92.0364
      Epoch 4 composite train-obj: 0.965520
            No improvement (1.0033), counter 1/5
    Epoch [5/50], Train Losses: mse: 5.0996, mae: 1.2899, huber: 0.9313, swd: 1.2238, ept: 96.7451
    Epoch [5/50], Val Losses: mse: 6.7842, mae: 1.3811, huber: 1.0270, swd: 0.9527, ept: 108.6563
    Epoch [5/50], Test Losses: mse: 9.6164, mae: 1.6665, huber: 1.3012, swd: 1.7121, ept: 88.5595
      Epoch 5 composite train-obj: 0.931293
            No improvement (1.0270), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.7970, mae: 1.2474, huber: 0.8916, swd: 1.0964, ept: 98.7133
    Epoch [6/50], Val Losses: mse: 8.3509, mae: 1.5605, huber: 1.1997, swd: 1.2664, ept: 103.4580
    Epoch [6/50], Test Losses: mse: 11.6876, mae: 1.9087, huber: 1.5364, swd: 2.5923, ept: 85.1435
      Epoch 6 composite train-obj: 0.891642
            No improvement (1.1997), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.5070, mae: 1.2078, huber: 0.8548, swd: 0.9821, ept: 100.4666
    Epoch [7/50], Val Losses: mse: 9.4263, mae: 1.6605, huber: 1.2931, swd: 1.0990, ept: 84.5221
    Epoch [7/50], Test Losses: mse: 12.4102, mae: 1.9735, huber: 1.5942, swd: 2.0603, ept: 62.9239
      Epoch 7 composite train-obj: 0.854802
            No improvement (1.2931), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.2371, mae: 1.1728, huber: 0.8219, swd: 0.8820, ept: 101.5039
    Epoch [8/50], Val Losses: mse: 8.3642, mae: 1.5871, huber: 1.2199, swd: 1.0255, ept: 99.5706
    Epoch [8/50], Test Losses: mse: 11.9521, mae: 1.9145, huber: 1.5389, swd: 1.6521, ept: 76.7904
      Epoch 8 composite train-obj: 0.821922
    Epoch [8/50], Test Losses: mse: 9.0093, mae: 1.6172, huber: 1.2528, swd: 1.9060, ept: 90.5238
    Best round's Test MSE: 9.0093, MAE: 1.6172, SWD: 1.9060
    Best round's Validation MSE: 6.2827, MAE: 1.3138, SWD: 0.8784
    Best round's Test verification MSE : 9.0093, MAE: 1.6172, SWD: 1.9060
    Time taken: 287.50 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.8090, mae: 1.5860, huber: 1.2131, swd: 2.1160, ept: 85.7216
    Epoch [1/50], Val Losses: mse: 6.7238, mae: 1.3550, huber: 1.0001, swd: 0.9863, ept: 109.5236
    Epoch [1/50], Test Losses: mse: 9.3599, mae: 1.6244, huber: 1.2587, swd: 1.5745, ept: 90.3406
      Epoch 1 composite train-obj: 1.213112
            Val objective improved inf → 1.0001, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.7505, mae: 1.3817, huber: 1.0181, swd: 1.5620, ept: 94.8363
    Epoch [2/50], Val Losses: mse: 6.1874, mae: 1.3085, huber: 0.9577, swd: 0.9762, ept: 109.7110
    Epoch [2/50], Test Losses: mse: 9.0455, mae: 1.6173, huber: 1.2526, swd: 1.9685, ept: 89.2830
      Epoch 2 composite train-obj: 1.018068
            Val objective improved 1.0001 → 0.9577, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.5037, mae: 1.3472, huber: 0.9854, swd: 1.4563, ept: 95.4170
    Epoch [3/50], Val Losses: mse: 6.2739, mae: 1.3266, huber: 0.9742, swd: 0.8824, ept: 109.9299
    Epoch [3/50], Test Losses: mse: 9.1208, mae: 1.6127, huber: 1.2480, swd: 1.5994, ept: 90.5807
      Epoch 3 composite train-obj: 0.985409
            No improvement (0.9742), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.2580, mae: 1.3147, huber: 0.9543, swd: 1.3398, ept: 95.9234
    Epoch [4/50], Val Losses: mse: 6.3879, mae: 1.3532, huber: 0.9981, swd: 1.0102, ept: 107.7087
    Epoch [4/50], Test Losses: mse: 9.3739, mae: 1.6608, huber: 1.2925, swd: 1.9926, ept: 89.6282
      Epoch 4 composite train-obj: 0.954294
            No improvement (0.9981), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.9460, mae: 1.2731, huber: 0.9147, swd: 1.1971, ept: 97.1845
    Epoch [5/50], Val Losses: mse: 6.3729, mae: 1.3553, huber: 0.9985, swd: 0.8795, ept: 110.0898
    Epoch [5/50], Test Losses: mse: 10.2754, mae: 1.7074, huber: 1.3392, swd: 1.6152, ept: 87.6596
      Epoch 5 composite train-obj: 0.914735
            No improvement (0.9985), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.6040, mae: 1.2270, huber: 0.8717, swd: 1.0522, ept: 99.0820
    Epoch [6/50], Val Losses: mse: 8.5824, mae: 1.5738, huber: 1.2120, swd: 1.4966, ept: 103.7029
    Epoch [6/50], Test Losses: mse: 12.1367, mae: 1.9004, huber: 1.5268, swd: 2.3128, ept: 85.8008
      Epoch 6 composite train-obj: 0.871698
            No improvement (1.2120), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.2669, mae: 1.1836, huber: 0.8309, swd: 0.9156, ept: 100.8207
    Epoch [7/50], Val Losses: mse: 7.9383, mae: 1.5571, huber: 1.1917, swd: 1.0408, ept: 102.7529
    Epoch [7/50], Test Losses: mse: 11.8669, mae: 1.8986, huber: 1.5245, swd: 1.6745, ept: 83.9771
      Epoch 7 composite train-obj: 0.830933
    Epoch [7/50], Test Losses: mse: 9.0455, mae: 1.6173, huber: 1.2526, swd: 1.9685, ept: 89.2830
    Best round's Test MSE: 9.0455, MAE: 1.6173, SWD: 1.9685
    Best round's Validation MSE: 6.1874, MAE: 1.3085, SWD: 0.9762
    Best round's Test verification MSE : 9.0455, MAE: 1.6173, SWD: 1.9685
    Time taken: 252.19 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.8492, mae: 1.5967, huber: 1.2233, swd: 1.8230, ept: 84.6237
    Epoch [1/50], Val Losses: mse: 6.2834, mae: 1.3212, huber: 0.9666, swd: 0.8662, ept: 109.7804
    Epoch [1/50], Test Losses: mse: 9.3476, mae: 1.6342, huber: 1.2689, swd: 1.8396, ept: 88.3991
      Epoch 1 composite train-obj: 1.223326
            Val objective improved inf → 0.9666, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.7564, mae: 1.3832, huber: 1.0195, swd: 1.3792, ept: 94.6077
    Epoch [2/50], Val Losses: mse: 6.2576, mae: 1.3307, huber: 0.9759, swd: 0.9280, ept: 109.4787
    Epoch [2/50], Test Losses: mse: 9.0257, mae: 1.6055, huber: 1.2408, swd: 1.5924, ept: 90.3207
      Epoch 2 composite train-obj: 1.019534
            No improvement (0.9759), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.4936, mae: 1.3437, huber: 0.9825, swd: 1.2785, ept: 95.2622
    Epoch [3/50], Val Losses: mse: 6.4127, mae: 1.3374, huber: 0.9855, swd: 0.9245, ept: 110.3573
    Epoch [3/50], Test Losses: mse: 8.8493, mae: 1.5955, huber: 1.2323, swd: 1.5396, ept: 91.7205
      Epoch 3 composite train-obj: 0.982543
            No improvement (0.9855), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.1968, mae: 1.3060, huber: 0.9464, swd: 1.1630, ept: 95.9897
    Epoch [4/50], Val Losses: mse: 6.8451, mae: 1.4034, huber: 1.0441, swd: 0.8334, ept: 107.7010
    Epoch [4/50], Test Losses: mse: 10.4511, mae: 1.7559, huber: 1.3855, swd: 1.7287, ept: 84.7165
      Epoch 4 composite train-obj: 0.946358
            No improvement (1.0441), counter 3/5
    Epoch [5/50], Train Losses: mse: 4.8575, mae: 1.2613, huber: 0.9042, swd: 1.0353, ept: 97.7771
    Epoch [5/50], Val Losses: mse: 6.7960, mae: 1.3999, huber: 1.0436, swd: 1.1556, ept: 112.3220
    Epoch [5/50], Test Losses: mse: 10.3131, mae: 1.7577, huber: 1.3878, swd: 2.3967, ept: 88.1886
      Epoch 5 composite train-obj: 0.904156
            No improvement (1.0436), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.5254, mae: 1.2163, huber: 0.8619, swd: 0.9221, ept: 99.7510
    Epoch [6/50], Val Losses: mse: 7.7595, mae: 1.5027, huber: 1.1436, swd: 1.0060, ept: 105.6434
    Epoch [6/50], Test Losses: mse: 10.8976, mae: 1.8058, huber: 1.4367, swd: 1.9474, ept: 85.4089
      Epoch 6 composite train-obj: 0.861940
    Epoch [6/50], Test Losses: mse: 9.3476, mae: 1.6342, huber: 1.2689, swd: 1.8396, ept: 88.3991
    Best round's Test MSE: 9.3476, MAE: 1.6342, SWD: 1.8396
    Best round's Validation MSE: 6.2834, MAE: 1.3212, SWD: 0.8662
    Best round's Test verification MSE : 9.3476, MAE: 1.6342, SWD: 1.8396
    Time taken: 217.40 seconds
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq720_pred196_20250512_1709)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.1341 ± 0.1517
      mae: 1.6229 ± 0.0080
      huber: 1.2581 ± 0.0077
      swd: 1.9047 ± 0.0526
      ept: 89.4019 ± 0.8715
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.2512 ± 0.0451
      mae: 1.3145 ± 0.0052
      huber: 0.9626 ± 0.0037
      swd: 0.9069 ± 0.0492
      ept: 110.1851 ± 0.6221
      count: 48.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 757.18 seconds
    
    Experiment complete: PatchTST_ettm1_seq720_pred196_20250512_1709
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 720-336



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.5425, mae: 1.6831, huber: 1.3045, swd: 2.0529, ept: 115.3870
    Epoch [1/50], Val Losses: mse: 7.3213, mae: 1.4036, huber: 1.0464, swd: 1.0040, ept: 151.9478
    Epoch [1/50], Test Losses: mse: 10.4681, mae: 1.7675, huber: 1.3946, swd: 2.1217, ept: 121.2842
      Epoch 1 composite train-obj: 1.304471
            Val objective improved inf → 1.0464, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.3958, mae: 1.4785, huber: 1.1078, swd: 1.5527, ept: 129.5919
    Epoch [2/50], Val Losses: mse: 7.5403, mae: 1.4313, huber: 1.0751, swd: 0.9062, ept: 146.7610
    Epoch [2/50], Test Losses: mse: 9.9682, mae: 1.7261, huber: 1.3543, swd: 1.8570, ept: 123.1547
      Epoch 2 composite train-obj: 1.107847
            No improvement (1.0751), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0752, mae: 1.4385, huber: 1.0696, swd: 1.4149, ept: 130.5923
    Epoch [3/50], Val Losses: mse: 7.3556, mae: 1.4548, huber: 1.0959, swd: 0.9569, ept: 145.7970
    Epoch [3/50], Test Losses: mse: 9.9446, mae: 1.7349, huber: 1.3637, swd: 1.9834, ept: 123.0654
      Epoch 3 composite train-obj: 1.069600
            No improvement (1.0959), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.6757, mae: 1.3906, huber: 1.0232, swd: 1.2356, ept: 131.6302
    Epoch [4/50], Val Losses: mse: 7.4793, mae: 1.4518, huber: 1.0925, swd: 0.9960, ept: 145.4312
    Epoch [4/50], Test Losses: mse: 10.2632, mae: 1.7531, huber: 1.3820, swd: 1.9081, ept: 122.4203
      Epoch 4 composite train-obj: 1.023225
            No improvement (1.0925), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.2639, mae: 1.3365, huber: 0.9715, swd: 1.0489, ept: 134.1127
    Epoch [5/50], Val Losses: mse: 7.8849, mae: 1.5087, huber: 1.1481, swd: 1.1028, ept: 145.5377
    Epoch [5/50], Test Losses: mse: 11.0530, mae: 1.8375, huber: 1.4646, swd: 2.1082, ept: 119.3985
      Epoch 5 composite train-obj: 0.971463
            No improvement (1.1481), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.8997, mae: 1.2857, huber: 0.9239, swd: 0.9067, ept: 137.1125
    Epoch [6/50], Val Losses: mse: 9.3193, mae: 1.6691, huber: 1.3014, swd: 1.1407, ept: 132.4649
    Epoch [6/50], Test Losses: mse: 12.8513, mae: 2.0329, huber: 1.6523, swd: 2.1080, ept: 109.4846
      Epoch 6 composite train-obj: 0.923950
    Epoch [6/50], Test Losses: mse: 10.4681, mae: 1.7675, huber: 1.3946, swd: 2.1217, ept: 121.2842
    Best round's Test MSE: 10.4681, MAE: 1.7675, SWD: 2.1217
    Best round's Validation MSE: 7.3213, MAE: 1.4036, SWD: 1.0040
    Best round's Test verification MSE : 10.4681, MAE: 1.7675, SWD: 2.1217
    Time taken: 218.38 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.6078, mae: 1.6920, huber: 1.3127, swd: 2.1201, ept: 114.6636
    Epoch [1/50], Val Losses: mse: 7.4546, mae: 1.4404, huber: 1.0813, swd: 1.1054, ept: 148.9934
    Epoch [1/50], Test Losses: mse: 10.2063, mae: 1.7542, huber: 1.3817, swd: 2.0936, ept: 121.2352
      Epoch 1 composite train-obj: 1.312722
            Val objective improved inf → 1.0813, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4179, mae: 1.4830, huber: 1.1118, swd: 1.6177, ept: 129.9621
    Epoch [2/50], Val Losses: mse: 7.3779, mae: 1.4193, huber: 1.0629, swd: 0.9238, ept: 150.1649
    Epoch [2/50], Test Losses: mse: 9.9293, mae: 1.7222, huber: 1.3502, swd: 1.8366, ept: 122.8229
      Epoch 2 composite train-obj: 1.111837
            Val objective improved 1.0813 → 1.0629, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0699, mae: 1.4399, huber: 1.0706, swd: 1.4717, ept: 131.0802
    Epoch [3/50], Val Losses: mse: 7.3910, mae: 1.4266, huber: 1.0687, swd: 0.9165, ept: 149.5544
    Epoch [3/50], Test Losses: mse: 10.2408, mae: 1.7513, huber: 1.3784, swd: 1.9482, ept: 121.5879
      Epoch 3 composite train-obj: 1.070623
            No improvement (1.0687), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.6304, mae: 1.3868, huber: 1.0196, swd: 1.2627, ept: 132.5438
    Epoch [4/50], Val Losses: mse: 7.7388, mae: 1.4750, huber: 1.1144, swd: 0.9829, ept: 149.0369
    Epoch [4/50], Test Losses: mse: 10.4440, mae: 1.7831, huber: 1.4114, swd: 2.0008, ept: 122.8986
      Epoch 4 composite train-obj: 1.019601
            No improvement (1.1144), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.2055, mae: 1.3318, huber: 0.9670, swd: 1.0553, ept: 134.6025
    Epoch [5/50], Val Losses: mse: 9.3465, mae: 1.6927, huber: 1.3181, swd: 0.9308, ept: 133.8421
    Epoch [5/50], Test Losses: mse: 12.6080, mae: 2.0255, huber: 1.6408, swd: 1.4882, ept: 112.3153
      Epoch 5 composite train-obj: 0.967034
            No improvement (1.3181), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.8538, mae: 1.2814, huber: 0.9196, swd: 0.9100, ept: 137.1953
    Epoch [6/50], Val Losses: mse: 9.3999, mae: 1.6440, huber: 1.2775, swd: 1.0007, ept: 139.8099
    Epoch [6/50], Test Losses: mse: 11.9722, mae: 1.9184, huber: 1.5412, swd: 1.6919, ept: 116.4109
      Epoch 6 composite train-obj: 0.919640
            No improvement (1.2775), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.5823, mae: 1.2408, huber: 0.8817, swd: 0.8111, ept: 139.1137
    Epoch [7/50], Val Losses: mse: 10.2005, mae: 1.6780, huber: 1.3111, swd: 1.0990, ept: 140.7668
    Epoch [7/50], Test Losses: mse: 12.1589, mae: 1.9337, huber: 1.5552, swd: 1.7961, ept: 115.6142
      Epoch 7 composite train-obj: 0.881683
    Epoch [7/50], Test Losses: mse: 9.9293, mae: 1.7222, huber: 1.3502, swd: 1.8366, ept: 122.8229
    Best round's Test MSE: 9.9293, MAE: 1.7222, SWD: 1.8366
    Best round's Validation MSE: 7.3779, MAE: 1.4193, SWD: 0.9238
    Best round's Test verification MSE : 9.9293, MAE: 1.7222, SWD: 1.8366
    Time taken: 254.49 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 8.4232, mae: 1.6757, huber: 1.2971, swd: 2.0030, ept: 115.4246
    Epoch [1/50], Val Losses: mse: 7.2357, mae: 1.4000, huber: 1.0443, swd: 1.0214, ept: 152.3014
    Epoch [1/50], Test Losses: mse: 10.2368, mae: 1.7385, huber: 1.3696, swd: 2.1153, ept: 124.3758
      Epoch 1 composite train-obj: 1.297060
            Val objective improved inf → 1.0443, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.4186, mae: 1.4821, huber: 1.1113, swd: 1.5505, ept: 130.0383
    Epoch [2/50], Val Losses: mse: 7.5297, mae: 1.4258, huber: 1.0710, swd: 1.0032, ept: 154.5077
    Epoch [2/50], Test Losses: mse: 10.0207, mae: 1.7237, huber: 1.3534, swd: 1.9856, ept: 124.6982
      Epoch 2 composite train-obj: 1.111331
            No improvement (1.0710), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0735, mae: 1.4374, huber: 1.0690, swd: 1.4114, ept: 131.1524
    Epoch [3/50], Val Losses: mse: 7.5827, mae: 1.4354, huber: 1.0792, swd: 1.0346, ept: 148.1521
    Epoch [3/50], Test Losses: mse: 10.0577, mae: 1.7266, huber: 1.3567, swd: 2.0142, ept: 123.1030
      Epoch 3 composite train-obj: 1.069034
            No improvement (1.0792), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.7166, mae: 1.3934, huber: 1.0266, swd: 1.2531, ept: 132.5225
    Epoch [4/50], Val Losses: mse: 7.9455, mae: 1.4851, huber: 1.1257, swd: 1.0224, ept: 146.1362
    Epoch [4/50], Test Losses: mse: 10.5450, mae: 1.7883, huber: 1.4155, swd: 1.9347, ept: 119.0728
      Epoch 4 composite train-obj: 1.026648
            No improvement (1.1257), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.3232, mae: 1.3418, huber: 0.9776, swd: 1.0856, ept: 135.2917
    Epoch [5/50], Val Losses: mse: 9.7433, mae: 1.7295, huber: 1.3576, swd: 1.2984, ept: 126.0376
    Epoch [5/50], Test Losses: mse: 13.6780, mae: 2.1222, huber: 1.7383, swd: 2.3510, ept: 103.4407
      Epoch 5 composite train-obj: 0.977630
            No improvement (1.3576), counter 4/5
    Epoch [6/50], Train Losses: mse: 4.9755, mae: 1.2944, huber: 0.9329, swd: 0.9541, ept: 137.7849
    Epoch [6/50], Val Losses: mse: 8.5935, mae: 1.5827, huber: 1.2174, swd: 1.0487, ept: 145.0776
    Epoch [6/50], Test Losses: mse: 12.1037, mae: 1.9317, huber: 1.5551, swd: 2.0663, ept: 116.2054
      Epoch 6 composite train-obj: 0.932870
    Epoch [6/50], Test Losses: mse: 10.2368, mae: 1.7385, huber: 1.3696, swd: 2.1153, ept: 124.3758
    Best round's Test MSE: 10.2368, MAE: 1.7385, SWD: 2.1153
    Best round's Validation MSE: 7.2357, MAE: 1.4000, SWD: 1.0214
    Best round's Test verification MSE : 10.2368, MAE: 1.7385, SWD: 2.1153
    Time taken: 218.29 seconds
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq720_pred336_20250512_1722)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2114 ± 0.2207
      mae: 1.7427 ± 0.0187
      huber: 1.3714 ± 0.0182
      swd: 2.0245 ± 0.1329
      ept: 122.8276 ± 1.2622
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.3117 ± 0.0584
      mae: 1.4076 ± 0.0084
      huber: 1.0512 ± 0.0083
      swd: 0.9831 ± 0.0425
      ept: 151.4714 ± 0.9350
      count: 47.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 691.29 seconds
    
    Experiment complete: PatchTST_ettm1_seq720_pred336_20250512_1722
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 720-720



```python
utils.reload_modules([utils])
cfg = train_config.FlatPatchTSTConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    enc_in=data_mgr.datasets['ettm1']['channels'],
    dec_in=data_mgr.datasets['ettm1']['channels'],
    c_out=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50,
    task_name='long_term_forecast',
    factor=3,
)
exp_tst_720_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    global_std.shape: torch.Size([7])
    Global Std for ettm1: tensor([7.0829, 2.0413, 6.8291, 1.8072, 1.1741, 0.6004, 8.5648],
           device='cuda:0')
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.5701, mae: 1.8286, huber: 1.4414, swd: 2.0180, ept: 163.1998
    Epoch [1/50], Val Losses: mse: 8.8971, mae: 1.5673, huber: 1.2041, swd: 0.9685, ept: 212.3231
    Epoch [1/50], Test Losses: mse: 10.6049, mae: 1.8279, huber: 1.4510, swd: 1.7429, ept: 190.4816
      Epoch 1 composite train-obj: 1.441376
            Val objective improved inf → 1.2041, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.0320, mae: 1.6004, huber: 1.2200, swd: 1.5334, ept: 192.1564
    Epoch [2/50], Val Losses: mse: 9.4503, mae: 1.6223, huber: 1.2560, swd: 1.3459, ept: 203.4277
    Epoch [2/50], Test Losses: mse: 10.3673, mae: 1.8283, huber: 1.4482, swd: 1.8106, ept: 186.5873
      Epoch 2 composite train-obj: 1.220044
            No improvement (1.2560), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.5196, mae: 1.5364, huber: 1.1584, swd: 1.2982, ept: 194.6934
    Epoch [3/50], Val Losses: mse: 9.6346, mae: 1.6400, huber: 1.2726, swd: 1.3686, ept: 202.7123
    Epoch [3/50], Test Losses: mse: 10.6409, mae: 1.8634, huber: 1.4809, swd: 1.9179, ept: 186.8737
      Epoch 3 composite train-obj: 1.158416
            No improvement (1.2726), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.0217, mae: 1.4710, huber: 1.0955, swd: 1.0761, ept: 197.9538
    Epoch [4/50], Val Losses: mse: 10.6284, mae: 1.7939, huber: 1.4174, swd: 0.9737, ept: 190.3235
    Epoch [4/50], Test Losses: mse: 13.3937, mae: 2.1012, huber: 1.7133, swd: 1.3560, ept: 172.9682
      Epoch 4 composite train-obj: 1.095513
            No improvement (1.4174), counter 3/5
    Epoch [5/50], Train Losses: mse: 5.5665, mae: 1.4073, huber: 1.0352, swd: 0.9098, ept: 204.3510
    Epoch [5/50], Val Losses: mse: 11.8172, mae: 1.9192, huber: 1.5371, swd: 1.1276, ept: 175.9025
    Epoch [5/50], Test Losses: mse: 15.3246, mae: 2.2820, huber: 1.8894, swd: 1.5515, ept: 160.8999
      Epoch 5 composite train-obj: 1.035214
            No improvement (1.5371), counter 4/5
    Epoch [6/50], Train Losses: mse: 5.1748, mae: 1.3504, huber: 0.9814, swd: 0.7805, ept: 209.3178
    Epoch [6/50], Val Losses: mse: 15.8041, mae: 2.2300, huber: 1.8429, swd: 2.4710, ept: 177.7041
    Epoch [6/50], Test Losses: mse: 18.3882, mae: 2.5549, huber: 2.1558, swd: 2.8263, ept: 164.9320
      Epoch 6 composite train-obj: 0.981396
    Epoch [6/50], Test Losses: mse: 10.6049, mae: 1.8279, huber: 1.4510, swd: 1.7429, ept: 190.4816
    Best round's Test MSE: 10.6049, MAE: 1.8279, SWD: 1.7429
    Best round's Validation MSE: 8.8971, MAE: 1.5673, SWD: 0.9685
    Best round's Test verification MSE : 10.6049, MAE: 1.8279, SWD: 1.7429
    Time taken: 227.04 seconds
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.4209, mae: 1.8196, huber: 1.4326, swd: 1.9497, ept: 164.7426
    Epoch [1/50], Val Losses: mse: 9.3240, mae: 1.6284, huber: 1.2623, swd: 1.1950, ept: 202.0037
    Epoch [1/50], Test Losses: mse: 10.5207, mae: 1.8466, huber: 1.4647, swd: 1.7627, ept: 188.6618
      Epoch 1 composite train-obj: 1.432638
            Val objective improved inf → 1.2623, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.0214, mae: 1.5989, huber: 1.2188, swd: 1.4799, ept: 193.2380
    Epoch [2/50], Val Losses: mse: 9.0233, mae: 1.6013, huber: 1.2371, swd: 0.8502, ept: 212.5536
    Epoch [2/50], Test Losses: mse: 10.4288, mae: 1.8353, huber: 1.4541, swd: 1.4764, ept: 192.2932
      Epoch 2 composite train-obj: 1.218755
            Val objective improved 1.2623 → 1.2371, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.5544, mae: 1.5397, huber: 1.1616, swd: 1.2912, ept: 195.2422
    Epoch [3/50], Val Losses: mse: 10.0756, mae: 1.6600, huber: 1.2946, swd: 1.1778, ept: 205.6732
    Epoch [3/50], Test Losses: mse: 10.4274, mae: 1.8472, huber: 1.4650, swd: 1.6890, ept: 187.0828
      Epoch 3 composite train-obj: 1.161573
            No improvement (1.2946), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.0689, mae: 1.4782, huber: 1.1018, swd: 1.0876, ept: 196.9405
    Epoch [4/50], Val Losses: mse: 9.5221, mae: 1.6344, huber: 1.2680, swd: 1.1999, ept: 205.1506
    Epoch [4/50], Test Losses: mse: 10.5158, mae: 1.8615, huber: 1.4795, swd: 2.0067, ept: 185.3645
      Epoch 4 composite train-obj: 1.101842
            No improvement (1.2680), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.5912, mae: 1.4150, huber: 1.0411, swd: 0.9009, ept: 200.8950
    Epoch [5/50], Val Losses: mse: 10.2327, mae: 1.7066, huber: 1.3369, swd: 1.2722, ept: 202.2851
    Epoch [5/50], Test Losses: mse: 11.4058, mae: 1.9690, huber: 1.5821, swd: 2.1946, ept: 181.6237
      Epoch 5 composite train-obj: 1.041120
            No improvement (1.3369), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.1837, mae: 1.3560, huber: 0.9852, swd: 0.7656, ept: 205.8721
    Epoch [6/50], Val Losses: mse: 11.1852, mae: 1.7738, huber: 1.4027, swd: 1.2805, ept: 197.4552
    Epoch [6/50], Test Losses: mse: 12.0707, mae: 2.0182, huber: 1.6309, swd: 2.1457, ept: 172.7620
      Epoch 6 composite train-obj: 0.985249
            No improvement (1.4027), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.8511, mae: 1.3062, huber: 0.9383, swd: 0.6811, ept: 210.0738
    Epoch [7/50], Val Losses: mse: 11.1879, mae: 1.7978, huber: 1.4243, swd: 0.9870, ept: 196.9122
    Epoch [7/50], Test Losses: mse: 12.4884, mae: 2.0360, huber: 1.6492, swd: 1.3300, ept: 174.9137
      Epoch 7 composite train-obj: 0.938344
    Epoch [7/50], Test Losses: mse: 10.4288, mae: 1.8353, huber: 1.4541, swd: 1.4764, ept: 192.2932
    Best round's Test MSE: 10.4288, MAE: 1.8353, SWD: 1.4764
    Best round's Validation MSE: 9.0233, MAE: 1.6013, SWD: 0.8502
    Best round's Test verification MSE : 10.4288, MAE: 1.8353, SWD: 1.4764
    Time taken: 264.61 seconds
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 9.1387, mae: 1.7928, huber: 1.4062, swd: 2.0676, ept: 167.2943
    Epoch [1/50], Val Losses: mse: 9.0220, mae: 1.5945, huber: 1.2297, swd: 1.0258, ept: 209.1217
    Epoch [1/50], Test Losses: mse: 10.4895, mae: 1.8318, huber: 1.4519, swd: 1.8200, ept: 189.3360
      Epoch 1 composite train-obj: 1.406167
            Val objective improved inf → 1.2297, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 7.1093, mae: 1.6070, huber: 1.2265, swd: 1.6538, ept: 193.5371
    Epoch [2/50], Val Losses: mse: 8.2080, mae: 1.5271, huber: 1.1665, swd: 1.4251, ept: 217.4743
    Epoch [2/50], Test Losses: mse: 10.5881, mae: 1.8689, huber: 1.4865, swd: 2.8146, ept: 192.6575
      Epoch 2 composite train-obj: 1.226489
            Val objective improved 1.2297 → 1.1665, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.7476, mae: 1.5615, huber: 1.1826, swd: 1.4949, ept: 195.3341
    Epoch [3/50], Val Losses: mse: 10.0872, mae: 1.6324, huber: 1.2680, swd: 1.1726, ept: 203.8316
    Epoch [3/50], Test Losses: mse: 10.2928, mae: 1.8516, huber: 1.4683, swd: 1.9686, ept: 188.7569
      Epoch 3 composite train-obj: 1.182639
            No improvement (1.2680), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.3510, mae: 1.5108, huber: 1.1339, swd: 1.3023, ept: 197.8093
    Epoch [4/50], Val Losses: mse: 9.7149, mae: 1.6522, huber: 1.2848, swd: 1.3045, ept: 200.4718
    Epoch [4/50], Test Losses: mse: 10.3478, mae: 1.8643, huber: 1.4807, swd: 1.8789, ept: 185.8455
      Epoch 4 composite train-obj: 1.133918
            No improvement (1.2848), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.9614, mae: 1.4580, huber: 1.0836, swd: 1.1277, ept: 201.7093
    Epoch [5/50], Val Losses: mse: 16.5275, mae: 2.2282, huber: 1.8419, swd: 1.1211, ept: 183.3925
    Epoch [5/50], Test Losses: mse: 16.7066, mae: 2.4544, huber: 2.0540, swd: 1.3864, ept: 159.8910
      Epoch 5 composite train-obj: 1.083559
            No improvement (1.8419), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.5993, mae: 1.4075, huber: 1.0359, swd: 0.9856, ept: 206.7263
    Epoch [6/50], Val Losses: mse: 11.9456, mae: 1.8628, huber: 1.4875, swd: 1.1782, ept: 190.7239
    Epoch [6/50], Test Losses: mse: 12.5083, mae: 2.0818, huber: 1.6914, swd: 1.4294, ept: 168.3360
      Epoch 6 composite train-obj: 1.035855
            No improvement (1.4875), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.2861, mae: 1.3624, huber: 0.9934, swd: 0.8664, ept: 210.3274
    Epoch [7/50], Val Losses: mse: 11.3023, mae: 1.8587, huber: 1.4830, swd: 1.3028, ept: 205.5851
    Epoch [7/50], Test Losses: mse: 13.3639, mae: 2.1641, huber: 1.7726, swd: 2.0923, ept: 176.7592
      Epoch 7 composite train-obj: 0.993358
    Epoch [7/50], Test Losses: mse: 10.5881, mae: 1.8689, huber: 1.4865, swd: 2.8146, ept: 192.6575
    Best round's Test MSE: 10.5881, MAE: 1.8689, SWD: 2.8146
    Best round's Validation MSE: 8.2080, MAE: 1.5271, SWD: 1.4251
    Best round's Test verification MSE : 10.5881, MAE: 1.8689, SWD: 2.8146
    Time taken: 264.85 seconds
    
    ==================================================
    Experiment Summary (PatchTST_ettm1_seq720_pred720_20250512_1733)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.5406 ± 0.0794
      mae: 1.8441 ± 0.0178
      huber: 1.4639 ± 0.0161
      swd: 2.0113 ± 0.5783
      ept: 191.8108 ± 0.9516
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.7094 ± 0.3583
      mae: 1.5652 ± 0.0303
      huber: 1.2026 ± 0.0288
      swd: 1.0813 ± 0.2478
      ept: 214.1170 ± 2.3758
      count: 44.0000 ± 0.0000
    ==================================================
    Three seeds Time taken: 756.77 seconds
    
    Experiment complete: PatchTST_ettm1_seq720_pred720_20250512_1733
    Model: PatchTST
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    

### DLinear

#### 720-96



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=96,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_336_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([96, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 375
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 96, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 96
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 375
    Validation Batches: 49
    Test Batches: 103
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.5251, mae: 1.3189, huber: 0.9651, swd: 1.7369, target_std: 6.4713
    Epoch [1/50], Val Losses: mse: 5.6397, mae: 1.2261, huber: 0.8826, swd: 0.9798, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.6110, mae: 1.4167, huber: 1.0705, swd: 1.3439, target_std: 4.7550
      Epoch 1 composite train-obj: 0.965111
            Val objective improved inf → 0.8826, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3622, mae: 1.1794, huber: 0.8355, swd: 1.3495, target_std: 6.4715
    Epoch [2/50], Val Losses: mse: 5.5766, mae: 1.2203, huber: 0.8762, swd: 0.9282, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.5776, mae: 1.4137, huber: 1.0654, swd: 1.3305, target_std: 4.7550
      Epoch 2 composite train-obj: 0.835548
            Val objective improved 0.8826 → 0.8762, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.3344, mae: 1.1748, huber: 0.8311, swd: 1.3341, target_std: 6.4719
    Epoch [3/50], Val Losses: mse: 5.5757, mae: 1.2081, huber: 0.8661, swd: 0.9410, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.5222, mae: 1.3991, huber: 1.0539, swd: 1.3193, target_std: 4.7550
      Epoch 3 composite train-obj: 0.831146
            Val objective improved 0.8762 → 0.8661, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.3228, mae: 1.1725, huber: 0.8289, swd: 1.3313, target_std: 6.4711
    Epoch [4/50], Val Losses: mse: 5.5837, mae: 1.2176, huber: 0.8750, swd: 0.9068, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 7.5630, mae: 1.4088, huber: 1.0623, swd: 1.2833, target_std: 4.7550
      Epoch 4 composite train-obj: 0.828949
            No improvement (0.8750), counter 1/5
    Epoch [5/50], Train Losses: mse: 4.3455, mae: 1.1762, huber: 0.8326, swd: 1.3400, target_std: 6.4717
    Epoch [5/50], Val Losses: mse: 5.5621, mae: 1.2134, huber: 0.8707, swd: 0.9384, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 7.5752, mae: 1.4143, huber: 1.0670, swd: 1.4072, target_std: 4.7550
      Epoch 5 composite train-obj: 0.832615
            No improvement (0.8707), counter 2/5
    Epoch [6/50], Train Losses: mse: 4.3170, mae: 1.1719, huber: 0.8286, swd: 1.3261, target_std: 6.4718
    Epoch [6/50], Val Losses: mse: 5.6178, mae: 1.2136, huber: 0.8709, swd: 0.9050, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 7.5884, mae: 1.4047, huber: 1.0589, swd: 1.2636, target_std: 4.7550
      Epoch 6 composite train-obj: 0.828574
            No improvement (0.8709), counter 3/5
    Epoch [7/50], Train Losses: mse: 4.3260, mae: 1.1725, huber: 0.8291, swd: 1.3293, target_std: 6.4715
    Epoch [7/50], Val Losses: mse: 5.6587, mae: 1.2184, huber: 0.8760, swd: 0.9183, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 7.5608, mae: 1.4048, huber: 1.0586, swd: 1.2778, target_std: 4.7550
      Epoch 7 composite train-obj: 0.829150
            No improvement (0.8760), counter 4/5
    Epoch [8/50], Train Losses: mse: 4.3174, mae: 1.1713, huber: 0.8281, swd: 1.3296, target_std: 6.4716
    Epoch [8/50], Val Losses: mse: 5.6302, mae: 1.2177, huber: 0.8744, swd: 0.8901, target_std: 4.3137
    Epoch [8/50], Test Losses: mse: 7.6125, mae: 1.4082, huber: 1.0617, swd: 1.2538, target_std: 4.7550
      Epoch 8 composite train-obj: 0.828147
    Epoch [8/50], Test Losses: mse: 7.5222, mae: 1.3991, huber: 1.0539, swd: 1.3193, target_std: 4.7550
    Best round's Test MSE: 7.5222, MAE: 1.3991, SWD: 1.3193
    Best round's Validation MSE: 5.5757, MAE: 1.2081
    Best round's Test verification MSE : 7.5222, MAE: 1.3991, SWD: 1.3193
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.5183, mae: 1.3151, huber: 0.9611, swd: 1.6535, target_std: 6.4720
    Epoch [1/50], Val Losses: mse: 5.6696, mae: 1.2221, huber: 0.8788, swd: 0.9241, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.7082, mae: 1.4191, huber: 1.0717, swd: 1.3550, target_std: 4.7550
      Epoch 1 composite train-obj: 0.961111
            Val objective improved inf → 0.8788, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3581, mae: 1.1791, huber: 0.8351, swd: 1.3349, target_std: 6.4715
    Epoch [2/50], Val Losses: mse: 5.5874, mae: 1.2186, huber: 0.8734, swd: 0.9571, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.5702, mae: 1.4183, huber: 1.0690, swd: 1.3708, target_std: 4.7550
      Epoch 2 composite train-obj: 0.835134
            Val objective improved 0.8788 → 0.8734, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.3505, mae: 1.1779, huber: 0.8341, swd: 1.3300, target_std: 6.4717
    Epoch [3/50], Val Losses: mse: 5.7034, mae: 1.2282, huber: 0.8848, swd: 0.9871, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.5647, mae: 1.4078, huber: 1.0622, swd: 1.3508, target_std: 4.7550
      Epoch 3 composite train-obj: 0.834123
            No improvement (0.8848), counter 1/5
    Epoch [4/50], Train Losses: mse: 4.3253, mae: 1.1728, huber: 0.8294, swd: 1.3166, target_std: 6.4713
    Epoch [4/50], Val Losses: mse: 5.6417, mae: 1.2300, huber: 0.8855, swd: 1.0918, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 7.4620, mae: 1.4041, huber: 1.0560, swd: 1.4632, target_std: 4.7550
      Epoch 4 composite train-obj: 0.829403
            No improvement (0.8855), counter 2/5
    Epoch [5/50], Train Losses: mse: 4.3285, mae: 1.1731, huber: 0.8299, swd: 1.3188, target_std: 6.4719
    Epoch [5/50], Val Losses: mse: 5.6154, mae: 1.2291, huber: 0.8858, swd: 1.0447, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 7.5347, mae: 1.4089, huber: 1.0617, swd: 1.4591, target_std: 4.7550
      Epoch 5 composite train-obj: 0.829861
            No improvement (0.8858), counter 3/5
    Epoch [6/50], Train Losses: mse: 4.3196, mae: 1.1722, huber: 0.8287, swd: 1.3171, target_std: 6.4718
    Epoch [6/50], Val Losses: mse: 5.5740, mae: 1.2198, huber: 0.8763, swd: 0.9992, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 7.5114, mae: 1.4055, huber: 1.0590, swd: 1.4142, target_std: 4.7550
      Epoch 6 composite train-obj: 0.828681
            No improvement (0.8763), counter 4/5
    Epoch [7/50], Train Losses: mse: 4.3288, mae: 1.1736, huber: 0.8302, swd: 1.3158, target_std: 6.4716
    Epoch [7/50], Val Losses: mse: 5.5633, mae: 1.2171, huber: 0.8740, swd: 1.0348, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 7.4917, mae: 1.4012, huber: 1.0545, swd: 1.4012, target_std: 4.7550
      Epoch 7 composite train-obj: 0.830225
    Epoch [7/50], Test Losses: mse: 7.5702, mae: 1.4183, huber: 1.0690, swd: 1.3708, target_std: 4.7550
    Best round's Test MSE: 7.5702, MAE: 1.4183, SWD: 1.3708
    Best round's Validation MSE: 5.5874, MAE: 1.2186
    Best round's Test verification MSE : 7.5702, MAE: 1.4183, SWD: 1.3708
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 5.5685, mae: 1.3181, huber: 0.9642, swd: 1.5585, target_std: 6.4721
    Epoch [1/50], Val Losses: mse: 5.6504, mae: 1.2199, huber: 0.8768, swd: 0.8743, target_std: 4.3137
    Epoch [1/50], Test Losses: mse: 7.6541, mae: 1.4173, huber: 1.0705, swd: 1.2313, target_std: 4.7550
      Epoch 1 composite train-obj: 0.964192
            Val objective improved inf → 0.8768, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 4.3571, mae: 1.1789, huber: 0.8350, swd: 1.2402, target_std: 6.4716
    Epoch [2/50], Val Losses: mse: 5.5853, mae: 1.2112, huber: 0.8696, swd: 0.8813, target_std: 4.3137
    Epoch [2/50], Test Losses: mse: 7.5361, mae: 1.3980, huber: 1.0526, swd: 1.2274, target_std: 4.7550
      Epoch 2 composite train-obj: 0.834999
            Val objective improved 0.8768 → 0.8696, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 4.3376, mae: 1.1744, huber: 0.8310, swd: 1.2293, target_std: 6.4717
    Epoch [3/50], Val Losses: mse: 5.5117, mae: 1.2121, huber: 0.8685, swd: 0.9507, target_std: 4.3137
    Epoch [3/50], Test Losses: mse: 7.4814, mae: 1.4067, huber: 1.0592, swd: 1.3250, target_std: 4.7550
      Epoch 3 composite train-obj: 0.831007
            Val objective improved 0.8696 → 0.8685, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 4.3379, mae: 1.1746, huber: 0.8311, swd: 1.2267, target_std: 6.4714
    Epoch [4/50], Val Losses: mse: 5.5668, mae: 1.2046, huber: 0.8633, swd: 0.8511, target_std: 4.3137
    Epoch [4/50], Test Losses: mse: 7.5326, mae: 1.4022, huber: 1.0560, swd: 1.2160, target_std: 4.7550
      Epoch 4 composite train-obj: 0.831093
            Val objective improved 0.8685 → 0.8633, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 4.3225, mae: 1.1731, huber: 0.8295, swd: 1.2258, target_std: 6.4715
    Epoch [5/50], Val Losses: mse: 5.6107, mae: 1.2135, huber: 0.8705, swd: 0.8476, target_std: 4.3137
    Epoch [5/50], Test Losses: mse: 7.5407, mae: 1.4043, huber: 1.0575, swd: 1.2232, target_std: 4.7550
      Epoch 5 composite train-obj: 0.829494
            No improvement (0.8705), counter 1/5
    Epoch [6/50], Train Losses: mse: 4.3343, mae: 1.1744, huber: 0.8310, swd: 1.2268, target_std: 6.4720
    Epoch [6/50], Val Losses: mse: 5.7042, mae: 1.2207, huber: 0.8775, swd: 0.8082, target_std: 4.3137
    Epoch [6/50], Test Losses: mse: 7.6631, mae: 1.4130, huber: 1.0669, swd: 1.1883, target_std: 4.7550
      Epoch 6 composite train-obj: 0.830955
            No improvement (0.8775), counter 2/5
    Epoch [7/50], Train Losses: mse: 4.3210, mae: 1.1720, huber: 0.8289, swd: 1.2234, target_std: 6.4720
    Epoch [7/50], Val Losses: mse: 5.5723, mae: 1.2051, huber: 0.8637, swd: 0.8259, target_std: 4.3137
    Epoch [7/50], Test Losses: mse: 7.5748, mae: 1.4028, huber: 1.0580, swd: 1.1922, target_std: 4.7550
      Epoch 7 composite train-obj: 0.828876
            No improvement (0.8637), counter 3/5
    Epoch [8/50], Train Losses: mse: 4.3176, mae: 1.1728, huber: 0.8292, swd: 1.2248, target_std: 6.4715
    Epoch [8/50], Val Losses: mse: 5.5033, mae: 1.2022, huber: 0.8599, swd: 0.8585, target_std: 4.3137
    Epoch [8/50], Test Losses: mse: 7.4940, mae: 1.3946, huber: 1.0498, swd: 1.2128, target_std: 4.7550
      Epoch 8 composite train-obj: 0.829158
            Val objective improved 0.8633 → 0.8599, saving checkpoint.
    Epoch [9/50], Train Losses: mse: 4.3383, mae: 1.1755, huber: 0.8320, swd: 1.2303, target_std: 6.4716
    Epoch [9/50], Val Losses: mse: 5.5939, mae: 1.2144, huber: 0.8724, swd: 0.9105, target_std: 4.3137
    Epoch [9/50], Test Losses: mse: 7.5196, mae: 1.4034, huber: 1.0578, swd: 1.2997, target_std: 4.7550
      Epoch 9 composite train-obj: 0.831959
            No improvement (0.8724), counter 1/5
    Epoch [10/50], Train Losses: mse: 4.3206, mae: 1.1728, huber: 0.8294, swd: 1.2304, target_std: 6.4717
    Epoch [10/50], Val Losses: mse: 5.6146, mae: 1.2233, huber: 0.8796, swd: 0.9400, target_std: 4.3137
    Epoch [10/50], Test Losses: mse: 7.5229, mae: 1.3990, huber: 1.0523, swd: 1.2361, target_std: 4.7550
      Epoch 10 composite train-obj: 0.829397
            No improvement (0.8796), counter 2/5
    Epoch [11/50], Train Losses: mse: 4.3123, mae: 1.1705, huber: 0.8273, swd: 1.2241, target_std: 6.4718
    Epoch [11/50], Val Losses: mse: 5.5686, mae: 1.2080, huber: 0.8666, swd: 0.8556, target_std: 4.3137
    Epoch [11/50], Test Losses: mse: 7.5371, mae: 1.3997, huber: 1.0550, swd: 1.2132, target_std: 4.7550
      Epoch 11 composite train-obj: 0.827284
            No improvement (0.8666), counter 3/5
    Epoch [12/50], Train Losses: mse: 4.3253, mae: 1.1729, huber: 0.8296, swd: 1.2233, target_std: 6.4719
    Epoch [12/50], Val Losses: mse: 5.4947, mae: 1.2021, huber: 0.8594, swd: 0.8452, target_std: 4.3137
    Epoch [12/50], Test Losses: mse: 7.5263, mae: 1.4025, huber: 1.0550, swd: 1.2113, target_std: 4.7550
      Epoch 12 composite train-obj: 0.829592
            Val objective improved 0.8599 → 0.8594, saving checkpoint.
    Epoch [13/50], Train Losses: mse: 4.3171, mae: 1.1715, huber: 0.8283, swd: 1.2220, target_std: 6.4715
    Epoch [13/50], Val Losses: mse: 5.6307, mae: 1.2183, huber: 0.8754, swd: 0.8789, target_std: 4.3137
    Epoch [13/50], Test Losses: mse: 7.5527, mae: 1.4001, huber: 1.0549, swd: 1.2464, target_std: 4.7550
      Epoch 13 composite train-obj: 0.828270
            No improvement (0.8754), counter 1/5
    Epoch [14/50], Train Losses: mse: 4.3281, mae: 1.1743, huber: 0.8305, swd: 1.2253, target_std: 6.4714
    Epoch [14/50], Val Losses: mse: 5.6131, mae: 1.2124, huber: 0.8703, swd: 0.8342, target_std: 4.3137
    Epoch [14/50], Test Losses: mse: 7.5812, mae: 1.4056, huber: 1.0602, swd: 1.1724, target_std: 4.7550
      Epoch 14 composite train-obj: 0.830523
            No improvement (0.8703), counter 2/5
    Epoch [15/50], Train Losses: mse: 4.3330, mae: 1.1739, huber: 0.8306, swd: 1.2291, target_std: 6.4714
    Epoch [15/50], Val Losses: mse: 5.5219, mae: 1.2035, huber: 0.8617, swd: 0.8591, target_std: 4.3137
    Epoch [15/50], Test Losses: mse: 7.5575, mae: 1.4008, huber: 1.0553, swd: 1.2180, target_std: 4.7550
      Epoch 15 composite train-obj: 0.830555
            No improvement (0.8617), counter 3/5
    Epoch [16/50], Train Losses: mse: 4.3211, mae: 1.1734, huber: 0.8299, swd: 1.2270, target_std: 6.4719
    Epoch [16/50], Val Losses: mse: 5.5783, mae: 1.2113, huber: 0.8696, swd: 0.8854, target_std: 4.3137
    Epoch [16/50], Test Losses: mse: 7.5588, mae: 1.4007, huber: 1.0556, swd: 1.2450, target_std: 4.7550
      Epoch 16 composite train-obj: 0.829857
            No improvement (0.8696), counter 4/5
    Epoch [17/50], Train Losses: mse: 4.3165, mae: 1.1712, huber: 0.8280, swd: 1.2224, target_std: 6.4717
    Epoch [17/50], Val Losses: mse: 5.5930, mae: 1.2276, huber: 0.8846, swd: 1.0595, target_std: 4.3137
    Epoch [17/50], Test Losses: mse: 7.4197, mae: 1.3912, huber: 1.0465, swd: 1.3495, target_std: 4.7550
      Epoch 17 composite train-obj: 0.828011
    Epoch [17/50], Test Losses: mse: 7.5263, mae: 1.4025, huber: 1.0550, swd: 1.2113, target_std: 4.7550
    Best round's Test MSE: 7.5263, MAE: 1.4025, SWD: 1.2113
    Best round's Validation MSE: 5.4947, MAE: 1.2021
    Best round's Test verification MSE : 7.5263, MAE: 1.4025, SWD: 1.2113
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq720_pred96_20250429_1939)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 7.5396 ± 0.0217
      mae: 1.4066 ± 0.0083
      huber: 1.0593 ± 0.0069
      swd: 1.3005 ± 0.0664
      target_std: 4.7550 ± 0.0000
      count: 49.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 5.5526 ± 0.0412
      mae: 1.2096 ± 0.0068
      huber: 0.8663 ± 0.0057
      swd: 0.9145 ± 0.0494
      target_std: 4.3137 ± 0.0000
      count: 49.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq720_pred96_20250429_1939
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 96
    Seeds: [1955, 7, 20]
    

#### 720-196



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=196,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_720_196 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 374
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 374
    Validation Batches: 48
    Test Batches: 102
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.3281, mae: 1.4317, huber: 1.0704, swd: 1.8242, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 6.5412, mae: 1.3365, huber: 0.9858, swd: 1.0074, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.2614, mae: 1.5858, huber: 1.2295, swd: 1.5761, target_std: 4.7514
      Epoch 1 composite train-obj: 1.070422
            Val objective improved inf → 0.9858, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.3437, mae: 1.3189, huber: 0.9653, swd: 1.5769, target_std: 6.4712
    Epoch [2/50], Val Losses: mse: 6.5041, mae: 1.3255, huber: 0.9767, swd: 1.0304, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 9.1574, mae: 1.5691, huber: 1.2145, swd: 1.5211, target_std: 4.7514
      Epoch 2 composite train-obj: 0.965290
            Val objective improved 0.9858 → 0.9767, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3255, mae: 1.3159, huber: 0.9627, swd: 1.5688, target_std: 6.4712
    Epoch [3/50], Val Losses: mse: 6.5099, mae: 1.3276, huber: 0.9779, swd: 0.9926, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.0994, mae: 1.5662, huber: 1.2115, swd: 1.5136, target_std: 4.7514
      Epoch 3 composite train-obj: 0.962667
            No improvement (0.9779), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.2991, mae: 1.3121, huber: 0.9590, swd: 1.5534, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 6.4364, mae: 1.3133, huber: 0.9642, swd: 0.8462, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.2121, mae: 1.5768, huber: 1.2214, swd: 1.4380, target_std: 4.7514
      Epoch 4 composite train-obj: 0.958972
            Val objective improved 0.9767 → 0.9642, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.2863, mae: 1.3099, huber: 0.9570, swd: 1.5474, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 6.4958, mae: 1.3246, huber: 0.9745, swd: 0.8662, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 9.2350, mae: 1.5810, huber: 1.2252, swd: 1.4977, target_std: 4.7514
      Epoch 5 composite train-obj: 0.956968
            No improvement (0.9745), counter 1/5
    Epoch [6/50], Train Losses: mse: 5.3179, mae: 1.3149, huber: 0.9615, swd: 1.5660, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 6.4688, mae: 1.3236, huber: 0.9737, swd: 0.8602, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 9.2569, mae: 1.5817, huber: 1.2264, swd: 1.4269, target_std: 4.7514
      Epoch 6 composite train-obj: 0.961544
            No improvement (0.9737), counter 2/5
    Epoch [7/50], Train Losses: mse: 5.3011, mae: 1.3120, huber: 0.9589, swd: 1.5524, target_std: 6.4712
    Epoch [7/50], Val Losses: mse: 6.4573, mae: 1.3147, huber: 0.9645, swd: 0.8453, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 9.1441, mae: 1.5733, huber: 1.2172, swd: 1.4444, target_std: 4.7514
      Epoch 7 composite train-obj: 0.958878
            No improvement (0.9645), counter 3/5
    Epoch [8/50], Train Losses: mse: 5.3156, mae: 1.3148, huber: 0.9614, swd: 1.5615, target_std: 6.4712
    Epoch [8/50], Val Losses: mse: 6.5037, mae: 1.3372, huber: 0.9862, swd: 1.0264, target_std: 4.3103
    Epoch [8/50], Test Losses: mse: 9.1495, mae: 1.5802, huber: 1.2225, swd: 1.5698, target_std: 4.7514
      Epoch 8 composite train-obj: 0.961359
            No improvement (0.9862), counter 4/5
    Epoch [9/50], Train Losses: mse: 5.3082, mae: 1.3138, huber: 0.9606, swd: 1.5583, target_std: 6.4713
    Epoch [9/50], Val Losses: mse: 6.4415, mae: 1.3188, huber: 0.9695, swd: 0.9242, target_std: 4.3103
    Epoch [9/50], Test Losses: mse: 9.1371, mae: 1.5743, huber: 1.2177, swd: 1.4970, target_std: 4.7514
      Epoch 9 composite train-obj: 0.960550
    Epoch [9/50], Test Losses: mse: 9.2121, mae: 1.5768, huber: 1.2214, swd: 1.4380, target_std: 4.7514
    Best round's Test MSE: 9.2121, MAE: 1.5768, SWD: 1.4380
    Best round's Validation MSE: 6.4364, MAE: 1.3133
    Best round's Test verification MSE : 9.2121, MAE: 1.5768, SWD: 1.4380
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.4052, mae: 1.4352, huber: 1.0738, swd: 1.9172, target_std: 6.4713
    Epoch [1/50], Val Losses: mse: 6.4318, mae: 1.3225, huber: 0.9714, swd: 0.9394, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.3326, mae: 1.5972, huber: 1.2408, swd: 1.5782, target_std: 4.7514
      Epoch 1 composite train-obj: 1.073827
            Val objective improved inf → 0.9714, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.3363, mae: 1.3179, huber: 0.9645, swd: 1.6110, target_std: 6.4713
    Epoch [2/50], Val Losses: mse: 6.5230, mae: 1.3291, huber: 0.9793, swd: 0.9208, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 9.2603, mae: 1.5852, huber: 1.2301, swd: 1.5154, target_std: 4.7514
      Epoch 2 composite train-obj: 0.964531
            No improvement (0.9793), counter 1/5
    Epoch [3/50], Train Losses: mse: 5.3431, mae: 1.3178, huber: 0.9646, swd: 1.6080, target_std: 6.4712
    Epoch [3/50], Val Losses: mse: 6.4635, mae: 1.3278, huber: 0.9773, swd: 0.9623, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.1621, mae: 1.5759, huber: 1.2204, swd: 1.5308, target_std: 4.7514
      Epoch 3 composite train-obj: 0.964553
            No improvement (0.9773), counter 2/5
    Epoch [4/50], Train Losses: mse: 5.3068, mae: 1.3120, huber: 0.9591, swd: 1.5938, target_std: 6.4713
    Epoch [4/50], Val Losses: mse: 6.4625, mae: 1.3194, huber: 0.9711, swd: 0.9957, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.1603, mae: 1.5717, huber: 1.2172, swd: 1.5393, target_std: 4.7514
      Epoch 4 composite train-obj: 0.959120
            Val objective improved 0.9714 → 0.9711, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 5.3031, mae: 1.3131, huber: 0.9599, swd: 1.5979, target_std: 6.4712
    Epoch [5/50], Val Losses: mse: 6.4383, mae: 1.3135, huber: 0.9650, swd: 0.8519, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 9.2806, mae: 1.5780, huber: 1.2236, swd: 1.4347, target_std: 4.7514
      Epoch 5 composite train-obj: 0.959936
            Val objective improved 0.9711 → 0.9650, saving checkpoint.
    Epoch [6/50], Train Losses: mse: 5.2917, mae: 1.3108, huber: 0.9577, swd: 1.5833, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 6.4949, mae: 1.3403, huber: 0.9911, swd: 1.2408, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 9.0967, mae: 1.5683, huber: 1.2150, swd: 1.7335, target_std: 4.7514
      Epoch 6 composite train-obj: 0.957668
            No improvement (0.9911), counter 1/5
    Epoch [7/50], Train Losses: mse: 5.3029, mae: 1.3129, huber: 0.9597, swd: 1.5919, target_std: 6.4713
    Epoch [7/50], Val Losses: mse: 6.4702, mae: 1.3233, huber: 0.9736, swd: 0.9416, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 9.2222, mae: 1.5749, huber: 1.2199, swd: 1.5254, target_std: 4.7514
      Epoch 7 composite train-obj: 0.959681
            No improvement (0.9736), counter 2/5
    Epoch [8/50], Train Losses: mse: 5.2951, mae: 1.3111, huber: 0.9579, swd: 1.5877, target_std: 6.4712
    Epoch [8/50], Val Losses: mse: 6.5057, mae: 1.3248, huber: 0.9758, swd: 0.9996, target_std: 4.3103
    Epoch [8/50], Test Losses: mse: 9.1847, mae: 1.5667, huber: 1.2116, swd: 1.4836, target_std: 4.7514
      Epoch 8 composite train-obj: 0.957940
            No improvement (0.9758), counter 3/5
    Epoch [9/50], Train Losses: mse: 5.2874, mae: 1.3112, huber: 0.9579, swd: 1.5815, target_std: 6.4712
    Epoch [9/50], Val Losses: mse: 6.3763, mae: 1.3080, huber: 0.9595, swd: 0.8965, target_std: 4.3103
    Epoch [9/50], Test Losses: mse: 9.2112, mae: 1.5761, huber: 1.2212, swd: 1.4853, target_std: 4.7514
      Epoch 9 composite train-obj: 0.957901
            Val objective improved 0.9650 → 0.9595, saving checkpoint.
    Epoch [10/50], Train Losses: mse: 5.2814, mae: 1.3090, huber: 0.9562, swd: 1.5749, target_std: 6.4713
    Epoch [10/50], Val Losses: mse: 6.4309, mae: 1.3171, huber: 0.9689, swd: 0.9223, target_std: 4.3103
    Epoch [10/50], Test Losses: mse: 9.1929, mae: 1.5710, huber: 1.2165, swd: 1.4839, target_std: 4.7514
      Epoch 10 composite train-obj: 0.956152
            No improvement (0.9689), counter 1/5
    Epoch [11/50], Train Losses: mse: 5.2960, mae: 1.3124, huber: 0.9591, swd: 1.5838, target_std: 6.4712
    Epoch [11/50], Val Losses: mse: 6.5681, mae: 1.3496, huber: 0.9992, swd: 1.1839, target_std: 4.3103
    Epoch [11/50], Test Losses: mse: 9.1405, mae: 1.5748, huber: 1.2200, swd: 1.6751, target_std: 4.7514
      Epoch 11 composite train-obj: 0.959055
            No improvement (0.9992), counter 2/5
    Epoch [12/50], Train Losses: mse: 5.2855, mae: 1.3108, huber: 0.9576, swd: 1.5770, target_std: 6.4713
    Epoch [12/50], Val Losses: mse: 6.4649, mae: 1.3275, huber: 0.9786, swd: 1.0517, target_std: 4.3103
    Epoch [12/50], Test Losses: mse: 9.1014, mae: 1.5674, huber: 1.2125, swd: 1.5758, target_std: 4.7514
      Epoch 12 composite train-obj: 0.957586
            No improvement (0.9786), counter 3/5
    Epoch [13/50], Train Losses: mse: 5.2828, mae: 1.3102, huber: 0.9569, swd: 1.5752, target_std: 6.4713
    Epoch [13/50], Val Losses: mse: 6.6465, mae: 1.3643, huber: 1.0122, swd: 1.2862, target_std: 4.3103
    Epoch [13/50], Test Losses: mse: 9.0735, mae: 1.5742, huber: 1.2166, swd: 1.6742, target_std: 4.7514
      Epoch 13 composite train-obj: 0.956904
            No improvement (1.0122), counter 4/5
    Epoch [14/50], Train Losses: mse: 5.2782, mae: 1.3093, huber: 0.9563, swd: 1.5809, target_std: 6.4714
    Epoch [14/50], Val Losses: mse: 6.4235, mae: 1.3123, huber: 0.9651, swd: 0.9350, target_std: 4.3103
    Epoch [14/50], Test Losses: mse: 9.1347, mae: 1.5662, huber: 1.2123, swd: 1.4765, target_std: 4.7514
      Epoch 14 composite train-obj: 0.956254
    Epoch [14/50], Test Losses: mse: 9.2112, mae: 1.5761, huber: 1.2212, swd: 1.4853, target_std: 4.7514
    Best round's Test MSE: 9.2112, MAE: 1.5761, SWD: 1.4853
    Best round's Validation MSE: 6.3763, MAE: 1.3080
    Best round's Test verification MSE : 9.2112, MAE: 1.5761, SWD: 1.4853
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 6.3839, mae: 1.4311, huber: 1.0700, swd: 1.6535, target_std: 6.4712
    Epoch [1/50], Val Losses: mse: 6.4882, mae: 1.3231, huber: 0.9736, swd: 0.9234, target_std: 4.3103
    Epoch [1/50], Test Losses: mse: 9.2783, mae: 1.5817, huber: 1.2263, swd: 1.4800, target_std: 4.7514
      Epoch 1 composite train-obj: 1.070040
            Val objective improved inf → 0.9736, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 5.3446, mae: 1.3193, huber: 0.9658, swd: 1.4228, target_std: 6.4713
    Epoch [2/50], Val Losses: mse: 6.4140, mae: 1.3178, huber: 0.9674, swd: 0.8372, target_std: 4.3103
    Epoch [2/50], Test Losses: mse: 9.2627, mae: 1.5881, huber: 1.2312, swd: 1.4772, target_std: 4.7514
      Epoch 2 composite train-obj: 0.965757
            Val objective improved 0.9736 → 0.9674, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 5.3153, mae: 1.3138, huber: 0.9608, swd: 1.4086, target_std: 6.4711
    Epoch [3/50], Val Losses: mse: 6.5240, mae: 1.3257, huber: 0.9764, swd: 0.9486, target_std: 4.3103
    Epoch [3/50], Test Losses: mse: 9.1548, mae: 1.5726, huber: 1.2166, swd: 1.4690, target_std: 4.7514
      Epoch 3 composite train-obj: 0.960756
            No improvement (0.9764), counter 1/5
    Epoch [4/50], Train Losses: mse: 5.3220, mae: 1.3149, huber: 0.9616, swd: 1.4114, target_std: 6.4712
    Epoch [4/50], Val Losses: mse: 6.5033, mae: 1.3292, huber: 0.9793, swd: 0.8885, target_std: 4.3103
    Epoch [4/50], Test Losses: mse: 9.2260, mae: 1.5809, huber: 1.2247, swd: 1.4261, target_std: 4.7514
      Epoch 4 composite train-obj: 0.961621
            No improvement (0.9793), counter 2/5
    Epoch [5/50], Train Losses: mse: 5.2972, mae: 1.3110, huber: 0.9580, swd: 1.4026, target_std: 6.4711
    Epoch [5/50], Val Losses: mse: 6.4688, mae: 1.3211, huber: 0.9717, swd: 0.8934, target_std: 4.3103
    Epoch [5/50], Test Losses: mse: 9.1324, mae: 1.5706, huber: 1.2155, swd: 1.4091, target_std: 4.7514
      Epoch 5 composite train-obj: 0.957991
            No improvement (0.9717), counter 3/5
    Epoch [6/50], Train Losses: mse: 5.3056, mae: 1.3127, huber: 0.9597, swd: 1.3994, target_std: 6.4712
    Epoch [6/50], Val Losses: mse: 6.4977, mae: 1.3221, huber: 0.9728, swd: 0.8971, target_std: 4.3103
    Epoch [6/50], Test Losses: mse: 9.2267, mae: 1.5707, huber: 1.2168, swd: 1.3911, target_std: 4.7514
      Epoch 6 composite train-obj: 0.959742
            No improvement (0.9728), counter 4/5
    Epoch [7/50], Train Losses: mse: 5.2985, mae: 1.3121, huber: 0.9589, swd: 1.4021, target_std: 6.4712
    Epoch [7/50], Val Losses: mse: 6.4718, mae: 1.3180, huber: 0.9695, swd: 0.8462, target_std: 4.3103
    Epoch [7/50], Test Losses: mse: 9.2376, mae: 1.5760, huber: 1.2208, swd: 1.4066, target_std: 4.7514
      Epoch 7 composite train-obj: 0.958924
    Epoch [7/50], Test Losses: mse: 9.2627, mae: 1.5881, huber: 1.2312, swd: 1.4772, target_std: 4.7514
    Best round's Test MSE: 9.2627, MAE: 1.5881, SWD: 1.4772
    Best round's Validation MSE: 6.4140, MAE: 1.3178
    Best round's Test verification MSE : 9.2627, MAE: 1.5881, SWD: 1.4772
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq720_pred196_20250429_1941)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 9.2287 ± 0.0241
      mae: 1.5803 ± 0.0055
      huber: 1.2246 ± 0.0046
      swd: 1.4668 ± 0.0207
      target_std: 4.7514 ± 0.0000
      count: 48.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 6.4089 ± 0.0248
      mae: 1.3130 ± 0.0040
      huber: 0.9637 ± 0.0032
      swd: 0.8600 ± 0.0261
      target_std: 4.3103 ± 0.0000
      count: 48.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq720_pred196_20250429_1941
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 196
    Seeds: [1955, 7, 20]
    

#### 720-336



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=336,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_720_336 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 373
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 373
    Validation Batches: 47
    Test Batches: 101
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.1105, mae: 1.5312, huber: 1.1631, swd: 1.8515, target_std: 6.4707
    Epoch [1/50], Val Losses: mse: 7.7028, mae: 1.4256, huber: 1.0701, swd: 0.8433, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.4199, mae: 1.7155, huber: 1.3501, swd: 1.5653, target_std: 4.7516
      Epoch 1 composite train-obj: 1.163085
            Val objective improved inf → 1.0701, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0634, mae: 1.4249, huber: 1.0630, swd: 1.6285, target_std: 6.4707
    Epoch [2/50], Val Losses: mse: 7.6244, mae: 1.4282, huber: 1.0726, swd: 0.9621, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.2625, mae: 1.7014, huber: 1.3383, swd: 1.6260, target_std: 4.7516
      Epoch 2 composite train-obj: 1.063004
            No improvement (1.0726), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0829, mae: 1.4257, huber: 1.0639, swd: 1.6327, target_std: 6.4709
    Epoch [3/50], Val Losses: mse: 7.8421, mae: 1.4488, huber: 1.0937, swd: 1.0476, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.2815, mae: 1.7050, huber: 1.3408, swd: 1.6338, target_std: 4.7516
      Epoch 3 composite train-obj: 1.063893
            No improvement (1.0937), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.0486, mae: 1.4218, huber: 1.0602, swd: 1.6230, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 7.5363, mae: 1.4062, huber: 1.0536, swd: 0.9400, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.2251, mae: 1.7011, huber: 1.3376, swd: 1.6758, target_std: 4.7516
      Epoch 4 composite train-obj: 1.060219
            Val objective improved 1.0701 → 1.0536, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.0551, mae: 1.4235, huber: 1.0617, swd: 1.6251, target_std: 6.4708
    Epoch [5/50], Val Losses: mse: 7.6736, mae: 1.4238, huber: 1.0700, swd: 0.8493, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.3867, mae: 1.7083, huber: 1.3444, swd: 1.5590, target_std: 4.7516
      Epoch 5 composite train-obj: 1.061710
            No improvement (1.0700), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.0437, mae: 1.4214, huber: 1.0597, swd: 1.6109, target_std: 6.4707
    Epoch [6/50], Val Losses: mse: 7.7349, mae: 1.4506, huber: 1.0960, swd: 1.1306, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.0960, mae: 1.6893, huber: 1.3264, swd: 1.6684, target_std: 4.7516
      Epoch 6 composite train-obj: 1.059680
            No improvement (1.0960), counter 2/5
    Epoch [7/50], Train Losses: mse: 6.0294, mae: 1.4207, huber: 1.0589, swd: 1.6082, target_std: 6.4708
    Epoch [7/50], Val Losses: mse: 7.6651, mae: 1.4237, huber: 1.0697, swd: 0.8477, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 10.2469, mae: 1.6990, huber: 1.3355, swd: 1.4658, target_std: 4.7516
      Epoch 7 composite train-obj: 1.058862
            No improvement (1.0697), counter 3/5
    Epoch [8/50], Train Losses: mse: 6.0215, mae: 1.4186, huber: 1.0570, swd: 1.6033, target_std: 6.4708
    Epoch [8/50], Val Losses: mse: 7.6480, mae: 1.4272, huber: 1.0714, swd: 0.9832, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 10.1734, mae: 1.6959, huber: 1.3318, swd: 1.5609, target_std: 4.7516
      Epoch 8 composite train-obj: 1.057036
            No improvement (1.0714), counter 4/5
    Epoch [9/50], Train Losses: mse: 6.0439, mae: 1.4223, huber: 1.0605, swd: 1.6069, target_std: 6.4707
    Epoch [9/50], Val Losses: mse: 7.6133, mae: 1.4149, huber: 1.0623, swd: 0.8914, target_std: 4.3126
    Epoch [9/50], Test Losses: mse: 10.2326, mae: 1.6950, huber: 1.3320, swd: 1.5486, target_std: 4.7516
      Epoch 9 composite train-obj: 1.060536
    Epoch [9/50], Test Losses: mse: 10.2251, mae: 1.7011, huber: 1.3376, swd: 1.6758, target_std: 4.7516
    Best round's Test MSE: 10.2251, MAE: 1.7011, SWD: 1.6758
    Best round's Validation MSE: 7.5363, MAE: 1.4062
    Best round's Test verification MSE : 10.2251, MAE: 1.7011, SWD: 1.6758
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0660, mae: 1.5289, huber: 1.1607, swd: 1.9296, target_std: 6.4707
    Epoch [1/50], Val Losses: mse: 7.8244, mae: 1.4416, huber: 1.0864, swd: 1.0227, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.3316, mae: 1.7076, huber: 1.3434, swd: 1.6811, target_std: 4.7516
      Epoch 1 composite train-obj: 1.160717
            Val objective improved inf → 1.0864, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0842, mae: 1.4274, huber: 1.0655, swd: 1.7051, target_std: 6.4707
    Epoch [2/50], Val Losses: mse: 7.7054, mae: 1.4233, huber: 1.0693, swd: 0.8828, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.3278, mae: 1.7079, huber: 1.3431, swd: 1.5810, target_std: 4.7516
      Epoch 2 composite train-obj: 1.065480
            Val objective improved 1.0864 → 1.0693, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.0495, mae: 1.4220, huber: 1.0604, swd: 1.6872, target_std: 6.4710
    Epoch [3/50], Val Losses: mse: 7.6407, mae: 1.4207, huber: 1.0676, swd: 0.9366, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.2816, mae: 1.6981, huber: 1.3352, swd: 1.6055, target_std: 4.7516
      Epoch 3 composite train-obj: 1.060387
            Val objective improved 1.0693 → 1.0676, saving checkpoint.
    Epoch [4/50], Train Losses: mse: 6.0505, mae: 1.4229, huber: 1.0611, swd: 1.6880, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 7.6901, mae: 1.4304, huber: 1.0744, swd: 0.9392, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.3333, mae: 1.7078, huber: 1.3443, swd: 1.6137, target_std: 4.7516
      Epoch 4 composite train-obj: 1.061051
            No improvement (1.0744), counter 1/5
    Epoch [5/50], Train Losses: mse: 6.0146, mae: 1.4185, huber: 1.0569, swd: 1.6618, target_std: 6.4708
    Epoch [5/50], Val Losses: mse: 7.6583, mae: 1.4256, huber: 1.0723, swd: 1.0800, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.2265, mae: 1.6928, huber: 1.3305, swd: 1.7352, target_std: 4.7516
      Epoch 5 composite train-obj: 1.056907
            No improvement (1.0723), counter 2/5
    Epoch [6/50], Train Losses: mse: 6.0414, mae: 1.4220, huber: 1.0601, swd: 1.6787, target_std: 6.4709
    Epoch [6/50], Val Losses: mse: 7.6981, mae: 1.4265, huber: 1.0719, swd: 0.9007, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.2679, mae: 1.7022, huber: 1.3376, swd: 1.5675, target_std: 4.7516
      Epoch 6 composite train-obj: 1.060088
            No improvement (1.0719), counter 3/5
    Epoch [7/50], Train Losses: mse: 6.0338, mae: 1.4207, huber: 1.0587, swd: 1.6737, target_std: 6.4707
    Epoch [7/50], Val Losses: mse: 7.6932, mae: 1.4381, huber: 1.0825, swd: 1.0794, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 10.1790, mae: 1.6964, huber: 1.3322, swd: 1.6919, target_std: 4.7516
      Epoch 7 composite train-obj: 1.058747
            No improvement (1.0825), counter 4/5
    Epoch [8/50], Train Losses: mse: 6.0332, mae: 1.4209, huber: 1.0591, swd: 1.6774, target_std: 6.4710
    Epoch [8/50], Val Losses: mse: 7.6528, mae: 1.4237, huber: 1.0703, swd: 1.0031, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 10.1867, mae: 1.6899, huber: 1.3276, swd: 1.6253, target_std: 4.7516
      Epoch 8 composite train-obj: 1.059105
    Epoch [8/50], Test Losses: mse: 10.2816, mae: 1.6981, huber: 1.3352, swd: 1.6055, target_std: 4.7516
    Best round's Test MSE: 10.2816, MAE: 1.6981, SWD: 1.6055
    Best round's Validation MSE: 7.6407, MAE: 1.4207
    Best round's Test verification MSE : 10.2816, MAE: 1.6981, SWD: 1.6055
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.0721, mae: 1.5300, huber: 1.1616, swd: 1.8256, target_std: 6.4707
    Epoch [1/50], Val Losses: mse: 7.8241, mae: 1.4413, huber: 1.0858, swd: 0.9413, target_std: 4.3126
    Epoch [1/50], Test Losses: mse: 10.3723, mae: 1.7172, huber: 1.3506, swd: 1.6444, target_std: 4.7516
      Epoch 1 composite train-obj: 1.161591
            Val objective improved inf → 1.0858, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.0856, mae: 1.4268, huber: 1.0649, swd: 1.6219, target_std: 6.4708
    Epoch [2/50], Val Losses: mse: 7.7658, mae: 1.4432, huber: 1.0870, swd: 1.1256, target_std: 4.3126
    Epoch [2/50], Test Losses: mse: 10.2704, mae: 1.7051, huber: 1.3405, swd: 1.7474, target_std: 4.7516
      Epoch 2 composite train-obj: 1.064896
            No improvement (1.0870), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.0598, mae: 1.4232, huber: 1.0614, swd: 1.6091, target_std: 6.4709
    Epoch [3/50], Val Losses: mse: 7.7877, mae: 1.4412, huber: 1.0864, swd: 1.1008, target_std: 4.3126
    Epoch [3/50], Test Losses: mse: 10.2995, mae: 1.7012, huber: 1.3373, swd: 1.7307, target_std: 4.7516
      Epoch 3 composite train-obj: 1.061418
            No improvement (1.0864), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.0324, mae: 1.4201, huber: 1.0584, swd: 1.6001, target_std: 6.4708
    Epoch [4/50], Val Losses: mse: 7.7146, mae: 1.4271, huber: 1.0734, swd: 0.9346, target_std: 4.3126
    Epoch [4/50], Test Losses: mse: 10.4072, mae: 1.7096, huber: 1.3460, swd: 1.6555, target_std: 4.7516
      Epoch 4 composite train-obj: 1.058416
            Val objective improved 1.0858 → 1.0734, saving checkpoint.
    Epoch [5/50], Train Losses: mse: 6.0559, mae: 1.4238, huber: 1.0619, swd: 1.6089, target_std: 6.4709
    Epoch [5/50], Val Losses: mse: 7.6795, mae: 1.4304, huber: 1.0753, swd: 0.9458, target_std: 4.3126
    Epoch [5/50], Test Losses: mse: 10.2902, mae: 1.7025, huber: 1.3372, swd: 1.6515, target_std: 4.7516
      Epoch 5 composite train-obj: 1.061930
            No improvement (1.0753), counter 1/5
    Epoch [6/50], Train Losses: mse: 6.0301, mae: 1.4202, huber: 1.0585, swd: 1.5918, target_std: 6.4710
    Epoch [6/50], Val Losses: mse: 7.5851, mae: 1.4165, huber: 1.0635, swd: 1.0119, target_std: 4.3126
    Epoch [6/50], Test Losses: mse: 10.1927, mae: 1.6942, huber: 1.3311, swd: 1.6975, target_std: 4.7516
      Epoch 6 composite train-obj: 1.058520
            Val objective improved 1.0734 → 1.0635, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.0216, mae: 1.4182, huber: 1.0567, swd: 1.5913, target_std: 6.4706
    Epoch [7/50], Val Losses: mse: 7.6312, mae: 1.4321, huber: 1.0760, swd: 1.0942, target_std: 4.3126
    Epoch [7/50], Test Losses: mse: 10.1703, mae: 1.6984, huber: 1.3337, swd: 1.7387, target_std: 4.7516
      Epoch 7 composite train-obj: 1.056719
            No improvement (1.0760), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.0356, mae: 1.4206, huber: 1.0591, swd: 1.5995, target_std: 6.4709
    Epoch [8/50], Val Losses: mse: 7.6475, mae: 1.4293, huber: 1.0747, swd: 1.0873, target_std: 4.3126
    Epoch [8/50], Test Losses: mse: 10.1824, mae: 1.6918, huber: 1.3281, swd: 1.7272, target_std: 4.7516
      Epoch 8 composite train-obj: 1.059086
            No improvement (1.0747), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.0419, mae: 1.4223, huber: 1.0604, swd: 1.6015, target_std: 6.4707
    Epoch [9/50], Val Losses: mse: 7.6753, mae: 1.4319, huber: 1.0766, swd: 1.0775, target_std: 4.3126
    Epoch [9/50], Test Losses: mse: 10.1540, mae: 1.6902, huber: 1.3254, swd: 1.6817, target_std: 4.7516
      Epoch 9 composite train-obj: 1.060370
            No improvement (1.0766), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.0265, mae: 1.4195, huber: 1.0577, swd: 1.5941, target_std: 6.4710
    Epoch [10/50], Val Losses: mse: 7.6428, mae: 1.4288, huber: 1.0746, swd: 1.0557, target_std: 4.3126
    Epoch [10/50], Test Losses: mse: 10.2201, mae: 1.6926, huber: 1.3299, swd: 1.6963, target_std: 4.7516
      Epoch 10 composite train-obj: 1.057706
            No improvement (1.0746), counter 4/5
    Epoch [11/50], Train Losses: mse: 6.0300, mae: 1.4210, huber: 1.0590, swd: 1.5976, target_std: 6.4708
    Epoch [11/50], Val Losses: mse: 7.6342, mae: 1.4279, huber: 1.0747, swd: 1.1157, target_std: 4.3126
    Epoch [11/50], Test Losses: mse: 10.2227, mae: 1.6987, huber: 1.3356, swd: 1.8130, target_std: 4.7516
      Epoch 11 composite train-obj: 1.059003
    Epoch [11/50], Test Losses: mse: 10.1927, mae: 1.6942, huber: 1.3311, swd: 1.6975, target_std: 4.7516
    Best round's Test MSE: 10.1927, MAE: 1.6942, SWD: 1.6975
    Best round's Validation MSE: 7.5851, MAE: 1.4165
    Best round's Test verification MSE : 10.1927, MAE: 1.6942, SWD: 1.6975
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq720_pred336_20250429_1943)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2331 ± 0.0367
      mae: 1.6978 ± 0.0028
      huber: 1.3346 ± 0.0027
      swd: 1.6596 ± 0.0393
      target_std: 4.7516 ± 0.0000
      count: 47.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.5874 ± 0.0426
      mae: 1.4145 ± 0.0061
      huber: 1.0615 ± 0.0059
      swd: 0.9628 ± 0.0347
      target_std: 4.3126 ± 0.0000
      count: 47.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq720_pred336_20250429_1943
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 336
    Seeds: [1955, 7, 20]
    

#### 720-720



```python
importlib.reload(monotonic)
importlib.reload(train_config)
utils.reload_modules([utils])
cfg = train_config.FlatDLinearConfig(
    seq_len=720,
    pred_len=720,
    channels=data_mgr.datasets['ettm1']['channels'],
    batch_size=128,
    learning_rate=9e-4,
    seeds=[1955, 7, 20],
    epochs=50, 
)
exp_dlinear_720_720 = execute_model_evaluation('ettm1', cfg, data_mgr, scale=False)
```

    Reloading modules...
      Reloaded: utils
    Module reload complete.
    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Validation set sample shapes: torch.Size([720, 7]), torch.Size([720, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 370
    Batch 0: Data shape torch.Size([128, 720, 7]), Target shape torch.Size([128, 720, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 720
    Prediction Length: 720
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 370
    Validation Batches: 44
    Test Batches: 98
    ==================================================
    
    ==================================================
     Running experiment with seed 1955 (1/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.8882, mae: 1.6539, huber: 1.2759, swd: 1.8523, target_std: 6.4637
    Epoch [1/50], Val Losses: mse: 9.4549, mae: 1.5798, huber: 1.2178, swd: 1.0790, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 11.0422, mae: 1.8386, huber: 1.4602, swd: 1.6584, target_std: 4.7627
      Epoch 1 composite train-obj: 1.275911
            Val objective improved inf → 1.2178, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9426, mae: 1.5631, huber: 1.1898, swd: 1.6652, target_std: 6.4636
    Epoch [2/50], Val Losses: mse: 9.4600, mae: 1.5834, huber: 1.2215, swd: 0.9669, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.9239, mae: 1.8247, huber: 1.4474, swd: 1.4917, target_std: 4.7627
      Epoch 2 composite train-obj: 1.189751
            No improvement (1.2215), counter 1/5
    Epoch [3/50], Train Losses: mse: 6.9088, mae: 1.5582, huber: 1.1852, swd: 1.6512, target_std: 6.4635
    Epoch [3/50], Val Losses: mse: 9.4062, mae: 1.5813, huber: 1.2205, swd: 1.1265, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.8636, mae: 1.8198, huber: 1.4435, swd: 1.6119, target_std: 4.7627
      Epoch 3 composite train-obj: 1.185222
            No improvement (1.2205), counter 2/5
    Epoch [4/50], Train Losses: mse: 6.8977, mae: 1.5568, huber: 1.1837, swd: 1.6454, target_std: 6.4636
    Epoch [4/50], Val Losses: mse: 9.3757, mae: 1.5817, huber: 1.2196, swd: 1.1582, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 10.8014, mae: 1.8100, huber: 1.4357, swd: 1.6087, target_std: 4.7627
      Epoch 4 composite train-obj: 1.183696
            No improvement (1.2196), counter 3/5
    Epoch [5/50], Train Losses: mse: 6.8942, mae: 1.5566, huber: 1.1836, swd: 1.6499, target_std: 6.4638
    Epoch [5/50], Val Losses: mse: 9.4954, mae: 1.5997, huber: 1.2373, swd: 1.3050, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 10.8228, mae: 1.8157, huber: 1.4394, swd: 1.6644, target_std: 4.7627
      Epoch 5 composite train-obj: 1.183573
            No improvement (1.2373), counter 4/5
    Epoch [6/50], Train Losses: mse: 6.8942, mae: 1.5564, huber: 1.1833, swd: 1.6427, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 9.4754, mae: 1.6059, huber: 1.2422, swd: 1.2205, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 10.8823, mae: 1.8263, huber: 1.4492, swd: 1.6019, target_std: 4.7627
      Epoch 6 composite train-obj: 1.183294
    Epoch [6/50], Test Losses: mse: 11.0422, mae: 1.8386, huber: 1.4602, swd: 1.6584, target_std: 4.7627
    Best round's Test MSE: 11.0422, MAE: 1.8386, SWD: 1.6584
    Best round's Validation MSE: 9.4549, MAE: 1.5798
    Best round's Test verification MSE : 11.0422, MAE: 1.8386, SWD: 1.6584
    
    ==================================================
     Running experiment with seed 7 (2/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.9444, mae: 1.6571, huber: 1.2789, swd: 1.7695, target_std: 6.4637
    Epoch [1/50], Val Losses: mse: 9.5194, mae: 1.5961, huber: 1.2330, swd: 1.0869, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 10.9485, mae: 1.8307, huber: 1.4553, swd: 1.6366, target_std: 4.7627
      Epoch 1 composite train-obj: 1.278913
            Val objective improved inf → 1.2330, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9297, mae: 1.5616, huber: 1.1884, swd: 1.5840, target_std: 6.4635
    Epoch [2/50], Val Losses: mse: 9.3785, mae: 1.5726, huber: 1.2114, swd: 0.9222, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.9666, mae: 1.8289, huber: 1.4533, swd: 1.5778, target_std: 4.7627
      Epoch 2 composite train-obj: 1.188443
            Val objective improved 1.2330 → 1.2114, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.9021, mae: 1.5572, huber: 1.1842, swd: 1.5669, target_std: 6.4635
    Epoch [3/50], Val Losses: mse: 9.7633, mae: 1.6336, huber: 1.2681, swd: 1.3965, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.9043, mae: 1.8270, huber: 1.4471, swd: 1.6906, target_std: 4.7627
      Epoch 3 composite train-obj: 1.184234
            No improvement (1.2681), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.8762, mae: 1.5538, huber: 1.1811, swd: 1.5537, target_std: 6.4637
    Epoch [4/50], Val Losses: mse: 9.5134, mae: 1.5981, huber: 1.2354, swd: 1.1576, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 10.8786, mae: 1.8208, huber: 1.4442, swd: 1.6041, target_std: 4.7627
      Epoch 4 composite train-obj: 1.181119
            No improvement (1.2354), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.8715, mae: 1.5538, huber: 1.1808, swd: 1.5484, target_std: 6.4638
    Epoch [5/50], Val Losses: mse: 9.3437, mae: 1.5789, huber: 1.2160, swd: 0.9211, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 10.9505, mae: 1.8231, huber: 1.4485, swd: 1.4744, target_std: 4.7627
      Epoch 5 composite train-obj: 1.180780
            No improvement (1.2160), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.9055, mae: 1.5570, huber: 1.1841, swd: 1.5643, target_std: 6.4636
    Epoch [6/50], Val Losses: mse: 9.3239, mae: 1.5645, huber: 1.2048, swd: 0.9170, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 10.8914, mae: 1.8169, huber: 1.4419, swd: 1.4873, target_std: 4.7627
      Epoch 6 composite train-obj: 1.184102
            Val objective improved 1.2114 → 1.2048, saving checkpoint.
    Epoch [7/50], Train Losses: mse: 6.8933, mae: 1.5554, huber: 1.1826, swd: 1.5620, target_std: 6.4636
    Epoch [7/50], Val Losses: mse: 9.3369, mae: 1.5859, huber: 1.2230, swd: 1.1424, target_std: 4.3111
    Epoch [7/50], Test Losses: mse: 10.8373, mae: 1.8234, huber: 1.4469, swd: 1.6763, target_std: 4.7627
      Epoch 7 composite train-obj: 1.182555
            No improvement (1.2230), counter 1/5
    Epoch [8/50], Train Losses: mse: 6.8615, mae: 1.5514, huber: 1.1787, swd: 1.5383, target_std: 6.4637
    Epoch [8/50], Val Losses: mse: 9.3404, mae: 1.5815, huber: 1.2177, swd: 0.9989, target_std: 4.3111
    Epoch [8/50], Test Losses: mse: 10.9380, mae: 1.8216, huber: 1.4471, swd: 1.5332, target_std: 4.7627
      Epoch 8 composite train-obj: 1.178655
            No improvement (1.2177), counter 2/5
    Epoch [9/50], Train Losses: mse: 6.8650, mae: 1.5517, huber: 1.1790, swd: 1.5424, target_std: 6.4637
    Epoch [9/50], Val Losses: mse: 9.3553, mae: 1.5806, huber: 1.2202, swd: 1.1141, target_std: 4.3111
    Epoch [9/50], Test Losses: mse: 10.8557, mae: 1.8133, huber: 1.4388, swd: 1.6071, target_std: 4.7627
      Epoch 9 composite train-obj: 1.178963
            No improvement (1.2202), counter 3/5
    Epoch [10/50], Train Losses: mse: 6.8859, mae: 1.5538, huber: 1.1810, swd: 1.5509, target_std: 6.4636
    Epoch [10/50], Val Losses: mse: 9.3901, mae: 1.5833, huber: 1.2218, swd: 1.0440, target_std: 4.3111
    Epoch [10/50], Test Losses: mse: 10.8551, mae: 1.8112, huber: 1.4377, swd: 1.5309, target_std: 4.7627
      Epoch 10 composite train-obj: 1.181037
            No improvement (1.2218), counter 4/5
    Epoch [11/50], Train Losses: mse: 6.8689, mae: 1.5523, huber: 1.1795, swd: 1.5402, target_std: 6.4636
    Epoch [11/50], Val Losses: mse: 9.4757, mae: 1.6198, huber: 1.2534, swd: 1.2596, target_std: 4.3111
    Epoch [11/50], Test Losses: mse: 10.8679, mae: 1.8236, huber: 1.4466, swd: 1.6512, target_std: 4.7627
      Epoch 11 composite train-obj: 1.179507
    Epoch [11/50], Test Losses: mse: 10.8914, mae: 1.8169, huber: 1.4419, swd: 1.4873, target_std: 4.7627
    Best round's Test MSE: 10.8914, MAE: 1.8169, SWD: 1.4873
    Best round's Validation MSE: 9.3239, MAE: 1.5645
    Best round's Test verification MSE : 10.8914, MAE: 1.8169, SWD: 1.4873
    
    ==================================================
     Running experiment with seed 20 (3/3)==================================================
    
    Epoch [1/50], Train Losses: mse: 7.8482, mae: 1.6523, huber: 1.2742, swd: 1.9080, target_std: 6.4637
    Epoch [1/50], Val Losses: mse: 9.5663, mae: 1.5904, huber: 1.2284, swd: 1.1257, target_std: 4.3111
    Epoch [1/50], Test Losses: mse: 11.0097, mae: 1.8300, huber: 1.4514, swd: 1.5912, target_std: 4.7627
      Epoch 1 composite train-obj: 1.274225
            Val objective improved inf → 1.2284, saving checkpoint.
    Epoch [2/50], Train Losses: mse: 6.9385, mae: 1.5620, huber: 1.1890, swd: 1.7321, target_std: 6.4636
    Epoch [2/50], Val Losses: mse: 9.3752, mae: 1.5723, huber: 1.2125, swd: 1.1726, target_std: 4.3111
    Epoch [2/50], Test Losses: mse: 10.8546, mae: 1.8114, huber: 1.4370, swd: 1.6789, target_std: 4.7627
      Epoch 2 composite train-obj: 1.188987
            Val objective improved 1.2284 → 1.2125, saving checkpoint.
    Epoch [3/50], Train Losses: mse: 6.9145, mae: 1.5590, huber: 1.1859, swd: 1.7255, target_std: 6.4635
    Epoch [3/50], Val Losses: mse: 9.6903, mae: 1.6318, huber: 1.2644, swd: 1.4813, target_std: 4.3111
    Epoch [3/50], Test Losses: mse: 10.9004, mae: 1.8276, huber: 1.4485, swd: 1.7643, target_std: 4.7627
      Epoch 3 composite train-obj: 1.185865
            No improvement (1.2644), counter 1/5
    Epoch [4/50], Train Losses: mse: 6.8951, mae: 1.5567, huber: 1.1837, swd: 1.7177, target_std: 6.4635
    Epoch [4/50], Val Losses: mse: 9.4103, mae: 1.5817, huber: 1.2202, swd: 1.1534, target_std: 4.3111
    Epoch [4/50], Test Losses: mse: 10.9038, mae: 1.8159, huber: 1.4407, swd: 1.6646, target_std: 4.7627
      Epoch 4 composite train-obj: 1.183707
            No improvement (1.2202), counter 2/5
    Epoch [5/50], Train Losses: mse: 6.8937, mae: 1.5554, huber: 1.1827, swd: 1.7129, target_std: 6.4637
    Epoch [5/50], Val Losses: mse: 9.4479, mae: 1.5916, huber: 1.2297, swd: 1.3375, target_std: 4.3111
    Epoch [5/50], Test Losses: mse: 10.8318, mae: 1.8141, huber: 1.4376, swd: 1.7357, target_std: 4.7627
      Epoch 5 composite train-obj: 1.182673
            No improvement (1.2297), counter 3/5
    Epoch [6/50], Train Losses: mse: 6.8729, mae: 1.5529, huber: 1.1802, swd: 1.6977, target_std: 6.4637
    Epoch [6/50], Val Losses: mse: 9.5181, mae: 1.5998, huber: 1.2376, swd: 1.2978, target_std: 4.3111
    Epoch [6/50], Test Losses: mse: 10.8100, mae: 1.8112, huber: 1.4353, swd: 1.6321, target_std: 4.7627
      Epoch 6 composite train-obj: 1.180160
            No improvement (1.2376), counter 4/5
    Epoch [7/50], Train Losses: mse: 6.8632, mae: 1.5522, huber: 1.1795, swd: 1.6882, target_std: 6.4638
    Epoch [7/50], Val Losses: mse: 9.5938, mae: 1.6046, huber: 1.2424, swd: 1.2335, target_std: 4.3111
    Epoch [7/50], Test Losses: mse: 10.8772, mae: 1.8176, huber: 1.4410, swd: 1.5914, target_std: 4.7627
      Epoch 7 composite train-obj: 1.179470
    Epoch [7/50], Test Losses: mse: 10.8546, mae: 1.8114, huber: 1.4370, swd: 1.6789, target_std: 4.7627
    Best round's Test MSE: 10.8546, MAE: 1.8114, SWD: 1.6789
    Best round's Validation MSE: 9.3752, MAE: 1.5723
    Best round's Test verification MSE : 10.8546, MAE: 1.8114, SWD: 1.6789
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq720_pred720_20250429_1945)
    ==================================================
    Number of runs: 3
    Seeds: [1955, 7, 20]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.9294 ± 0.0812
      mae: 1.8223 ± 0.0118
      huber: 1.4464 ± 0.0100
      swd: 1.6082 ± 0.0859
      target_std: 4.7627 ± 0.0000
      count: 44.0000 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 9.3847 ± 0.0539
      mae: 1.5722 ± 0.0063
      huber: 1.2117 ± 0.0053
      swd: 1.0562 ± 0.1056
      target_std: 4.3111 ± 0.0000
      count: 44.0000 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq720_pred720_20250429_1945
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 720
    Prediction Length: 720
    Seeds: [1955, 7, 20]
    


```python
exp.results[0].test_losses

```




    {'mse': 8.373206586749465,
     'mae': 1.5061821485007252,
     'huber': 1.1453082288304965,
     'swd': 1.743723650497419,
     'target_std': 4.7755307290289135,
     'count': 53}




```python
import data_manager
importlib.reload(data_manager)
new_seq, new_pred = 96, 196
data_mgr.prepare_data('ettm1', new_seq, new_pred, 128)
cfg = replace(cfg, seq_len=new_seq, pred_len=new_pred)
exp_96_196 = execute_model_evaluation('ettm1', cfg, data_mgr)


```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([96, 7]), torch.Size([196, 7])
    Validation set sample shapes: torch.Size([96, 7]), torch.Size([196, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 379
    Batch 0: Data shape torch.Size([128, 96, 7]), Target shape torch.Size([128, 196, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 96
    Prediction Length: 196
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 379
    Validation Batches: 53
    Test Batches: 107
    ==================================================
    

    [autoreload of train failed: Traceback (most recent call last):
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\autoreload.py", line 280, in check
        elif self.deduper_reloader.maybe_reload_module(m):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      File "c:\proj\DL_notebook\study\.venv\Lib\site-packages\IPython\extensions\deduperreload\deduperreload.py", line 533, in maybe_reload_module
        new_source_code = f.read()
                          ^^^^^^^^
    UnicodeDecodeError: 'gbk' codec can't decode byte 0x92 in position 11604: illegal multibyte sequence
    ]
    


    ---------------------------------------------------------------------------

    TypeError                                 Traceback (most recent call last)

    Cell In[17], line 6
          4 data_mgr.prepare_data('ettm1', new_seq, new_pred, 128)
          5 cfg = replace(cfg, seq_len=new_seq, pred_len=new_pred)
    ----> 6 exp_96_196 = execute_model_evaluation('ettm1', cfg, data_mgr)
    

    TypeError: execute_model_evaluation() takes 2 positional arguments but 3 were given



```python
importlib.reload(Train)
importlib.reload(train_config)  
importlib.reload(monotonic)
acl_experiment = run_experiment(
    model_type='ACL',
    data_manager=data_mgr,
    seq_len=336,
    pred_len=336,
    dim_hidden=96,
    seeds=[2026, 3022],
    learning_rate=9e-4
)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
    Running experiment with seed 2026 (1/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 22.1249, huber: 2.1810, mae: 2.5871, swd: 7.7690, target_std: 6.5009
    Epoch [1/50], Val Losses:  mse: 16.1910, huber: 1.8060, mae: 2.2021, swd: 3.5093, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 26.2619, huber: 2.3828, mae: 2.7885, swd: 6.0155, target_std: 4.7502
            Validation loss decreased (inf --> 1.8060).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 16.8496, huber: 1.8351, mae: 2.2305, swd: 3.4240, target_std: 6.5010
    Epoch [2/50], Val Losses:  mse: 12.0258, huber: 1.5810, mae: 1.9641, swd: 2.5360, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 15.6464, huber: 1.8176, mae: 2.2066, swd: 4.2484, target_std: 4.7502
            Validation loss decreased (1.8060 --> 1.5810).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 9.1334, huber: 1.3364, mae: 1.7178, swd: 2.1165, target_std: 6.5009
    Epoch [3/50], Val Losses:  mse: 9.5026, huber: 1.3240, mae: 1.6958, swd: 1.8503, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 11.9691, huber: 1.5220, mae: 1.9029, swd: 2.4115, target_std: 4.7502
            Validation loss decreased (1.5810 --> 1.3240).  Saving model ...
    Epoch [4/50], Train Losses:  mse: 6.7370, huber: 1.1543, mae: 1.5292, swd: 1.7329, target_std: 6.5010
    Epoch [4/50], Val Losses:  mse: 9.1821, huber: 1.2908, mae: 1.6634, swd: 1.7995, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 11.5599, huber: 1.4801, mae: 1.8614, swd: 2.2743, target_std: 4.7502
            Validation loss decreased (1.3240 --> 1.2908).  Saving model ...
    Epoch [5/50], Train Losses:  mse: 6.5298, huber: 1.1185, mae: 1.4890, swd: 1.6360, target_std: 6.5011
    Epoch [5/50], Val Losses:  mse: 8.8524, huber: 1.2418, mae: 1.6054, swd: 1.7580, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 11.2162, huber: 1.4377, mae: 1.8099, swd: 2.3836, target_std: 4.7502
            Validation loss decreased (1.2908 --> 1.2418).  Saving model ...
    Epoch [6/50], Train Losses:  mse: 6.4199, huber: 1.1006, mae: 1.4687, swd: 1.6245, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 8.9293, huber: 1.2460, mae: 1.6098, swd: 1.8384, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 11.0553, huber: 1.4279, mae: 1.8004, swd: 2.3953, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [7/50], Train Losses:  mse: 6.2705, huber: 1.0807, mae: 1.4472, swd: 1.5656, target_std: 6.5010
    Epoch [7/50], Val Losses:  mse: 8.7020, huber: 1.2318, mae: 1.5947, swd: 1.8653, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 10.7845, huber: 1.4126, mae: 1.7848, swd: 2.4540, target_std: 4.7502
            Validation loss decreased (1.2418 --> 1.2318).  Saving model ...
    Epoch [8/50], Train Losses:  mse: 6.1218, huber: 1.0703, mae: 1.4366, swd: 1.5697, target_std: 6.5010
    Epoch [8/50], Val Losses:  mse: 8.6002, huber: 1.2362, mae: 1.6003, swd: 1.9984, target_std: 4.2763
    Epoch [8/50], Test Losses:  mse: 10.6333, huber: 1.4125, mae: 1.7851, swd: 2.6076, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [9/50], Train Losses:  mse: 6.0296, huber: 1.0601, mae: 1.4256, swd: 1.5378, target_std: 6.5010
    Epoch [9/50], Val Losses:  mse: 8.6572, huber: 1.2292, mae: 1.5915, swd: 1.8794, target_std: 4.2763
    Epoch [9/50], Test Losses:  mse: 10.5612, huber: 1.3968, mae: 1.7681, swd: 2.5248, target_std: 4.7502
            Validation loss decreased (1.2318 --> 1.2292).  Saving model ...
    Epoch [10/50], Train Losses:  mse: 5.8707, huber: 1.0443, mae: 1.4093, swd: 1.5003, target_std: 6.5009
    Epoch [10/50], Val Losses:  mse: 8.4215, huber: 1.2192, mae: 1.5821, swd: 1.8866, target_std: 4.2763
    Epoch [10/50], Test Losses:  mse: 10.1349, huber: 1.3729, mae: 1.7457, swd: 2.4012, target_std: 4.7502
            Validation loss decreased (1.2292 --> 1.2192).  Saving model ...
    Epoch [11/50], Train Losses:  mse: 5.7775, huber: 1.0369, mae: 1.4017, swd: 1.4859, target_std: 6.5011
    Epoch [11/50], Val Losses:  mse: 8.4318, huber: 1.2162, mae: 1.5781, swd: 1.9036, target_std: 4.2763
    Epoch [11/50], Test Losses:  mse: 10.0998, huber: 1.3735, mae: 1.7445, swd: 2.5237, target_std: 4.7502
            Validation loss decreased (1.2192 --> 1.2162).  Saving model ...
    Epoch [12/50], Train Losses:  mse: 5.6926, huber: 1.0270, mae: 1.3911, swd: 1.4518, target_std: 6.5011
    Epoch [12/50], Val Losses:  mse: 8.4423, huber: 1.2067, mae: 1.5674, swd: 1.7891, target_std: 4.2763
    Epoch [12/50], Test Losses:  mse: 10.1805, huber: 1.3728, mae: 1.7436, swd: 2.4822, target_std: 4.7502
            Validation loss decreased (1.2162 --> 1.2067).  Saving model ...
    Epoch [13/50], Train Losses:  mse: 5.6221, huber: 1.0199, mae: 1.3838, swd: 1.4314, target_std: 6.5011
    Epoch [13/50], Val Losses:  mse: 8.5608, huber: 1.2131, mae: 1.5749, swd: 1.7216, target_std: 4.2763
    Epoch [13/50], Test Losses:  mse: 10.2547, huber: 1.3785, mae: 1.7509, swd: 2.4357, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [14/50], Train Losses:  mse: 5.5374, huber: 1.0091, mae: 1.3724, swd: 1.3937, target_std: 6.5010
    Epoch [14/50], Val Losses:  mse: 8.4859, huber: 1.2072, mae: 1.5676, swd: 1.6981, target_std: 4.2763
    Epoch [14/50], Test Losses:  mse: 10.2196, huber: 1.3766, mae: 1.7481, swd: 2.4003, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [15/50], Train Losses:  mse: 5.4658, huber: 1.0015, mae: 1.3645, swd: 1.3732, target_std: 6.5011
    Epoch [15/50], Val Losses:  mse: 8.7677, huber: 1.2601, mae: 1.6220, swd: 2.0567, target_std: 4.2763
    Epoch [15/50], Test Losses:  mse: 10.4501, huber: 1.4041, mae: 1.7764, swd: 2.6162, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [16/50], Train Losses:  mse: 5.4119, huber: 0.9969, mae: 1.3599, swd: 1.3655, target_std: 6.5009
    Epoch [16/50], Val Losses:  mse: 8.8884, huber: 1.2582, mae: 1.6201, swd: 1.9014, target_std: 4.2763
    Epoch [16/50], Test Losses:  mse: 10.3782, huber: 1.3959, mae: 1.7677, swd: 2.5031, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [17/50], Train Losses:  mse: 5.2570, huber: 0.9773, mae: 1.3391, swd: 1.2791, target_std: 6.5010
    Epoch [17/50], Val Losses:  mse: 9.1279, huber: 1.2845, mae: 1.6476, swd: 2.0190, target_std: 4.2763
    Epoch [17/50], Test Losses:  mse: 10.5311, huber: 1.4084, mae: 1.7813, swd: 2.5509, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [17/50], Test Losses:  mse: 10.1782, huber: 1.3726, mae: 1.7434, swd: 2.4819, target_std: 4.7502
    Best round's Test MSE: 10.1805, MAE: 1.7436
    Best round's Validation MSE: 8.4423, MAE: 1.5674
    Best round's Test verification MSE : 10.1782, MAE: 1.7434
    
    ==================================================
    Running experiment with seed 3022 (2/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 18.6533, huber: 1.9386, mae: 2.3369, swd: 6.5960, target_std: 6.5011
    Epoch [1/50], Val Losses:  mse: 13.0727, huber: 1.5361, mae: 1.9174, swd: 2.9308, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 20.8224, huber: 1.9886, mae: 2.3814, swd: 4.8213, target_std: 4.7502
            Validation loss decreased (inf --> 1.5361).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 9.9323, huber: 1.3720, mae: 1.7528, swd: 2.2640, target_std: 6.5012
    Epoch [2/50], Val Losses:  mse: 10.0959, huber: 1.4040, mae: 1.7767, swd: 2.3482, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 12.4598, huber: 1.5723, mae: 1.9530, swd: 2.8615, target_std: 4.7502
            Validation loss decreased (1.5361 --> 1.4040).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 6.8542, huber: 1.1631, mae: 1.5375, swd: 1.7603, target_std: 6.5011
    Epoch [3/50], Val Losses:  mse: 9.4705, huber: 1.3608, mae: 1.7287, swd: 2.2938, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 10.8337, huber: 1.4602, mae: 1.8356, swd: 2.5201, target_std: 4.7502
            Validation loss decreased (1.4040 --> 1.3608).  Saving model ...
    Epoch [4/50], Train Losses:  mse: 6.1095, huber: 1.0887, mae: 1.4573, swd: 1.6230, target_std: 6.5012
    Epoch [4/50], Val Losses:  mse: 9.2677, huber: 1.3095, mae: 1.6731, swd: 1.9644, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 10.5165, huber: 1.4140, mae: 1.7859, swd: 2.2200, target_std: 4.7502
            Validation loss decreased (1.3608 --> 1.3095).  Saving model ...
    Epoch [5/50], Train Losses:  mse: 5.9911, huber: 1.0699, mae: 1.4368, swd: 1.5726, target_std: 6.5010
    Epoch [5/50], Val Losses:  mse: 9.0222, huber: 1.2864, mae: 1.6487, swd: 1.9507, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 10.3780, huber: 1.3956, mae: 1.7663, swd: 2.1915, target_std: 4.7502
            Validation loss decreased (1.3095 --> 1.2864).  Saving model ...
    Epoch [6/50], Train Losses:  mse: 5.9009, huber: 1.0569, mae: 1.4226, swd: 1.5365, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 8.9514, huber: 1.2939, mae: 1.6577, swd: 2.1734, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 10.1719, huber: 1.3935, mae: 1.7652, swd: 2.4966, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [7/50], Train Losses:  mse: 5.8000, huber: 1.0450, mae: 1.4101, swd: 1.5156, target_std: 6.5011
    Epoch [7/50], Val Losses:  mse: 9.0840, huber: 1.3189, mae: 1.6880, swd: 2.2277, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 10.1810, huber: 1.3869, mae: 1.7622, swd: 2.2421, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [8/50], Train Losses:  mse: 5.7230, huber: 1.0355, mae: 1.4004, swd: 1.4976, target_std: 6.5010
    Epoch [8/50], Val Losses:  mse: 9.1691, huber: 1.3150, mae: 1.6842, swd: 2.2387, target_std: 4.2763
    Epoch [8/50], Test Losses:  mse: 10.2204, huber: 1.4064, mae: 1.7833, swd: 2.5847, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [9/50], Train Losses:  mse: 5.6231, huber: 1.0213, mae: 1.3847, swd: 1.4502, target_std: 6.5011
    Epoch [9/50], Val Losses:  mse: 9.0593, huber: 1.3021, mae: 1.6684, swd: 2.1967, target_std: 4.2763
    Epoch [9/50], Test Losses:  mse: 10.1932, huber: 1.4018, mae: 1.7757, swd: 2.6078, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [10/50], Train Losses:  mse: 5.5717, huber: 1.0149, mae: 1.3779, swd: 1.4404, target_std: 6.5011
    Epoch [10/50], Val Losses:  mse: 9.3571, huber: 1.3337, mae: 1.6973, swd: 2.4294, target_std: 4.2763
    Epoch [10/50], Test Losses:  mse: 10.2435, huber: 1.3974, mae: 1.7688, swd: 2.6135, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [10/50], Test Losses:  mse: 10.3767, huber: 1.3955, mae: 1.7663, swd: 2.1914, target_std: 4.7502
    Best round's Test MSE: 10.3780, MAE: 1.7663
    Best round's Validation MSE: 9.0222, MAE: 1.6487
    Best round's Test verification MSE : 10.3767, MAE: 1.7663
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250331_1044)
    ==================================================
    Number of runs: 2
    Seeds: [2026, 3022]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2792 ± 0.0988
      huber: 1.3842 ± 0.0114
      mae: 1.7550 ± 0.0113
      swd: 2.3368 ± 0.1454
      target_std: 4.7502 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.7322 ± 0.2900
      huber: 1.2465 ± 0.0398
      mae: 1.6081 ± 0.0406
      swd: 1.8699 ± 0.0808
      target_std: 4.2763 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250331_1044
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [2026, 3022]
    


```python
importlib.reload(Train)
importlib.reload(train_config)  
importlib.reload(monotonic)
acl_experiment = run_experiment(
    model_type='ACL',
    data_manager=data_mgr,
    seq_len=336,
    pred_len=336,
    dim_hidden=96,
    seeds=[2026, 3022],
    learning_rate=9e-4
)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
    Running experiment with seed 2026 (1/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 27.1340, huber: 2.4589, mae: 2.8647, swd: 7.7144, target_std: 6.5011
    Epoch [1/50], Val Losses:  mse: 13.4506, huber: 1.7256, mae: 2.1208, swd: 2.0305, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 17.3288, huber: 2.0302, mae: 2.4318, swd: 3.4717, target_std: 4.7502
            Validation loss decreased (inf --> 1.7256).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 17.3012, huber: 1.8230, mae: 2.2110, swd: 2.9365, target_std: 6.5010
    Epoch [2/50], Val Losses:  mse: 11.9345, huber: 1.5806, mae: 1.9551, swd: 2.9244, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 14.7776, huber: 1.8148, mae: 2.1989, swd: 3.8418, target_std: 4.7502
            Validation loss decreased (1.7256 --> 1.5806).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 9.4330, huber: 1.3163, mae: 1.6919, swd: 1.9946, target_std: 6.5011
    Epoch [3/50], Val Losses:  mse: 9.9112, huber: 1.3117, mae: 1.6793, swd: 1.8616, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 13.2791, huber: 1.5557, mae: 1.9321, swd: 2.5911, target_std: 4.7502
            Validation loss decreased (1.5806 --> 1.3117).  Saving model ...
    Epoch [4/50], Train Losses:  mse: 6.6380, huber: 1.1197, mae: 1.4898, swd: 1.6907, target_std: 6.5012
    Epoch [4/50], Val Losses:  mse: 8.9917, huber: 1.2716, mae: 1.6367, swd: 1.9793, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 11.1036, huber: 1.4382, mae: 1.8114, swd: 2.7211, target_std: 4.7502
            Validation loss decreased (1.3117 --> 1.2716).  Saving model ...
    Epoch [5/50], Train Losses:  mse: 6.1704, huber: 1.0806, mae: 1.4489, swd: 1.5969, target_std: 6.5010
    Epoch [5/50], Val Losses:  mse: 9.1019, huber: 1.3265, mae: 1.6952, swd: 2.4813, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 10.7553, huber: 1.4512, mae: 1.8279, swd: 3.1378, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [6/50], Train Losses:  mse: 5.9912, huber: 1.0662, mae: 1.4337, swd: 1.5764, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 8.9363, huber: 1.2961, mae: 1.6626, swd: 2.1585, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 10.6164, huber: 1.4274, mae: 1.8024, swd: 2.7373, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [7/50], Train Losses:  mse: 5.8192, huber: 1.0494, mae: 1.4160, swd: 1.5230, target_std: 6.5011
    Epoch [7/50], Val Losses:  mse: 8.7803, huber: 1.2819, mae: 1.6482, swd: 2.0873, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 10.4005, huber: 1.4108, mae: 1.7858, swd: 2.6770, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [8/50], Train Losses:  mse: 5.6763, huber: 1.0336, mae: 1.3992, swd: 1.4707, target_std: 6.5009
    Epoch [8/50], Val Losses:  mse: 8.9002, huber: 1.2844, mae: 1.6495, swd: 1.9013, target_std: 4.2763
    Epoch [8/50], Test Losses:  mse: 10.3601, huber: 1.4002, mae: 1.7739, swd: 2.3285, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [9/50], Train Losses:  mse: 5.5883, huber: 1.0245, mae: 1.3896, swd: 1.4560, target_std: 6.5009
    Epoch [9/50], Val Losses:  mse: 8.9240, huber: 1.2856, mae: 1.6497, swd: 2.1340, target_std: 4.2763
    Epoch [9/50], Test Losses:  mse: 10.5665, huber: 1.4252, mae: 1.7986, swd: 2.8201, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [9/50], Test Losses:  mse: 11.1043, huber: 1.4382, mae: 1.8114, swd: 2.7206, target_std: 4.7502
    Best round's Test MSE: 11.1036, MAE: 1.8114
    Best round's Validation MSE: 8.9917, MAE: 1.6367
    Best round's Test verification MSE : 11.1043, MAE: 1.8114
    
    ==================================================
    Running experiment with seed 3022 (2/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 24.0250, huber: 2.2731, mae: 2.6757, swd: 7.1564, target_std: 6.5011
    Epoch [1/50], Val Losses:  mse: 12.0289, huber: 1.5768, mae: 1.9609, swd: 2.3518, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 15.4795, huber: 1.8602, mae: 2.2529, swd: 3.4534, target_std: 4.7502
            Validation loss decreased (inf --> 1.5768).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 14.4516, huber: 1.6483, mae: 2.0328, swd: 2.7688, target_std: 6.5009
    Epoch [2/50], Val Losses:  mse: 11.0732, huber: 1.4813, mae: 1.8527, swd: 2.1491, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 13.8260, huber: 1.7179, mae: 2.0986, swd: 3.0201, target_std: 4.7502
            Validation loss decreased (1.5768 --> 1.4813).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 11.9513, huber: 1.4663, mae: 1.8431, swd: 2.2409, target_std: 6.5008
    Epoch [3/50], Val Losses:  mse: 10.0531, huber: 1.3826, mae: 1.7519, swd: 2.3044, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 12.2477, huber: 1.5648, mae: 1.9430, swd: 2.9220, target_std: 4.7502
            Validation loss decreased (1.4813 --> 1.3826).  Saving model ...
    Epoch [4/50], Train Losses:  mse: 7.2879, huber: 1.1622, mae: 1.5327, swd: 1.7176, target_std: 6.5012
    Epoch [4/50], Val Losses:  mse: 9.3711, huber: 1.2808, mae: 1.6468, swd: 1.9564, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 11.8491, huber: 1.4702, mae: 1.8453, swd: 2.5838, target_std: 4.7502
            Validation loss decreased (1.3826 --> 1.2808).  Saving model ...
    Epoch [5/50], Train Losses:  mse: 6.3565, huber: 1.0902, mae: 1.4585, swd: 1.6252, target_std: 6.5011
    Epoch [5/50], Val Losses:  mse: 9.2567, huber: 1.3131, mae: 1.6793, swd: 2.2416, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 11.0807, huber: 1.4431, mae: 1.8170, swd: 2.7650, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [6/50], Train Losses:  mse: 6.0823, huber: 1.0659, mae: 1.4328, swd: 1.5686, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 9.0995, huber: 1.2936, mae: 1.6611, swd: 2.0715, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 10.6704, huber: 1.4271, mae: 1.8045, swd: 2.6437, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [7/50], Train Losses:  mse: 5.9135, huber: 1.0513, mae: 1.4172, swd: 1.5325, target_std: 6.5009
    Epoch [7/50], Val Losses:  mse: 8.9904, huber: 1.2783, mae: 1.6432, swd: 1.9722, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 10.5672, huber: 1.4150, mae: 1.7901, swd: 2.6407, target_std: 4.7502
            Validation loss decreased (1.2808 --> 1.2783).  Saving model ...
    Epoch [8/50], Train Losses:  mse: 5.7620, huber: 1.0369, mae: 1.4020, swd: 1.4957, target_std: 6.5011
    Epoch [8/50], Val Losses:  mse: 9.0507, huber: 1.3009, mae: 1.6650, swd: 2.1865, target_std: 4.2763
    Epoch [8/50], Test Losses:  mse: 10.5562, huber: 1.4245, mae: 1.7983, swd: 2.8151, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [9/50], Train Losses:  mse: 5.6342, huber: 1.0241, mae: 1.3886, swd: 1.4572, target_std: 6.5010
    Epoch [9/50], Val Losses:  mse: 9.3241, huber: 1.3257, mae: 1.6904, swd: 2.1753, target_std: 4.2763
    Epoch [9/50], Test Losses:  mse: 10.6477, huber: 1.4276, mae: 1.8009, swd: 2.6665, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [10/50], Train Losses:  mse: 5.5038, huber: 1.0099, mae: 1.3735, swd: 1.4091, target_std: 6.5010
    Epoch [10/50], Val Losses:  mse: 9.1351, huber: 1.3036, mae: 1.6672, swd: 2.1806, target_std: 4.2763
    Epoch [10/50], Test Losses:  mse: 10.6928, huber: 1.4346, mae: 1.8094, swd: 2.8281, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [11/50], Train Losses:  mse: 5.4432, huber: 1.0052, mae: 1.3687, swd: 1.4161, target_std: 6.5012
    Epoch [11/50], Val Losses:  mse: 9.3629, huber: 1.3317, mae: 1.6959, swd: 2.3726, target_std: 4.2763
    Epoch [11/50], Test Losses:  mse: 10.6431, huber: 1.4274, mae: 1.8020, swd: 2.7715, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [12/50], Train Losses:  mse: 5.2732, huber: 0.9839, mae: 1.3462, swd: 1.3330, target_std: 6.5008
    Epoch [12/50], Val Losses:  mse: 9.3715, huber: 1.3290, mae: 1.6924, swd: 2.3845, target_std: 4.2763
    Epoch [12/50], Test Losses:  mse: 10.7153, huber: 1.4290, mae: 1.8031, swd: 2.7903, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [12/50], Test Losses:  mse: 10.5658, huber: 1.4149, mae: 1.7900, swd: 2.6404, target_std: 4.7502
    Best round's Test MSE: 10.5672, MAE: 1.7901
    Best round's Validation MSE: 8.9904, MAE: 1.6432
    Best round's Test verification MSE : 10.5658, MAE: 1.7900
    
    ==================================================
    Experiment Summary (ACL_ettm1_seq336_pred336_20250331_0342)
    ==================================================
    Number of runs: 2
    Seeds: [2026, 3022]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.8354 ± 0.2682
      huber: 1.4266 ± 0.0116
      mae: 1.8008 ± 0.0107
      swd: 2.6809 ± 0.0402
      target_std: 4.7502 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 8.9910 ± 0.0007
      huber: 1.2749 ± 0.0033
      mae: 1.6400 ± 0.0032
      swd: 1.9758 ± 0.0036
      target_std: 4.2763 ± 0.0000
    ==================================================
    
    Experiment complete: ACL_ettm1_seq336_pred336_20250331_0342
    Model: ACL
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [2026, 3022]
    


```python
importlib.reload(Train)
importlib.reload(train_config)  
importlib.reload(monotonic)
acl_experiment = run_experiment(
    model_type='TimeMixer',
    data_manager=data_mgr,
    seq_len=336,
    pred_len=336,
    dim_hidden=96,
    seeds=[2026, 3022],
    learning_rate=9e-4
)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
    Running experiment with seed 2026 (1/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 6.8247, huber: 1.1372, mae: 1.5023, swd: 1.9696, target_std: 6.5010
    Epoch [1/50], Val Losses:  mse: 7.7885, huber: 1.0680, mae: 1.4181, swd: 0.9126, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 10.6476, huber: 1.3520, mae: 1.7136, swd: 1.8163, target_std: 4.7502
            Validation loss decreased (inf --> 1.0680).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 5.8518, huber: 1.0289, mae: 1.3860, swd: 1.7224, target_std: 6.5010
    Epoch [2/50], Val Losses:  mse: 7.5670, huber: 1.0625, mae: 1.4129, swd: 0.8440, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 10.1687, huber: 1.3265, mae: 1.6871, swd: 1.7139, target_std: 4.7502
            Validation loss decreased (1.0680 --> 1.0625).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 5.5304, huber: 0.9920, mae: 1.3475, swd: 1.5759, target_std: 6.5011
    Epoch [3/50], Val Losses:  mse: 7.4007, huber: 1.0641, mae: 1.4171, swd: 0.8704, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 10.2253, huber: 1.3557, mae: 1.7208, swd: 1.8677, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [4/50], Train Losses:  mse: 5.0661, huber: 0.9408, mae: 1.2949, swd: 1.3480, target_std: 6.5011
    Epoch [4/50], Val Losses:  mse: 7.8185, huber: 1.1124, mae: 1.4676, swd: 0.9067, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 10.6739, huber: 1.3707, mae: 1.7351, swd: 1.7270, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [5/50], Train Losses:  mse: 4.4606, huber: 0.8709, mae: 1.2230, swd: 1.0628, target_std: 6.5011
    Epoch [5/50], Val Losses:  mse: 8.1853, huber: 1.1329, mae: 1.4893, swd: 1.0001, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 11.2316, huber: 1.4197, mae: 1.7872, swd: 2.1402, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [6/50], Train Losses:  mse: 3.8709, huber: 0.7987, mae: 1.1481, swd: 0.8278, target_std: 6.5013
    Epoch [6/50], Val Losses:  mse: 8.3227, huber: 1.1508, mae: 1.5080, swd: 1.0639, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 11.6990, huber: 1.4451, mae: 1.8124, swd: 2.2438, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [7/50], Train Losses:  mse: 3.3802, huber: 0.7344, mae: 1.0810, swd: 0.6512, target_std: 6.5010
    Epoch [7/50], Val Losses:  mse: 8.6267, huber: 1.1879, mae: 1.5475, swd: 1.0291, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 12.1207, huber: 1.4683, mae: 1.8374, swd: 2.1099, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [7/50], Test Losses:  mse: 10.1687, huber: 1.3265, mae: 1.6871, swd: 1.7139, target_std: 4.7502
    Best round's Test MSE: 10.1687, MAE: 1.6871
    Best round's Validation MSE: 7.5670, MAE: 1.4129
    Best round's Test verification MSE : 10.1687, MAE: 1.6871
    
    ==================================================
    Running experiment with seed 3022 (2/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 6.5336, huber: 1.1092, mae: 1.4719, swd: 1.8996, target_std: 6.5012
    Epoch [1/50], Val Losses:  mse: 7.5843, huber: 1.0594, mae: 1.4090, swd: 0.9063, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 10.4230, huber: 1.3352, mae: 1.6947, swd: 1.7812, target_std: 4.7502
            Validation loss decreased (inf --> 1.0594).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 5.8009, huber: 1.0234, mae: 1.3798, swd: 1.7085, target_std: 6.5011
    Epoch [2/50], Val Losses:  mse: 7.5243, huber: 1.0595, mae: 1.4086, swd: 0.9035, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 10.1026, huber: 1.3333, mae: 1.6952, swd: 1.8237, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [3/50], Train Losses:  mse: 5.4148, huber: 0.9796, mae: 1.3347, swd: 1.5280, target_std: 6.5011
    Epoch [3/50], Val Losses:  mse: 7.6886, huber: 1.0873, mae: 1.4397, swd: 0.9278, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 10.3796, huber: 1.3466, mae: 1.7085, swd: 1.7814, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [4/50], Train Losses:  mse: 4.8905, huber: 0.9210, mae: 1.2747, swd: 1.2839, target_std: 6.5012
    Epoch [4/50], Val Losses:  mse: 7.8200, huber: 1.1094, mae: 1.4643, swd: 1.0281, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 10.8613, huber: 1.3935, mae: 1.7589, swd: 2.1498, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [5/50], Train Losses:  mse: 4.3119, huber: 0.8537, mae: 1.2053, swd: 1.0270, target_std: 6.5009
    Epoch [5/50], Val Losses:  mse: 8.1540, huber: 1.1451, mae: 1.5015, swd: 1.0973, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 11.4437, huber: 1.4422, mae: 1.8087, swd: 2.3322, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [6/50], Train Losses:  mse: 3.8222, huber: 0.7939, mae: 1.1432, swd: 0.8422, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 8.4113, huber: 1.1729, mae: 1.5312, swd: 1.0831, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 11.4992, huber: 1.4343, mae: 1.8012, swd: 2.0254, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [6/50], Test Losses:  mse: 10.4230, huber: 1.3352, mae: 1.6947, swd: 1.7812, target_std: 4.7502
    Best round's Test MSE: 10.4230, MAE: 1.6947
    Best round's Validation MSE: 7.5843, MAE: 1.4090
    Best round's Test verification MSE : 10.4230, MAE: 1.6947
    
    ==================================================
    Experiment Summary (TimeMixer_ettm1_seq336_pred336_20250331_0345)
    ==================================================
    Number of runs: 2
    Seeds: [2026, 3022]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.2958 ± 0.1272
      huber: 1.3309 ± 0.0044
      mae: 1.6909 ± 0.0038
      swd: 1.7476 ± 0.0337
      target_std: 4.7502 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.5756 ± 0.0087
      huber: 1.0609 ± 0.0016
      mae: 1.4110 ± 0.0019
      swd: 0.8751 ± 0.0311
      target_std: 4.2763 ± 0.0000
    ==================================================
    
    Experiment complete: TimeMixer_ettm1_seq336_pred336_20250331_0345
    Model: TimeMixer
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [2026, 3022]
    


```python
importlib.reload(Train)
importlib.reload(train_config)  
importlib.reload(monotonic)
importlib.reload(data_manager)
importlib.reload(utils)
importlib.reload(train_config)
acl_experiment = run_experiment(
    model_type='DLinear',
    data_manager=data_mgr,
    seq_len=336,
    pred_len=336,
    dim_hidden=96,
    dim_augment=128,
    seeds=[2026, 3022],
    learning_rate=9e-4
)
```

    Shape of training data: torch.Size([48776, 7])
    Shape of validation data: torch.Size([6968, 7])
    Shape of testing data: torch.Size([13936, 7])
    Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])
    Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])
    Number of batches in train_loader: 376
    Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])
    
    ==================================================
    Data Preparation: ettm1
    ==================================================
    Sequence Length: 336
    Prediction Length: 336
    Batch Size: 128
    Scaling: No
    Train Split: 0.7
    Val Split: 0.8
    Training Batches: 376
    Validation Batches: 50
    Test Batches: 104
    ==================================================
    
    ==================================================
    Running experiment with seed 2026 (1/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 7.3912, huber: 1.1743, mae: 1.5409, swd: 2.2200, target_std: 6.5009
    Epoch [1/50], Val Losses:  mse: 7.9025, huber: 1.0484, mae: 1.3981, swd: 0.9136, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 11.0805, huber: 1.3664, mae: 1.7287, swd: 1.8622, target_std: 4.7502
            Validation loss decreased (inf --> 1.0484).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 6.2593, huber: 1.0682, mae: 1.4276, swd: 1.9326, target_std: 6.5009
    Epoch [2/50], Val Losses:  mse: 7.9493, huber: 1.0642, mae: 1.4141, swd: 1.0957, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 10.8740, huber: 1.3527, mae: 1.7138, swd: 1.9387, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [3/50], Train Losses:  mse: 6.2319, huber: 1.0647, mae: 1.4239, swd: 1.9184, target_std: 6.5012
    Epoch [3/50], Val Losses:  mse: 7.8196, huber: 1.0486, mae: 1.3990, swd: 0.9863, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 10.8696, huber: 1.3509, mae: 1.7120, swd: 1.8658, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [4/50], Train Losses:  mse: 6.2033, huber: 1.0616, mae: 1.4206, swd: 1.9045, target_std: 6.5012
    Epoch [4/50], Val Losses:  mse: 7.9253, huber: 1.0516, mae: 1.4009, swd: 0.9158, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 11.0203, huber: 1.3583, mae: 1.7198, swd: 1.7743, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [5/50], Train Losses:  mse: 6.1912, huber: 1.0606, mae: 1.4199, swd: 1.8899, target_std: 6.5012
    Epoch [5/50], Val Losses:  mse: 7.8698, huber: 1.0516, mae: 1.4020, swd: 0.9345, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 10.9618, huber: 1.3550, mae: 1.7164, swd: 1.7848, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [6/50], Train Losses:  mse: 6.1862, huber: 1.0602, mae: 1.4194, swd: 1.8846, target_std: 6.5010
    Epoch [6/50], Val Losses:  mse: 7.7931, huber: 1.0586, mae: 1.4091, swd: 1.1730, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 10.7184, huber: 1.3441, mae: 1.7049, swd: 1.9627, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [6/50], Test Losses:  mse: 11.0805, huber: 1.3664, mae: 1.7287, swd: 1.8622, target_std: 4.7502
    Best round's Test MSE: 11.0805, MAE: 1.7287
    Best round's Validation MSE: 7.9025, MAE: 1.3981
    Best round's Test verification MSE : 11.0805, MAE: 1.7287
    
    ==================================================
    Running experiment with seed 3022 (2/2)
    ==================================================
    
    Epoch [1/50], Train Losses:  mse: 7.4612, huber: 1.1785, mae: 1.5452, swd: 2.2207, target_std: 6.5011
    Epoch [1/50], Val Losses:  mse: 8.0561, huber: 1.0648, mae: 1.4159, swd: 0.9222, target_std: 4.2763
    Epoch [1/50], Test Losses:  mse: 11.1882, huber: 1.3784, mae: 1.7423, swd: 1.8675, target_std: 4.7502
            Validation loss decreased (inf --> 1.0648).  Saving model ...
    Epoch [2/50], Train Losses:  mse: 6.2745, huber: 1.0699, mae: 1.4294, swd: 1.9467, target_std: 6.5010
    Epoch [2/50], Val Losses:  mse: 7.8977, huber: 1.0490, mae: 1.3982, swd: 0.9033, target_std: 4.2763
    Epoch [2/50], Test Losses:  mse: 11.0469, huber: 1.3627, mae: 1.7248, swd: 1.8315, target_std: 4.7502
            Validation loss decreased (1.0648 --> 1.0490).  Saving model ...
    Epoch [3/50], Train Losses:  mse: 6.2236, huber: 1.0640, mae: 1.4233, swd: 1.9181, target_std: 6.5010
    Epoch [3/50], Val Losses:  mse: 7.9414, huber: 1.0519, mae: 1.4024, swd: 0.9214, target_std: 4.2763
    Epoch [3/50], Test Losses:  mse: 11.0517, huber: 1.3581, mae: 1.7198, swd: 1.7559, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [4/50], Train Losses:  mse: 6.2061, huber: 1.0620, mae: 1.4213, swd: 1.9024, target_std: 6.5013
    Epoch [4/50], Val Losses:  mse: 7.8439, huber: 1.0464, mae: 1.3977, swd: 0.9368, target_std: 4.2763
    Epoch [4/50], Test Losses:  mse: 10.9201, huber: 1.3513, mae: 1.7129, swd: 1.7932, target_std: 4.7502
            Validation loss decreased (1.0490 --> 1.0464).  Saving model ...
    Epoch [5/50], Train Losses:  mse: 6.1983, huber: 1.0614, mae: 1.4206, swd: 1.8928, target_std: 6.5012
    Epoch [5/50], Val Losses:  mse: 7.9856, huber: 1.0792, mae: 1.4312, swd: 1.1799, target_std: 4.2763
    Epoch [5/50], Test Losses:  mse: 10.8587, huber: 1.3541, mae: 1.7147, swd: 1.9839, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [6/50], Train Losses:  mse: 6.2010, huber: 1.0621, mae: 1.4215, swd: 1.8981, target_std: 6.5011
    Epoch [6/50], Val Losses:  mse: 7.8393, huber: 1.0499, mae: 1.3989, swd: 1.0062, target_std: 4.2763
    Epoch [6/50], Test Losses:  mse: 10.8670, huber: 1.3463, mae: 1.7063, swd: 1.8377, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [7/50], Train Losses:  mse: 6.1946, huber: 1.0613, mae: 1.4205, swd: 1.8918, target_std: 6.5012
    Epoch [7/50], Val Losses:  mse: 7.8559, huber: 1.0572, mae: 1.4082, swd: 0.9560, target_std: 4.2763
    Epoch [7/50], Test Losses:  mse: 10.9827, huber: 1.3611, mae: 1.7234, swd: 1.8115, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [8/50], Train Losses:  mse: 6.1942, huber: 1.0616, mae: 1.4208, swd: 1.8874, target_std: 6.5011
    Epoch [8/50], Val Losses:  mse: 7.8012, huber: 1.0521, mae: 1.4017, swd: 1.0567, target_std: 4.2763
    Epoch [8/50], Test Losses:  mse: 10.7515, huber: 1.3400, mae: 1.7004, swd: 1.8345, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [9/50], Train Losses:  mse: 6.1811, huber: 1.0602, mae: 1.4195, swd: 1.8830, target_std: 6.5011
    Epoch [9/50], Val Losses:  mse: 7.7615, huber: 1.0361, mae: 1.3848, swd: 0.9168, target_std: 4.2763
    Epoch [9/50], Test Losses:  mse: 10.8711, huber: 1.3464, mae: 1.7073, swd: 1.7580, target_std: 4.7502
            Validation loss decreased (1.0464 --> 1.0361).  Saving model ...
    Epoch [10/50], Train Losses:  mse: 6.1797, huber: 1.0597, mae: 1.4189, swd: 1.8770, target_std: 6.5011
    Epoch [10/50], Val Losses:  mse: 7.8980, huber: 1.0662, mae: 1.4165, swd: 1.1143, target_std: 4.2763
    Epoch [10/50], Test Losses:  mse: 10.8271, huber: 1.3469, mae: 1.7081, swd: 1.8755, target_std: 4.7502
            EarlyStopping counter: 1 out of 5
    Epoch [11/50], Train Losses:  mse: 6.1799, huber: 1.0601, mae: 1.4194, swd: 1.8754, target_std: 6.5013
    Epoch [11/50], Val Losses:  mse: 7.8520, huber: 1.0537, mae: 1.4029, swd: 0.9862, target_std: 4.2763
    Epoch [11/50], Test Losses:  mse: 10.9000, huber: 1.3467, mae: 1.7081, swd: 1.7660, target_std: 4.7502
            EarlyStopping counter: 2 out of 5
    Epoch [12/50], Train Losses:  mse: 6.1749, huber: 1.0591, mae: 1.4181, swd: 1.8726, target_std: 6.5010
    Epoch [12/50], Val Losses:  mse: 7.8721, huber: 1.0684, mae: 1.4203, swd: 1.1534, target_std: 4.2763
    Epoch [12/50], Test Losses:  mse: 10.7480, huber: 1.3433, mae: 1.7044, swd: 1.8788, target_std: 4.7502
            EarlyStopping counter: 3 out of 5
    Epoch [13/50], Train Losses:  mse: 6.1934, huber: 1.0616, mae: 1.4209, swd: 1.8827, target_std: 6.5010
    Epoch [13/50], Val Losses:  mse: 7.7948, huber: 1.0468, mae: 1.3961, swd: 0.9892, target_std: 4.2763
    Epoch [13/50], Test Losses:  mse: 10.8517, huber: 1.3444, mae: 1.7052, swd: 1.7729, target_std: 4.7502
            EarlyStopping counter: 4 out of 5
    Epoch [14/50], Train Losses:  mse: 6.1747, huber: 1.0597, mae: 1.4190, swd: 1.8744, target_std: 6.5009
    Epoch [14/50], Val Losses:  mse: 7.8717, huber: 1.0583, mae: 1.4089, swd: 1.0128, target_std: 4.2763
    Epoch [14/50], Test Losses:  mse: 10.7582, huber: 1.3433, mae: 1.7061, swd: 1.7725, target_std: 4.7502
            EarlyStopping counter: 5 out of 5
    Early stopping
    Epoch [14/50], Test Losses:  mse: 10.8711, huber: 1.3464, mae: 1.7073, swd: 1.7580, target_std: 4.7502
    Best round's Test MSE: 10.8711, MAE: 1.7073
    Best round's Validation MSE: 7.7615, MAE: 1.3848
    Best round's Test verification MSE : 10.8711, MAE: 1.7073
    
    ==================================================
    Experiment Summary (DLinear_ettm1_seq336_pred336_20250331_1038)
    ==================================================
    Number of runs: 2
    Seeds: [2026, 3022]
    
    Test Performance at Best Validation (mean ± std):
      mse: 10.9758 ± 0.1047
      huber: 1.3564 ± 0.0100
      mae: 1.7180 ± 0.0107
      swd: 1.8101 ± 0.0521
      target_std: 4.7502 ± 0.0000
    
    Corresponding Validation Performance (mean ± std):
      mse: 7.8320 ± 0.0705
      huber: 1.0422 ± 0.0061
      mae: 1.3914 ± 0.0066
      swd: 0.9152 ± 0.0016
      target_std: 4.2763 ± 0.0000
    ==================================================
    
    Experiment complete: DLinear_ettm1_seq336_pred336_20250331_1038
    Model: DLinear
    Dataset: ettm1
    Sequence Length: 336
    Prediction Length: 336
    Seeds: [2026, 3022]
    
