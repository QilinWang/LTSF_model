{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a21a3c",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016376c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "==================================================\n",
      "Dataset: ettm2 (csv)\n",
      "==================================================\n",
      "Shape: torch.Size([69680, 7])\n",
      "Channels: 7\n",
      "Length: 69680\n",
      "Source: ./ettm2.csv\n",
      "\n",
      "Sample data (first 2 rows):\n",
      "tensor([[41.1300, 12.4810, 36.5360,  9.3550,  4.4240,  1.3110, 38.6620],\n",
      "        [39.6220, 11.3090, 35.5440,  8.5510,  3.2090,  1.2580, 38.2230]])\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<data_manager.DatasetManager at 0x15d6a1d7e30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "from importlib import reload  \n",
    "  \n",
    "import monotonic\n",
    "import utils\n",
    "from train import execute_model_evaluation\n",
    "from train_config import FlatACLConfig\n",
    "import train_config\n",
    "import data_manager\n",
    "from data_manager import DatasetManager\n",
    "import metrics\n",
    "from dataclasses import replace\n",
    "\n",
    "reload(utils)\n",
    "reload(monotonic)\n",
    "reload(train_config)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "data_mgr = DatasetManager(device='cuda')\n",
    " \n",
    "data_mgr.load_csv('ettm2', './ettm2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9573c4",
   "metadata": {},
   "source": [
    "# Seq=336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745e5d6",
   "metadata": {},
   "source": [
    "### EigenACL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7c5de",
   "metadata": {},
   "source": [
    "#### pred=96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc9741",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79b158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "global_std.shape: torch.Size([7])\n",
      "Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],\n",
      "       device='cuda:0')\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.9086, mae: 2.9131, huber: 2.4963, swd: 24.9905, ept: 81.6228\n",
      "Epoch [1/50], Val Losses: mse: 15.6704, mae: 2.4658, huber: 2.0593, swd: 7.8415, ept: 82.0076\n",
      "Epoch [1/50], Test Losses: mse: 12.5085, mae: 2.2797, huber: 1.8573, swd: 6.3179, ept: 84.7773\n",
      "  Epoch 1 composite train-obj: 2.496347\n",
      "        Val objective improved inf → 2.0593, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.7320, mae: 1.9785, huber: 1.5741, swd: 6.3065, ept: 89.3198\n",
      "Epoch [2/50], Val Losses: mse: 13.0250, mae: 2.2332, huber: 1.8322, swd: 6.5612, ept: 84.7385\n",
      "Epoch [2/50], Test Losses: mse: 10.0509, mae: 2.0040, huber: 1.5892, swd: 4.9339, ept: 87.3395\n",
      "  Epoch 2 composite train-obj: 1.574073\n",
      "        Val objective improved 2.0593 → 1.8322, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.9779, mae: 1.9022, huber: 1.5014, swd: 5.8368, ept: 89.8030\n",
      "Epoch [3/50], Val Losses: mse: 12.3917, mae: 2.1766, huber: 1.7785, swd: 6.3697, ept: 84.5256\n",
      "Epoch [3/50], Test Losses: mse: 9.6001, mae: 1.9627, huber: 1.5481, swd: 4.8374, ept: 87.0552\n",
      "  Epoch 3 composite train-obj: 1.501437\n",
      "        Val objective improved 1.8322 → 1.7785, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.4971, mae: 1.8562, huber: 1.4580, swd: 5.4770, ept: 90.0395\n",
      "Epoch [4/50], Val Losses: mse: 15.8648, mae: 2.5018, huber: 2.1015, swd: 9.0932, ept: 80.7675\n",
      "Epoch [4/50], Test Losses: mse: 13.3835, mae: 2.3573, huber: 1.9351, swd: 7.9719, ept: 82.8661\n",
      "  Epoch 4 composite train-obj: 1.458016\n",
      "        No improvement (2.1015), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.1703, mae: 1.8311, huber: 1.4340, swd: 5.2610, ept: 90.1913\n",
      "Epoch [5/50], Val Losses: mse: 12.0827, mae: 2.1396, huber: 1.7491, swd: 6.2626, ept: 84.2331\n",
      "Epoch [5/50], Test Losses: mse: 9.3583, mae: 1.9223, huber: 1.5145, swd: 4.6966, ept: 87.0072\n",
      "  Epoch 5 composite train-obj: 1.434047\n",
      "        Val objective improved 1.7785 → 1.7491, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 9.7782, mae: 1.7950, huber: 1.3994, swd: 4.9637, ept: 90.3895\n",
      "Epoch [6/50], Val Losses: mse: 12.3424, mae: 2.1491, huber: 1.7593, swd: 6.6220, ept: 84.2090\n",
      "Epoch [6/50], Test Losses: mse: 9.5060, mae: 1.9352, huber: 1.5285, swd: 4.8952, ept: 86.6797\n",
      "  Epoch 6 composite train-obj: 1.399358\n",
      "        No improvement (1.7593), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 9.5094, mae: 1.7666, huber: 1.3723, swd: 4.7698, ept: 90.5421\n",
      "Epoch [7/50], Val Losses: mse: 12.4932, mae: 2.1577, huber: 1.7674, swd: 6.6136, ept: 83.8025\n",
      "Epoch [7/50], Test Losses: mse: 9.8545, mae: 1.9526, huber: 1.5442, swd: 5.1275, ept: 86.1302\n",
      "  Epoch 7 composite train-obj: 1.372297\n",
      "        No improvement (1.7674), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 9.3094, mae: 1.7441, huber: 1.3509, swd: 4.6373, ept: 90.6236\n",
      "Epoch [8/50], Val Losses: mse: 12.3741, mae: 2.1586, huber: 1.7680, swd: 6.5202, ept: 83.8382\n",
      "Epoch [8/50], Test Losses: mse: 9.6083, mae: 1.9445, huber: 1.5358, swd: 4.8921, ept: 86.6293\n",
      "  Epoch 8 composite train-obj: 1.350931\n",
      "        No improvement (1.7680), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 9.1052, mae: 1.7343, huber: 1.3412, swd: 4.4980, ept: 90.7175\n",
      "Epoch [9/50], Val Losses: mse: 13.0811, mae: 2.2232, huber: 1.8335, swd: 7.1217, ept: 82.7547\n",
      "Epoch [9/50], Test Losses: mse: 10.0898, mae: 1.9650, huber: 1.5574, swd: 5.2983, ept: 85.5427\n",
      "  Epoch 9 composite train-obj: 1.341156\n",
      "        No improvement (1.8335), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 8.8417, mae: 1.7103, huber: 1.3186, swd: 4.3185, ept: 90.8436\n",
      "Epoch [10/50], Val Losses: mse: 13.1254, mae: 2.2142, huber: 1.8256, swd: 7.2762, ept: 83.0540\n",
      "Epoch [10/50], Test Losses: mse: 9.9472, mae: 1.9472, huber: 1.5403, swd: 5.2757, ept: 86.3709\n",
      "  Epoch 10 composite train-obj: 1.318621\n",
      "Epoch [10/50], Test Losses: mse: 9.3582, mae: 1.9223, huber: 1.5145, swd: 4.6965, ept: 87.0073\n",
      "Best round's Test MSE: 9.3583, MAE: 1.9223, SWD: 4.6966\n",
      "Best round's Validation MSE: 12.0827, MAE: 2.1396, SWD: 6.2626\n",
      "Best round's Test verification MSE : 9.3582, MAE: 1.9223, SWD: 4.6965\n",
      "Time taken: 110.99 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.0901, mae: 2.9272, huber: 2.5100, swd: 23.8367, ept: 79.9089\n",
      "Epoch [1/50], Val Losses: mse: 13.5612, mae: 2.2865, huber: 1.8835, swd: 6.5441, ept: 84.3538\n",
      "Epoch [1/50], Test Losses: mse: 10.0877, mae: 2.0318, huber: 1.6147, swd: 4.6577, ept: 87.1437\n",
      "  Epoch 1 composite train-obj: 2.510044\n",
      "        Val objective improved inf → 1.8835, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.7327, mae: 1.9808, huber: 1.5762, swd: 6.0959, ept: 89.2619\n",
      "Epoch [2/50], Val Losses: mse: 13.0498, mae: 2.2442, huber: 1.8416, swd: 6.6106, ept: 84.5885\n",
      "Epoch [2/50], Test Losses: mse: 9.8670, mae: 2.0385, huber: 1.6179, swd: 4.7932, ept: 88.0163\n",
      "  Epoch 2 composite train-obj: 1.576236\n",
      "        Val objective improved 1.8835 → 1.8416, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.8179, mae: 1.8962, huber: 1.4952, swd: 5.4881, ept: 89.8042\n",
      "Epoch [3/50], Val Losses: mse: 13.1000, mae: 2.2413, huber: 1.8411, swd: 6.5958, ept: 83.6750\n",
      "Epoch [3/50], Test Losses: mse: 10.3111, mae: 2.0173, huber: 1.6035, swd: 5.1469, ept: 86.5148\n",
      "  Epoch 3 composite train-obj: 1.495230\n",
      "        Val objective improved 1.8416 → 1.8411, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.2895, mae: 1.8462, huber: 1.4473, swd: 5.1256, ept: 90.0377\n",
      "Epoch [4/50], Val Losses: mse: 12.4147, mae: 2.1745, huber: 1.7770, swd: 6.1912, ept: 84.1758\n",
      "Epoch [4/50], Test Losses: mse: 9.5039, mae: 1.9368, huber: 1.5256, swd: 4.5890, ept: 87.1912\n",
      "  Epoch 4 composite train-obj: 1.447343\n",
      "        Val objective improved 1.8411 → 1.7770, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 9.9102, mae: 1.8142, huber: 1.4167, swd: 4.8603, ept: 90.2049\n",
      "Epoch [5/50], Val Losses: mse: 12.7868, mae: 2.1927, huber: 1.7965, swd: 6.5832, ept: 83.9263\n",
      "Epoch [5/50], Test Losses: mse: 9.6907, mae: 1.9529, huber: 1.5431, swd: 4.8719, ept: 87.1574\n",
      "  Epoch 5 composite train-obj: 1.416723\n",
      "        No improvement (1.7965), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 9.6115, mae: 1.7851, huber: 1.3888, swd: 4.6646, ept: 90.3629\n",
      "Epoch [6/50], Val Losses: mse: 13.0910, mae: 2.2241, huber: 1.8292, swd: 6.6671, ept: 83.5106\n",
      "Epoch [6/50], Test Losses: mse: 9.8407, mae: 1.9595, huber: 1.5503, swd: 4.8795, ept: 86.5128\n",
      "  Epoch 6 composite train-obj: 1.388815\n",
      "        No improvement (1.8292), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.3840, mae: 1.7611, huber: 1.3663, swd: 4.5257, ept: 90.4909\n",
      "Epoch [7/50], Val Losses: mse: 15.3878, mae: 2.4513, huber: 2.0526, swd: 8.4450, ept: 81.4447\n",
      "Epoch [7/50], Test Losses: mse: 12.8269, mae: 2.2712, huber: 1.8542, swd: 7.4143, ept: 83.5088\n",
      "  Epoch 7 composite train-obj: 1.366325\n",
      "        No improvement (2.0526), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 9.1947, mae: 1.7433, huber: 1.3494, swd: 4.4050, ept: 90.6242\n",
      "Epoch [8/50], Val Losses: mse: 13.2194, mae: 2.2271, huber: 1.8318, swd: 6.7466, ept: 83.6633\n",
      "Epoch [8/50], Test Losses: mse: 9.9532, mae: 1.9614, huber: 1.5523, swd: 5.0290, ept: 86.4535\n",
      "  Epoch 8 composite train-obj: 1.349401\n",
      "        No improvement (1.8318), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 9.0235, mae: 1.7244, huber: 1.3313, swd: 4.3093, ept: 90.7321\n",
      "Epoch [9/50], Val Losses: mse: 13.4106, mae: 2.2240, huber: 1.8321, swd: 7.0497, ept: 83.5237\n",
      "Epoch [9/50], Test Losses: mse: 10.4223, mae: 2.0035, huber: 1.5923, swd: 5.3337, ept: 86.0806\n",
      "  Epoch 9 composite train-obj: 1.331300\n",
      "Epoch [9/50], Test Losses: mse: 9.5033, mae: 1.9367, huber: 1.5256, swd: 4.5881, ept: 87.1831\n",
      "Best round's Test MSE: 9.5039, MAE: 1.9368, SWD: 4.5890\n",
      "Best round's Validation MSE: 12.4147, MAE: 2.1745, SWD: 6.1912\n",
      "Best round's Test verification MSE : 9.5033, MAE: 1.9367, SWD: 4.5881\n",
      "Time taken: 109.00 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.9903, mae: 2.8997, huber: 2.4829, swd: 22.4224, ept: 81.0937\n",
      "Epoch [1/50], Val Losses: mse: 14.1053, mae: 2.3349, huber: 1.9304, swd: 6.2403, ept: 83.7657\n",
      "Epoch [1/50], Test Losses: mse: 10.6614, mae: 2.0959, huber: 1.6777, swd: 4.4709, ept: 86.9662\n",
      "  Epoch 1 composite train-obj: 2.482894\n",
      "        Val objective improved inf → 1.9304, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8262, mae: 1.9917, huber: 1.5865, swd: 5.7012, ept: 89.1526\n",
      "Epoch [2/50], Val Losses: mse: 12.8963, mae: 2.2266, huber: 1.8228, swd: 5.9312, ept: 84.6249\n",
      "Epoch [2/50], Test Losses: mse: 9.8978, mae: 2.0011, huber: 1.5846, swd: 4.3957, ept: 87.1562\n",
      "  Epoch 2 composite train-obj: 1.586544\n",
      "        Val objective improved 1.9304 → 1.8228, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.1133, mae: 1.9185, huber: 1.5171, swd: 5.3006, ept: 89.5773\n",
      "Epoch [3/50], Val Losses: mse: 12.7149, mae: 2.2146, huber: 1.8123, swd: 5.9376, ept: 83.7907\n",
      "Epoch [3/50], Test Losses: mse: 9.6117, mae: 1.9671, huber: 1.5524, swd: 4.2662, ept: 87.7368\n",
      "  Epoch 3 composite train-obj: 1.517100\n",
      "        Val objective improved 1.8228 → 1.8123, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.6086, mae: 1.8669, huber: 1.4675, swd: 5.0088, ept: 89.8652\n",
      "Epoch [4/50], Val Losses: mse: 12.6112, mae: 2.1985, huber: 1.8013, swd: 6.0087, ept: 83.8612\n",
      "Epoch [4/50], Test Losses: mse: 9.4583, mae: 1.9369, huber: 1.5263, swd: 4.2571, ept: 87.5578\n",
      "  Epoch 4 composite train-obj: 1.467524\n",
      "        Val objective improved 1.8123 → 1.8013, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.3050, mae: 1.8355, huber: 1.4375, swd: 4.8348, ept: 90.1053\n",
      "Epoch [5/50], Val Losses: mse: 12.7653, mae: 2.2011, huber: 1.8066, swd: 6.0850, ept: 83.3672\n",
      "Epoch [5/50], Test Losses: mse: 9.7048, mae: 1.9428, huber: 1.5340, swd: 4.4135, ept: 87.0500\n",
      "  Epoch 5 composite train-obj: 1.437526\n",
      "        No improvement (1.8066), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 9.9053, mae: 1.7951, huber: 1.3990, swd: 4.5906, ept: 90.3209\n",
      "Epoch [6/50], Val Losses: mse: 12.9222, mae: 2.2152, huber: 1.8223, swd: 6.2814, ept: 83.6509\n",
      "Epoch [6/50], Test Losses: mse: 9.7597, mae: 1.9769, huber: 1.5653, swd: 4.4553, ept: 87.4489\n",
      "  Epoch 6 composite train-obj: 1.399026\n",
      "        No improvement (1.8223), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.7155, mae: 1.7914, huber: 1.3954, swd: 4.4902, ept: 90.4015\n",
      "Epoch [7/50], Val Losses: mse: 12.9124, mae: 2.2081, huber: 1.8170, swd: 6.4801, ept: 83.5939\n",
      "Epoch [7/50], Test Losses: mse: 9.9361, mae: 1.9705, huber: 1.5614, swd: 4.7124, ept: 86.4835\n",
      "  Epoch 7 composite train-obj: 1.395419\n",
      "        No improvement (1.8170), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 9.2405, mae: 1.7491, huber: 1.3550, swd: 4.1729, ept: 90.5798\n",
      "Epoch [8/50], Val Losses: mse: 13.1673, mae: 2.2170, huber: 1.8247, swd: 6.4788, ept: 83.1143\n",
      "Epoch [8/50], Test Losses: mse: 10.2657, mae: 1.9748, huber: 1.5672, swd: 4.9267, ept: 85.8138\n",
      "  Epoch 8 composite train-obj: 1.354954\n",
      "        No improvement (1.8247), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 8.9869, mae: 1.7323, huber: 1.3384, swd: 4.0251, ept: 90.6756\n",
      "Epoch [9/50], Val Losses: mse: 13.9602, mae: 2.2776, huber: 1.8868, swd: 6.9775, ept: 82.7224\n",
      "Epoch [9/50], Test Losses: mse: 10.7118, mae: 2.0053, huber: 1.5976, swd: 5.2017, ept: 85.7123\n",
      "  Epoch 9 composite train-obj: 1.338401\n",
      "Epoch [9/50], Test Losses: mse: 9.4582, mae: 1.9369, huber: 1.5263, swd: 4.2570, ept: 87.5576\n",
      "Best round's Test MSE: 9.4583, MAE: 1.9369, SWD: 4.2571\n",
      "Best round's Validation MSE: 12.6112, MAE: 2.1985, SWD: 6.0087\n",
      "Best round's Test verification MSE : 9.4582, MAE: 1.9369, SWD: 4.2570\n",
      "Time taken: 100.52 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred96_20250512_1847)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.4402 ± 0.0608\n",
      "  mae: 1.9320 ± 0.0068\n",
      "  huber: 1.5221 ± 0.0054\n",
      "  swd: 4.5142 ± 0.1870\n",
      "  ept: 87.2521 ± 0.2289\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.3695 ± 0.2181\n",
      "  mae: 2.1708 ± 0.0242\n",
      "  huber: 1.7758 ± 0.0213\n",
      "  swd: 6.1542 ± 0.1069\n",
      "  ept: 84.0900 ± 0.1635\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 322.05 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred96_20250512_1847\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only', \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f1862da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 31.6610, mae: 2.8255, huber: 2.4096, swd: 23.2325, target_std: 20.3532\n",
      "Epoch [1/50], Val Losses: mse: 15.6386, mae: 2.4859, huber: 2.0822, swd: 9.5497, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 11.3643, mae: 2.2445, huber: 1.8198, swd: 6.5601, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.409571\n",
      "        Val objective improved inf → 2.0822, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8374, mae: 1.9989, huber: 1.5947, swd: 6.4110, target_std: 20.3539\n",
      "Epoch [2/50], Val Losses: mse: 13.5936, mae: 2.2682, huber: 1.8674, swd: 7.1909, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 10.4200, mae: 2.0156, huber: 1.6030, swd: 5.3508, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.594742\n",
      "        Val objective improved 2.0822 → 1.8674, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.0605, mae: 1.9227, huber: 1.5213, swd: 5.8943, target_std: 20.3534\n",
      "Epoch [3/50], Val Losses: mse: 12.5927, mae: 2.1908, huber: 1.7925, swd: 6.6229, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.5013, mae: 1.9255, huber: 1.5163, swd: 4.8281, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.521345\n",
      "        Val objective improved 1.8674 → 1.7925, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.8225, mae: 1.8978, huber: 1.4976, swd: 5.7736, target_std: 20.3537\n",
      "Epoch [4/50], Val Losses: mse: 12.3857, mae: 2.1775, huber: 1.7809, swd: 6.4086, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.4054, mae: 1.9189, huber: 1.5109, swd: 4.6967, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.497559\n",
      "        Val objective improved 1.7925 → 1.7809, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.4743, mae: 1.8562, huber: 1.4579, swd: 5.5292, target_std: 20.3533\n",
      "Epoch [5/50], Val Losses: mse: 12.6647, mae: 2.1981, huber: 1.8024, swd: 6.6863, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.9370, mae: 1.9628, huber: 1.5535, swd: 5.1892, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.457926\n",
      "        No improvement (1.8024), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 10.1723, mae: 1.8214, huber: 1.4248, swd: 5.3332, target_std: 20.3533\n",
      "Epoch [6/50], Val Losses: mse: 12.4987, mae: 2.2030, huber: 1.8063, swd: 6.5164, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.6342, mae: 1.9585, huber: 1.5495, swd: 4.8421, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.424750\n",
      "        No improvement (1.8063), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.8947, mae: 1.7922, huber: 1.3967, swd: 5.1347, target_std: 20.3537\n",
      "Epoch [7/50], Val Losses: mse: 12.2481, mae: 2.1478, huber: 1.7526, swd: 6.5658, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.5284, mae: 1.9231, huber: 1.5162, swd: 4.9554, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.396688\n",
      "        Val objective improved 1.7809 → 1.7526, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 9.7693, mae: 1.7922, huber: 1.3968, swd: 5.0570, target_std: 20.3535\n",
      "Epoch [8/50], Val Losses: mse: 12.5850, mae: 2.1793, huber: 1.7833, swd: 6.7352, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.8404, mae: 1.9490, huber: 1.5403, swd: 5.0837, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.396844\n",
      "        No improvement (1.7833), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 9.4000, mae: 1.7553, huber: 1.3614, swd: 4.7751, target_std: 20.3531\n",
      "Epoch [9/50], Val Losses: mse: 14.9592, mae: 2.4070, huber: 2.0059, swd: 8.7969, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 11.9939, mae: 2.1529, huber: 1.7415, swd: 7.0495, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.361398\n",
      "        No improvement (2.0059), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 9.3338, mae: 1.7597, huber: 1.3657, swd: 4.7572, target_std: 20.3526\n",
      "Epoch [10/50], Val Losses: mse: 12.8104, mae: 2.2071, huber: 1.8118, swd: 6.9917, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 9.6793, mae: 1.9526, huber: 1.5445, swd: 4.9368, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.365694\n",
      "        No improvement (1.8118), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 9.0159, mae: 1.7249, huber: 1.3322, swd: 4.5229, target_std: 20.3530\n",
      "Epoch [11/50], Val Losses: mse: 13.6305, mae: 2.2807, huber: 1.8796, swd: 7.5167, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 11.1153, mae: 2.0462, huber: 1.6366, swd: 6.0855, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.332221\n",
      "        No improvement (1.8796), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 8.8026, mae: 1.7121, huber: 1.3195, swd: 4.4012, target_std: 20.3539\n",
      "Epoch [12/50], Val Losses: mse: 13.4608, mae: 2.2501, huber: 1.8520, swd: 7.4624, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 10.4398, mae: 2.0010, huber: 1.5914, swd: 5.5080, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.319511\n",
      "Epoch [12/50], Test Losses: mse: 9.5288, mae: 1.9232, huber: 1.5162, swd: 4.9550, target_std: 18.3806\n",
      "Best round's Test MSE: 9.5284, MAE: 1.9231, SWD: 4.9554\n",
      "Best round's Validation MSE: 12.2481, MAE: 2.1478\n",
      "Best round's Test verification MSE : 9.5288, MAE: 1.9232, SWD: 4.9550\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.6864, mae: 2.7806, huber: 2.3653, swd: 21.3704, target_std: 20.3530\n",
      "Epoch [1/50], Val Losses: mse: 13.4514, mae: 2.2937, huber: 1.8915, swd: 6.8387, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.0055, mae: 2.0490, huber: 1.6304, swd: 4.7286, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.365302\n",
      "        Val objective improved inf → 1.8915, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.5158, mae: 1.9626, huber: 1.5590, swd: 6.0029, target_std: 20.3538\n",
      "Epoch [2/50], Val Losses: mse: 12.7680, mae: 2.2060, huber: 1.8044, swd: 6.2817, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.9571, mae: 1.9952, huber: 1.5802, swd: 4.7722, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.559025\n",
      "        Val objective improved 1.8915 → 1.8044, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.7810, mae: 1.8880, huber: 1.4880, swd: 5.4765, target_std: 20.3523\n",
      "Epoch [3/50], Val Losses: mse: 12.1060, mae: 2.1467, huber: 1.7506, swd: 6.0399, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.5943, mae: 1.9497, huber: 1.5383, swd: 4.7135, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.488048\n",
      "        Val objective improved 1.8044 → 1.7506, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.3688, mae: 1.8435, huber: 1.4456, swd: 5.2066, target_std: 20.3531\n",
      "Epoch [4/50], Val Losses: mse: 11.8974, mae: 2.1199, huber: 1.7261, swd: 6.0147, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.3321, mae: 1.9125, huber: 1.5043, swd: 4.5678, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.445605\n",
      "        Val objective improved 1.7506 → 1.7261, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.0561, mae: 1.8076, huber: 1.4112, swd: 5.0368, target_std: 20.3537\n",
      "Epoch [5/50], Val Losses: mse: 12.2331, mae: 2.1322, huber: 1.7394, swd: 6.2589, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.6450, mae: 1.9347, huber: 1.5266, swd: 4.7949, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.411163\n",
      "        No improvement (1.7394), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 9.8642, mae: 1.7903, huber: 1.3945, swd: 4.9118, target_std: 20.3531\n",
      "Epoch [6/50], Val Losses: mse: 12.2655, mae: 2.1529, huber: 1.7583, swd: 6.4143, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.3449, mae: 1.9322, huber: 1.5240, swd: 4.5773, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.394497\n",
      "        No improvement (1.7583), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.4963, mae: 1.7496, huber: 1.3557, swd: 4.6634, target_std: 20.3529\n",
      "Epoch [7/50], Val Losses: mse: 11.9556, mae: 2.1331, huber: 1.7387, swd: 6.2130, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.1844, mae: 1.9066, huber: 1.5000, swd: 4.4338, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.355671\n",
      "        No improvement (1.7387), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 9.2008, mae: 1.7293, huber: 1.3358, swd: 4.4491, target_std: 20.3524\n",
      "Epoch [8/50], Val Losses: mse: 12.6464, mae: 2.1699, huber: 1.7763, swd: 6.5942, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 10.1345, mae: 1.9610, huber: 1.5553, swd: 5.1033, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.335762\n",
      "        No improvement (1.7763), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 8.9687, mae: 1.7236, huber: 1.3301, swd: 4.2884, target_std: 20.3539\n",
      "Epoch [9/50], Val Losses: mse: 12.1555, mae: 2.1444, huber: 1.7483, swd: 6.3198, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.5253, mae: 1.9313, huber: 1.5225, swd: 4.5833, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.330113\n",
      "Epoch [9/50], Test Losses: mse: 9.3322, mae: 1.9125, huber: 1.5043, swd: 4.5678, target_std: 18.3806\n",
      "Best round's Test MSE: 9.3321, MAE: 1.9125, SWD: 4.5678\n",
      "Best round's Validation MSE: 11.8974, MAE: 2.1199\n",
      "Best round's Test verification MSE : 9.3322, MAE: 1.9125, SWD: 4.5678\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.0303, mae: 2.8097, huber: 2.3945, swd: 20.6951, target_std: 20.3537\n",
      "Epoch [1/50], Val Losses: mse: 13.4827, mae: 2.2870, huber: 1.8844, swd: 6.5875, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.0793, mae: 2.0550, huber: 1.6354, swd: 4.5996, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.394485\n",
      "        Val objective improved inf → 1.8844, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.7952, mae: 1.9846, huber: 1.5801, swd: 5.8280, target_std: 20.3548\n",
      "Epoch [2/50], Val Losses: mse: 12.7174, mae: 2.2179, huber: 1.8174, swd: 6.0488, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.8465, mae: 2.0130, huber: 1.5950, swd: 4.5167, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.580054\n",
      "        Val objective improved 1.8844 → 1.8174, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.0711, mae: 1.9162, huber: 1.5147, swd: 5.3277, target_std: 20.3526\n",
      "Epoch [3/50], Val Losses: mse: 12.5819, mae: 2.1916, huber: 1.7973, swd: 6.1109, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.7232, mae: 1.9773, huber: 1.5644, swd: 4.5064, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.514692\n",
      "        Val objective improved 1.8174 → 1.7973, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.6809, mae: 1.8717, huber: 1.4721, swd: 5.1140, target_std: 20.3532\n",
      "Epoch [4/50], Val Losses: mse: 12.9225, mae: 2.2080, huber: 1.8144, swd: 6.6778, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 10.0239, mae: 1.9961, huber: 1.5835, swd: 4.9261, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.472064\n",
      "        No improvement (1.8144), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.4236, mae: 1.8499, huber: 1.4512, swd: 4.9615, target_std: 20.3537\n",
      "Epoch [5/50], Val Losses: mse: 13.1006, mae: 2.2101, huber: 1.8167, swd: 6.5434, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 10.1783, mae: 1.9771, huber: 1.5685, swd: 4.7670, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.451162\n",
      "        No improvement (1.8167), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 10.1040, mae: 1.8184, huber: 1.4204, swd: 4.7749, target_std: 20.3540\n",
      "Epoch [6/50], Val Losses: mse: 13.2913, mae: 2.2293, huber: 1.8349, swd: 6.7742, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.9826, mae: 2.0105, huber: 1.5940, swd: 4.6700, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.420448\n",
      "        No improvement (1.8349), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 9.6700, mae: 1.7761, huber: 1.3802, swd: 4.4669, target_std: 20.3537\n",
      "Epoch [7/50], Val Losses: mse: 13.1371, mae: 2.2126, huber: 1.8181, swd: 6.7079, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 10.1115, mae: 1.9973, huber: 1.5846, swd: 4.8341, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.380241\n",
      "        No improvement (1.8181), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.4487, mae: 1.7615, huber: 1.3660, swd: 4.3491, target_std: 20.3531\n",
      "Epoch [8/50], Val Losses: mse: 12.4954, mae: 2.1644, huber: 1.7716, swd: 6.2053, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.6530, mae: 1.9486, huber: 1.5396, swd: 4.4764, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.366044\n",
      "        Val objective improved 1.7973 → 1.7716, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 9.1040, mae: 1.7304, huber: 1.3366, swd: 4.1051, target_std: 20.3530\n",
      "Epoch [9/50], Val Losses: mse: 13.0332, mae: 2.2298, huber: 1.8331, swd: 6.5841, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 10.1224, mae: 2.0174, huber: 1.6023, swd: 4.8686, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.336556\n",
      "        No improvement (1.8331), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 8.8395, mae: 1.7110, huber: 1.3178, swd: 3.9511, target_std: 20.3533\n",
      "Epoch [10/50], Val Losses: mse: 13.0019, mae: 2.2306, huber: 1.8357, swd: 6.4157, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 10.5199, mae: 2.0056, huber: 1.5974, swd: 4.9420, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.317800\n",
      "        No improvement (1.8357), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 8.6021, mae: 1.6900, huber: 1.2976, swd: 3.8090, target_std: 20.3530\n",
      "Epoch [11/50], Val Losses: mse: 13.3717, mae: 2.2279, huber: 1.8337, swd: 6.6963, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 10.5781, mae: 2.0660, huber: 1.6496, swd: 4.9962, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.297585\n",
      "        No improvement (1.8337), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 8.3769, mae: 1.6681, huber: 1.2766, swd: 3.6840, target_std: 20.3528\n",
      "Epoch [12/50], Val Losses: mse: 14.2077, mae: 2.2869, huber: 1.8913, swd: 7.5029, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 10.7155, mae: 2.0320, huber: 1.6220, swd: 5.2120, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.276600\n",
      "        No improvement (1.8913), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 8.1614, mae: 1.6412, huber: 1.2510, swd: 3.5387, target_std: 20.3537\n",
      "Epoch [13/50], Val Losses: mse: 13.8180, mae: 2.2750, huber: 1.8794, swd: 6.9953, target_std: 20.5735\n",
      "Epoch [13/50], Test Losses: mse: 10.7755, mae: 2.0200, huber: 1.6107, swd: 5.1613, target_std: 18.3806\n",
      "  Epoch 13 composite train-obj: 1.250961\n",
      "Epoch [13/50], Test Losses: mse: 9.6529, mae: 1.9486, huber: 1.5396, swd: 4.4762, target_std: 18.3806\n",
      "Best round's Test MSE: 9.6530, MAE: 1.9486, SWD: 4.4764\n",
      "Best round's Validation MSE: 12.4954, MAE: 2.1644\n",
      "Best round's Test verification MSE : 9.6529, MAE: 1.9486, SWD: 4.4762\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred96_20250430_2006)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.5045 ± 0.1321\n",
      "  mae: 1.9281 ± 0.0152\n",
      "  huber: 1.5200 ± 0.0147\n",
      "  swd: 4.6666 ± 0.2076\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.2136 ± 0.2453\n",
      "  mae: 2.1441 ± 0.0184\n",
      "  huber: 1.7501 ± 0.0186\n",
      "  swd: 6.2619 ± 0.2285\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred96_20250430_2006\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "\n",
    "cfg = train_config.FlatACLConfig( \n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128,\n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=False, \n",
    "    ablate_shift_inside_scale=False,\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9ed5c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 31.1372, mae: 2.8134, huber: 2.3973, swd: 21.9180, target_std: 20.3536\n",
      "Epoch [1/50], Val Losses: mse: 14.0418, mae: 2.3357, huber: 1.9325, swd: 7.5180, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.7121, mae: 2.1377, huber: 1.7155, swd: 5.6250, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.397334\n",
      "        Val objective improved inf → 1.9325, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8040, mae: 1.9931, huber: 1.5883, swd: 6.4186, target_std: 20.3525\n",
      "Epoch [2/50], Val Losses: mse: 12.7739, mae: 2.2210, huber: 1.8198, swd: 6.6315, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.6858, mae: 2.0007, huber: 1.5834, swd: 4.8685, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.588268\n",
      "        Val objective improved 1.9325 → 1.8198, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.2782, mae: 1.9390, huber: 1.5368, swd: 6.0879, target_std: 20.3533\n",
      "Epoch [3/50], Val Losses: mse: 12.7651, mae: 2.2093, huber: 1.8119, swd: 6.9223, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.4663, mae: 1.9737, huber: 1.5597, swd: 4.8684, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.536840\n",
      "        Val objective improved 1.8198 → 1.8119, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.5924, mae: 1.8703, huber: 1.4713, swd: 5.5327, target_std: 20.3533\n",
      "Epoch [4/50], Val Losses: mse: 12.7739, mae: 2.2125, huber: 1.8166, swd: 6.7339, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.5773, mae: 1.9800, huber: 1.5646, swd: 4.7814, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.471320\n",
      "        No improvement (1.8166), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.2238, mae: 1.8442, huber: 1.4466, swd: 5.2797, target_std: 20.3538\n",
      "Epoch [5/50], Val Losses: mse: 12.0896, mae: 2.1469, huber: 1.7551, swd: 6.3043, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.1773, mae: 1.9181, huber: 1.5086, swd: 4.6068, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.446558\n",
      "        Val objective improved 1.8119 → 1.7551, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 9.8120, mae: 1.8030, huber: 1.4074, swd: 4.9770, target_std: 20.3531\n",
      "Epoch [6/50], Val Losses: mse: 12.6850, mae: 2.1711, huber: 1.7798, swd: 6.7857, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.5482, mae: 1.9324, huber: 1.5228, swd: 4.8004, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.407405\n",
      "        No improvement (1.7798), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 9.6708, mae: 1.8022, huber: 1.4065, swd: 4.8860, target_std: 20.3544\n",
      "Epoch [7/50], Val Losses: mse: 12.8407, mae: 2.1810, huber: 1.7910, swd: 6.7820, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.7871, mae: 1.9459, huber: 1.5381, swd: 5.0323, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.406454\n",
      "        No improvement (1.7910), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 9.3892, mae: 1.7688, huber: 1.3747, swd: 4.7004, target_std: 20.3530\n",
      "Epoch [8/50], Val Losses: mse: 12.4072, mae: 2.1887, huber: 1.7964, swd: 6.5674, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.6049, mae: 1.9896, huber: 1.5750, swd: 4.9640, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.374731\n",
      "        No improvement (1.7964), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 9.1965, mae: 1.7514, huber: 1.3578, swd: 4.5765, target_std: 20.3541\n",
      "Epoch [9/50], Val Losses: mse: 12.4059, mae: 2.1594, huber: 1.7691, swd: 6.4473, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.6926, mae: 1.9604, huber: 1.5500, swd: 4.9047, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.357779\n",
      "        No improvement (1.7691), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 9.0151, mae: 1.7344, huber: 1.3415, swd: 4.4647, target_std: 20.3539\n",
      "Epoch [10/50], Val Losses: mse: 13.1800, mae: 2.2020, huber: 1.8109, swd: 7.1154, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 10.1468, mae: 1.9670, huber: 1.5593, swd: 5.3887, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.341530\n",
      "Epoch [10/50], Test Losses: mse: 9.1773, mae: 1.9181, huber: 1.5086, swd: 4.6068, target_std: 18.3806\n",
      "Best round's Test MSE: 9.1773, MAE: 1.9181, SWD: 4.6068\n",
      "Best round's Validation MSE: 12.0896, MAE: 2.1469\n",
      "Best round's Test verification MSE : 9.1773, MAE: 1.9181, SWD: 4.6068\n",
      "Time taken: 146.25 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.7078, mae: 2.8311, huber: 2.4151, swd: 22.8112, target_std: 20.3525\n",
      "Epoch [1/50], Val Losses: mse: 13.3021, mae: 2.2707, huber: 1.8700, swd: 6.4079, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.1616, mae: 2.0338, huber: 1.6168, swd: 4.7589, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.415091\n",
      "        Val objective improved inf → 1.8700, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.4843, mae: 1.9581, huber: 1.5545, swd: 5.9758, target_std: 20.3538\n",
      "Epoch [2/50], Val Losses: mse: 12.9200, mae: 2.2092, huber: 1.8092, swd: 6.4768, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.6770, mae: 1.9733, huber: 1.5585, swd: 4.6589, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.554468\n",
      "        Val objective improved 1.8700 → 1.8092, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.9355, mae: 1.9065, huber: 1.5055, swd: 5.5912, target_std: 20.3529\n",
      "Epoch [3/50], Val Losses: mse: 12.5696, mae: 2.1880, huber: 1.7889, swd: 6.3869, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.3916, mae: 1.9496, huber: 1.5365, swd: 4.4858, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.505458\n",
      "        Val objective improved 1.8092 → 1.7889, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.4202, mae: 1.8534, huber: 1.4546, swd: 5.2583, target_std: 20.3535\n",
      "Epoch [4/50], Val Losses: mse: 12.2416, mae: 2.1641, huber: 1.7669, swd: 6.3208, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.3431, mae: 1.9448, huber: 1.5333, swd: 4.5534, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.454574\n",
      "        Val objective improved 1.7889 → 1.7669, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.0811, mae: 1.8268, huber: 1.4293, swd: 5.0512, target_std: 20.3531\n",
      "Epoch [5/50], Val Losses: mse: 12.2336, mae: 2.1712, huber: 1.7758, swd: 6.1968, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.4599, mae: 1.9479, huber: 1.5364, swd: 4.5422, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.429260\n",
      "        No improvement (1.7758), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 9.6767, mae: 1.7913, huber: 1.3954, swd: 4.7524, target_std: 20.3530\n",
      "Epoch [6/50], Val Losses: mse: 13.4098, mae: 2.2371, huber: 1.8423, swd: 6.9588, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.1575, mae: 1.9624, huber: 1.5544, swd: 4.9889, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.395414\n",
      "        No improvement (1.8423), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.4200, mae: 1.7723, huber: 1.3771, swd: 4.5994, target_std: 20.3545\n",
      "Epoch [7/50], Val Losses: mse: 14.3595, mae: 2.3429, huber: 1.9454, swd: 7.7885, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 11.8464, mae: 2.1558, huber: 1.7413, swd: 6.6196, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.377093\n",
      "        No improvement (1.9454), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 9.1189, mae: 1.7461, huber: 1.3519, swd: 4.3831, target_std: 20.3535\n",
      "Epoch [8/50], Val Losses: mse: 12.7631, mae: 2.1968, huber: 1.8051, swd: 6.5752, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.6236, mae: 1.9335, huber: 1.5269, swd: 4.7397, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.351921\n",
      "        No improvement (1.8051), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 8.8887, mae: 1.7241, huber: 1.3307, swd: 4.2410, target_std: 20.3532\n",
      "Epoch [9/50], Val Losses: mse: 13.2077, mae: 2.2226, huber: 1.8307, swd: 6.8152, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 10.2177, mae: 1.9751, huber: 1.5656, swd: 5.2477, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.330688\n",
      "Epoch [9/50], Test Losses: mse: 9.3431, mae: 1.9448, huber: 1.5333, swd: 4.5534, target_std: 18.3806\n",
      "Best round's Test MSE: 9.3431, MAE: 1.9448, SWD: 4.5534\n",
      "Best round's Validation MSE: 12.2416, MAE: 2.1641\n",
      "Best round's Test verification MSE : 9.3431, MAE: 1.9448, SWD: 4.5534\n",
      "Time taken: 154.89 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.4253, mae: 2.8338, huber: 2.4177, swd: 20.8622, target_std: 20.3537\n",
      "Epoch [1/50], Val Losses: mse: 13.9157, mae: 2.3249, huber: 1.9220, swd: 6.6139, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.6245, mae: 2.1073, huber: 1.6878, swd: 4.8572, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.417711\n",
      "        Val objective improved inf → 1.9220, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.9562, mae: 2.0011, huber: 1.5956, swd: 5.9236, target_std: 20.3528\n",
      "Epoch [2/50], Val Losses: mse: 12.8514, mae: 2.2370, huber: 1.8337, swd: 5.8746, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 10.1260, mae: 2.0458, huber: 1.6258, swd: 4.5852, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.595644\n",
      "        Val objective improved 1.9220 → 1.8337, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.3685, mae: 1.9495, huber: 1.5468, swd: 5.5340, target_std: 20.3532\n",
      "Epoch [3/50], Val Losses: mse: 12.5736, mae: 2.1965, huber: 1.7961, swd: 5.8499, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.7877, mae: 1.9868, huber: 1.5709, swd: 4.4166, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.546753\n",
      "        Val objective improved 1.8337 → 1.7961, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.7294, mae: 1.8782, huber: 1.4781, swd: 5.0960, target_std: 20.3534\n",
      "Epoch [4/50], Val Losses: mse: 12.5660, mae: 2.2064, huber: 1.8059, swd: 5.7971, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 10.2347, mae: 2.0004, huber: 1.5878, swd: 4.7308, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.478092\n",
      "        No improvement (1.8059), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.4201, mae: 1.8530, huber: 1.4539, swd: 4.9418, target_std: 20.3542\n",
      "Epoch [5/50], Val Losses: mse: 12.6520, mae: 2.2080, huber: 1.8095, swd: 5.9695, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.8787, mae: 1.9538, huber: 1.5445, swd: 4.5542, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.453936\n",
      "        No improvement (1.8095), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 9.9911, mae: 1.8137, huber: 1.4160, swd: 4.6658, target_std: 20.3532\n",
      "Epoch [6/50], Val Losses: mse: 13.0231, mae: 2.2375, huber: 1.8408, swd: 6.2317, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.4087, mae: 1.9999, huber: 1.5901, swd: 4.9601, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.416039\n",
      "        No improvement (1.8408), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 9.6252, mae: 1.7894, huber: 1.3929, swd: 4.4086, target_std: 20.3539\n",
      "Epoch [7/50], Val Losses: mse: 14.1612, mae: 2.3045, huber: 1.9089, swd: 7.1357, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 10.4943, mae: 2.0006, huber: 1.5896, swd: 5.0479, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.392906\n",
      "        No improvement (1.9089), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.1762, mae: 1.7465, huber: 1.3518, swd: 4.1115, target_std: 20.3529\n",
      "Epoch [8/50], Val Losses: mse: 13.1459, mae: 2.2155, huber: 1.8235, swd: 6.4250, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 10.3169, mae: 1.9724, huber: 1.5637, swd: 4.9643, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.351806\n",
      "Epoch [8/50], Test Losses: mse: 9.7880, mae: 1.9868, huber: 1.5709, swd: 4.4169, target_std: 18.3806\n",
      "Best round's Test MSE: 9.7877, MAE: 1.9868, SWD: 4.4166\n",
      "Best round's Validation MSE: 12.5736, MAE: 2.1965\n",
      "Best round's Test verification MSE : 9.7880, MAE: 1.9868, SWD: 4.4169\n",
      "Time taken: 131.29 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred96_20250503_1821)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.4360 ± 0.2577\n",
      "  mae: 1.9499 ± 0.0283\n",
      "  huber: 1.5376 ± 0.0256\n",
      "  swd: 4.5256 ± 0.0801\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.3016 ± 0.2021\n",
      "  mae: 2.1692 ± 0.0206\n",
      "  huber: 1.7727 ± 0.0172\n",
      "  swd: 6.1583 ± 0.2182\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 432.56 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred96_20250503_1821\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  \n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=True,\n",
    "    householder_reflects_latent = 4,\n",
    "    householder_reflects_data = 8,\n",
    "    mixing_strategy='delay_only',\n",
    "    # single_magnitude_for_shift=True,\n",
    "\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fc90ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 31.5703, mae: 2.8403, huber: 2.4277, swd: 20.9222, target_std: 20.3536\n",
      "Epoch [1/50], Val Losses: mse: 13.3048, mae: 2.2805, huber: 1.8886, swd: 7.2631, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.0134, mae: 2.0725, huber: 1.6517, swd: 5.1384, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.427748\n",
      "        Val objective improved inf → 1.8886, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.3706, mae: 1.9494, huber: 1.5484, swd: 6.1899, target_std: 20.3525\n",
      "Epoch [2/50], Val Losses: mse: 13.0693, mae: 2.2485, huber: 1.8571, swd: 7.3348, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.9634, mae: 2.0605, huber: 1.6409, swd: 5.3001, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.548425\n",
      "        Val objective improved 1.8886 → 1.8571, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.9397, mae: 1.9123, huber: 1.5124, swd: 5.9385, target_std: 20.3533\n",
      "Epoch [3/50], Val Losses: mse: 12.0019, mae: 2.1288, huber: 1.7386, swd: 6.4345, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.4373, mae: 1.9672, huber: 1.5517, swd: 4.8525, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.512412\n",
      "        Val objective improved 1.8571 → 1.7386, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.4146, mae: 1.8532, huber: 1.4548, swd: 5.5104, target_std: 20.3533\n",
      "Epoch [4/50], Val Losses: mse: 12.0928, mae: 2.1466, huber: 1.7547, swd: 6.5261, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.5429, mae: 1.9876, huber: 1.5716, swd: 4.9132, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.454817\n",
      "        No improvement (1.7547), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.1131, mae: 1.8282, huber: 1.4303, swd: 5.2855, target_std: 20.3538\n",
      "Epoch [5/50], Val Losses: mse: 11.8735, mae: 2.1169, huber: 1.7271, swd: 6.3844, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.4412, mae: 1.9506, huber: 1.5394, swd: 4.8735, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.430298\n",
      "        Val objective improved 1.7386 → 1.7271, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 9.8341, mae: 1.7993, huber: 1.4031, swd: 5.0486, target_std: 20.3531\n",
      "Epoch [6/50], Val Losses: mse: 12.1130, mae: 2.1258, huber: 1.7365, swd: 6.5325, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.6625, mae: 1.9427, huber: 1.5329, swd: 4.9475, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.403097\n",
      "        No improvement (1.7365), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 9.9295, mae: 1.8181, huber: 1.4207, swd: 5.1541, target_std: 20.3544\n",
      "Epoch [7/50], Val Losses: mse: 12.0711, mae: 2.1177, huber: 1.7275, swd: 6.5035, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.7586, mae: 1.9497, huber: 1.5393, swd: 5.1070, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.420732\n",
      "        No improvement (1.7275), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 9.5273, mae: 1.7687, huber: 1.3740, swd: 4.8348, target_std: 20.3530\n",
      "Epoch [8/50], Val Losses: mse: 12.5091, mae: 2.1854, huber: 1.7956, swd: 7.0508, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.4923, mae: 1.9678, huber: 1.5550, swd: 4.9429, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.374044\n",
      "        No improvement (1.7956), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 9.3106, mae: 1.7504, huber: 1.3568, swd: 4.6832, target_std: 20.3541\n",
      "Epoch [9/50], Val Losses: mse: 11.6405, mae: 2.1051, huber: 1.7155, swd: 6.1110, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.5950, mae: 1.9413, huber: 1.5311, swd: 4.9443, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.356829\n",
      "        Val objective improved 1.7271 → 1.7155, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 9.1950, mae: 1.7404, huber: 1.3474, swd: 4.6329, target_std: 20.3539\n",
      "Epoch [10/50], Val Losses: mse: 12.1476, mae: 2.1251, huber: 1.7367, swd: 6.4945, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 9.9726, mae: 1.9585, huber: 1.5488, swd: 5.3405, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.347426\n",
      "        No improvement (1.7367), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 9.0365, mae: 1.7199, huber: 1.3281, swd: 4.5214, target_std: 20.3531\n",
      "Epoch [11/50], Val Losses: mse: 12.0462, mae: 2.1330, huber: 1.7453, swd: 6.5622, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 9.5770, mae: 1.9449, huber: 1.5360, swd: 4.9972, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.328072\n",
      "        No improvement (1.7453), counter 2/5\n",
      "Epoch [12/50], Train Losses: mse: 8.9180, mae: 1.7118, huber: 1.3204, swd: 4.4408, target_std: 20.3534\n",
      "Epoch [12/50], Val Losses: mse: 12.0297, mae: 2.1332, huber: 1.7442, swd: 6.4767, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 9.6135, mae: 1.9355, huber: 1.5270, swd: 4.9681, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.320435\n",
      "        No improvement (1.7442), counter 3/5\n",
      "Epoch [13/50], Train Losses: mse: 8.7368, mae: 1.6983, huber: 1.3074, swd: 4.3200, target_std: 20.3531\n",
      "Epoch [13/50], Val Losses: mse: 12.6041, mae: 2.1472, huber: 1.7601, swd: 6.9048, target_std: 20.5735\n",
      "Epoch [13/50], Test Losses: mse: 10.0936, mae: 1.9587, huber: 1.5506, swd: 5.3421, target_std: 18.3806\n",
      "  Epoch 13 composite train-obj: 1.307438\n",
      "        No improvement (1.7601), counter 4/5\n",
      "Epoch [14/50], Train Losses: mse: 8.6845, mae: 1.6874, huber: 1.2973, swd: 4.3114, target_std: 20.3526\n",
      "Epoch [14/50], Val Losses: mse: 12.5546, mae: 2.1496, huber: 1.7606, swd: 6.8225, target_std: 20.5735\n",
      "Epoch [14/50], Test Losses: mse: 10.1723, mae: 1.9879, huber: 1.5763, swd: 5.4629, target_std: 18.3806\n",
      "  Epoch 14 composite train-obj: 1.297312\n",
      "Epoch [14/50], Test Losses: mse: 9.5901, mae: 1.9409, huber: 1.5308, swd: 4.9399, target_std: 18.3806\n",
      "Best round's Test MSE: 9.5950, MAE: 1.9413, SWD: 4.9443\n",
      "Best round's Validation MSE: 11.6405, MAE: 2.1051\n",
      "Best round's Test verification MSE : 9.5901, MAE: 1.9409, SWD: 4.9399\n",
      "Time taken: 178.37 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.9699, mae: 2.7559, huber: 2.3441, swd: 19.2959, target_std: 20.3525\n",
      "Epoch [1/50], Val Losses: mse: 13.6026, mae: 2.2812, huber: 1.8890, swd: 6.8789, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.5182, mae: 2.1005, huber: 1.6782, swd: 5.1245, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.344087\n",
      "        Val objective improved inf → 1.8890, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.4997, mae: 1.9660, huber: 1.5641, swd: 6.0987, target_std: 20.3538\n",
      "Epoch [2/50], Val Losses: mse: 12.9724, mae: 2.2028, huber: 1.8116, swd: 6.6878, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 10.0085, mae: 2.0105, huber: 1.5932, swd: 4.9638, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.564126\n",
      "        Val objective improved 1.8890 → 1.8116, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 10.9538, mae: 1.9123, huber: 1.5119, swd: 5.7012, target_std: 20.3529\n",
      "Epoch [3/50], Val Losses: mse: 12.1580, mae: 2.1416, huber: 1.7494, swd: 6.1792, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.6967, mae: 2.0039, huber: 1.5859, swd: 4.7663, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.511907\n",
      "        Val objective improved 1.8116 → 1.7494, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 10.5199, mae: 1.8666, huber: 1.4671, swd: 5.3915, target_std: 20.3535\n",
      "Epoch [4/50], Val Losses: mse: 12.0733, mae: 2.1315, huber: 1.7390, swd: 6.2259, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.4129, mae: 1.9701, huber: 1.5539, swd: 4.6102, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.467058\n",
      "        Val objective improved 1.7494 → 1.7390, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.3285, mae: 1.8457, huber: 1.4467, swd: 5.2578, target_std: 20.3531\n",
      "Epoch [5/50], Val Losses: mse: 12.1822, mae: 2.1515, huber: 1.7576, swd: 6.4032, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.3379, mae: 1.9608, huber: 1.5450, swd: 4.6024, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.446677\n",
      "        No improvement (1.7576), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 10.0647, mae: 1.8183, huber: 1.4207, swd: 5.1007, target_std: 20.3530\n",
      "Epoch [6/50], Val Losses: mse: 13.5253, mae: 2.2137, huber: 1.8224, swd: 7.4398, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.5146, mae: 2.0153, huber: 1.6030, swd: 5.4867, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.420748\n",
      "        No improvement (1.8224), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 9.9598, mae: 1.8051, huber: 1.4087, swd: 5.0494, target_std: 20.3545\n",
      "Epoch [7/50], Val Losses: mse: 13.7902, mae: 2.2574, huber: 1.8660, swd: 7.7125, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 11.0738, mae: 2.0950, huber: 1.6803, swd: 5.9946, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.408729\n",
      "        No improvement (1.8660), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 9.6959, mae: 1.7760, huber: 1.3811, swd: 4.8440, target_std: 20.3535\n",
      "Epoch [8/50], Val Losses: mse: 12.3347, mae: 2.1189, huber: 1.7308, swd: 6.6389, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.5618, mae: 1.9444, huber: 1.5330, swd: 4.8175, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.381075\n",
      "        Val objective improved 1.7390 → 1.7308, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 9.5582, mae: 1.7601, huber: 1.3663, swd: 4.7544, target_std: 20.3532\n",
      "Epoch [9/50], Val Losses: mse: 12.6973, mae: 2.1461, huber: 1.7575, swd: 6.9014, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.7572, mae: 1.9569, huber: 1.5451, swd: 4.9627, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.366306\n",
      "        No improvement (1.7575), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 9.4577, mae: 1.7561, huber: 1.3627, swd: 4.7025, target_std: 20.3529\n",
      "Epoch [10/50], Val Losses: mse: 13.3620, mae: 2.1941, huber: 1.8062, swd: 7.4020, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 10.2559, mae: 1.9930, huber: 1.5821, swd: 5.3844, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.362733\n",
      "        No improvement (1.8062), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 9.2834, mae: 1.7332, huber: 1.3411, swd: 4.5618, target_std: 20.3529\n",
      "Epoch [11/50], Val Losses: mse: 12.8397, mae: 2.1635, huber: 1.7761, swd: 7.1654, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 9.7379, mae: 1.9389, huber: 1.5305, swd: 5.0052, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.341078\n",
      "        No improvement (1.7761), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 9.2085, mae: 1.7321, huber: 1.3404, swd: 4.5405, target_std: 20.3534\n",
      "Epoch [12/50], Val Losses: mse: 12.3404, mae: 2.1362, huber: 1.7484, swd: 6.4612, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 9.9402, mae: 1.9443, huber: 1.5364, swd: 5.0624, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.340402\n",
      "        No improvement (1.7484), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 9.0488, mae: 1.7234, huber: 1.3320, swd: 4.4180, target_std: 20.3538\n",
      "Epoch [13/50], Val Losses: mse: 12.6256, mae: 2.1473, huber: 1.7596, swd: 6.7814, target_std: 20.5735\n",
      "Epoch [13/50], Test Losses: mse: 9.9674, mae: 1.9639, huber: 1.5526, swd: 5.1094, target_std: 18.3806\n",
      "  Epoch 13 composite train-obj: 1.331999\n",
      "Epoch [13/50], Test Losses: mse: 9.5654, mae: 1.9446, huber: 1.5331, swd: 4.8216, target_std: 18.3806\n",
      "Best round's Test MSE: 9.5618, MAE: 1.9444, SWD: 4.8175\n",
      "Best round's Validation MSE: 12.3347, MAE: 2.1189\n",
      "Best round's Test verification MSE : 9.5654, MAE: 1.9446, SWD: 4.8216\n",
      "Time taken: 183.61 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.9934, mae: 2.8366, huber: 2.4231, swd: 18.4601, target_std: 20.3537\n",
      "Epoch [1/50], Val Losses: mse: 13.7747, mae: 2.3144, huber: 1.9220, swd: 6.7347, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 10.4759, mae: 2.0938, huber: 1.6723, swd: 4.7794, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 2.423120\n",
      "        Val objective improved inf → 1.9220, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 12.1919, mae: 2.0179, huber: 1.6136, swd: 6.1809, target_std: 20.3528\n",
      "Epoch [2/50], Val Losses: mse: 13.0800, mae: 2.2460, huber: 1.8503, swd: 6.3973, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 10.2403, mae: 2.0447, huber: 1.6257, swd: 4.7572, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.613617\n",
      "        Val objective improved 1.9220 → 1.8503, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.7990, mae: 1.9848, huber: 1.5812, swd: 5.9875, target_std: 20.3532\n",
      "Epoch [3/50], Val Losses: mse: 13.0714, mae: 2.2272, huber: 1.8340, swd: 6.4663, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 10.5902, mae: 2.0739, huber: 1.6558, swd: 5.1105, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.581249\n",
      "        Val objective improved 1.8503 → 1.8340, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.2120, mae: 1.9195, huber: 1.5184, swd: 5.5617, target_std: 20.3534\n",
      "Epoch [4/50], Val Losses: mse: 12.7221, mae: 2.1994, huber: 1.8036, swd: 6.1842, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 10.4705, mae: 2.0493, huber: 1.6328, swd: 4.9844, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.518382\n",
      "        Val objective improved 1.8340 → 1.8036, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 10.8248, mae: 1.8847, huber: 1.4850, swd: 5.2885, target_std: 20.3542\n",
      "Epoch [5/50], Val Losses: mse: 12.6311, mae: 2.1779, huber: 1.7860, swd: 6.2731, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 10.3606, mae: 2.0246, huber: 1.6110, swd: 5.0372, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.484955\n",
      "        Val objective improved 1.8036 → 1.7860, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 10.6029, mae: 1.8718, huber: 1.4729, swd: 5.1323, target_std: 20.3532\n",
      "Epoch [6/50], Val Losses: mse: 12.7556, mae: 2.1974, huber: 1.8036, swd: 6.3860, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.0013, mae: 1.9956, huber: 1.5815, swd: 4.7162, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.472883\n",
      "        No improvement (1.8036), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 10.1718, mae: 1.8286, huber: 1.4314, swd: 4.8456, target_std: 20.3539\n",
      "Epoch [7/50], Val Losses: mse: 13.1384, mae: 2.2020, huber: 1.8122, swd: 6.7734, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.8277, mae: 1.9567, huber: 1.5472, swd: 4.6046, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.431361\n",
      "        No improvement (1.8122), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 9.7468, mae: 1.7911, huber: 1.3958, swd: 4.5218, target_std: 20.3529\n",
      "Epoch [8/50], Val Losses: mse: 12.5100, mae: 2.1635, huber: 1.7729, swd: 6.1816, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.7342, mae: 1.9623, huber: 1.5514, swd: 4.4595, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.395817\n",
      "        Val objective improved 1.7860 → 1.7729, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 9.5276, mae: 1.7724, huber: 1.3781, swd: 4.3765, target_std: 20.3540\n",
      "Epoch [9/50], Val Losses: mse: 12.8777, mae: 2.1766, huber: 1.7871, swd: 6.5154, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.8805, mae: 1.9428, huber: 1.5352, swd: 4.6580, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.378082\n",
      "        No improvement (1.7871), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 9.3305, mae: 1.7580, huber: 1.3644, swd: 4.2509, target_std: 20.3535\n",
      "Epoch [10/50], Val Losses: mse: 13.8618, mae: 2.2507, huber: 1.8596, swd: 7.2518, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 11.2053, mae: 2.1041, huber: 1.6873, swd: 5.7175, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.364407\n",
      "        No improvement (1.8596), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 9.0603, mae: 1.7279, huber: 1.3357, swd: 4.0747, target_std: 20.3532\n",
      "Epoch [11/50], Val Losses: mse: 13.2233, mae: 2.1925, huber: 1.8041, swd: 6.8993, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 10.3047, mae: 2.0192, huber: 1.6049, swd: 5.0551, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.335657\n",
      "        No improvement (1.8041), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 9.0508, mae: 1.7267, huber: 1.3346, swd: 4.0954, target_std: 20.3541\n",
      "Epoch [12/50], Val Losses: mse: 13.2677, mae: 2.1945, huber: 1.8067, swd: 6.9441, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 10.2855, mae: 1.9829, huber: 1.5743, swd: 4.9956, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.334647\n",
      "        No improvement (1.8067), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 8.8852, mae: 1.7104, huber: 1.3191, swd: 3.9754, target_std: 20.3537\n",
      "Epoch [13/50], Val Losses: mse: 13.4579, mae: 2.2144, huber: 1.8255, swd: 6.8829, target_std: 20.5735\n",
      "Epoch [13/50], Test Losses: mse: 10.5311, mae: 2.0103, huber: 1.6004, swd: 5.0539, target_std: 18.3806\n",
      "  Epoch 13 composite train-obj: 1.319142\n",
      "Epoch [13/50], Test Losses: mse: 9.7280, mae: 1.9619, huber: 1.5512, swd: 4.4541, target_std: 18.3806\n",
      "Best round's Test MSE: 9.7342, MAE: 1.9623, SWD: 4.4595\n",
      "Best round's Validation MSE: 12.5100, MAE: 2.1635\n",
      "Best round's Test verification MSE : 9.7280, MAE: 1.9619, SWD: 4.4541\n",
      "Time taken: 207.39 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred96_20250503_1938)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.6303 ± 0.0747\n",
      "  mae: 1.9493 ± 0.0093\n",
      "  huber: 1.5385 ± 0.0092\n",
      "  swd: 4.7404 ± 0.2053\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.1617 ± 0.3754\n",
      "  mae: 2.1292 ± 0.0249\n",
      "  huber: 1.7397 ± 0.0242\n",
      "  swd: 6.3105 ± 0.2340\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 569.47 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred96_20250503_1938\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "import torch.nn as nn\n",
    "cfg = train_config.FlatACLConfig(  \n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=True,\n",
    "    householder_reflects_latent = 4,\n",
    "    householder_reflects_data = 8,\n",
    "    mixing_strategy='delay_only',\n",
    "    # single_magnitude_for_shift=True,\n",
    "\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.LogSigmoid, nn.Mish]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.LogSigmoid, nn.Mish]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.LogSigmoid, nn.Mish]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.LogSigmoid, nn.Mish]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.LogSigmoid, nn.Mish]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a29e1",
   "metadata": {},
   "source": [
    "#### pred=196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e375de",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8f5f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "global_std.shape: torch.Size([7])\n",
      "Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],\n",
      "       device='cuda:0')\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 377\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 377\n",
      "Validation Batches: 51\n",
      "Test Batches: 105\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 38.4921, mae: 3.1895, huber: 2.7680, swd: 26.4039, ept: 149.2469\n",
      "Epoch [1/50], Val Losses: mse: 20.3081, mae: 2.8062, huber: 2.3913, swd: 9.2768, ept: 147.3334\n",
      "Epoch [1/50], Test Losses: mse: 14.3545, mae: 2.4347, huber: 2.0092, swd: 6.4110, ept: 159.2610\n",
      "  Epoch 1 composite train-obj: 2.768049\n",
      "        Val objective improved inf → 2.3913, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.9524, mae: 2.3320, huber: 1.9200, swd: 9.1583, ept: 168.5181\n",
      "Epoch [2/50], Val Losses: mse: 19.1515, mae: 2.7139, huber: 2.2987, swd: 9.7741, ept: 151.8288\n",
      "Epoch [2/50], Test Losses: mse: 14.6897, mae: 2.4436, huber: 2.0163, swd: 7.9713, ept: 158.5419\n",
      "  Epoch 2 composite train-obj: 1.919961\n",
      "        Val objective improved 2.3913 → 2.2987, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.7720, mae: 2.2227, huber: 1.8147, swd: 8.3607, ept: 171.1390\n",
      "Epoch [3/50], Val Losses: mse: 17.6724, mae: 2.6196, huber: 2.2075, swd: 8.7940, ept: 152.4925\n",
      "Epoch [3/50], Test Losses: mse: 12.6705, mae: 2.2357, huber: 1.8161, swd: 6.2990, ept: 162.2957\n",
      "  Epoch 3 composite train-obj: 1.814669\n",
      "        Val objective improved 2.2987 → 2.2075, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 15.2108, mae: 2.1823, huber: 1.7757, swd: 7.9252, ept: 171.6555\n",
      "Epoch [4/50], Val Losses: mse: 18.1167, mae: 2.6458, huber: 2.2348, swd: 9.2162, ept: 151.5593\n",
      "Epoch [4/50], Test Losses: mse: 13.2574, mae: 2.2879, huber: 1.8692, swd: 6.8533, ept: 160.0368\n",
      "  Epoch 4 composite train-obj: 1.775718\n",
      "        No improvement (2.2348), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 14.7373, mae: 2.1511, huber: 1.7455, swd: 7.5891, ept: 172.1950\n",
      "Epoch [5/50], Val Losses: mse: 16.8298, mae: 2.5687, huber: 2.1615, swd: 8.1959, ept: 154.8352\n",
      "Epoch [5/50], Test Losses: mse: 12.2212, mae: 2.1915, huber: 1.7751, swd: 5.8919, ept: 164.4375\n",
      "  Epoch 5 composite train-obj: 1.745534\n",
      "        Val objective improved 2.2075 → 2.1615, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 14.3011, mae: 2.1192, huber: 1.7149, swd: 7.2709, ept: 172.6018\n",
      "Epoch [6/50], Val Losses: mse: 17.1456, mae: 2.5945, huber: 2.1907, swd: 8.9509, ept: 154.9420\n",
      "Epoch [6/50], Test Losses: mse: 11.7947, mae: 2.1928, huber: 1.7756, swd: 5.7328, ept: 165.8688\n",
      "  Epoch 6 composite train-obj: 1.714873\n",
      "        No improvement (2.1907), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 14.0054, mae: 2.1054, huber: 1.7014, swd: 7.0893, ept: 172.9007\n",
      "Epoch [7/50], Val Losses: mse: 16.5995, mae: 2.5513, huber: 2.1486, swd: 8.1323, ept: 154.9638\n",
      "Epoch [7/50], Test Losses: mse: 12.5462, mae: 2.2293, huber: 1.8125, swd: 6.1783, ept: 162.8079\n",
      "  Epoch 7 composite train-obj: 1.701357\n",
      "        Val objective improved 2.1615 → 2.1486, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 13.4964, mae: 2.0639, huber: 1.6617, swd: 6.6993, ept: 173.4855\n",
      "Epoch [8/50], Val Losses: mse: 18.9339, mae: 2.6781, huber: 2.2750, swd: 10.0955, ept: 151.5757\n",
      "Epoch [8/50], Test Losses: mse: 13.8030, mae: 2.3138, huber: 1.8982, swd: 7.3263, ept: 158.6318\n",
      "  Epoch 8 composite train-obj: 1.661650\n",
      "        No improvement (2.2750), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 13.2969, mae: 2.0621, huber: 1.6598, swd: 6.5757, ept: 173.5544\n",
      "Epoch [9/50], Val Losses: mse: 16.5811, mae: 2.5419, huber: 2.1414, swd: 8.2749, ept: 154.6927\n",
      "Epoch [9/50], Test Losses: mse: 12.5160, mae: 2.2118, huber: 1.7972, swd: 6.2550, ept: 162.7424\n",
      "  Epoch 9 composite train-obj: 1.659775\n",
      "        Val objective improved 2.1486 → 2.1414, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 12.8139, mae: 2.0161, huber: 1.6155, swd: 6.2049, ept: 174.3336\n",
      "Epoch [10/50], Val Losses: mse: 17.5471, mae: 2.6111, huber: 2.2096, swd: 8.8697, ept: 152.2362\n",
      "Epoch [10/50], Test Losses: mse: 13.3886, mae: 2.2654, huber: 1.8512, swd: 6.8940, ept: 159.0846\n",
      "  Epoch 10 composite train-obj: 1.615505\n",
      "        No improvement (2.2096), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 12.6911, mae: 2.0067, huber: 1.6067, swd: 6.1237, ept: 174.5493\n",
      "Epoch [11/50], Val Losses: mse: 17.0414, mae: 2.5667, huber: 2.1667, swd: 8.8793, ept: 153.7269\n",
      "Epoch [11/50], Test Losses: mse: 12.6738, mae: 2.2102, huber: 1.7961, swd: 6.2835, ept: 162.2550\n",
      "  Epoch 11 composite train-obj: 1.606660\n",
      "        No improvement (2.1667), counter 2/5\n",
      "Epoch [12/50], Train Losses: mse: 12.4663, mae: 1.9848, huber: 1.5856, swd: 5.9889, ept: 174.8747\n",
      "Epoch [12/50], Val Losses: mse: 18.0284, mae: 2.6015, huber: 2.2018, swd: 9.5205, ept: 152.8033\n",
      "Epoch [12/50], Test Losses: mse: 13.7722, mae: 2.2887, huber: 1.8740, swd: 7.2688, ept: 158.7376\n",
      "  Epoch 12 composite train-obj: 1.585626\n",
      "        No improvement (2.2018), counter 3/5\n",
      "Epoch [13/50], Train Losses: mse: 12.2459, mae: 1.9642, huber: 1.5659, swd: 5.8460, ept: 175.2619\n",
      "Epoch [13/50], Val Losses: mse: 18.5073, mae: 2.6609, huber: 2.2574, swd: 9.9948, ept: 150.9526\n",
      "Epoch [13/50], Test Losses: mse: 14.1882, mae: 2.3434, huber: 1.9259, swd: 7.7087, ept: 157.3010\n",
      "  Epoch 13 composite train-obj: 1.565949\n",
      "        No improvement (2.2574), counter 4/5\n",
      "Epoch [14/50], Train Losses: mse: 12.1602, mae: 1.9600, huber: 1.5617, swd: 5.8122, ept: 175.3888\n",
      "Epoch [14/50], Val Losses: mse: 17.7392, mae: 2.6136, huber: 2.2128, swd: 9.2039, ept: 153.1819\n",
      "Epoch [14/50], Test Losses: mse: 13.9917, mae: 2.3422, huber: 1.9235, swd: 7.4006, ept: 157.4184\n",
      "  Epoch 14 composite train-obj: 1.561703\n",
      "Epoch [14/50], Test Losses: mse: 12.5159, mae: 2.2118, huber: 1.7972, swd: 6.2550, ept: 162.7424\n",
      "Best round's Test MSE: 12.5160, MAE: 2.2118, SWD: 6.2550\n",
      "Best round's Validation MSE: 16.5811, MAE: 2.5419, SWD: 8.2749\n",
      "Best round's Test verification MSE : 12.5159, MAE: 2.2118, SWD: 6.2550\n",
      "Time taken: 157.51 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 37.7172, mae: 3.1455, huber: 2.7244, swd: 26.1949, ept: 151.9907\n",
      "Epoch [1/50], Val Losses: mse: 20.4954, mae: 2.8520, huber: 2.4371, swd: 10.3130, ept: 149.4655\n",
      "Epoch [1/50], Test Losses: mse: 14.6734, mae: 2.4988, huber: 2.0679, swd: 7.3967, ept: 161.5582\n",
      "  Epoch 1 composite train-obj: 2.724402\n",
      "        Val objective improved inf → 2.4371, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.9761, mae: 2.3522, huber: 1.9391, swd: 9.2974, ept: 167.2702\n",
      "Epoch [2/50], Val Losses: mse: 16.8189, mae: 2.5748, huber: 2.1648, swd: 8.4331, ept: 155.5842\n",
      "Epoch [2/50], Test Losses: mse: 12.1433, mae: 2.2524, huber: 1.8274, swd: 6.0113, ept: 165.6894\n",
      "  Epoch 2 composite train-obj: 1.939082\n",
      "        Val objective improved 2.4371 → 2.1648, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.5204, mae: 2.2137, huber: 1.8051, swd: 8.4234, ept: 171.1028\n",
      "Epoch [3/50], Val Losses: mse: 16.8579, mae: 2.5461, huber: 2.1373, swd: 8.5356, ept: 154.7549\n",
      "Epoch [3/50], Test Losses: mse: 12.3934, mae: 2.2108, huber: 1.7907, swd: 6.2314, ept: 163.5361\n",
      "  Epoch 3 composite train-obj: 1.805053\n",
      "        Val objective improved 2.1648 → 2.1373, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.9309, mae: 2.1668, huber: 1.7599, swd: 7.9963, ept: 171.7285\n",
      "Epoch [4/50], Val Losses: mse: 16.7419, mae: 2.5863, huber: 2.1743, swd: 8.9790, ept: 155.0065\n",
      "Epoch [4/50], Test Losses: mse: 11.9649, mae: 2.2582, huber: 1.8317, swd: 6.0470, ept: 164.7882\n",
      "  Epoch 4 composite train-obj: 1.759932\n",
      "        No improvement (2.1743), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 14.3735, mae: 2.1264, huber: 1.7205, swd: 7.5685, ept: 172.5408\n",
      "Epoch [5/50], Val Losses: mse: 16.6618, mae: 2.5768, huber: 2.1673, swd: 8.7390, ept: 154.7020\n",
      "Epoch [5/50], Test Losses: mse: 12.3632, mae: 2.2618, huber: 1.8383, swd: 6.2986, ept: 163.0541\n",
      "  Epoch 5 composite train-obj: 1.720471\n",
      "        No improvement (2.1673), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 13.9386, mae: 2.0905, huber: 1.6860, swd: 7.2330, ept: 173.2273\n",
      "Epoch [6/50], Val Losses: mse: 16.3356, mae: 2.5144, huber: 2.1088, swd: 8.5650, ept: 156.4064\n",
      "Epoch [6/50], Test Losses: mse: 12.0116, mae: 2.1978, huber: 1.7790, swd: 5.9981, ept: 163.8581\n",
      "  Epoch 6 composite train-obj: 1.686041\n",
      "        Val objective improved 2.1373 → 2.1088, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 13.4287, mae: 2.0567, huber: 1.6534, swd: 6.8163, ept: 173.9007\n",
      "Epoch [7/50], Val Losses: mse: 17.2243, mae: 2.5601, huber: 2.1564, swd: 9.4466, ept: 154.5587\n",
      "Epoch [7/50], Test Losses: mse: 12.5121, mae: 2.2094, huber: 1.7932, swd: 6.3958, ept: 163.1566\n",
      "  Epoch 7 composite train-obj: 1.653393\n",
      "        No improvement (2.1564), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 12.8329, mae: 2.0167, huber: 1.6146, swd: 6.3596, ept: 174.5130\n",
      "Epoch [8/50], Val Losses: mse: 18.2676, mae: 2.6159, huber: 2.2139, swd: 10.4039, ept: 152.8874\n",
      "Epoch [8/50], Test Losses: mse: 14.4916, mae: 2.3866, huber: 1.9675, swd: 8.2572, ept: 156.1794\n",
      "  Epoch 8 composite train-obj: 1.614633\n",
      "        No improvement (2.2139), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 12.5389, mae: 1.9928, huber: 1.5913, swd: 6.1877, ept: 174.9512\n",
      "Epoch [9/50], Val Losses: mse: 17.2509, mae: 2.5581, huber: 2.1560, swd: 9.7738, ept: 155.8061\n",
      "Epoch [9/50], Test Losses: mse: 12.9275, mae: 2.2698, huber: 1.8487, swd: 6.9460, ept: 162.8160\n",
      "  Epoch 9 composite train-obj: 1.591341\n",
      "        No improvement (2.1560), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 12.2048, mae: 1.9712, huber: 1.5704, swd: 5.9746, ept: 175.3268\n",
      "Epoch [10/50], Val Losses: mse: 17.8945, mae: 2.6014, huber: 2.2020, swd: 10.4171, ept: 154.0895\n",
      "Epoch [10/50], Test Losses: mse: 12.9498, mae: 2.2389, huber: 1.8237, swd: 6.9103, ept: 160.6809\n",
      "  Epoch 10 composite train-obj: 1.570420\n",
      "        No improvement (2.2020), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 11.8792, mae: 1.9371, huber: 1.5377, swd: 5.7480, ept: 175.8140\n",
      "Epoch [11/50], Val Losses: mse: 17.3475, mae: 2.5615, huber: 2.1620, swd: 9.7678, ept: 154.2702\n",
      "Epoch [11/50], Test Losses: mse: 13.1099, mae: 2.2510, huber: 1.8345, swd: 7.0017, ept: 161.4601\n",
      "  Epoch 11 composite train-obj: 1.537677\n",
      "Epoch [11/50], Test Losses: mse: 12.0115, mae: 2.1978, huber: 1.7789, swd: 5.9981, ept: 163.8612\n",
      "Best round's Test MSE: 12.0116, MAE: 2.1978, SWD: 5.9981\n",
      "Best round's Validation MSE: 16.3356, MAE: 2.5144, SWD: 8.5650\n",
      "Best round's Test verification MSE : 12.0115, MAE: 2.1978, SWD: 5.9981\n",
      "Time taken: 120.10 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 40.1261, mae: 3.1959, huber: 2.7746, swd: 25.2361, ept: 152.1096\n",
      "Epoch [1/50], Val Losses: mse: 19.5812, mae: 2.7652, huber: 2.3499, swd: 8.2853, ept: 151.3653\n",
      "Epoch [1/50], Test Losses: mse: 13.5640, mae: 2.3673, huber: 1.9415, swd: 5.4549, ept: 162.7265\n",
      "  Epoch 1 composite train-obj: 2.774621\n",
      "        Val objective improved inf → 2.3499, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.2587, mae: 2.3614, huber: 1.9488, swd: 8.2707, ept: 167.9171\n",
      "Epoch [2/50], Val Losses: mse: 17.6860, mae: 2.6131, huber: 2.1990, swd: 8.0523, ept: 156.2615\n",
      "Epoch [2/50], Test Losses: mse: 12.0720, mae: 2.2268, huber: 1.8030, swd: 5.1474, ept: 165.7200\n",
      "  Epoch 2 composite train-obj: 1.948783\n",
      "        Val objective improved 2.3499 → 2.1990, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 16.0588, mae: 2.2508, huber: 1.8417, swd: 7.6285, ept: 171.0080\n",
      "Epoch [3/50], Val Losses: mse: 17.7265, mae: 2.6066, huber: 2.1954, swd: 7.9154, ept: 155.1056\n",
      "Epoch [3/50], Test Losses: mse: 12.5660, mae: 2.2295, huber: 1.8097, swd: 5.3662, ept: 162.8745\n",
      "  Epoch 3 composite train-obj: 1.841693\n",
      "        Val objective improved 2.1990 → 2.1954, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 15.6123, mae: 2.2074, huber: 1.8002, swd: 7.3091, ept: 171.4505\n",
      "Epoch [4/50], Val Losses: mse: 17.4585, mae: 2.5963, huber: 2.1859, swd: 7.7341, ept: 155.4357\n",
      "Epoch [4/50], Test Losses: mse: 12.8212, mae: 2.2410, huber: 1.8221, swd: 5.5679, ept: 162.7346\n",
      "  Epoch 4 composite train-obj: 1.800166\n",
      "        Val objective improved 2.1954 → 2.1859, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 14.9514, mae: 2.1469, huber: 1.7417, swd: 6.8460, ept: 172.4592\n",
      "Epoch [5/50], Val Losses: mse: 17.2551, mae: 2.6054, huber: 2.1959, swd: 7.7312, ept: 154.1789\n",
      "Epoch [5/50], Test Losses: mse: 12.1308, mae: 2.2002, huber: 1.7808, swd: 5.1391, ept: 164.6085\n",
      "  Epoch 5 composite train-obj: 1.741722\n",
      "        No improvement (2.1959), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 14.4577, mae: 2.1113, huber: 1.7076, swd: 6.5354, ept: 172.9958\n",
      "Epoch [6/50], Val Losses: mse: 18.2301, mae: 2.6296, huber: 2.2242, swd: 8.5471, ept: 154.3184\n",
      "Epoch [6/50], Test Losses: mse: 12.4709, mae: 2.1870, huber: 1.7714, swd: 5.3658, ept: 165.1049\n",
      "  Epoch 6 composite train-obj: 1.707585\n",
      "        No improvement (2.2242), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 14.1946, mae: 2.1002, huber: 1.6968, swd: 6.3960, ept: 173.1953\n",
      "Epoch [7/50], Val Losses: mse: 18.7796, mae: 2.6435, huber: 2.2384, swd: 9.0700, ept: 154.5498\n",
      "Epoch [7/50], Test Losses: mse: 12.8271, mae: 2.2236, huber: 1.8054, swd: 5.7356, ept: 164.1409\n",
      "  Epoch 7 composite train-obj: 1.696776\n",
      "        No improvement (2.2384), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 13.7619, mae: 2.0666, huber: 1.6643, swd: 6.1177, ept: 173.7871\n",
      "Epoch [8/50], Val Losses: mse: 19.9758, mae: 2.6693, huber: 2.2675, swd: 10.2523, ept: 153.9708\n",
      "Epoch [8/50], Test Losses: mse: 13.2250, mae: 2.2158, huber: 1.8019, swd: 6.0900, ept: 163.1733\n",
      "  Epoch 8 composite train-obj: 1.664334\n",
      "        No improvement (2.2675), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 13.3294, mae: 2.0369, huber: 1.6357, swd: 5.8219, ept: 174.3132\n",
      "Epoch [9/50], Val Losses: mse: 20.6685, mae: 2.7158, huber: 2.3143, swd: 10.8875, ept: 154.0428\n",
      "Epoch [9/50], Test Losses: mse: 13.4918, mae: 2.2873, huber: 1.8667, swd: 6.2474, ept: 161.9987\n",
      "  Epoch 9 composite train-obj: 1.635749\n",
      "Epoch [9/50], Test Losses: mse: 12.8210, mae: 2.2410, huber: 1.8220, swd: 5.5677, ept: 162.7360\n",
      "Best round's Test MSE: 12.8212, MAE: 2.2410, SWD: 5.5679\n",
      "Best round's Validation MSE: 17.4585, MAE: 2.5963, SWD: 7.7341\n",
      "Best round's Test verification MSE : 12.8210, MAE: 2.2410, SWD: 5.5677\n",
      "Time taken: 97.04 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred196_20250512_1853)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 12.4496 ± 0.3338\n",
      "  mae: 2.2169 ± 0.0180\n",
      "  huber: 1.7994 ± 0.0177\n",
      "  swd: 5.9403 ± 0.2835\n",
      "  ept: 163.1117 ± 0.5278\n",
      "  count: 51.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 16.7917 ± 0.4820\n",
      "  mae: 2.5509 ± 0.0340\n",
      "  huber: 2.1453 ± 0.0316\n",
      "  swd: 8.1913 ± 0.3443\n",
      "  ept: 155.5116 ± 0.7016\n",
      "  count: 51.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 374.72 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred196_20250512_1853\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=196,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only', \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f3038e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 377\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 377\n",
      "Validation Batches: 51\n",
      "Test Batches: 105\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 37.2775, mae: 3.0779, huber: 2.6587, swd: 26.6849, target_std: 20.3580\n",
      "Epoch [1/50], Val Losses: mse: 17.6471, mae: 2.6186, huber: 2.2082, swd: 9.0289, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1696, mae: 2.2450, huber: 1.8212, swd: 5.9111, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.658653\n",
      "        Val objective improved inf → 2.2082, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.1604, mae: 2.2565, huber: 1.8470, swd: 8.6988, target_std: 20.3576\n",
      "Epoch [2/50], Val Losses: mse: 16.8536, mae: 2.5627, huber: 2.1503, swd: 8.3018, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.4947, mae: 2.2738, huber: 1.8478, swd: 6.0659, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.846954\n",
      "        Val objective improved 2.2082 → 2.1503, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.4368, mae: 2.2084, huber: 1.8005, swd: 8.1438, target_std: 20.3580\n",
      "Epoch [3/50], Val Losses: mse: 16.6820, mae: 2.5564, huber: 2.1474, swd: 8.5670, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 11.6256, mae: 2.1794, huber: 1.7587, swd: 5.4969, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.800474\n",
      "        Val objective improved 2.1503 → 2.1474, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.9243, mae: 2.1619, huber: 1.7556, swd: 7.7644, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 16.6727, mae: 2.5397, huber: 2.1316, swd: 8.3668, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 12.6159, mae: 2.2116, huber: 1.7950, swd: 6.2162, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.755584\n",
      "        Val objective improved 2.1474 → 2.1316, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 14.4457, mae: 2.1255, huber: 1.7205, swd: 7.4014, target_std: 20.3578\n",
      "Epoch [5/50], Val Losses: mse: 17.2732, mae: 2.5805, huber: 2.1737, swd: 8.8164, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.6307, mae: 2.2427, huber: 1.8234, swd: 6.2662, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.720471\n",
      "        No improvement (2.1737), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 14.0539, mae: 2.1041, huber: 1.6998, swd: 7.1530, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 16.5473, mae: 2.5300, huber: 2.1235, swd: 8.4977, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 12.3487, mae: 2.1932, huber: 1.7784, swd: 5.9996, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.699791\n",
      "        Val objective improved 2.1316 → 2.1235, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 13.3771, mae: 2.0537, huber: 1.6508, swd: 6.6911, target_std: 20.3579\n",
      "Epoch [7/50], Val Losses: mse: 17.3037, mae: 2.5671, huber: 2.1609, swd: 9.1529, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 13.6834, mae: 2.2991, huber: 1.8814, swd: 7.2152, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.650810\n",
      "        No improvement (2.1609), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 12.9155, mae: 2.0240, huber: 1.6214, swd: 6.3463, target_std: 20.3578\n",
      "Epoch [8/50], Val Losses: mse: 16.7230, mae: 2.5449, huber: 2.1380, swd: 8.5034, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 13.3043, mae: 2.3234, huber: 1.8990, swd: 6.7803, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.621443\n",
      "        No improvement (2.1380), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 12.7090, mae: 2.0055, huber: 1.6037, swd: 6.2193, target_std: 20.3581\n",
      "Epoch [9/50], Val Losses: mse: 16.3396, mae: 2.5192, huber: 2.1121, swd: 8.4823, target_std: 20.5630\n",
      "Epoch [9/50], Test Losses: mse: 12.8563, mae: 2.2503, huber: 1.8328, swd: 6.4904, target_std: 18.3527\n",
      "  Epoch 9 composite train-obj: 1.603667\n",
      "        Val objective improved 2.1235 → 2.1121, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 12.4098, mae: 1.9825, huber: 1.5814, swd: 5.9918, target_std: 20.3581\n",
      "Epoch [10/50], Val Losses: mse: 18.0997, mae: 2.6476, huber: 2.2386, swd: 9.8430, target_std: 20.5630\n",
      "Epoch [10/50], Test Losses: mse: 13.7933, mae: 2.3079, huber: 1.8917, swd: 7.1672, target_std: 18.3527\n",
      "  Epoch 10 composite train-obj: 1.581376\n",
      "        No improvement (2.2386), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 12.1086, mae: 1.9540, huber: 1.5536, swd: 5.8095, target_std: 20.3579\n",
      "Epoch [11/50], Val Losses: mse: 17.7315, mae: 2.6165, huber: 2.2094, swd: 9.6903, target_std: 20.5630\n",
      "Epoch [11/50], Test Losses: mse: 13.1878, mae: 2.2682, huber: 1.8513, swd: 6.8387, target_std: 18.3527\n",
      "  Epoch 11 composite train-obj: 1.553640\n",
      "        No improvement (2.2094), counter 2/5\n",
      "Epoch [12/50], Train Losses: mse: 11.8251, mae: 1.9318, huber: 1.5320, swd: 5.6143, target_std: 20.3579\n",
      "Epoch [12/50], Val Losses: mse: 18.1193, mae: 2.6361, huber: 2.2302, swd: 9.8120, target_std: 20.5630\n",
      "Epoch [12/50], Test Losses: mse: 14.5513, mae: 2.3769, huber: 1.9595, swd: 7.9214, target_std: 18.3527\n",
      "  Epoch 12 composite train-obj: 1.532022\n",
      "        No improvement (2.2302), counter 3/5\n",
      "Epoch [13/50], Train Losses: mse: 11.5744, mae: 1.9139, huber: 1.5146, swd: 5.4768, target_std: 20.3581\n",
      "Epoch [13/50], Val Losses: mse: 17.7395, mae: 2.6427, huber: 2.2344, swd: 9.6718, target_std: 20.5630\n",
      "Epoch [13/50], Test Losses: mse: 14.1133, mae: 2.3642, huber: 1.9427, swd: 7.5459, target_std: 18.3527\n",
      "  Epoch 13 composite train-obj: 1.514571\n",
      "        No improvement (2.2344), counter 4/5\n",
      "Epoch [14/50], Train Losses: mse: 11.2891, mae: 1.8867, huber: 1.4884, swd: 5.2727, target_std: 20.3578\n",
      "Epoch [14/50], Val Losses: mse: 18.2518, mae: 2.6944, huber: 2.2873, swd: 10.3212, target_std: 20.5630\n",
      "Epoch [14/50], Test Losses: mse: 14.3020, mae: 2.3793, huber: 1.9607, swd: 7.6186, target_std: 18.3527\n",
      "  Epoch 14 composite train-obj: 1.488429\n",
      "Epoch [14/50], Test Losses: mse: 12.8560, mae: 2.2503, huber: 1.8328, swd: 6.4901, target_std: 18.3527\n",
      "Best round's Test MSE: 12.8563, MAE: 2.2503, SWD: 6.4904\n",
      "Best round's Validation MSE: 16.3396, MAE: 2.5192\n",
      "Best round's Test verification MSE : 12.8560, MAE: 2.2503, SWD: 6.4901\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 37.4795, mae: 3.1262, huber: 2.7060, swd: 27.7041, target_std: 20.3578\n",
      "Epoch [1/50], Val Losses: mse: 17.5924, mae: 2.5971, huber: 2.1867, swd: 9.0679, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.3931, mae: 2.2593, huber: 1.8351, swd: 6.1852, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.706005\n",
      "        Val objective improved inf → 2.1867, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.1921, mae: 2.2686, huber: 1.8588, swd: 8.9540, target_std: 20.3577\n",
      "Epoch [2/50], Val Losses: mse: 17.9343, mae: 2.6509, huber: 2.2390, swd: 10.0370, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.2541, mae: 2.2765, huber: 1.8508, swd: 6.3406, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.858751\n",
      "        No improvement (2.2390), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.2721, mae: 2.1950, huber: 1.7880, swd: 8.2229, target_std: 20.3580\n",
      "Epoch [3/50], Val Losses: mse: 16.9789, mae: 2.5805, huber: 2.1742, swd: 9.1380, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 11.9419, mae: 2.1978, huber: 1.7783, swd: 5.8698, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.787988\n",
      "        Val objective improved 2.1867 → 2.1742, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.6115, mae: 2.1435, huber: 1.7386, swd: 7.7528, target_std: 20.3577\n",
      "Epoch [4/50], Val Losses: mse: 18.2250, mae: 2.6195, huber: 2.2176, swd: 10.1263, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 13.1552, mae: 2.2698, huber: 1.8535, swd: 6.9307, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.738573\n",
      "        No improvement (2.2176), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 14.2361, mae: 2.1180, huber: 1.7139, swd: 7.5268, target_std: 20.3580\n",
      "Epoch [5/50], Val Losses: mse: 17.9659, mae: 2.6967, huber: 2.2908, swd: 10.3648, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.6369, mae: 2.3240, huber: 1.8983, swd: 6.5686, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.713911\n",
      "        No improvement (2.2908), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 13.8222, mae: 2.0817, huber: 1.6789, swd: 7.2593, target_std: 20.3579\n",
      "Epoch [6/50], Val Losses: mse: 17.6709, mae: 2.5984, huber: 2.1962, swd: 9.7762, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 13.7086, mae: 2.3625, huber: 1.9411, swd: 7.3868, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.678908\n",
      "        No improvement (2.1962), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 13.4348, mae: 2.0577, huber: 1.6553, swd: 6.9619, target_std: 20.3578\n",
      "Epoch [7/50], Val Losses: mse: 17.1293, mae: 2.5805, huber: 2.1766, swd: 9.5276, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 12.4770, mae: 2.2116, huber: 1.7952, swd: 6.4629, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.655308\n",
      "        No improvement (2.1766), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 12.9514, mae: 2.0234, huber: 1.6220, swd: 6.5776, target_std: 20.3579\n",
      "Epoch [8/50], Val Losses: mse: 18.5162, mae: 2.6509, huber: 2.2459, swd: 10.6433, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 13.5962, mae: 2.2993, huber: 1.8799, swd: 7.3061, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.622035\n",
      "Epoch [8/50], Test Losses: mse: 11.9422, mae: 2.1978, huber: 1.7783, swd: 5.8700, target_std: 18.3527\n",
      "Best round's Test MSE: 11.9419, MAE: 2.1978, SWD: 5.8698\n",
      "Best round's Validation MSE: 16.9789, MAE: 2.5805\n",
      "Best round's Test verification MSE : 11.9422, MAE: 2.1978, SWD: 5.8700\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 36.0424, mae: 3.0684, huber: 2.6488, swd: 22.0481, target_std: 20.3577\n",
      "Epoch [1/50], Val Losses: mse: 18.8180, mae: 2.6802, huber: 2.2684, swd: 8.4832, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 14.3822, mae: 2.4205, huber: 1.9949, swd: 6.7614, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.648786\n",
      "        Val objective improved inf → 2.2684, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.1945, mae: 2.2684, huber: 1.8582, swd: 7.6268, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 16.8975, mae: 2.5810, huber: 2.1704, swd: 7.6133, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 11.9164, mae: 2.2166, huber: 1.7945, swd: 4.9952, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.858250\n",
      "        Val objective improved 2.2684 → 2.1704, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.2716, mae: 2.1920, huber: 1.7851, swd: 7.0153, target_std: 20.3581\n",
      "Epoch [3/50], Val Losses: mse: 16.5842, mae: 2.5272, huber: 2.1211, swd: 7.3021, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 12.6443, mae: 2.2563, huber: 1.8342, swd: 5.5115, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.785124\n",
      "        Val objective improved 2.1704 → 2.1211, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.6472, mae: 2.1462, huber: 1.7411, swd: 6.6275, target_std: 20.3578\n",
      "Epoch [4/50], Val Losses: mse: 15.8633, mae: 2.4718, huber: 2.0671, swd: 7.0937, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 12.1941, mae: 2.2039, huber: 1.7847, swd: 5.3860, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.741145\n",
      "        Val objective improved 2.1211 → 2.0671, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 13.9966, mae: 2.0881, huber: 1.6849, swd: 6.2367, target_std: 20.3578\n",
      "Epoch [5/50], Val Losses: mse: 16.9697, mae: 2.5519, huber: 2.1472, swd: 7.8314, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.4977, mae: 2.2135, huber: 1.7967, swd: 5.4377, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.684915\n",
      "        No improvement (2.1472), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 13.6288, mae: 2.0751, huber: 1.6721, swd: 6.0241, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 16.4471, mae: 2.5471, huber: 2.1428, swd: 7.8687, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 12.5284, mae: 2.2561, huber: 1.8356, swd: 5.7949, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.672111\n",
      "        No improvement (2.1428), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 13.0675, mae: 2.0425, huber: 1.6403, swd: 5.6656, target_std: 20.3579\n",
      "Epoch [7/50], Val Losses: mse: 16.3257, mae: 2.5156, huber: 2.1120, swd: 7.5493, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 12.3115, mae: 2.1765, huber: 1.7635, swd: 5.3874, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.640337\n",
      "        No improvement (2.1120), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 12.5933, mae: 2.0044, huber: 1.6031, swd: 5.3720, target_std: 20.3577\n",
      "Epoch [8/50], Val Losses: mse: 16.7677, mae: 2.5203, huber: 2.1180, swd: 7.6877, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 13.0022, mae: 2.2152, huber: 1.8017, swd: 5.8900, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.603072\n",
      "        No improvement (2.1180), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 12.3531, mae: 1.9787, huber: 1.5776, swd: 5.2672, target_std: 20.3579\n",
      "Epoch [9/50], Val Losses: mse: 16.8482, mae: 2.5476, huber: 2.1430, swd: 7.8705, target_std: 20.5630\n",
      "Epoch [9/50], Test Losses: mse: 12.9553, mae: 2.2191, huber: 1.8056, swd: 5.7903, target_std: 18.3527\n",
      "  Epoch 9 composite train-obj: 1.577642\n",
      "Epoch [9/50], Test Losses: mse: 12.1943, mae: 2.2039, huber: 1.7847, swd: 5.3862, target_std: 18.3527\n",
      "Best round's Test MSE: 12.1941, MAE: 2.2039, SWD: 5.3860\n",
      "Best round's Validation MSE: 15.8633, MAE: 2.4718\n",
      "Best round's Test verification MSE : 12.1943, MAE: 2.2039, SWD: 5.3862\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred196_20250430_2231)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 12.3308 ± 0.3856\n",
      "  mae: 2.2173 ± 0.0235\n",
      "  huber: 1.7986 ± 0.0243\n",
      "  swd: 5.9154 ± 0.4520\n",
      "  target_std: 18.3527 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 16.3939 ± 0.4571\n",
      "  mae: 2.5238 ± 0.0445\n",
      "  huber: 2.1178 ± 0.0439\n",
      "  swd: 8.2380 ± 0.8523\n",
      "  target_std: 20.5630 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred196_20250430_2231\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "\n",
    "cfg = train_config.FlatACLConfig( \n",
    "    seq_len=336,\n",
    "    pred_len=196,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128,\n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=False, \n",
    "    ablate_shift_inside_scale=False,\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96038b75",
   "metadata": {},
   "source": [
    "#### pred=336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d249596",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732554d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "global_std.shape: torch.Size([7])\n",
      "Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],\n",
      "       device='cuda:0')\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 42.6391, mae: 3.4097, huber: 2.9854, swd: 27.8345, ept: 231.5834\n",
      "Epoch [1/50], Val Losses: mse: 23.8987, mae: 3.1318, huber: 2.7119, swd: 9.1935, ept: 220.8213\n",
      "Epoch [1/50], Test Losses: mse: 17.0549, mae: 2.6600, huber: 2.2297, swd: 7.2869, ept: 246.7975\n",
      "  Epoch 1 composite train-obj: 2.985376\n",
      "        Val objective improved inf → 2.7119, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.3312, mae: 2.6861, huber: 2.2675, swd: 10.9393, ept: 255.7975\n",
      "Epoch [2/50], Val Losses: mse: 21.3204, mae: 2.9372, huber: 2.5178, swd: 8.6497, ept: 226.4288\n",
      "Epoch [2/50], Test Losses: mse: 16.2145, mae: 2.5530, huber: 2.1255, swd: 7.7111, ept: 240.9522\n",
      "  Epoch 2 composite train-obj: 2.267506\n",
      "        Val objective improved 2.7119 → 2.5178, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.2568, mae: 2.5272, huber: 2.1116, swd: 10.0462, ept: 265.2070\n",
      "Epoch [3/50], Val Losses: mse: 20.0786, mae: 2.8782, huber: 2.4579, swd: 8.2664, ept: 232.4761\n",
      "Epoch [3/50], Test Losses: mse: 15.0091, mae: 2.4630, huber: 2.0351, swd: 7.0453, ept: 250.3003\n",
      "  Epoch 3 composite train-obj: 2.111634\n",
      "        Val objective improved 2.5178 → 2.4579, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.4179, mae: 2.4765, huber: 2.0621, swd: 9.5545, ept: 268.1996\n",
      "Epoch [4/50], Val Losses: mse: 20.8179, mae: 2.9302, huber: 2.5111, swd: 8.6169, ept: 230.8134\n",
      "Epoch [4/50], Test Losses: mse: 15.7112, mae: 2.5044, huber: 2.0775, swd: 7.6036, ept: 246.6404\n",
      "  Epoch 4 composite train-obj: 2.062077\n",
      "        No improvement (2.5111), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.6359, mae: 2.4024, huber: 1.9904, swd: 9.0565, ept: 270.9615\n",
      "Epoch [5/50], Val Losses: mse: 21.3994, mae: 2.9211, huber: 2.5075, swd: 9.2162, ept: 232.5356\n",
      "Epoch [5/50], Test Losses: mse: 15.8264, mae: 2.4820, huber: 2.0579, swd: 7.8298, ept: 250.5434\n",
      "  Epoch 5 composite train-obj: 1.990379\n",
      "        No improvement (2.5075), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 18.1828, mae: 2.3706, huber: 1.9596, swd: 8.7425, ept: 272.0228\n",
      "Epoch [6/50], Val Losses: mse: 23.3930, mae: 3.0323, huber: 2.6193, swd: 11.1467, ept: 227.3300\n",
      "Epoch [6/50], Test Losses: mse: 16.7275, mae: 2.5591, huber: 2.1350, swd: 8.5744, ept: 244.4767\n",
      "  Epoch 6 composite train-obj: 1.959595\n",
      "        No improvement (2.6193), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.7806, mae: 2.3415, huber: 1.9314, swd: 8.4577, ept: 273.3862\n",
      "Epoch [7/50], Val Losses: mse: 20.5624, mae: 2.8934, huber: 2.4810, swd: 8.6793, ept: 231.9676\n",
      "Epoch [7/50], Test Losses: mse: 16.2223, mae: 2.5500, huber: 2.1234, swd: 8.2319, ept: 244.3676\n",
      "  Epoch 7 composite train-obj: 1.931440\n",
      "        No improvement (2.4810), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 17.2263, mae: 2.3065, huber: 1.8978, swd: 8.0325, ept: 274.3589\n",
      "Epoch [8/50], Val Losses: mse: 21.8138, mae: 2.9726, huber: 2.5619, swd: 10.2041, ept: 231.1686\n",
      "Epoch [8/50], Test Losses: mse: 16.4689, mae: 2.5605, huber: 2.1366, swd: 8.4528, ept: 246.1141\n",
      "  Epoch 8 composite train-obj: 1.897770\n",
      "Epoch [8/50], Test Losses: mse: 15.0094, mae: 2.4630, huber: 2.0352, swd: 7.0459, ept: 250.3050\n",
      "Best round's Test MSE: 15.0091, MAE: 2.4630, SWD: 7.0453\n",
      "Best round's Validation MSE: 20.0786, MAE: 2.8782, SWD: 8.2664\n",
      "Best round's Test verification MSE : 15.0094, MAE: 2.4630, SWD: 7.0459\n",
      "Time taken: 85.95 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 43.3329, mae: 3.4157, huber: 2.9912, swd: 30.2929, ept: 234.7651\n",
      "Epoch [1/50], Val Losses: mse: 24.1469, mae: 3.1390, huber: 2.7163, swd: 9.9074, ept: 224.5032\n",
      "Epoch [1/50], Test Losses: mse: 16.7671, mae: 2.6289, huber: 2.1985, swd: 7.5586, ept: 250.9166\n",
      "  Epoch 1 composite train-obj: 2.991182\n",
      "        Val objective improved inf → 2.7163, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.5742, mae: 2.7046, huber: 2.2857, swd: 11.8421, ept: 257.2544\n",
      "Epoch [2/50], Val Losses: mse: 21.2298, mae: 2.9225, huber: 2.5017, swd: 9.2955, ept: 233.7132\n",
      "Epoch [2/50], Test Losses: mse: 14.7889, mae: 2.4728, huber: 2.0438, swd: 7.1917, ept: 252.6417\n",
      "  Epoch 2 composite train-obj: 2.285704\n",
      "        Val objective improved 2.7163 → 2.5017, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.0905, mae: 2.4970, huber: 2.0832, swd: 10.4819, ept: 270.1578\n",
      "Epoch [3/50], Val Losses: mse: 21.6698, mae: 2.9522, huber: 2.5340, swd: 9.4970, ept: 229.7350\n",
      "Epoch [3/50], Test Losses: mse: 16.6988, mae: 2.5810, huber: 2.1537, swd: 8.9032, ept: 243.4846\n",
      "  Epoch 3 composite train-obj: 2.083231\n",
      "        No improvement (2.5340), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 19.2033, mae: 2.4509, huber: 2.0381, swd: 9.8400, ept: 271.1911\n",
      "Epoch [4/50], Val Losses: mse: 21.0000, mae: 2.9553, huber: 2.5340, swd: 9.4405, ept: 230.5415\n",
      "Epoch [4/50], Test Losses: mse: 15.2105, mae: 2.5067, huber: 2.0757, swd: 7.6521, ept: 251.1123\n",
      "  Epoch 4 composite train-obj: 2.038118\n",
      "        No improvement (2.5340), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 18.3415, mae: 2.3865, huber: 1.9748, swd: 9.1908, ept: 273.2115\n",
      "Epoch [5/50], Val Losses: mse: 23.0436, mae: 3.0419, huber: 2.6265, swd: 10.9112, ept: 231.3584\n",
      "Epoch [5/50], Test Losses: mse: 15.9550, mae: 2.4813, huber: 2.0590, swd: 8.3293, ept: 250.5352\n",
      "  Epoch 5 composite train-obj: 1.974776\n",
      "        No improvement (2.6265), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.8134, mae: 2.3499, huber: 1.9395, swd: 8.8338, ept: 274.2113\n",
      "Epoch [6/50], Val Losses: mse: 24.8684, mae: 3.1184, huber: 2.7041, swd: 12.8599, ept: 230.4006\n",
      "Epoch [6/50], Test Losses: mse: 16.1742, mae: 2.5082, huber: 2.0861, swd: 8.4056, ept: 249.0880\n",
      "  Epoch 6 composite train-obj: 1.939465\n",
      "        No improvement (2.7041), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 17.1170, mae: 2.3072, huber: 1.8974, swd: 8.2806, ept: 275.4492\n",
      "Epoch [7/50], Val Losses: mse: 24.0517, mae: 3.0591, huber: 2.6464, swd: 12.0381, ept: 231.9045\n",
      "Epoch [7/50], Test Losses: mse: 16.1741, mae: 2.4738, huber: 2.0551, swd: 8.3980, ept: 251.2974\n",
      "  Epoch 7 composite train-obj: 1.897419\n",
      "Epoch [7/50], Test Losses: mse: 14.7889, mae: 2.4728, huber: 2.0438, swd: 7.1916, ept: 252.6764\n",
      "Best round's Test MSE: 14.7889, MAE: 2.4728, SWD: 7.1917\n",
      "Best round's Validation MSE: 21.2298, MAE: 2.9225, SWD: 9.2955\n",
      "Best round's Test verification MSE : 14.7889, MAE: 2.4728, SWD: 7.1916\n",
      "Time taken: 76.35 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 44.1653, mae: 3.4325, huber: 3.0075, swd: 28.9319, ept: 233.1018\n",
      "Epoch [1/50], Val Losses: mse: 26.0954, mae: 3.2186, huber: 2.7953, swd: 10.7279, ept: 209.9797\n",
      "Epoch [1/50], Test Losses: mse: 20.2633, mae: 2.8891, huber: 2.4565, swd: 9.9375, ept: 226.9306\n",
      "  Epoch 1 composite train-obj: 3.007478\n",
      "        Val objective improved inf → 2.7953, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7179, mae: 2.6236, huber: 2.2059, swd: 10.8152, ept: 261.7834\n",
      "Epoch [2/50], Val Losses: mse: 21.7894, mae: 2.9310, huber: 2.5108, swd: 9.0574, ept: 230.5313\n",
      "Epoch [2/50], Test Losses: mse: 15.8279, mae: 2.5196, huber: 2.0920, swd: 7.4374, ept: 248.1093\n",
      "  Epoch 2 composite train-obj: 2.205876\n",
      "        Val objective improved 2.7953 → 2.5108, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.1149, mae: 2.5128, huber: 2.0982, swd: 9.8441, ept: 268.4131\n",
      "Epoch [3/50], Val Losses: mse: 19.5211, mae: 2.8239, huber: 2.4056, swd: 7.6682, ept: 236.6374\n",
      "Epoch [3/50], Test Losses: mse: 14.6267, mae: 2.4161, huber: 1.9906, swd: 6.5182, ept: 255.4169\n",
      "  Epoch 3 composite train-obj: 2.098168\n",
      "        Val objective improved 2.5108 → 2.4056, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.2178, mae: 2.4565, huber: 2.0432, swd: 9.2232, ept: 270.5014\n",
      "Epoch [4/50], Val Losses: mse: 20.2674, mae: 2.8807, huber: 2.4620, swd: 7.8961, ept: 233.5423\n",
      "Epoch [4/50], Test Losses: mse: 15.4143, mae: 2.4799, huber: 2.0525, swd: 7.1278, ept: 253.3250\n",
      "  Epoch 4 composite train-obj: 2.043207\n",
      "        No improvement (2.4620), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.6524, mae: 2.4172, huber: 2.0048, swd: 8.8230, ept: 271.3852\n",
      "Epoch [5/50], Val Losses: mse: 23.2820, mae: 3.0802, huber: 2.6623, swd: 10.3012, ept: 231.7206\n",
      "Epoch [5/50], Test Losses: mse: 15.0411, mae: 2.4408, huber: 2.0168, swd: 6.9217, ept: 256.6623\n",
      "  Epoch 5 composite train-obj: 2.004765\n",
      "        No improvement (2.6623), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 18.0279, mae: 2.3783, huber: 1.9670, swd: 8.3329, ept: 272.5796\n",
      "Epoch [6/50], Val Losses: mse: 25.6335, mae: 3.0997, huber: 2.6851, swd: 12.2520, ept: 231.5661\n",
      "Epoch [6/50], Test Losses: mse: 16.0439, mae: 2.4946, huber: 2.0699, swd: 7.6069, ept: 254.8724\n",
      "  Epoch 6 composite train-obj: 1.967029\n",
      "        No improvement (2.6851), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.3891, mae: 2.3451, huber: 1.9346, swd: 7.8680, ept: 273.4187\n",
      "Epoch [7/50], Val Losses: mse: 31.3095, mae: 3.2353, huber: 2.8205, swd: 17.0979, ept: 228.2181\n",
      "Epoch [7/50], Test Losses: mse: 17.9896, mae: 2.5801, huber: 2.1560, swd: 9.3156, ept: 247.8735\n",
      "  Epoch 7 composite train-obj: 1.934552\n",
      "        No improvement (2.8205), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.9418, mae: 2.3112, huber: 1.9016, swd: 7.5622, ept: 274.6207\n",
      "Epoch [8/50], Val Losses: mse: 29.4598, mae: 3.1671, huber: 2.7545, swd: 15.9688, ept: 231.5807\n",
      "Epoch [8/50], Test Losses: mse: 17.0350, mae: 2.5308, huber: 2.1081, swd: 8.5283, ept: 249.2134\n",
      "  Epoch 8 composite train-obj: 1.901629\n",
      "Epoch [8/50], Test Losses: mse: 14.6261, mae: 2.4160, huber: 1.9905, swd: 6.5174, ept: 255.4148\n",
      "Best round's Test MSE: 14.6267, MAE: 2.4161, SWD: 6.5182\n",
      "Best round's Validation MSE: 19.5211, MAE: 2.8239, SWD: 7.6682\n",
      "Best round's Test verification MSE : 14.6261, MAE: 2.4160, SWD: 6.5174\n",
      "Time taken: 91.03 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred336_20250512_1859)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.8082 ± 0.1567\n",
      "  mae: 2.4506 ± 0.0248\n",
      "  huber: 2.0232 ± 0.0233\n",
      "  swd: 6.9184 ± 0.2892\n",
      "  ept: 252.7863 ± 2.0914\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.2765 ± 0.7115\n",
      "  mae: 2.8748 ± 0.0403\n",
      "  huber: 2.4551 ± 0.0393\n",
      "  swd: 8.4100 ± 0.6720\n",
      "  ept: 234.2756 ± 1.7448\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 253.41 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred336_20250512_1859\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only', \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1075954",
   "metadata": {},
   "source": [
    "##### model I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68354348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 42.6391, mae: 3.4097, huber: 2.9854, swd: 27.8345, target_std: 20.3626\n",
      "Epoch [1/50], Val Losses: mse: 23.8987, mae: 3.1318, huber: 2.7119, swd: 9.1935, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 17.0549, mae: 2.6600, huber: 2.2297, swd: 7.2869, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.985376\n",
      "        Val objective improved inf → 2.7119, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.3312, mae: 2.6861, huber: 2.2675, swd: 10.9393, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 21.3204, mae: 2.9372, huber: 2.5178, swd: 8.6497, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 16.2145, mae: 2.5530, huber: 2.1255, swd: 7.7111, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.267506\n",
      "        Val objective improved 2.7119 → 2.5178, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.2568, mae: 2.5272, huber: 2.1116, swd: 10.0462, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 20.0786, mae: 2.8782, huber: 2.4579, swd: 8.2664, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0091, mae: 2.4630, huber: 2.0351, swd: 7.0453, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.111634\n",
      "        Val objective improved 2.5178 → 2.4579, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.4179, mae: 2.4765, huber: 2.0621, swd: 9.5545, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 20.8179, mae: 2.9302, huber: 2.5111, swd: 8.6169, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.7112, mae: 2.5044, huber: 2.0775, swd: 7.6036, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.062077\n",
      "        No improvement (2.5111), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.6359, mae: 2.4024, huber: 1.9904, swd: 9.0565, target_std: 20.3628\n",
      "Epoch [5/50], Val Losses: mse: 21.3994, mae: 2.9211, huber: 2.5075, swd: 9.2162, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.8264, mae: 2.4820, huber: 2.0579, swd: 7.8298, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.990379\n",
      "        No improvement (2.5075), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 18.1828, mae: 2.3706, huber: 1.9596, swd: 8.7425, target_std: 20.3629\n",
      "Epoch [6/50], Val Losses: mse: 23.3930, mae: 3.0323, huber: 2.6193, swd: 11.1467, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.7275, mae: 2.5591, huber: 2.1350, swd: 8.5744, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.959595\n",
      "        No improvement (2.6193), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.7806, mae: 2.3415, huber: 1.9314, swd: 8.4577, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 20.5624, mae: 2.8934, huber: 2.4810, swd: 8.6793, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.2223, mae: 2.5500, huber: 2.1234, swd: 8.2319, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.931440\n",
      "        No improvement (2.4810), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 17.2263, mae: 2.3065, huber: 1.8978, swd: 8.0325, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.8138, mae: 2.9726, huber: 2.5619, swd: 10.2041, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 16.4689, mae: 2.5605, huber: 2.1366, swd: 8.4528, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.897770\n",
      "Epoch [8/50], Test Losses: mse: 15.0094, mae: 2.4630, huber: 2.0352, swd: 7.0459, target_std: 18.3439\n",
      "Best round's Test MSE: 15.0091, MAE: 2.4630, SWD: 7.0453\n",
      "Best round's Validation MSE: 20.0786, MAE: 2.8782, SWD: 8.2664\n",
      "Best round's Test verification MSE : 15.0094, MAE: 2.4630, SWD: 7.0459\n",
      "Time taken: 81.90 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 43.3329, mae: 3.4157, huber: 2.9912, swd: 30.2929, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 24.1469, mae: 3.1390, huber: 2.7163, swd: 9.9074, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.7671, mae: 2.6289, huber: 2.1985, swd: 7.5586, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.991182\n",
      "        Val objective improved inf → 2.7163, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.5742, mae: 2.7046, huber: 2.2857, swd: 11.8421, target_std: 20.3630\n",
      "Epoch [2/50], Val Losses: mse: 21.2298, mae: 2.9225, huber: 2.5017, swd: 9.2955, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7889, mae: 2.4728, huber: 2.0438, swd: 7.1917, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.285704\n",
      "        Val objective improved 2.7163 → 2.5017, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.0905, mae: 2.4970, huber: 2.0832, swd: 10.4819, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 21.6698, mae: 2.9522, huber: 2.5340, swd: 9.4970, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.6988, mae: 2.5810, huber: 2.1537, swd: 8.9032, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.083231\n",
      "        No improvement (2.5340), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 19.2033, mae: 2.4509, huber: 2.0381, swd: 9.8400, target_std: 20.3626\n",
      "Epoch [4/50], Val Losses: mse: 21.0000, mae: 2.9553, huber: 2.5340, swd: 9.4405, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2105, mae: 2.5067, huber: 2.0757, swd: 7.6521, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.038118\n",
      "        No improvement (2.5340), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 18.3415, mae: 2.3865, huber: 1.9748, swd: 9.1908, target_std: 20.3635\n",
      "Epoch [5/50], Val Losses: mse: 23.0436, mae: 3.0419, huber: 2.6265, swd: 10.9112, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.9550, mae: 2.4813, huber: 2.0590, swd: 8.3293, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.974776\n",
      "        No improvement (2.6265), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.8134, mae: 2.3499, huber: 1.9395, swd: 8.8338, target_std: 20.3629\n",
      "Epoch [6/50], Val Losses: mse: 24.8684, mae: 3.1184, huber: 2.7041, swd: 12.8599, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.1742, mae: 2.5082, huber: 2.0861, swd: 8.4056, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.939465\n",
      "        No improvement (2.7041), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 17.1170, mae: 2.3072, huber: 1.8974, swd: 8.2806, target_std: 20.3630\n",
      "Epoch [7/50], Val Losses: mse: 24.0517, mae: 3.0591, huber: 2.6464, swd: 12.0381, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.1741, mae: 2.4738, huber: 2.0551, swd: 8.3980, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.897419\n",
      "Epoch [7/50], Test Losses: mse: 14.7889, mae: 2.4728, huber: 2.0438, swd: 7.1916, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7889, MAE: 2.4728, SWD: 7.1917\n",
      "Best round's Validation MSE: 21.2298, MAE: 2.9225, SWD: 9.2955\n",
      "Best round's Test verification MSE : 14.7889, MAE: 2.4728, SWD: 7.1916\n",
      "Time taken: 70.38 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 44.1653, mae: 3.4325, huber: 3.0075, swd: 28.9319, target_std: 20.3633\n",
      "Epoch [1/50], Val Losses: mse: 26.0954, mae: 3.2186, huber: 2.7953, swd: 10.7279, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 20.2633, mae: 2.8891, huber: 2.4565, swd: 9.9375, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.007478\n",
      "        Val objective improved inf → 2.7953, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7179, mae: 2.6236, huber: 2.2059, swd: 10.8152, target_std: 20.3631\n",
      "Epoch [2/50], Val Losses: mse: 21.7894, mae: 2.9310, huber: 2.5108, swd: 9.0574, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.8279, mae: 2.5196, huber: 2.0920, swd: 7.4374, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.205876\n",
      "        Val objective improved 2.7953 → 2.5108, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.1149, mae: 2.5128, huber: 2.0982, swd: 9.8441, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.5211, mae: 2.8239, huber: 2.4056, swd: 7.6682, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.6267, mae: 2.4161, huber: 1.9906, swd: 6.5182, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.098168\n",
      "        Val objective improved 2.5108 → 2.4056, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.2178, mae: 2.4565, huber: 2.0432, swd: 9.2232, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 20.2674, mae: 2.8807, huber: 2.4620, swd: 7.8961, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.4143, mae: 2.4799, huber: 2.0525, swd: 7.1278, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.043207\n",
      "        No improvement (2.4620), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.6524, mae: 2.4172, huber: 2.0048, swd: 8.8230, target_std: 20.3628\n",
      "Epoch [5/50], Val Losses: mse: 23.2820, mae: 3.0802, huber: 2.6623, swd: 10.3012, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.0411, mae: 2.4408, huber: 2.0168, swd: 6.9217, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.004765\n",
      "        No improvement (2.6623), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 18.0279, mae: 2.3783, huber: 1.9670, swd: 8.3329, target_std: 20.3635\n",
      "Epoch [6/50], Val Losses: mse: 25.6335, mae: 3.0997, huber: 2.6851, swd: 12.2520, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.0439, mae: 2.4946, huber: 2.0699, swd: 7.6069, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.967029\n",
      "        No improvement (2.6851), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.3891, mae: 2.3451, huber: 1.9346, swd: 7.8680, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 31.3095, mae: 3.2353, huber: 2.8205, swd: 17.0979, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.9896, mae: 2.5801, huber: 2.1560, swd: 9.3156, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.934552\n",
      "        No improvement (2.8205), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.9418, mae: 2.3112, huber: 1.9016, swd: 7.5622, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 29.4598, mae: 3.1671, huber: 2.7545, swd: 15.9688, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 17.0350, mae: 2.5308, huber: 2.1081, swd: 8.5283, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.901629\n",
      "Epoch [8/50], Test Losses: mse: 14.6261, mae: 2.4160, huber: 1.9905, swd: 6.5174, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6267, MAE: 2.4161, SWD: 6.5182\n",
      "Best round's Validation MSE: 19.5211, MAE: 2.8239, SWD: 7.6682\n",
      "Best round's Test verification MSE : 14.6261, MAE: 2.4160, SWD: 6.5174\n",
      "Time taken: 76.85 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred336_20250509_0407)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.8082 ± 0.1567\n",
      "  mae: 2.4506 ± 0.0248\n",
      "  huber: 2.0232 ± 0.0233\n",
      "  swd: 6.9184 ± 0.2892\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.2765 ± 0.7115\n",
      "  mae: 2.8748 ± 0.0403\n",
      "  huber: 2.4551 ± 0.0393\n",
      "  swd: 8.4100 ± 0.6720\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 229.24 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred336_20250509_0407\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only',\n",
    "    # single_magnitude_for_shift=True,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False,\n",
    "    \n",
    "\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU,\n",
    "                                              nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU,\n",
    "                                              nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU,\n",
    "                                              nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,\n",
    "                                              nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU,\n",
    "                                              nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7adff0",
   "metadata": {},
   "source": [
    "##### model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43ac45a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.1773, mae: 3.1092, huber: 2.6877, swd: 18.0032, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 25.6371, mae: 3.1818, huber: 2.7641, swd: 12.2080, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 18.2179, mae: 2.7053, huber: 2.2762, swd: 9.4321, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.687735\n",
      "        Val objective improved inf → 2.7641, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.5293, mae: 2.5647, huber: 2.1499, swd: 11.2345, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 20.6311, mae: 2.9047, huber: 2.4879, swd: 8.5972, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.2244, mae: 2.4586, huber: 2.0341, swd: 7.3262, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.149907\n",
      "        Val objective improved 2.7641 → 2.4879, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.0816, mae: 2.4489, huber: 2.0364, swd: 9.2658, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 19.8213, mae: 2.8773, huber: 2.4611, swd: 8.3477, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0944, mae: 2.4643, huber: 2.0409, swd: 7.4844, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.036388\n",
      "        Val objective improved 2.4879 → 2.4611, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 17.7204, mae: 2.3717, huber: 1.9607, swd: 8.3140, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 20.0718, mae: 2.8356, huber: 2.4216, swd: 8.5737, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2756, mae: 2.4493, huber: 2.0257, swd: 7.5344, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.960714\n",
      "        Val objective improved 2.4611 → 2.4216, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 16.9282, mae: 2.3114, huber: 1.9020, swd: 7.7938, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.4144, mae: 2.9091, huber: 2.4989, swd: 9.5474, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.0707, mae: 2.4923, huber: 2.0706, swd: 7.9856, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.902042\n",
      "        No improvement (2.4989), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 16.3366, mae: 2.2670, huber: 1.8588, swd: 7.4617, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.5084, mae: 2.8497, huber: 2.4392, swd: 9.3237, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5973, mae: 2.4670, huber: 2.0430, swd: 7.7100, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.858801\n",
      "        No improvement (2.4392), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 15.7130, mae: 2.2129, huber: 1.8061, swd: 7.0894, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 20.7918, mae: 2.8614, huber: 2.4538, swd: 9.0340, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.8154, mae: 2.5483, huber: 2.1260, swd: 8.5777, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.806050\n",
      "        No improvement (2.4538), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 15.2020, mae: 2.1711, huber: 1.7655, swd: 6.8167, target_std: 20.3632\n",
      "Epoch [8/50], Val Losses: mse: 20.5737, mae: 2.8468, huber: 2.4425, swd: 9.0410, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 18.0722, mae: 2.6768, huber: 2.2513, swd: 9.7667, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.765458\n",
      "        No improvement (2.4425), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 14.6051, mae: 2.1241, huber: 1.7194, swd: 6.4406, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.6965, mae: 2.9317, huber: 2.5258, swd: 9.8302, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 18.2724, mae: 2.6726, huber: 2.2505, swd: 9.7373, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 1.719437\n",
      "Epoch [9/50], Test Losses: mse: 15.2749, mae: 2.4493, huber: 2.0257, swd: 7.5339, target_std: 18.3439\n",
      "Best round's Test MSE: 15.2756, MAE: 2.4493, SWD: 7.5344\n",
      "Best round's Validation MSE: 20.0718, MAE: 2.8356, SWD: 8.5737\n",
      "Best round's Test verification MSE : 15.2749, MAE: 2.4493, SWD: 7.5339\n",
      "Time taken: 94.13 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.0657, mae: 3.0960, huber: 2.6751, swd: 18.5803, target_std: 20.3633\n",
      "Epoch [1/50], Val Losses: mse: 23.2263, mae: 3.0414, huber: 2.6251, swd: 11.1442, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.4866, mae: 2.5167, huber: 2.0903, swd: 7.7511, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.675143\n",
      "        Val objective improved inf → 2.6251, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.2164, mae: 2.5848, huber: 2.1709, swd: 12.4252, target_std: 20.3631\n",
      "Epoch [2/50], Val Losses: mse: 23.1966, mae: 3.0243, huber: 2.6072, swd: 10.9588, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 17.1806, mae: 2.5972, huber: 2.1737, swd: 9.3938, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.170908\n",
      "        Val objective improved 2.6251 → 2.6072, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.1558, mae: 2.5284, huber: 2.1160, swd: 11.6570, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 21.7188, mae: 2.9337, huber: 2.5146, swd: 10.0400, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0969, mae: 2.4668, huber: 2.0390, swd: 7.6220, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.115964\n",
      "        Val objective improved 2.6072 → 2.5146, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.4854, mae: 2.4504, huber: 2.0393, swd: 10.2353, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 21.0908, mae: 2.9072, huber: 2.4922, swd: 9.4476, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.0500, mae: 2.5165, huber: 2.0945, swd: 8.3011, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.039296\n",
      "        Val objective improved 2.5146 → 2.4922, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.5435, mae: 2.3976, huber: 1.9878, swd: 9.4361, target_std: 20.3625\n",
      "Epoch [5/50], Val Losses: mse: 20.8716, mae: 2.8978, huber: 2.4856, swd: 9.7074, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2145, mae: 2.4845, huber: 2.0619, swd: 7.7083, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.987829\n",
      "        Val objective improved 2.4922 → 2.4856, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 18.0352, mae: 2.3668, huber: 1.9582, swd: 9.0678, target_std: 20.3625\n",
      "Epoch [6/50], Val Losses: mse: 20.9004, mae: 2.8839, huber: 2.4748, swd: 9.7387, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.7204, mae: 2.3890, huber: 1.9711, swd: 7.2380, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.958230\n",
      "        Val objective improved 2.4856 → 2.4748, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 17.5655, mae: 2.3378, huber: 1.9303, swd: 8.6955, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 21.0650, mae: 2.8430, huber: 2.4358, swd: 9.7611, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.9246, mae: 2.6707, huber: 2.2451, swd: 9.9953, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.930349\n",
      "        Val objective improved 2.4748 → 2.4358, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 17.2242, mae: 2.3203, huber: 1.9133, swd: 8.4481, target_std: 20.3636\n",
      "Epoch [8/50], Val Losses: mse: 19.8141, mae: 2.8345, huber: 2.4246, swd: 8.9595, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.3603, mae: 2.5412, huber: 2.1108, swd: 7.8793, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.913310\n",
      "        Val objective improved 2.4358 → 2.4246, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 17.0709, mae: 2.3063, huber: 1.8996, swd: 8.3594, target_std: 20.3628\n",
      "Epoch [9/50], Val Losses: mse: 20.4026, mae: 2.8337, huber: 2.4269, swd: 9.0705, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 16.8284, mae: 2.6079, huber: 2.1803, swd: 8.9765, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 1.899642\n",
      "        No improvement (2.4269), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 16.6992, mae: 2.2751, huber: 1.8694, swd: 8.1125, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 20.1633, mae: 2.8186, huber: 2.4139, swd: 9.1860, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.5598, mae: 2.4483, huber: 2.0296, swd: 8.0417, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 1.869359\n",
      "        Val objective improved 2.4246 → 2.4139, saving checkpoint.\n",
      "Epoch [11/50], Train Losses: mse: 16.4849, mae: 2.2592, huber: 1.8539, swd: 7.9694, target_std: 20.3631\n",
      "Epoch [11/50], Val Losses: mse: 19.9205, mae: 2.8165, huber: 2.4101, swd: 8.8299, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 16.0720, mae: 2.4879, huber: 2.0657, swd: 8.3482, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 1.853877\n",
      "        Val objective improved 2.4139 → 2.4101, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 16.2525, mae: 2.2410, huber: 1.8358, swd: 7.8215, target_std: 20.3625\n",
      "Epoch [12/50], Val Losses: mse: 18.7154, mae: 2.7496, huber: 2.3436, swd: 7.8903, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 15.1499, mae: 2.4112, huber: 1.9919, swd: 7.5752, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 1.835758\n",
      "        Val objective improved 2.4101 → 2.3436, saving checkpoint.\n",
      "Epoch [13/50], Train Losses: mse: 16.0838, mae: 2.2304, huber: 1.8253, swd: 7.7143, target_std: 20.3629\n",
      "Epoch [13/50], Val Losses: mse: 20.2071, mae: 2.8149, huber: 2.4089, swd: 9.0229, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 17.0487, mae: 2.6046, huber: 2.1796, swd: 9.2785, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 1.825298\n",
      "        No improvement (2.4089), counter 1/5\n",
      "Epoch [14/50], Train Losses: mse: 15.8878, mae: 2.2118, huber: 1.8073, swd: 7.6165, target_std: 20.3624\n",
      "Epoch [14/50], Val Losses: mse: 20.6485, mae: 2.8518, huber: 2.4479, swd: 9.4039, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 18.0531, mae: 2.6932, huber: 2.2664, swd: 10.1095, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 1.807254\n",
      "        No improvement (2.4479), counter 2/5\n",
      "Epoch [15/50], Train Losses: mse: 15.6184, mae: 2.1906, huber: 1.7863, swd: 7.4310, target_std: 20.3630\n",
      "Epoch [15/50], Val Losses: mse: 19.7271, mae: 2.7965, huber: 2.3922, swd: 8.8240, target_std: 20.5432\n",
      "Epoch [15/50], Test Losses: mse: 16.3205, mae: 2.5351, huber: 2.1132, swd: 8.6443, target_std: 18.3439\n",
      "  Epoch 15 composite train-obj: 1.786268\n",
      "        No improvement (2.3922), counter 3/5\n",
      "Epoch [16/50], Train Losses: mse: 15.5462, mae: 2.1844, huber: 1.7801, swd: 7.4078, target_std: 20.3624\n",
      "Epoch [16/50], Val Losses: mse: 19.7269, mae: 2.7855, huber: 2.3823, swd: 8.7518, target_std: 20.5432\n",
      "Epoch [16/50], Test Losses: mse: 17.0749, mae: 2.5969, huber: 2.1726, swd: 9.2557, target_std: 18.3439\n",
      "  Epoch 16 composite train-obj: 1.780077\n",
      "        No improvement (2.3823), counter 4/5\n",
      "Epoch [17/50], Train Losses: mse: 15.3006, mae: 2.1601, huber: 1.7566, swd: 7.2325, target_std: 20.3627\n",
      "Epoch [17/50], Val Losses: mse: 20.1220, mae: 2.8229, huber: 2.4192, swd: 9.1708, target_std: 20.5432\n",
      "Epoch [17/50], Test Losses: mse: 15.6134, mae: 2.4994, huber: 2.0772, swd: 8.0041, target_std: 18.3439\n",
      "  Epoch 17 composite train-obj: 1.756650\n",
      "Epoch [17/50], Test Losses: mse: 15.1503, mae: 2.4112, huber: 1.9919, swd: 7.5754, target_std: 18.3439\n",
      "Best round's Test MSE: 15.1499, MAE: 2.4112, SWD: 7.5752\n",
      "Best round's Validation MSE: 18.7154, MAE: 2.7496, SWD: 7.8903\n",
      "Best round's Test verification MSE : 15.1503, MAE: 2.4112, SWD: 7.5754\n",
      "Time taken: 202.70 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.8010, mae: 3.1007, huber: 2.6795, swd: 18.3603, target_std: 20.3626\n",
      "Epoch [1/50], Val Losses: mse: 22.9257, mae: 2.9989, huber: 2.5834, swd: 10.1278, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.1195, mae: 2.4519, huber: 2.0266, swd: 6.8853, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.679504\n",
      "        Val objective improved inf → 2.5834, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.2145, mae: 2.5918, huber: 2.1768, swd: 11.5845, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 23.0766, mae: 2.9951, huber: 2.5793, swd: 10.3490, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3007, mae: 2.4509, huber: 2.0278, swd: 7.1487, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.176783\n",
      "        Val objective improved 2.5834 → 2.5793, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.5523, mae: 2.4989, huber: 2.0859, swd: 10.2804, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 22.0455, mae: 2.9447, huber: 2.5267, swd: 9.1753, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.7067, mae: 2.6083, huber: 2.1839, swd: 9.0045, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.085880\n",
      "        Val objective improved 2.5793 → 2.5267, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.6451, mae: 2.4024, huber: 1.9917, swd: 8.8215, target_std: 20.3633\n",
      "Epoch [4/50], Val Losses: mse: 20.0517, mae: 2.8297, huber: 2.4158, swd: 7.9397, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.1948, mae: 2.4130, huber: 1.9937, swd: 7.0540, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.991656\n",
      "        Val objective improved 2.5267 → 2.4158, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 17.4076, mae: 2.3411, huber: 1.9319, swd: 7.8070, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 20.2084, mae: 2.8144, huber: 2.4076, swd: 8.3457, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.2799, mae: 2.5437, huber: 2.1209, swd: 7.9122, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.931876\n",
      "        Val objective improved 2.4158 → 2.4076, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 16.9267, mae: 2.3020, huber: 1.8940, swd: 7.4926, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.0319, mae: 2.8295, huber: 2.4238, swd: 8.1981, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.7401, mae: 2.4864, huber: 2.0654, swd: 7.3239, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.894032\n",
      "        No improvement (2.4238), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 16.3164, mae: 2.2554, huber: 1.8486, swd: 7.1714, target_std: 20.3628\n",
      "Epoch [7/50], Val Losses: mse: 20.0893, mae: 2.8198, huber: 2.4166, swd: 8.5247, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.0484, mae: 2.6082, huber: 2.1853, swd: 8.5662, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.848572\n",
      "        No improvement (2.4166), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 15.8428, mae: 2.2092, huber: 1.8037, swd: 6.9163, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 20.6508, mae: 2.8508, huber: 2.4476, swd: 8.8422, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 17.8413, mae: 2.6546, huber: 2.2318, swd: 9.1168, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.803716\n",
      "        No improvement (2.4476), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 15.3562, mae: 2.1724, huber: 1.7675, swd: 6.6141, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.4282, mae: 2.8902, huber: 2.4856, swd: 9.3662, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 17.2138, mae: 2.6127, huber: 2.1910, swd: 8.6708, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 1.767458\n",
      "        No improvement (2.4856), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 15.0314, mae: 2.1402, huber: 1.7361, swd: 6.4359, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 20.7578, mae: 2.8497, huber: 2.4454, swd: 8.9331, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 17.3851, mae: 2.6147, huber: 2.1918, swd: 8.7987, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 1.736091\n",
      "Epoch [10/50], Test Losses: mse: 16.2797, mae: 2.5436, huber: 2.1209, swd: 7.9121, target_std: 18.3439\n",
      "Best round's Test MSE: 16.2799, MAE: 2.5437, SWD: 7.9122\n",
      "Best round's Validation MSE: 20.2084, MAE: 2.8144, SWD: 8.3457\n",
      "Best round's Test verification MSE : 16.2797, MAE: 2.5436, SWD: 7.9121\n",
      "Time taken: 110.24 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred336_20250509_0411)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.5685 ± 0.5057\n",
      "  mae: 2.4681 ± 0.0557\n",
      "  huber: 2.0462 ± 0.0546\n",
      "  swd: 7.6739 ± 0.1693\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.6652 ± 0.6739\n",
      "  mae: 2.7999 ± 0.0366\n",
      "  huber: 2.3909 ± 0.0340\n",
      "  swd: 8.2699 ± 0.2841\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 407.18 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred336_20250509_0411\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=True,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only',\n",
    "    # single_magnitude_for_shift=True,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=True, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,  nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741d276",
   "metadata": {},
   "source": [
    "##### model III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2400ef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 41.7774, mae: 3.3723, huber: 2.9479, swd: 27.4229, target_std: 20.3625\n",
      "Epoch [1/50], Val Losses: mse: 23.2774, mae: 3.0707, huber: 2.6497, swd: 9.2939, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 17.3442, mae: 2.6652, huber: 2.2356, swd: 8.1506, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.947933\n",
      "        Val objective improved inf → 2.6497, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.0962, mae: 2.5813, huber: 2.1644, swd: 10.5983, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 19.8046, mae: 2.8518, huber: 2.4344, swd: 8.1053, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.6286, mae: 2.4428, huber: 2.0163, swd: 6.8071, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.164437\n",
      "        Val objective improved 2.6497 → 2.4344, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.5982, mae: 2.4697, huber: 2.0559, swd: 9.6695, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 19.8116, mae: 2.8297, huber: 2.4136, swd: 8.4447, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.4304, mae: 2.4033, huber: 1.9788, swd: 6.6444, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.055902\n",
      "        Val objective improved 2.4344 → 2.4136, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.9152, mae: 2.4290, huber: 2.0163, swd: 9.2487, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 20.3827, mae: 2.8784, huber: 2.4590, swd: 8.6509, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.5412, mae: 2.4621, huber: 2.0393, swd: 7.4371, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.016271\n",
      "        No improvement (2.4590), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.0046, mae: 2.3589, huber: 1.9474, swd: 8.5793, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.6345, mae: 2.9524, huber: 2.5328, swd: 9.3626, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.0800, mae: 2.6004, huber: 2.1740, swd: 8.7941, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.947407\n",
      "        No improvement (2.5328), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.5411, mae: 2.3326, huber: 1.9219, swd: 8.2527, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 20.7012, mae: 2.8726, huber: 2.4595, swd: 8.9280, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.7106, mae: 2.5470, huber: 2.1256, swd: 8.5041, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.921908\n",
      "        No improvement (2.4595), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.8826, mae: 2.2947, huber: 1.8856, swd: 7.7383, target_std: 20.3627\n",
      "Epoch [7/50], Val Losses: mse: 21.6555, mae: 2.9216, huber: 2.5103, swd: 9.6555, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.7940, mae: 2.5771, huber: 2.1517, swd: 8.5676, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.885589\n",
      "        No improvement (2.5103), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4449, mae: 2.2691, huber: 1.8606, swd: 7.4203, target_std: 20.3635\n",
      "Epoch [8/50], Val Losses: mse: 22.9053, mae: 2.9886, huber: 2.5781, swd: 10.7966, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 18.7542, mae: 2.7380, huber: 2.3119, swd: 10.2661, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.860605\n",
      "Epoch [8/50], Test Losses: mse: 14.4302, mae: 2.4033, huber: 1.9788, swd: 6.6443, target_std: 18.3439\n",
      "Best round's Test MSE: 14.4304, MAE: 2.4033, SWD: 6.6444\n",
      "Best round's Validation MSE: 19.8116, MAE: 2.8297, SWD: 8.4447\n",
      "Best round's Test verification MSE : 14.4302, MAE: 2.4033, SWD: 6.6443\n",
      "Time taken: 99.75 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 42.8665, mae: 3.4190, huber: 2.9944, swd: 29.9140, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 24.9674, mae: 3.2145, huber: 2.7925, swd: 11.7357, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.9993, mae: 2.6592, huber: 2.2299, swd: 8.4444, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.994354\n",
      "        Val objective improved inf → 2.7925, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.9614, mae: 2.6341, huber: 2.2166, swd: 11.7114, target_std: 20.3631\n",
      "Epoch [2/50], Val Losses: mse: 20.9763, mae: 2.9470, huber: 2.5257, swd: 9.5727, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.8040, mae: 2.5100, huber: 2.0771, swd: 7.5162, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.216636\n",
      "        Val objective improved 2.7925 → 2.5257, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.3002, mae: 2.5187, huber: 2.1040, swd: 10.6834, target_std: 20.3629\n",
      "Epoch [3/50], Val Losses: mse: 20.1496, mae: 2.8717, huber: 2.4517, swd: 8.6125, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.4627, mae: 2.4178, huber: 1.9909, swd: 7.1150, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.103984\n",
      "        Val objective improved 2.5257 → 2.4517, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.2062, mae: 2.4387, huber: 2.0264, swd: 9.7876, target_std: 20.3632\n",
      "Epoch [4/50], Val Losses: mse: 21.2726, mae: 2.9585, huber: 2.5382, swd: 9.1697, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.9520, mae: 2.5191, huber: 2.0941, swd: 8.1852, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.026404\n",
      "        No improvement (2.5382), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.6195, mae: 2.4063, huber: 1.9948, swd: 9.4094, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 21.1943, mae: 2.9562, huber: 2.5408, swd: 9.4106, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.6087, mae: 2.4851, huber: 2.0623, swd: 7.9196, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.994819\n",
      "        No improvement (2.5408), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 18.2572, mae: 2.3818, huber: 1.9711, swd: 9.2543, target_std: 20.3629\n",
      "Epoch [6/50], Val Losses: mse: 23.4354, mae: 3.0535, huber: 2.6392, swd: 11.1071, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.3440, mae: 2.6024, huber: 2.1807, swd: 9.4634, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.971067\n",
      "        No improvement (2.6392), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.7918, mae: 2.3394, huber: 1.9302, swd: 8.9065, target_std: 20.3628\n",
      "Epoch [7/50], Val Losses: mse: 22.6052, mae: 3.0025, huber: 2.5894, swd: 10.5744, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.9337, mae: 2.5870, huber: 2.1646, swd: 9.1065, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.930215\n",
      "        No improvement (2.5894), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 17.5085, mae: 2.3205, huber: 1.9121, swd: 8.7123, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 20.9557, mae: 2.8973, huber: 2.4871, swd: 9.5432, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.8106, mae: 2.5095, huber: 2.0858, swd: 8.1435, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.912118\n",
      "Epoch [8/50], Test Losses: mse: 14.4627, mae: 2.4178, huber: 1.9909, swd: 7.1150, target_std: 18.3439\n",
      "Best round's Test MSE: 14.4627, MAE: 2.4178, SWD: 7.1150\n",
      "Best round's Validation MSE: 20.1496, MAE: 2.8717, SWD: 8.6125\n",
      "Best round's Test verification MSE : 14.4627, MAE: 2.4178, SWD: 7.1150\n",
      "Time taken: 100.66 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 44.1872, mae: 3.4514, huber: 3.0264, swd: 29.0855, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 24.5858, mae: 3.1893, huber: 2.7677, swd: 10.4102, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.9016, mae: 2.6390, huber: 2.2098, swd: 7.5710, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.026448\n",
      "        Val objective improved inf → 2.7677, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.8694, mae: 2.6378, huber: 2.2198, swd: 10.8220, target_std: 20.3625\n",
      "Epoch [2/50], Val Losses: mse: 20.5171, mae: 2.8935, huber: 2.4754, swd: 8.1175, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0694, mae: 2.4698, huber: 2.0440, swd: 6.8164, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.219821\n",
      "        Val objective improved 2.7677 → 2.4754, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.4604, mae: 2.5307, huber: 2.1155, swd: 10.1107, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 20.2580, mae: 2.8648, huber: 2.4491, swd: 8.1000, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.9940, mae: 2.4247, huber: 2.0010, swd: 6.8491, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.115483\n",
      "        Val objective improved 2.4754 → 2.4491, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.6440, mae: 2.4771, huber: 2.0640, swd: 9.5751, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.9274, mae: 2.8365, huber: 2.4200, swd: 8.0741, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.5271, mae: 2.3974, huber: 1.9747, swd: 6.5656, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.063991\n",
      "        Val objective improved 2.4491 → 2.4200, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.9405, mae: 2.4213, huber: 2.0095, swd: 9.1122, target_std: 20.3628\n",
      "Epoch [5/50], Val Losses: mse: 19.9263, mae: 2.8836, huber: 2.4660, swd: 7.9791, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.7922, mae: 2.4332, huber: 2.0101, swd: 6.6390, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.009462\n",
      "        No improvement (2.4660), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 18.3320, mae: 2.3827, huber: 1.9716, swd: 8.6549, target_std: 20.3629\n",
      "Epoch [6/50], Val Losses: mse: 21.0345, mae: 2.9468, huber: 2.5317, swd: 8.8030, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.0406, mae: 2.4554, huber: 2.0323, swd: 6.9025, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.971582\n",
      "        No improvement (2.5317), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.8917, mae: 2.3552, huber: 1.9453, swd: 8.3509, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 21.6461, mae: 2.9319, huber: 2.5195, swd: 9.0528, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.4760, mae: 2.6231, huber: 2.1983, swd: 8.7541, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.945256\n",
      "        No improvement (2.5195), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 17.3303, mae: 2.3191, huber: 1.9101, swd: 7.9585, target_std: 20.3627\n",
      "Epoch [8/50], Val Losses: mse: 22.1773, mae: 2.9460, huber: 2.5343, swd: 9.9241, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 16.7749, mae: 2.5427, huber: 2.1177, swd: 8.4248, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.910068\n",
      "        No improvement (2.5343), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.9487, mae: 2.3059, huber: 1.8970, swd: 7.6940, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 20.4775, mae: 2.8325, huber: 2.4274, swd: 8.6855, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 16.6234, mae: 2.5310, huber: 2.1104, swd: 8.1902, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 1.897014\n",
      "Epoch [9/50], Test Losses: mse: 14.5271, mae: 2.3974, huber: 1.9747, swd: 6.5655, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5271, MAE: 2.3974, SWD: 6.5656\n",
      "Best round's Validation MSE: 19.9274, MAE: 2.8365, SWD: 8.0741\n",
      "Best round's Test verification MSE : 14.5271, MAE: 2.3974, SWD: 6.5655\n",
      "Time taken: 112.18 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred336_20250509_0418)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.4734 ± 0.0402\n",
      "  mae: 2.4061 ± 0.0086\n",
      "  huber: 1.9815 ± 0.0069\n",
      "  swd: 6.7750 ± 0.2426\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.9629 ± 0.1403\n",
      "  mae: 2.8460 ± 0.0184\n",
      "  huber: 2.4284 ± 0.0167\n",
      "  swd: 8.3771 ± 0.2249\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 312.68 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred336_20250509_0418\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 4,\n",
    "    householder_reflects_data = 8,\n",
    "    mixing_strategy='delay_only',\n",
    "    # single_magnitude_for_shift=True,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU,  nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf0a46",
   "metadata": {},
   "source": [
    "#### pred=720"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74148d",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b7e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "global_std.shape: torch.Size([7])\n",
      "Global Std for ettm2: tensor([10.2434,  6.0312, 13.0618,  4.3690,  6.1544,  6.0135, 11.8865],\n",
      "       device='cuda:0')\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 373\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 373\n",
      "Validation Batches: 47\n",
      "Test Batches: 101\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 49.1809, mae: 3.7493, huber: 3.3193, swd: 30.7613, ept: 409.0927\n",
      "Epoch [1/50], Val Losses: mse: 28.4035, mae: 3.5223, huber: 3.0908, swd: 9.5849, ept: 356.2176\n",
      "Epoch [1/50], Test Losses: mse: 20.8011, mae: 2.9916, huber: 2.5549, swd: 8.8240, ept: 404.1009\n",
      "  Epoch 1 composite train-obj: 3.319287\n",
      "        Val objective improved inf → 3.0908, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.0691, mae: 3.0443, huber: 2.6192, swd: 13.6033, ept: 452.5389\n",
      "Epoch [2/50], Val Losses: mse: 27.4798, mae: 3.5388, huber: 3.1082, swd: 12.6940, ept: 376.8425\n",
      "Epoch [2/50], Test Losses: mse: 19.0950, mae: 2.9409, huber: 2.5017, swd: 9.9787, ept: 438.9919\n",
      "  Epoch 2 composite train-obj: 2.619216\n",
      "        No improvement (3.1082), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 26.7573, mae: 2.8642, huber: 2.4428, swd: 12.4885, ept: 480.2651\n",
      "Epoch [3/50], Val Losses: mse: 23.8988, mae: 3.1982, huber: 2.7722, swd: 8.5140, ept: 398.1553\n",
      "Epoch [3/50], Test Losses: mse: 17.2784, mae: 2.6807, huber: 2.2478, swd: 7.6831, ept: 443.2201\n",
      "  Epoch 3 composite train-obj: 2.442825\n",
      "        Val objective improved 3.0908 → 2.7722, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 25.9441, mae: 2.8022, huber: 2.3825, swd: 11.9307, ept: 487.3051\n",
      "Epoch [4/50], Val Losses: mse: 24.3645, mae: 3.2876, huber: 2.8603, swd: 8.6405, ept: 395.2358\n",
      "Epoch [4/50], Test Losses: mse: 17.2341, mae: 2.7047, huber: 2.2718, swd: 7.5298, ept: 439.0029\n",
      "  Epoch 4 composite train-obj: 2.382470\n",
      "        No improvement (2.8603), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 25.5755, mae: 2.7778, huber: 2.3586, swd: 11.7222, ept: 488.8580\n",
      "Epoch [5/50], Val Losses: mse: 24.4487, mae: 3.2918, huber: 2.8632, swd: 8.4555, ept: 392.4734\n",
      "Epoch [5/50], Test Losses: mse: 17.6053, mae: 2.6954, huber: 2.2648, swd: 7.9224, ept: 437.8445\n",
      "  Epoch 5 composite train-obj: 2.358592\n",
      "        No improvement (2.8632), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 24.9223, mae: 2.7206, huber: 2.3022, swd: 11.2113, ept: 492.7715\n",
      "Epoch [6/50], Val Losses: mse: 24.3570, mae: 3.2369, huber: 2.8106, swd: 8.5132, ept: 392.1237\n",
      "Epoch [6/50], Test Losses: mse: 18.0365, mae: 2.7332, huber: 2.3014, swd: 8.3659, ept: 436.2550\n",
      "  Epoch 6 composite train-obj: 2.302223\n",
      "        No improvement (2.8106), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 24.5325, mae: 2.6926, huber: 2.2748, swd: 10.9399, ept: 494.3434\n",
      "Epoch [7/50], Val Losses: mse: 23.8307, mae: 3.1940, huber: 2.7696, swd: 7.9287, ept: 392.6303\n",
      "Epoch [7/50], Test Losses: mse: 18.4040, mae: 2.7153, huber: 2.2879, swd: 8.7680, ept: 427.7607\n",
      "  Epoch 7 composite train-obj: 2.274752\n",
      "        Val objective improved 2.7722 → 2.7696, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 24.1785, mae: 2.6690, huber: 2.2517, swd: 10.6942, ept: 495.4636\n",
      "Epoch [8/50], Val Losses: mse: 24.1875, mae: 3.2720, huber: 2.8472, swd: 8.9223, ept: 398.8476\n",
      "Epoch [8/50], Test Losses: mse: 17.5901, mae: 2.7565, huber: 2.3236, swd: 8.2512, ept: 442.0008\n",
      "  Epoch 8 composite train-obj: 2.251739\n",
      "        No improvement (2.8472), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 23.7480, mae: 2.6335, huber: 2.2174, swd: 10.4059, ept: 497.7560\n",
      "Epoch [9/50], Val Losses: mse: 23.6980, mae: 3.1827, huber: 2.7581, swd: 8.2856, ept: 398.4711\n",
      "Epoch [9/50], Test Losses: mse: 17.9814, mae: 2.7222, huber: 2.2930, swd: 8.5157, ept: 440.6592\n",
      "  Epoch 9 composite train-obj: 2.217447\n",
      "        Val objective improved 2.7696 → 2.7581, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 23.4024, mae: 2.6087, huber: 2.1935, swd: 10.1609, ept: 499.6285\n",
      "Epoch [10/50], Val Losses: mse: 24.4543, mae: 3.2228, huber: 2.7979, swd: 8.9559, ept: 399.5035\n",
      "Epoch [10/50], Test Losses: mse: 18.0070, mae: 2.7605, huber: 2.3276, swd: 8.5260, ept: 439.9624\n",
      "  Epoch 10 composite train-obj: 2.193471\n",
      "        No improvement (2.7979), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 23.0520, mae: 2.5865, huber: 2.1718, swd: 9.9321, ept: 501.2360\n",
      "Epoch [11/50], Val Losses: mse: 23.3598, mae: 3.1439, huber: 2.7226, swd: 8.1684, ept: 403.4491\n",
      "Epoch [11/50], Test Losses: mse: 18.2883, mae: 2.7743, huber: 2.3424, swd: 8.7497, ept: 438.0477\n",
      "  Epoch 11 composite train-obj: 2.171781\n",
      "        Val objective improved 2.7581 → 2.7226, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 22.8001, mae: 2.5681, huber: 2.1538, swd: 9.8249, ept: 502.5856\n",
      "Epoch [12/50], Val Losses: mse: 23.7180, mae: 3.1919, huber: 2.7714, swd: 8.4984, ept: 404.6365\n",
      "Epoch [12/50], Test Losses: mse: 18.2416, mae: 2.7847, huber: 2.3528, swd: 8.7449, ept: 440.4317\n",
      "  Epoch 12 composite train-obj: 2.153773\n",
      "        No improvement (2.7714), counter 1/5\n",
      "Epoch [13/50], Train Losses: mse: 22.5125, mae: 2.5470, huber: 2.1332, swd: 9.6586, ept: 504.4391\n",
      "Epoch [13/50], Val Losses: mse: 24.5535, mae: 3.2003, huber: 2.7817, swd: 8.8117, ept: 398.4192\n",
      "Epoch [13/50], Test Losses: mse: 19.0600, mae: 2.8076, huber: 2.3781, swd: 9.2131, ept: 434.1331\n",
      "  Epoch 13 composite train-obj: 2.133207\n",
      "        No improvement (2.7817), counter 2/5\n",
      "Epoch [14/50], Train Losses: mse: 22.1574, mae: 2.5205, huber: 2.1073, swd: 9.4610, ept: 506.1032\n",
      "Epoch [14/50], Val Losses: mse: 24.5749, mae: 3.2264, huber: 2.8055, swd: 9.0878, ept: 397.3547\n",
      "Epoch [14/50], Test Losses: mse: 18.6300, mae: 2.8463, huber: 2.4094, swd: 9.0134, ept: 440.7208\n",
      "  Epoch 14 composite train-obj: 2.107287\n",
      "        No improvement (2.8055), counter 3/5\n",
      "Epoch [15/50], Train Losses: mse: 21.8711, mae: 2.5050, huber: 2.0920, swd: 9.3233, ept: 507.0622\n",
      "Epoch [15/50], Val Losses: mse: 25.4319, mae: 3.2563, huber: 2.8379, swd: 9.6032, ept: 393.1024\n",
      "Epoch [15/50], Test Losses: mse: 19.2345, mae: 2.8232, huber: 2.3933, swd: 9.3654, ept: 431.9015\n",
      "  Epoch 15 composite train-obj: 2.092036\n",
      "        No improvement (2.8379), counter 4/5\n",
      "Epoch [16/50], Train Losses: mse: 21.2723, mae: 2.4586, huber: 2.0468, swd: 8.9443, ept: 510.4389\n",
      "Epoch [16/50], Val Losses: mse: 26.2707, mae: 3.2954, huber: 2.8756, swd: 9.9270, ept: 389.1783\n",
      "Epoch [16/50], Test Losses: mse: 20.8110, mae: 2.9227, huber: 2.4915, swd: 10.5859, ept: 422.6785\n",
      "  Epoch 16 composite train-obj: 2.046772\n",
      "Epoch [16/50], Test Losses: mse: 18.2885, mae: 2.7743, huber: 2.3424, swd: 8.7499, ept: 438.0678\n",
      "Best round's Test MSE: 18.2883, MAE: 2.7743, SWD: 8.7497\n",
      "Best round's Validation MSE: 23.3598, MAE: 3.1439, SWD: 8.1684\n",
      "Best round's Test verification MSE : 18.2885, MAE: 2.7743, SWD: 8.7499\n",
      "Time taken: 201.44 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 49.4814, mae: 3.7607, huber: 3.3309, swd: 28.8551, ept: 409.7345\n",
      "Epoch [1/50], Val Losses: mse: 27.6836, mae: 3.4840, huber: 3.0536, swd: 8.5631, ept: 365.6170\n",
      "Epoch [1/50], Test Losses: mse: 19.8255, mae: 2.9116, huber: 2.4765, swd: 7.6373, ept: 413.6100\n",
      "  Epoch 1 composite train-obj: 3.330872\n",
      "        Val objective improved inf → 3.0536, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 28.6441, mae: 3.0130, huber: 2.5885, swd: 12.3324, ept: 456.7516\n",
      "Epoch [2/50], Val Losses: mse: 24.2083, mae: 3.2513, huber: 2.8264, swd: 7.7348, ept: 390.2680\n",
      "Epoch [2/50], Test Losses: mse: 17.5194, mae: 2.7093, huber: 2.2780, swd: 7.2319, ept: 439.0833\n",
      "  Epoch 2 composite train-obj: 2.588500\n",
      "        Val objective improved 3.0536 → 2.8264, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.4560, mae: 2.8445, huber: 2.4232, swd: 11.3300, ept: 482.5943\n",
      "Epoch [3/50], Val Losses: mse: 25.8292, mae: 3.2919, huber: 2.8639, swd: 8.6371, ept: 391.7136\n",
      "Epoch [3/50], Test Losses: mse: 20.2202, mae: 2.8644, huber: 2.4328, swd: 9.2475, ept: 421.8082\n",
      "  Epoch 3 composite train-obj: 2.423228\n",
      "        No improvement (2.8639), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 25.6384, mae: 2.7837, huber: 2.3636, swd: 10.8609, ept: 487.8713\n",
      "Epoch [4/50], Val Losses: mse: 26.2162, mae: 3.3273, huber: 2.8997, swd: 8.8068, ept: 385.1800\n",
      "Epoch [4/50], Test Losses: mse: 20.6328, mae: 2.9218, huber: 2.4873, swd: 9.5702, ept: 417.1417\n",
      "  Epoch 4 composite train-obj: 2.363588\n",
      "        No improvement (2.8997), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 25.1550, mae: 2.7458, huber: 2.3273, swd: 10.5583, ept: 490.5604\n",
      "Epoch [5/50], Val Losses: mse: 25.0454, mae: 3.2849, huber: 2.8615, swd: 8.2691, ept: 390.8735\n",
      "Epoch [5/50], Test Losses: mse: 18.2719, mae: 2.7534, huber: 2.3222, swd: 7.8297, ept: 429.9813\n",
      "  Epoch 5 composite train-obj: 2.327286\n",
      "        No improvement (2.8615), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 24.5218, mae: 2.6893, huber: 2.2720, swd: 10.0871, ept: 494.9698\n",
      "Epoch [6/50], Val Losses: mse: 25.6259, mae: 3.3001, huber: 2.8794, swd: 8.7812, ept: 390.3215\n",
      "Epoch [6/50], Test Losses: mse: 19.5138, mae: 2.8929, huber: 2.4576, swd: 8.7187, ept: 428.1136\n",
      "  Epoch 6 composite train-obj: 2.271988\n",
      "        No improvement (2.8794), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 24.3189, mae: 2.6769, huber: 2.2598, swd: 9.9749, ept: 495.2480\n",
      "Epoch [7/50], Val Losses: mse: 26.8650, mae: 3.3788, huber: 2.9566, swd: 9.5010, ept: 380.8586\n",
      "Epoch [7/50], Test Losses: mse: 21.1871, mae: 2.9798, huber: 2.5472, swd: 10.1610, ept: 412.5463\n",
      "  Epoch 7 composite train-obj: 2.259755\n",
      "Epoch [7/50], Test Losses: mse: 17.5203, mae: 2.7093, huber: 2.2780, swd: 7.2326, ept: 439.0260\n",
      "Best round's Test MSE: 17.5194, MAE: 2.7093, SWD: 7.2319\n",
      "Best round's Validation MSE: 24.2083, MAE: 3.2513, SWD: 7.7348\n",
      "Best round's Test verification MSE : 17.5203, MAE: 2.7093, SWD: 7.2326\n",
      "Time taken: 92.83 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 48.8646, mae: 3.7170, huber: 3.2871, swd: 31.1394, ept: 412.8021\n",
      "Epoch [1/50], Val Losses: mse: 27.4530, mae: 3.4692, huber: 3.0389, swd: 9.7796, ept: 370.6133\n",
      "Epoch [1/50], Test Losses: mse: 19.6687, mae: 2.8851, huber: 2.4507, swd: 8.5290, ept: 418.2892\n",
      "  Epoch 1 composite train-obj: 3.287068\n",
      "        Val objective improved inf → 3.0389, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.0418, mae: 3.0444, huber: 2.6195, swd: 14.2804, ept: 449.3308\n",
      "Epoch [2/50], Val Losses: mse: 25.4289, mae: 3.3028, huber: 2.8733, swd: 8.8712, ept: 376.0683\n",
      "Epoch [2/50], Test Losses: mse: 19.8616, mae: 2.8913, huber: 2.4540, swd: 9.6231, ept: 410.0332\n",
      "  Epoch 2 composite train-obj: 2.619459\n",
      "        Val objective improved 3.0389 → 2.8733, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.6011, mae: 2.8528, huber: 2.4314, swd: 12.8644, ept: 477.4154\n",
      "Epoch [3/50], Val Losses: mse: 23.9406, mae: 3.2395, huber: 2.8081, swd: 8.6494, ept: 397.4510\n",
      "Epoch [3/50], Test Losses: mse: 17.3183, mae: 2.7069, huber: 2.2731, swd: 8.0828, ept: 435.3105\n",
      "  Epoch 3 composite train-obj: 2.431368\n",
      "        Val objective improved 2.8733 → 2.8081, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 25.7858, mae: 2.7911, huber: 2.3711, swd: 12.4261, ept: 488.5686\n",
      "Epoch [4/50], Val Losses: mse: 24.4408, mae: 3.3064, huber: 2.8747, swd: 8.8332, ept: 394.8221\n",
      "Epoch [4/50], Test Losses: mse: 17.6468, mae: 2.7551, huber: 2.3206, swd: 8.2719, ept: 431.6897\n",
      "  Epoch 4 composite train-obj: 2.371089\n",
      "        No improvement (2.8747), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 25.1249, mae: 2.7423, huber: 2.3233, swd: 11.9426, ept: 491.9817\n",
      "Epoch [5/50], Val Losses: mse: 26.3287, mae: 3.3504, huber: 2.9203, swd: 9.9313, ept: 383.4503\n",
      "Epoch [5/50], Test Losses: mse: 21.4062, mae: 2.9926, huber: 2.5569, swd: 11.5963, ept: 411.2974\n",
      "  Epoch 5 composite train-obj: 2.323306\n",
      "        No improvement (2.9203), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 24.6142, mae: 2.6970, huber: 2.2791, swd: 11.5569, ept: 494.8759\n",
      "Epoch [6/50], Val Losses: mse: 24.0732, mae: 3.2144, huber: 2.7872, swd: 8.5132, ept: 395.4207\n",
      "Epoch [6/50], Test Losses: mse: 18.2944, mae: 2.7530, huber: 2.3202, swd: 8.9617, ept: 433.0331\n",
      "  Epoch 6 composite train-obj: 2.279122\n",
      "        Val objective improved 2.8081 → 2.7872, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 24.2906, mae: 2.6714, huber: 2.2543, swd: 11.3602, ept: 496.8038\n",
      "Epoch [7/50], Val Losses: mse: 23.7171, mae: 3.2110, huber: 2.7873, swd: 8.6725, ept: 400.2162\n",
      "Epoch [7/50], Test Losses: mse: 17.7146, mae: 2.7437, huber: 2.3119, swd: 8.5473, ept: 438.6507\n",
      "  Epoch 7 composite train-obj: 2.254305\n",
      "        No improvement (2.7873), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 23.8344, mae: 2.6370, huber: 2.2208, swd: 11.0167, ept: 498.7671\n",
      "Epoch [8/50], Val Losses: mse: 24.3460, mae: 3.2018, huber: 2.7820, swd: 9.1379, ept: 399.9240\n",
      "Epoch [8/50], Test Losses: mse: 19.0523, mae: 2.8040, huber: 2.3764, swd: 9.7013, ept: 429.4266\n",
      "  Epoch 8 composite train-obj: 2.220820\n",
      "        Val objective improved 2.7872 → 2.7820, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 23.4591, mae: 2.6139, huber: 2.1982, swd: 10.7655, ept: 501.0228\n",
      "Epoch [9/50], Val Losses: mse: 24.0928, mae: 3.2033, huber: 2.7851, swd: 8.9903, ept: 398.2494\n",
      "Epoch [9/50], Test Losses: mse: 17.9374, mae: 2.7196, huber: 2.2923, swd: 8.7390, ept: 430.8620\n",
      "  Epoch 9 composite train-obj: 2.198221\n",
      "        No improvement (2.7851), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 23.3906, mae: 2.6137, huber: 2.1981, swd: 10.7718, ept: 500.9653\n",
      "Epoch [10/50], Val Losses: mse: 25.0278, mae: 3.2134, huber: 2.7970, swd: 9.6362, ept: 401.7890\n",
      "Epoch [10/50], Test Losses: mse: 19.0858, mae: 2.7742, huber: 2.3479, swd: 9.6567, ept: 431.6361\n",
      "  Epoch 10 composite train-obj: 2.198054\n",
      "        No improvement (2.7970), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 22.9614, mae: 2.5803, huber: 2.1656, swd: 10.5165, ept: 503.6075\n",
      "Epoch [11/50], Val Losses: mse: 24.4831, mae: 3.2076, huber: 2.7922, swd: 9.4623, ept: 401.9801\n",
      "Epoch [11/50], Test Losses: mse: 18.5199, mae: 2.7782, huber: 2.3507, swd: 9.2451, ept: 428.0688\n",
      "  Epoch 11 composite train-obj: 2.165645\n",
      "        No improvement (2.7922), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 22.4290, mae: 2.5374, huber: 2.1241, swd: 10.1352, ept: 506.4275\n",
      "Epoch [12/50], Val Losses: mse: 25.6603, mae: 3.2699, huber: 2.8540, swd: 10.5547, ept: 401.9519\n",
      "Epoch [12/50], Test Losses: mse: 18.1060, mae: 2.7460, huber: 2.3180, swd: 8.8597, ept: 438.4795\n",
      "  Epoch 12 composite train-obj: 2.124056\n",
      "        No improvement (2.8540), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 22.1749, mae: 2.5252, huber: 2.1119, swd: 10.0024, ept: 506.5200\n",
      "Epoch [13/50], Val Losses: mse: 25.6736, mae: 3.2611, huber: 2.8448, swd: 10.2387, ept: 395.9237\n",
      "Epoch [13/50], Test Losses: mse: 19.6942, mae: 2.8728, huber: 2.4406, swd: 10.2161, ept: 426.4651\n",
      "  Epoch 13 composite train-obj: 2.111937\n",
      "Epoch [13/50], Test Losses: mse: 19.0521, mae: 2.8040, huber: 2.3764, swd: 9.7009, ept: 429.4137\n",
      "Best round's Test MSE: 19.0523, MAE: 2.8040, SWD: 9.7013\n",
      "Best round's Validation MSE: 24.3460, MAE: 3.2018, SWD: 9.1379\n",
      "Best round's Test verification MSE : 19.0521, MAE: 2.8040, SWD: 9.7009\n",
      "Time taken: 170.85 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred720_20250512_1903)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 18.2867 ± 0.6258\n",
      "  mae: 2.7625 ± 0.0396\n",
      "  huber: 2.3322 ± 0.0408\n",
      "  swd: 8.5610 ± 1.0169\n",
      "  ept: 435.5192 ± 4.3288\n",
      "  count: 47.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 23.9714 ± 0.4361\n",
      "  mae: 3.1990 ± 0.0439\n",
      "  huber: 2.7770 ± 0.0425\n",
      "  swd: 8.3471 ± 0.5866\n",
      "  ept: 397.8803 ± 5.5718\n",
      "  count: 47.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 465.23 seconds\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred720_20250512_1903\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "from monotonic import DynamicTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config) \n",
    "cfg = train_config.FlatACLConfig(  # original householder \n",
    "    seq_len=336,\n",
    "    pred_len=720,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128, \n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=True, \n",
    "    ablate_shift_inside_scale=False,\n",
    "    householder_reflects_latent = 2,\n",
    "    householder_reflects_data = 4,\n",
    "    mixing_strategy='delay_only', \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    ablate_deterministic_y0=False, \n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_delay.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_delay.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_delay.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_delay.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_scale_shift = [True, False]\n",
    "cfg.x_to_z_deri.spectral_flags_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.x_to_z_deri.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.x_to_z_deri.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_x_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_x_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_x_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_push_to_z.enable_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_push_to_z.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_push_to_z.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_push_to_z.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_push_to_z.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_scale_shift = [True, False]\n",
    "cfg.z_to_y_main.spectral_flags_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.spectral_flags_hidden_layers = [False, False]\n",
    "cfg.z_to_y_main.activations_scale_shift = [\"relu6\", \"dynamic_tanh\"]\n",
    "cfg.z_to_y_main.activations_hidden_layers = [nn.ELU, nn.LogSigmoid]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b71b9ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 373\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 373\n",
      "Validation Batches: 47\n",
      "Test Batches: 101\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 54.7940, mae: 3.9060, huber: 3.4764, swd: 36.3485, target_std: 20.3716\n",
      "Epoch [1/50], Val Losses: mse: 27.4639, mae: 3.4771, huber: 3.0505, swd: 9.8745, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 19.1577, mae: 2.8692, huber: 2.4338, swd: 7.9000, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 3.476373\n",
      "        Val objective improved inf → 3.0505, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 28.4906, mae: 2.9757, huber: 2.5525, swd: 13.5281, target_std: 20.3712\n",
      "Epoch [2/50], Val Losses: mse: 24.0537, mae: 3.2261, huber: 2.8024, swd: 8.3951, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.5681, mae: 2.6809, huber: 2.2520, swd: 7.8072, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.552541\n",
      "        Val objective improved 3.0505 → 2.8024, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 27.3862, mae: 2.8965, huber: 2.4746, swd: 12.9898, target_std: 20.3714\n",
      "Epoch [3/50], Val Losses: mse: 24.4882, mae: 3.2429, huber: 2.8181, swd: 9.2201, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.2227, mae: 2.6796, huber: 2.2479, swd: 7.6923, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.474643\n",
      "        No improvement (2.8181), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 26.2392, mae: 2.8136, huber: 2.3934, swd: 12.0894, target_std: 20.3719\n",
      "Epoch [4/50], Val Losses: mse: 24.1664, mae: 3.2283, huber: 2.7998, swd: 8.2622, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 18.2456, mae: 2.7747, huber: 2.3401, swd: 8.4664, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.393352\n",
      "        Val objective improved 2.8024 → 2.7998, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 25.6720, mae: 2.7721, huber: 2.3534, swd: 11.7065, target_std: 20.3712\n",
      "Epoch [5/50], Val Losses: mse: 24.5670, mae: 3.2520, huber: 2.8277, swd: 8.5463, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 18.1076, mae: 2.7709, huber: 2.3375, swd: 8.2473, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.353356\n",
      "        No improvement (2.8277), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 25.1913, mae: 2.7336, huber: 2.3160, swd: 11.3416, target_std: 20.3713\n",
      "Epoch [6/50], Val Losses: mse: 24.4342, mae: 3.2544, huber: 2.8338, swd: 8.6484, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.4392, mae: 2.7162, huber: 2.2860, swd: 7.8824, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.316045\n",
      "        No improvement (2.8338), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 24.8566, mae: 2.7125, huber: 2.2953, swd: 11.1030, target_std: 20.3718\n",
      "Epoch [7/50], Val Losses: mse: 23.6931, mae: 3.2003, huber: 2.7790, swd: 8.0047, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 17.8173, mae: 2.7224, huber: 2.2934, swd: 8.2234, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.295324\n",
      "        Val objective improved 2.7998 → 2.7790, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 24.4995, mae: 2.6849, huber: 2.2688, swd: 10.8799, target_std: 20.3716\n",
      "Epoch [8/50], Val Losses: mse: 24.5528, mae: 3.2480, huber: 2.8248, swd: 8.5209, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 18.2959, mae: 2.8079, huber: 2.3728, swd: 8.6235, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.268835\n",
      "        No improvement (2.8248), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 24.2814, mae: 2.6729, huber: 2.2574, swd: 10.7722, target_std: 20.3716\n",
      "Epoch [9/50], Val Losses: mse: 24.9225, mae: 3.2658, huber: 2.8432, swd: 8.8160, target_std: 20.5636\n",
      "Epoch [9/50], Test Losses: mse: 18.1357, mae: 2.7078, huber: 2.2815, swd: 8.3696, target_std: 18.3446\n",
      "  Epoch 9 composite train-obj: 2.257411\n",
      "        No improvement (2.8432), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 23.8225, mae: 2.6338, huber: 2.2191, swd: 10.4830, target_std: 20.3714\n",
      "Epoch [10/50], Val Losses: mse: 24.3970, mae: 3.2498, huber: 2.8294, swd: 8.3884, target_std: 20.5636\n",
      "Epoch [10/50], Test Losses: mse: 17.5229, mae: 2.6423, huber: 2.2192, swd: 7.9928, target_std: 18.3446\n",
      "  Epoch 10 composite train-obj: 2.219124\n",
      "        No improvement (2.8294), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 23.5363, mae: 2.6174, huber: 2.2029, swd: 10.3254, target_std: 20.3713\n",
      "Epoch [11/50], Val Losses: mse: 25.7633, mae: 3.2887, huber: 2.8704, swd: 9.2275, target_std: 20.5636\n",
      "Epoch [11/50], Test Losses: mse: 18.8052, mae: 2.7549, huber: 2.3282, swd: 8.9579, target_std: 18.3446\n",
      "  Epoch 11 composite train-obj: 2.202933\n",
      "        No improvement (2.8704), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 23.1125, mae: 2.5833, huber: 2.1698, swd: 10.0382, target_std: 20.3712\n",
      "Epoch [12/50], Val Losses: mse: 26.0798, mae: 3.2864, huber: 2.8678, swd: 9.5570, target_std: 20.5636\n",
      "Epoch [12/50], Test Losses: mse: 19.8076, mae: 2.8508, huber: 2.4229, swd: 9.8156, target_std: 18.3446\n",
      "  Epoch 12 composite train-obj: 2.169838\n",
      "Epoch [12/50], Test Losses: mse: 17.8176, mae: 2.7224, huber: 2.2934, swd: 8.2234, target_std: 18.3446\n",
      "Best round's Test MSE: 17.8173, MAE: 2.7224, SWD: 8.2234\n",
      "Best round's Validation MSE: 23.6931, MAE: 3.2003\n",
      "Best round's Test verification MSE : 17.8176, MAE: 2.7224, SWD: 8.2234\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 50.5554, mae: 3.7600, huber: 3.3305, swd: 30.1738, target_std: 20.3714\n",
      "Epoch [1/50], Val Losses: mse: 27.1854, mae: 3.4213, huber: 2.9922, swd: 8.7940, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 20.9970, mae: 3.0056, huber: 2.5666, swd: 9.0962, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 3.330458\n",
      "        Val objective improved inf → 2.9922, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.4653, mae: 2.9082, huber: 2.4862, swd: 11.8307, target_std: 20.3716\n",
      "Epoch [2/50], Val Losses: mse: 24.0743, mae: 3.2395, huber: 2.8119, swd: 7.7902, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.9999, mae: 2.7786, huber: 2.3424, swd: 7.7788, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.486150\n",
      "        Val objective improved 2.9922 → 2.8119, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 25.8559, mae: 2.7965, huber: 2.3770, swd: 10.8826, target_std: 20.3710\n",
      "Epoch [3/50], Val Losses: mse: 24.7207, mae: 3.3034, huber: 2.8747, swd: 8.2026, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.6368, mae: 2.6974, huber: 2.2678, swd: 7.3660, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.376995\n",
      "        No improvement (2.8747), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 25.1877, mae: 2.7485, huber: 2.3296, swd: 10.5336, target_std: 20.3712\n",
      "Epoch [4/50], Val Losses: mse: 24.9315, mae: 3.3188, huber: 2.8932, swd: 8.2962, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.9565, mae: 2.7594, huber: 2.3278, swd: 7.6337, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.329609\n",
      "        No improvement (2.8932), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 24.3889, mae: 2.6861, huber: 2.2687, swd: 9.9794, target_std: 20.3720\n",
      "Epoch [5/50], Val Losses: mse: 24.8996, mae: 3.2843, huber: 2.8595, swd: 8.1278, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 18.5023, mae: 2.7873, huber: 2.3551, swd: 8.0304, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.268660\n",
      "        No improvement (2.8595), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 23.9893, mae: 2.6589, huber: 2.2420, swd: 9.7324, target_std: 20.3713\n",
      "Epoch [6/50], Val Losses: mse: 24.6541, mae: 3.2720, huber: 2.8464, swd: 8.1264, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 18.6818, mae: 2.8369, huber: 2.4010, swd: 8.2640, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.242030\n",
      "        No improvement (2.8464), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 23.6393, mae: 2.6329, huber: 2.2168, swd: 9.5217, target_std: 20.3716\n",
      "Epoch [7/50], Val Losses: mse: 25.9587, mae: 3.3076, huber: 2.8851, swd: 9.0880, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 19.5838, mae: 2.8341, huber: 2.4048, swd: 8.9236, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.216766\n",
      "Epoch [7/50], Test Losses: mse: 18.0007, mae: 2.7787, huber: 2.3424, swd: 7.7797, target_std: 18.3446\n",
      "Best round's Test MSE: 17.9999, MAE: 2.7786, SWD: 7.7788\n",
      "Best round's Validation MSE: 24.0743, MAE: 3.2395\n",
      "Best round's Test verification MSE : 18.0007, MAE: 2.7787, SWD: 7.7797\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 49.7562, mae: 3.7427, huber: 3.3131, swd: 32.4946, target_std: 20.3712\n",
      "Epoch [1/50], Val Losses: mse: 25.6173, mae: 3.3426, huber: 2.9133, swd: 8.5713, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 19.6784, mae: 2.9021, huber: 2.4652, swd: 9.0391, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 3.313126\n",
      "        Val objective improved inf → 2.9133, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.2118, mae: 2.9012, huber: 2.4786, swd: 13.1534, target_std: 20.3713\n",
      "Epoch [2/50], Val Losses: mse: 23.5153, mae: 3.1918, huber: 2.7640, swd: 8.4625, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.6644, mae: 2.7315, huber: 2.2965, swd: 8.2943, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.478602\n",
      "        Val objective improved 2.9133 → 2.7640, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 25.6870, mae: 2.7849, huber: 2.3648, swd: 12.1447, target_std: 20.3718\n",
      "Epoch [3/50], Val Losses: mse: 24.2282, mae: 3.1911, huber: 2.7669, swd: 8.9155, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 19.4946, mae: 2.9279, huber: 2.4864, swd: 9.8538, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.364774\n",
      "        No improvement (2.7669), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 25.2172, mae: 2.7549, huber: 2.3353, swd: 11.9112, target_std: 20.3716\n",
      "Epoch [4/50], Val Losses: mse: 24.1834, mae: 3.2104, huber: 2.7864, swd: 9.0471, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 18.1961, mae: 2.7983, huber: 2.3601, swd: 8.7424, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.335343\n",
      "        No improvement (2.7864), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 24.5106, mae: 2.6972, huber: 2.2788, swd: 11.4084, target_std: 20.3715\n",
      "Epoch [5/50], Val Losses: mse: 24.4928, mae: 3.2260, huber: 2.8031, swd: 9.2025, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 18.5222, mae: 2.7860, huber: 2.3525, swd: 8.9491, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.278812\n",
      "        No improvement (2.8031), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 24.1391, mae: 2.6715, huber: 2.2535, swd: 11.1788, target_std: 20.3712\n",
      "Epoch [6/50], Val Losses: mse: 23.9296, mae: 3.1941, huber: 2.7708, swd: 8.6944, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 18.3517, mae: 2.8062, huber: 2.3717, swd: 9.0438, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.253511\n",
      "        No improvement (2.7708), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 23.5856, mae: 2.6346, huber: 2.2178, swd: 10.8295, target_std: 20.3716\n",
      "Epoch [7/50], Val Losses: mse: 22.9928, mae: 3.1370, huber: 2.7156, swd: 8.2566, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 18.3173, mae: 2.7419, huber: 2.3134, swd: 9.1106, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.217802\n",
      "        Val objective improved 2.7640 → 2.7156, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 23.1229, mae: 2.5980, huber: 2.1826, swd: 10.5372, target_std: 20.3715\n",
      "Epoch [8/50], Val Losses: mse: 23.2253, mae: 3.1412, huber: 2.7169, swd: 8.3297, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 18.3066, mae: 2.8140, huber: 2.3779, swd: 9.0017, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.182629\n",
      "        No improvement (2.7169), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 22.6490, mae: 2.5657, huber: 2.1510, swd: 10.2496, target_std: 20.3711\n",
      "Epoch [9/50], Val Losses: mse: 24.0694, mae: 3.1987, huber: 2.7762, swd: 8.8033, target_std: 20.5636\n",
      "Epoch [9/50], Test Losses: mse: 19.0523, mae: 2.8706, huber: 2.4360, swd: 9.5156, target_std: 18.3446\n",
      "  Epoch 9 composite train-obj: 2.151038\n",
      "        No improvement (2.7762), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 22.1460, mae: 2.5321, huber: 2.1182, swd: 9.9327, target_std: 20.3713\n",
      "Epoch [10/50], Val Losses: mse: 24.8174, mae: 3.2262, huber: 2.8039, swd: 9.3001, target_std: 20.5636\n",
      "Epoch [10/50], Test Losses: mse: 18.6911, mae: 2.7611, huber: 2.3340, swd: 9.1293, target_std: 18.3446\n",
      "  Epoch 10 composite train-obj: 2.118239\n",
      "        No improvement (2.8039), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.7862, mae: 2.5113, huber: 2.0980, swd: 9.7554, target_std: 20.3714\n",
      "Epoch [11/50], Val Losses: mse: 24.3317, mae: 3.1981, huber: 2.7768, swd: 9.0219, target_std: 20.5636\n",
      "Epoch [11/50], Test Losses: mse: 19.0474, mae: 2.8051, huber: 2.3757, swd: 9.5062, target_std: 18.3446\n",
      "  Epoch 11 composite train-obj: 2.097980\n",
      "        No improvement (2.7768), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.3738, mae: 2.4803, huber: 2.0679, swd: 9.5165, target_std: 20.3719\n",
      "Epoch [12/50], Val Losses: mse: 25.2002, mae: 3.2235, huber: 2.8026, swd: 9.6262, target_std: 20.5636\n",
      "Epoch [12/50], Test Losses: mse: 20.0729, mae: 2.8691, huber: 2.4395, swd: 10.2032, target_std: 18.3446\n",
      "  Epoch 12 composite train-obj: 2.067893\n",
      "Epoch [12/50], Test Losses: mse: 18.3173, mae: 2.7419, huber: 2.3134, swd: 9.1106, target_std: 18.3446\n",
      "Best round's Test MSE: 18.3173, MAE: 2.7419, SWD: 9.1106\n",
      "Best round's Validation MSE: 22.9928, MAE: 3.1370\n",
      "Best round's Test verification MSE : 18.3173, MAE: 2.7419, SWD: 9.1106\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (ACL_ettm2_seq336_pred720_20250430_2245)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 18.0448 ± 0.2066\n",
      "  mae: 2.7476 ± 0.0233\n",
      "  huber: 2.3164 ± 0.0201\n",
      "  swd: 8.3709 ± 0.5536\n",
      "  target_std: 18.3446 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 23.5868 ± 0.4479\n",
      "  mae: 3.1923 ± 0.0422\n",
      "  huber: 2.7688 ± 0.0400\n",
      "  swd: 8.0172 ± 0.1906\n",
      "  target_std: 20.5636 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: ACL_ettm2_seq336_pred720_20250430_2245\n",
      "Model: ACL\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "\n",
    "cfg = train_config.FlatACLConfig( \n",
    "    seq_len=336,\n",
    "    pred_len=720,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],# data_mgr.channels,              # ← number of features in your data\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4, \n",
    "    seeds=[1955, 7, 20],  \n",
    "    epochs=50, \n",
    "    dim_hidden=128,\n",
    "    dim_augment=128,\n",
    "    ablate_no_koopman=False,\n",
    "    use_complex_eigenvalues=True,\n",
    "    second_delay_use_shift=True,\n",
    "    ablate_rotate_back_Koopman=False, \n",
    "    ablate_shift_inside_scale=False,\n",
    ")\n",
    "cfg.x_to_z_delay.enable_magnitudes = [False, True]\n",
    "cfg.x_to_z_deri.enable_magnitudes = [False, True]\n",
    "cfg.z_to_x_main.enable_magnitudes = [False, True]\n",
    "cfg.z_to_y_main.enable_magnitudes = [False, True]\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3389a",
   "metadata": {},
   "source": [
    "### Timemixer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12baebb",
   "metadata": {},
   "source": [
    "#### pred=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeaf61ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 11.4886, mae: 1.8500, huber: 1.4600, swd: 6.4130, target_std: 20.3534\n",
      "Epoch [1/50], Val Losses: mse: 12.0195, mae: 2.0837, huber: 1.6888, swd: 6.4556, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.2397, mae: 1.8602, huber: 1.4582, swd: 4.8929, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.459998\n",
      "        Val objective improved inf → 1.6888, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 9.9712, mae: 1.7086, huber: 1.3242, swd: 5.4828, target_std: 20.3525\n",
      "Epoch [2/50], Val Losses: mse: 12.1186, mae: 2.0836, huber: 1.6894, swd: 6.6037, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.3425, mae: 1.8390, huber: 1.4388, swd: 4.9642, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.324187\n",
      "        No improvement (1.6894), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 9.3250, mae: 1.6521, huber: 1.2693, swd: 5.0204, target_std: 20.3538\n",
      "Epoch [3/50], Val Losses: mse: 12.4664, mae: 2.1155, huber: 1.7204, swd: 6.8442, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.4616, mae: 1.8420, huber: 1.4411, swd: 5.0530, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.269297\n",
      "        No improvement (1.7204), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 8.5603, mae: 1.5898, huber: 1.2085, swd: 4.4387, target_std: 20.3535\n",
      "Epoch [4/50], Val Losses: mse: 12.3615, mae: 2.1279, huber: 1.7312, swd: 6.7323, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.6449, mae: 1.8866, huber: 1.4835, swd: 5.2117, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.208548\n",
      "        No improvement (1.7312), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 7.7156, mae: 1.5246, huber: 1.1450, swd: 3.8068, target_std: 20.3530\n",
      "Epoch [5/50], Val Losses: mse: 13.1168, mae: 2.1906, huber: 1.7912, swd: 7.2383, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 10.4663, mae: 1.9467, huber: 1.5421, swd: 5.7588, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.144953\n",
      "        No improvement (1.7912), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 6.9114, mae: 1.4523, huber: 1.0747, swd: 3.2329, target_std: 20.3540\n",
      "Epoch [6/50], Val Losses: mse: 13.3160, mae: 2.2111, huber: 1.8109, swd: 7.2462, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.6124, mae: 1.9814, huber: 1.5755, swd: 5.7775, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.074670\n",
      "Epoch [6/50], Test Losses: mse: 9.2397, mae: 1.8602, huber: 1.4582, swd: 4.8929, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2397, MAE: 1.8602, SWD: 4.8929\n",
      "Best round's Validation MSE: 12.0195, MAE: 2.0837\n",
      "Best round's Test verification MSE : 9.2397, MAE: 1.8602, SWD: 4.8929\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 11.2626, mae: 1.8319, huber: 1.4428, swd: 5.9731, target_std: 20.3537\n",
      "Epoch [1/50], Val Losses: mse: 12.2373, mae: 2.1061, huber: 1.7107, swd: 6.3678, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.3989, mae: 1.8613, huber: 1.4587, swd: 4.7345, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.442815\n",
      "        Val objective improved inf → 1.7107, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 9.4628, mae: 1.6655, huber: 1.2825, swd: 4.9292, target_std: 20.3536\n",
      "Epoch [2/50], Val Losses: mse: 12.5733, mae: 2.1170, huber: 1.7216, swd: 6.6873, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.4703, mae: 1.8528, huber: 1.4512, swd: 4.8851, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.282453\n",
      "        No improvement (1.7216), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 8.4367, mae: 1.5796, huber: 1.1989, swd: 4.1792, target_std: 20.3529\n",
      "Epoch [3/50], Val Losses: mse: 12.4214, mae: 2.1365, huber: 1.7388, swd: 6.5278, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.9256, mae: 1.9127, huber: 1.5091, swd: 5.1846, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.198870\n",
      "        No improvement (1.7388), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 7.3467, mae: 1.4927, huber: 1.1139, swd: 3.4037, target_std: 20.3537\n",
      "Epoch [4/50], Val Losses: mse: 12.9728, mae: 2.1954, huber: 1.7951, swd: 6.8170, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 10.3427, mae: 1.9510, huber: 1.5462, swd: 5.4446, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.113923\n",
      "        No improvement (1.7951), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 6.4197, mae: 1.4041, huber: 1.0279, swd: 2.7988, target_std: 20.3544\n",
      "Epoch [5/50], Val Losses: mse: 13.4544, mae: 2.2375, huber: 1.8359, swd: 7.0846, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 10.7204, mae: 1.9861, huber: 1.5803, swd: 5.6626, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.027894\n",
      "        No improvement (1.8359), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 5.7631, mae: 1.3332, huber: 0.9594, swd: 2.3922, target_std: 20.3534\n",
      "Epoch [6/50], Val Losses: mse: 13.4656, mae: 2.2396, huber: 1.8377, swd: 7.0627, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.8024, mae: 1.9937, huber: 1.5881, swd: 5.6653, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 0.959364\n",
      "Epoch [6/50], Test Losses: mse: 9.3989, mae: 1.8613, huber: 1.4587, swd: 4.7345, target_std: 18.3806\n",
      "Best round's Test MSE: 9.3989, MAE: 1.8613, SWD: 4.7345\n",
      "Best round's Validation MSE: 12.2373, MAE: 2.1061\n",
      "Best round's Test verification MSE : 9.3989, MAE: 1.8613, SWD: 4.7345\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 11.7216, mae: 1.8674, huber: 1.4770, swd: 5.6869, target_std: 20.3532\n",
      "Epoch [1/50], Val Losses: mse: 12.0172, mae: 2.0888, huber: 1.6946, swd: 5.8092, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.2392, mae: 1.8407, huber: 1.4401, swd: 4.3879, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.476981\n",
      "        Val objective improved inf → 1.6946, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 9.8231, mae: 1.6983, huber: 1.3143, swd: 4.8356, target_std: 20.3531\n",
      "Epoch [2/50], Val Losses: mse: 12.3364, mae: 2.0907, huber: 1.6969, swd: 6.1773, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.3151, mae: 1.8527, huber: 1.4502, swd: 4.4949, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.314303\n",
      "        No improvement (1.6969), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 9.0455, mae: 1.6296, huber: 1.2475, swd: 4.3321, target_std: 20.3533\n",
      "Epoch [3/50], Val Losses: mse: 12.5569, mae: 2.1221, huber: 1.7269, swd: 6.2395, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.6887, mae: 1.8705, huber: 1.4683, swd: 4.6498, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.247475\n",
      "        No improvement (1.7269), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 8.2254, mae: 1.5640, huber: 1.1833, swd: 3.7802, target_std: 20.3540\n",
      "Epoch [4/50], Val Losses: mse: 13.0501, mae: 2.1734, huber: 1.7756, swd: 6.5938, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.8130, mae: 1.9082, huber: 1.5029, swd: 4.7472, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.183342\n",
      "        No improvement (1.7756), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 7.3193, mae: 1.4879, huber: 1.1092, swd: 3.1834, target_std: 20.3535\n",
      "Epoch [5/50], Val Losses: mse: 13.1765, mae: 2.1987, huber: 1.7993, swd: 6.5232, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 10.2333, mae: 1.9316, huber: 1.5269, swd: 4.9492, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.109189\n",
      "        No improvement (1.7993), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 6.5613, mae: 1.4158, huber: 1.0393, swd: 2.7163, target_std: 20.3528\n",
      "Epoch [6/50], Val Losses: mse: 13.5471, mae: 2.2389, huber: 1.8378, swd: 6.6682, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 10.9860, mae: 1.9959, huber: 1.5897, swd: 5.4713, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.039286\n",
      "Epoch [6/50], Test Losses: mse: 9.2392, mae: 1.8407, huber: 1.4401, swd: 4.3879, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2392, MAE: 1.8407, SWD: 4.3879\n",
      "Best round's Validation MSE: 12.0172, MAE: 2.0888\n",
      "Best round's Test verification MSE : 9.2392, MAE: 1.8407, SWD: 4.3879\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred96_20250430_2053)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.2926 ± 0.0752\n",
      "  mae: 1.8541 ± 0.0095\n",
      "  huber: 1.4523 ± 0.0086\n",
      "  swd: 4.6718 ± 0.2109\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.0913 ± 0.1032\n",
      "  mae: 2.0929 ± 0.0096\n",
      "  huber: 1.6980 ± 0.0092\n",
      "  swd: 6.2109 ± 0.2863\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred96_20250430_2053\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22644d4c",
   "metadata": {},
   "source": [
    "#### pred=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9835ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 377\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 377\n",
      "Validation Batches: 51\n",
      "Test Batches: 105\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 16.2482, mae: 2.1641, huber: 1.7665, swd: 9.0275, target_std: 20.3579\n",
      "Epoch [1/50], Val Losses: mse: 17.1636, mae: 2.5089, huber: 2.1041, swd: 9.2272, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1472, mae: 2.1226, huber: 1.7133, swd: 6.2025, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.766549\n",
      "        Val objective improved inf → 2.1041, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 14.2305, mae: 2.0090, huber: 1.6158, swd: 7.7021, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 17.4802, mae: 2.5286, huber: 2.1220, swd: 9.5636, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.4295, mae: 2.1403, huber: 1.7305, swd: 6.4716, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.615763\n",
      "        No improvement (2.1220), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 12.5692, mae: 1.9079, huber: 1.5158, swd: 6.4815, target_std: 20.3578\n",
      "Epoch [3/50], Val Losses: mse: 18.6820, mae: 2.6152, huber: 2.2053, swd: 10.4012, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 13.0214, mae: 2.1939, huber: 1.7825, swd: 6.9639, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.515848\n",
      "        No improvement (2.2053), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 11.0450, mae: 1.8031, huber: 1.4126, swd: 5.3299, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 19.4202, mae: 2.6658, huber: 2.2541, swd: 10.7724, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 13.5309, mae: 2.2322, huber: 1.8197, swd: 7.3713, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.412617\n",
      "        No improvement (2.2541), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 9.8797, mae: 1.7113, huber: 1.3227, swd: 4.4806, target_std: 20.3578\n",
      "Epoch [5/50], Val Losses: mse: 20.2512, mae: 2.7239, huber: 2.3115, swd: 11.3131, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 14.2553, mae: 2.2825, huber: 1.8689, swd: 7.8791, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.322725\n",
      "        No improvement (2.3115), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 9.0311, mae: 1.6330, huber: 1.2464, swd: 3.9213, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 19.8927, mae: 2.7252, huber: 2.3123, swd: 10.8250, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 14.5932, mae: 2.3177, huber: 1.9035, swd: 8.0218, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.246350\n",
      "Epoch [6/50], Test Losses: mse: 12.1472, mae: 2.1226, huber: 1.7133, swd: 6.2025, target_std: 18.3527\n",
      "Best round's Test MSE: 12.1472, MAE: 2.1226, SWD: 6.2025\n",
      "Best round's Validation MSE: 17.1636, MAE: 2.5089\n",
      "Best round's Test verification MSE : 12.1472, MAE: 2.1226, SWD: 6.2025\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 16.0358, mae: 2.1471, huber: 1.7499, swd: 9.2370, target_std: 20.3579\n",
      "Epoch [1/50], Val Losses: mse: 17.1776, mae: 2.5084, huber: 2.1033, swd: 9.5996, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.3042, mae: 2.1211, huber: 1.7117, swd: 6.5181, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.749882\n",
      "        Val objective improved inf → 2.1033, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 14.0863, mae: 1.9957, huber: 1.6030, swd: 7.9168, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 17.4464, mae: 2.5274, huber: 2.1217, swd: 10.1317, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.7785, mae: 2.1645, huber: 1.7531, swd: 7.1375, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.603035\n",
      "        No improvement (2.1217), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 12.1794, mae: 1.8817, huber: 1.4906, swd: 6.3583, target_std: 20.3579\n",
      "Epoch [3/50], Val Losses: mse: 18.1659, mae: 2.5857, huber: 2.1773, swd: 10.4161, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 13.4975, mae: 2.2085, huber: 1.7969, swd: 7.6059, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.490594\n",
      "        No improvement (2.1773), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 10.3436, mae: 1.7484, huber: 1.3596, swd: 4.9019, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 19.6767, mae: 2.6893, huber: 2.2793, swd: 11.4588, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 14.2678, mae: 2.2762, huber: 1.8629, swd: 8.1649, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.359645\n",
      "        No improvement (2.2793), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 9.0749, mae: 1.6376, huber: 1.2513, swd: 4.0095, target_std: 20.3579\n",
      "Epoch [5/50], Val Losses: mse: 19.0092, mae: 2.6545, huber: 2.2443, swd: 10.9742, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 14.2842, mae: 2.2875, huber: 1.8739, swd: 8.1278, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.251264\n",
      "        No improvement (2.2443), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 8.1294, mae: 1.5542, huber: 1.1700, swd: 3.3732, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 20.1043, mae: 2.7353, huber: 2.3232, swd: 11.7091, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 15.2584, mae: 2.3602, huber: 1.9454, swd: 8.7963, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.169985\n",
      "Epoch [6/50], Test Losses: mse: 12.3042, mae: 2.1211, huber: 1.7117, swd: 6.5181, target_std: 18.3527\n",
      "Best round's Test MSE: 12.3042, MAE: 2.1211, SWD: 6.5181\n",
      "Best round's Validation MSE: 17.1776, MAE: 2.5084\n",
      "Best round's Test verification MSE : 12.3042, MAE: 2.1211, SWD: 6.5181\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 16.2368, mae: 2.1598, huber: 1.7628, swd: 7.9769, target_std: 20.3580\n",
      "Epoch [1/50], Val Losses: mse: 17.4354, mae: 2.5104, huber: 2.1070, swd: 8.5063, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1240, mae: 2.1108, huber: 1.7012, swd: 5.4671, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.762844\n",
      "        Val objective improved inf → 2.1070, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 14.0571, mae: 1.9942, huber: 1.6021, swd: 6.6967, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 17.4043, mae: 2.5130, huber: 2.1088, swd: 8.5154, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.4709, mae: 2.1334, huber: 1.7236, swd: 5.7388, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.602111\n",
      "        No improvement (2.1088), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 12.3759, mae: 1.8983, huber: 1.5075, swd: 5.5834, target_std: 20.3577\n",
      "Epoch [3/50], Val Losses: mse: 18.2085, mae: 2.5792, huber: 2.1717, swd: 8.8535, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 13.2649, mae: 2.2091, huber: 1.7973, swd: 6.2492, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.507527\n",
      "        No improvement (2.1717), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 10.7818, mae: 1.7854, huber: 1.3963, swd: 4.5321, target_std: 20.3578\n",
      "Epoch [4/50], Val Losses: mse: 19.2755, mae: 2.6705, huber: 2.2609, swd: 9.4515, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 13.9073, mae: 2.2552, huber: 1.8421, swd: 6.7422, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.396293\n",
      "        No improvement (2.2609), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 9.6268, mae: 1.6836, huber: 1.2965, swd: 3.8262, target_std: 20.3579\n",
      "Epoch [5/50], Val Losses: mse: 19.7842, mae: 2.7138, huber: 2.3025, swd: 9.5579, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 14.7099, mae: 2.3208, huber: 1.9070, swd: 7.1629, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.296516\n",
      "        No improvement (2.3025), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 8.6325, mae: 1.5939, huber: 1.2088, swd: 3.2498, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 19.6859, mae: 2.7211, huber: 2.3083, swd: 9.3034, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 15.2504, mae: 2.3584, huber: 1.9435, swd: 7.4601, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.208782\n",
      "Epoch [6/50], Test Losses: mse: 12.1240, mae: 2.1108, huber: 1.7012, swd: 5.4671, target_std: 18.3527\n",
      "Best round's Test MSE: 12.1240, MAE: 2.1108, SWD: 5.4671\n",
      "Best round's Validation MSE: 17.4354, MAE: 2.5104\n",
      "Best round's Test verification MSE : 12.1240, MAE: 2.1108, SWD: 5.4671\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred196_20250430_2207)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 12.1918 ± 0.0800\n",
      "  mae: 2.1182 ± 0.0052\n",
      "  huber: 1.7087 ± 0.0054\n",
      "  swd: 6.0626 ± 0.4404\n",
      "  target_std: 18.3527 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 17.2589 ± 0.1250\n",
      "  mae: 2.5092 ± 0.0008\n",
      "  huber: 2.1048 ± 0.0016\n",
      "  swd: 9.1110 ± 0.4538\n",
      "  target_std: 20.5630 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred196_20250430_2207\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=196,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be6b39",
   "metadata": {},
   "source": [
    "#### pred=336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eed99a",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76fa8daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.3876, mae: 2.4607, huber: 2.0573, swd: 11.4909, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 20.8653, mae: 2.8194, huber: 2.4075, swd: 9.9837, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.6160, mae: 2.3378, huber: 1.9238, swd: 7.2468, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.057332\n",
      "        Val objective improved inf → 2.4075, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.9603, mae: 2.3063, huber: 1.9068, swd: 10.0015, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 21.4790, mae: 2.8386, huber: 2.4269, swd: 10.7677, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.5599, mae: 2.3457, huber: 1.9303, swd: 7.2873, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 1.906804\n",
      "        No improvement (2.4269), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.9474, mae: 2.2003, huber: 1.8017, swd: 8.4853, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.3169, mae: 2.9209, huber: 2.5048, swd: 11.2879, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1436, mae: 2.4053, huber: 1.9886, swd: 7.7485, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.801688\n",
      "        No improvement (2.5048), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.7756, mae: 2.0681, huber: 1.6709, swd: 6.8342, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 22.1013, mae: 2.9326, huber: 2.5154, swd: 10.6925, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.1030, mae: 2.4853, huber: 2.0666, swd: 8.4118, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.670918\n",
      "        No improvement (2.5154), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 13.0545, mae: 1.9460, huber: 1.5506, swd: 5.6386, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 22.8146, mae: 2.9852, huber: 2.5669, swd: 11.1074, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.4206, mae: 2.4957, huber: 2.0770, swd: 8.5552, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.550619\n",
      "        No improvement (2.5669), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.8312, mae: 1.8467, huber: 1.4531, swd: 4.8876, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 23.7316, mae: 3.0504, huber: 2.6308, swd: 11.5376, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.0264, mae: 2.5457, huber: 2.1256, swd: 8.9300, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.453146\n",
      "Epoch [6/50], Test Losses: mse: 14.6160, mae: 2.3378, huber: 1.9238, swd: 7.2468, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6160, MAE: 2.3378, SWD: 7.2468\n",
      "Best round's Validation MSE: 20.8653, MAE: 2.8194\n",
      "Best round's Test verification MSE : 14.6160, MAE: 2.3378, SWD: 7.2468\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.4947, mae: 2.4700, huber: 2.0658, swd: 11.9807, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 20.5455, mae: 2.7997, huber: 2.3880, swd: 10.1555, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.5022, mae: 2.3489, huber: 1.9333, swd: 7.6029, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.065837\n",
      "        Val objective improved inf → 2.3880, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.8535, mae: 2.3047, huber: 1.9045, swd: 10.3314, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 22.6131, mae: 2.8963, huber: 2.4827, swd: 11.8322, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7874, mae: 2.3692, huber: 1.9529, swd: 7.8375, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 1.904494\n",
      "        No improvement (2.4827), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.8233, mae: 2.1948, huber: 1.7956, swd: 8.7223, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 21.6008, mae: 2.8810, huber: 2.4645, swd: 10.8280, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.4393, mae: 2.4089, huber: 1.9927, swd: 8.2553, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.795640\n",
      "        No improvement (2.4645), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.8452, mae: 2.0723, huber: 1.6745, swd: 7.1421, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 21.7285, mae: 2.9120, huber: 2.4934, swd: 10.7943, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.0692, mae: 2.4764, huber: 2.0579, swd: 8.9128, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.674504\n",
      "        No improvement (2.4934), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 13.2714, mae: 1.9587, huber: 1.5627, swd: 5.9865, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.8674, mae: 2.9950, huber: 2.5759, swd: 11.6283, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.9952, mae: 2.5440, huber: 2.1245, swd: 9.5178, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.562681\n",
      "        No improvement (2.5759), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 12.0669, mae: 1.8632, huber: 1.4689, swd: 5.1894, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 22.9708, mae: 3.0130, huber: 2.5928, swd: 11.6467, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.7516, mae: 2.5936, huber: 2.1734, swd: 10.0712, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.468932\n",
      "Epoch [6/50], Test Losses: mse: 14.5022, mae: 2.3489, huber: 1.9333, swd: 7.6029, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5022, MAE: 2.3489, SWD: 7.6029\n",
      "Best round's Validation MSE: 20.5455, MAE: 2.7997\n",
      "Best round's Test verification MSE : 14.5022, MAE: 2.3489, SWD: 7.6029\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.1779, mae: 2.4468, huber: 2.0442, swd: 11.0156, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.1918, mae: 2.7678, huber: 2.3586, swd: 9.0784, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.5262, mae: 2.3326, huber: 1.9183, swd: 6.9684, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.044234\n",
      "        Val objective improved inf → 2.3586, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.6491, mae: 2.2899, huber: 1.8908, swd: 9.4772, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 21.1532, mae: 2.8210, huber: 2.4098, swd: 9.7796, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.4061, mae: 2.3239, huber: 1.9095, swd: 6.8307, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 1.890827\n",
      "        No improvement (2.4098), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.3279, mae: 2.1630, huber: 1.7651, swd: 7.7903, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 21.3661, mae: 2.8725, huber: 2.4581, swd: 9.6986, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.5147, mae: 2.4074, huber: 1.9913, swd: 7.6094, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.765066\n",
      "        No improvement (2.4581), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.2152, mae: 2.0257, huber: 1.6293, swd: 6.2540, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 22.1909, mae: 2.9420, huber: 2.5245, swd: 10.1638, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.6531, mae: 2.4892, huber: 2.0709, swd: 8.4112, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.629264\n",
      "        No improvement (2.5245), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.5392, mae: 1.9021, huber: 1.5075, swd: 5.1512, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 24.2205, mae: 3.0661, huber: 2.6475, swd: 11.5976, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.4791, mae: 2.5531, huber: 2.1333, swd: 8.9053, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.507544\n",
      "        No improvement (2.6475), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.2610, mae: 1.8023, huber: 1.4095, swd: 4.3778, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 24.2843, mae: 3.0770, huber: 2.6575, swd: 11.2772, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.5761, mae: 2.5609, huber: 2.1411, swd: 8.7556, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.409521\n",
      "Epoch [6/50], Test Losses: mse: 14.5262, mae: 2.3326, huber: 1.9183, swd: 6.9684, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5262, MAE: 2.3326, SWD: 6.9684\n",
      "Best round's Validation MSE: 20.1918, MAE: 2.7678\n",
      "Best round's Test verification MSE : 14.5262, MAE: 2.3326, SWD: 6.9684\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250430_2214)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.5481 ± 0.0490\n",
      "  mae: 2.3398 ± 0.0068\n",
      "  huber: 1.9251 ± 0.0062\n",
      "  swd: 7.2727 ± 0.2597\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.5342 ± 0.2750\n",
      "  mae: 2.7957 ± 0.0213\n",
      "  huber: 2.3847 ± 0.0201\n",
      "  swd: 9.7392 ± 0.4725\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250430_2214\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46aa2a",
   "metadata": {},
   "source": [
    "##### huber + 0.1SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54a3252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.6828, mae: 2.5282, huber: 2.1219, swd: 11.0287, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 20.6632, mae: 2.8228, huber: 2.4092, swd: 9.7816, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.7160, mae: 2.3694, huber: 1.9532, swd: 7.3529, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.224775\n",
      "        Val objective improved inf → 3.3874, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.6842, mae: 2.3707, huber: 1.9678, swd: 9.1024, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.2321, mae: 2.8901, huber: 2.4765, swd: 11.4382, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7602, mae: 2.3723, huber: 1.9556, swd: 7.4436, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.878018\n",
      "        No improvement (3.6204), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.8118, mae: 2.2770, huber: 1.8752, swd: 7.7603, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.4469, mae: 2.9165, huber: 2.5011, swd: 11.4380, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0689, mae: 2.4129, huber: 1.9948, swd: 7.7557, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.651243\n",
      "        No improvement (3.6449), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 15.0352, mae: 2.1720, huber: 1.7710, swd: 6.4165, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 21.9536, mae: 2.9222, huber: 2.5053, swd: 10.8009, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.8240, mae: 2.4789, huber: 2.0595, swd: 8.5004, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.412644\n",
      "        No improvement (3.5854), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 13.5303, mae: 2.0730, huber: 1.6730, swd: 5.3228, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 22.8237, mae: 2.9743, huber: 2.5557, swd: 11.0533, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.6722, mae: 2.5164, huber: 2.0968, swd: 9.0004, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.205304\n",
      "        No improvement (3.6611), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 12.2128, mae: 1.9743, huber: 1.5759, swd: 4.4595, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 23.5780, mae: 3.0316, huber: 2.6116, swd: 11.5899, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.4208, mae: 2.5685, huber: 2.1483, swd: 9.5208, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.021807\n",
      "Epoch [6/50], Test Losses: mse: 14.7160, mae: 2.3694, huber: 1.9532, swd: 7.3529, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7160, MAE: 2.3694, SWD: 7.3529\n",
      "Best round's Validation MSE: 20.6632, MAE: 2.8228, SWD: 9.7816\n",
      "Best round's Test verification MSE : 14.7160, MAE: 2.3694, SWD: 7.3529\n",
      "Time taken: 146.86 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.6265, mae: 2.5293, huber: 2.1222, swd: 11.3797, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 20.5712, mae: 2.8360, huber: 2.4213, swd: 10.1157, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8905, mae: 2.3958, huber: 1.9781, swd: 7.8844, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.260176\n",
      "        Val objective improved inf → 3.4329, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.4938, mae: 2.3593, huber: 1.9560, swd: 9.3169, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 22.1868, mae: 2.9029, huber: 2.4873, swd: 11.4741, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.1553, mae: 2.4164, huber: 1.9982, swd: 8.1079, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.887724\n",
      "        No improvement (3.6347), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.2386, mae: 2.2420, huber: 1.8396, swd: 7.5664, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 21.0918, mae: 2.8785, huber: 2.4601, swd: 10.2441, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.7278, mae: 2.4454, huber: 2.0268, swd: 8.5662, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.596250\n",
      "        No improvement (3.4845), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.3968, mae: 2.1287, huber: 1.7273, swd: 6.1218, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 21.9759, mae: 2.9421, huber: 2.5223, swd: 11.1389, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.8444, mae: 2.4825, huber: 2.0619, swd: 8.6644, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.339438\n",
      "        No improvement (3.6362), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.9722, mae: 2.0266, huber: 1.6268, swd: 5.0867, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.8495, mae: 3.0086, huber: 2.5879, swd: 11.7311, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.9784, mae: 2.5724, huber: 2.1508, swd: 9.5197, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.135433\n",
      "        No improvement (3.7610), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.8489, mae: 1.9356, huber: 1.5375, swd: 4.3482, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 23.5573, mae: 3.0786, huber: 2.6574, swd: 12.1864, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.5284, mae: 2.6075, huber: 2.1861, swd: 9.9544, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.972273\n",
      "Epoch [6/50], Test Losses: mse: 14.8905, mae: 2.3958, huber: 1.9781, swd: 7.8844, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8905, MAE: 2.3958, SWD: 7.8844\n",
      "Best round's Validation MSE: 20.5712, MAE: 2.8360, SWD: 10.1157\n",
      "Best round's Test verification MSE : 14.8905, MAE: 2.3958, SWD: 7.8844\n",
      "Time taken: 147.64 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.3911, mae: 2.5034, huber: 2.0980, swd: 10.5598, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.5796, mae: 2.8149, huber: 2.4022, swd: 9.1902, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.5903, mae: 2.3546, huber: 1.9385, swd: 6.8941, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.153984\n",
      "        Val objective improved inf → 3.3212, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.3714, mae: 2.3475, huber: 1.9450, swd: 8.5316, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 21.5050, mae: 2.8736, huber: 2.4590, swd: 10.0581, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.6019, mae: 2.3722, huber: 1.9552, swd: 6.9419, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.798128\n",
      "        No improvement (3.4648), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.0471, mae: 2.2265, huber: 1.8248, swd: 6.9325, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 21.4478, mae: 2.9015, huber: 2.4838, swd: 9.9299, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.6752, mae: 2.4567, huber: 2.0376, swd: 7.9211, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.518087\n",
      "        No improvement (3.4768), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.1760, mae: 2.1090, huber: 1.7083, swd: 5.5683, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 21.7164, mae: 2.9255, huber: 2.5071, swd: 10.0573, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.6512, mae: 2.4996, huber: 2.0806, swd: 8.6129, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.265113\n",
      "        No improvement (3.5128), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.8040, mae: 2.0105, huber: 1.6111, swd: 4.6234, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 22.8412, mae: 3.0035, huber: 2.5833, swd: 10.9067, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.0653, mae: 2.5408, huber: 2.1205, swd: 8.8034, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.073404\n",
      "        No improvement (3.6740), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.6666, mae: 1.9200, huber: 1.5221, swd: 3.9190, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 23.1309, mae: 3.0220, huber: 2.6016, swd: 11.0604, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.4465, mae: 2.5749, huber: 2.1540, swd: 9.0236, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.913953\n",
      "Epoch [6/50], Test Losses: mse: 14.5903, mae: 2.3546, huber: 1.9385, swd: 6.8941, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5903, MAE: 2.3546, SWD: 6.8941\n",
      "Best round's Validation MSE: 20.5796, MAE: 2.8149, SWD: 9.1902\n",
      "Best round's Test verification MSE : 14.5903, MAE: 2.3546, SWD: 6.8941\n",
      "Time taken: 147.83 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_1436)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.7323 ± 0.1231\n",
      "  mae: 2.3733 ± 0.0171\n",
      "  huber: 1.9566 ± 0.0163\n",
      "  swd: 7.3771 ± 0.4047\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.6047 ± 0.0415\n",
      "  mae: 2.8246 ± 0.0087\n",
      "  huber: 2.4109 ± 0.0079\n",
      "  swd: 9.6959 ± 0.3827\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 442.41 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_1436\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.1, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b67784",
   "metadata": {},
   "source": [
    "##### huber + 0.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d879cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 25.2914, mae: 2.7466, huber: 2.3351, swd: 10.6852, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 23.0500, mae: 2.9698, huber: 2.5517, swd: 9.8682, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.2675, mae: 2.4985, huber: 2.0781, swd: 7.3048, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 7.677713\n",
      "        Val objective improved inf → 7.4858, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.4044, mae: 2.5493, huber: 2.1414, swd: 8.6135, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 23.4653, mae: 3.0100, huber: 2.5899, swd: 10.9318, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.8313, mae: 2.4731, huber: 2.0525, swd: 7.2897, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 6.448158\n",
      "        No improvement (8.0558), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 20.1334, mae: 2.4418, huber: 2.0345, swd: 7.3338, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.8645, mae: 3.0007, huber: 2.5793, swd: 10.4228, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.1855, mae: 2.5195, huber: 2.0972, swd: 8.0194, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 5.701461\n",
      "        No improvement (7.7907), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 18.1295, mae: 2.3475, huber: 1.9409, swd: 6.1054, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 23.8108, mae: 3.0594, huber: 2.6370, swd: 11.6996, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.1656, mae: 2.5729, huber: 2.1500, swd: 9.0789, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 4.993635\n",
      "        No improvement (8.4868), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 16.3915, mae: 2.2470, huber: 1.8416, swd: 5.1321, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 23.1675, mae: 3.0319, huber: 2.6100, swd: 11.2004, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.8423, mae: 2.5618, huber: 2.1396, swd: 8.8050, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 4.407698\n",
      "        No improvement (8.2102), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 14.6785, mae: 2.1396, huber: 1.7360, swd: 4.3515, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 23.0160, mae: 3.0378, huber: 2.6152, swd: 11.0989, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.4362, mae: 2.5960, huber: 2.1740, swd: 9.4809, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.911726\n",
      "Epoch [6/50], Test Losses: mse: 16.2675, mae: 2.4985, huber: 2.0781, swd: 7.3048, target_std: 18.3439\n",
      "Best round's Test MSE: 16.2675, MAE: 2.4985, SWD: 7.3048\n",
      "Best round's Validation MSE: 23.0500, MAE: 2.9698, SWD: 9.8682\n",
      "Best round's Test verification MSE : 16.2675, MAE: 2.4985, SWD: 7.3048\n",
      "Time taken: 147.22 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.8079, mae: 2.6849, huber: 2.2736, swd: 11.0541, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 22.2092, mae: 2.9563, huber: 2.5376, swd: 10.3921, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.0553, mae: 2.4934, huber: 2.0730, swd: 8.1340, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 7.800670\n",
      "        Val objective improved inf → 7.7337, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.9970, mae: 2.5075, huber: 2.0998, swd: 9.0214, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 23.4487, mae: 2.9983, huber: 2.5794, swd: 10.8042, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 16.3640, mae: 2.5059, huber: 2.0850, swd: 8.0348, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 6.610507\n",
      "        No improvement (7.9815), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 18.8876, mae: 2.4037, huber: 1.9965, swd: 7.4300, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 21.3783, mae: 2.9305, huber: 2.5093, swd: 9.7476, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.0403, mae: 2.5129, huber: 2.0907, swd: 8.5977, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 5.711438\n",
      "        Val objective improved 7.7337 → 7.3831, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 16.6908, mae: 2.2908, huber: 1.8845, swd: 5.9425, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 22.2181, mae: 2.9932, huber: 2.5710, swd: 10.7211, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.6440, mae: 2.5659, huber: 2.1428, swd: 9.1585, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 4.855761\n",
      "        No improvement (7.9315), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 14.7642, mae: 2.1686, huber: 1.7641, swd: 4.8645, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.6950, mae: 3.0182, huber: 2.5963, swd: 11.1840, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.1369, mae: 2.5685, huber: 2.1466, swd: 9.6518, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 4.196336\n",
      "        No improvement (8.1883), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 13.3965, mae: 2.0735, huber: 1.6705, swd: 4.1639, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 23.0829, mae: 3.0362, huber: 2.6144, swd: 11.5859, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.3154, mae: 2.5828, huber: 2.1612, swd: 9.8405, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.752429\n",
      "        No improvement (8.4074), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 12.2388, mae: 1.9876, huber: 1.5862, swd: 3.6047, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 23.1894, mae: 3.0628, huber: 2.6403, swd: 11.5932, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 18.2150, mae: 2.6309, huber: 2.2090, swd: 10.6692, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 3.388537\n",
      "        No improvement (8.4369), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 11.4816, mae: 1.9242, huber: 1.5242, swd: 3.2833, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 22.7220, mae: 3.0416, huber: 2.6189, swd: 11.2186, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 17.9315, mae: 2.6157, huber: 2.1941, swd: 10.4050, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 3.165907\n",
      "Epoch [8/50], Test Losses: mse: 16.0403, mae: 2.5129, huber: 2.0907, swd: 8.5977, target_std: 18.3439\n",
      "Best round's Test MSE: 16.0403, MAE: 2.5129, SWD: 8.5977\n",
      "Best round's Validation MSE: 21.3783, MAE: 2.9305, SWD: 9.7476\n",
      "Best round's Test verification MSE : 16.0403, MAE: 2.5129, SWD: 8.5977\n",
      "Time taken: 204.68 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 24.1065, mae: 2.6861, huber: 2.2756, swd: 10.2991, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 23.2170, mae: 2.9855, huber: 2.5668, swd: 9.4379, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.1980, mae: 2.4916, huber: 2.0713, swd: 7.1777, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 7.425135\n",
      "        Val objective improved inf → 7.2857, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.2234, mae: 2.5065, huber: 2.0990, swd: 8.1967, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 22.8886, mae: 2.9902, huber: 2.5699, swd: 9.6532, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.5726, mae: 2.4632, huber: 2.0425, swd: 7.0129, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 6.197381\n",
      "        No improvement (7.3965), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.0412, mae: 2.4002, huber: 1.9933, swd: 6.8271, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 22.9159, mae: 3.0091, huber: 2.5879, swd: 10.0775, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.0725, mae: 2.5063, huber: 2.0851, swd: 7.6809, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 5.406822\n",
      "        No improvement (7.6266), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 16.9699, mae: 2.2948, huber: 1.8887, swd: 5.6753, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 21.9533, mae: 2.9667, huber: 2.5449, swd: 9.5831, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.7904, mae: 2.5404, huber: 2.1189, swd: 8.6940, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 4.726363\n",
      "        No improvement (7.3364), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 15.1675, mae: 2.1899, huber: 1.7851, swd: 4.7254, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 22.7035, mae: 3.0272, huber: 2.6043, swd: 10.4977, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.0698, mae: 2.5563, huber: 2.1350, swd: 8.7811, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 4.147769\n",
      "        No improvement (7.8531), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 13.6371, mae: 2.0860, huber: 1.6826, swd: 3.9832, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 22.7314, mae: 3.0282, huber: 2.6046, swd: 10.4810, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.3519, mae: 2.5809, huber: 2.1587, swd: 9.1395, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.674243\n",
      "Epoch [6/50], Test Losses: mse: 16.1980, mae: 2.4916, huber: 2.0713, swd: 7.1777, target_std: 18.3439\n",
      "Best round's Test MSE: 16.1980, MAE: 2.4916, SWD: 7.1777\n",
      "Best round's Validation MSE: 23.2170, MAE: 2.9855, SWD: 9.4379\n",
      "Best round's Test verification MSE : 16.1980, MAE: 2.4916, SWD: 7.1777\n",
      "Time taken: 155.05 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_0444)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 16.1686 ± 0.0951\n",
      "  mae: 2.5010 ± 0.0089\n",
      "  huber: 2.0801 ± 0.0080\n",
      "  swd: 7.6934 ± 0.6415\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 22.5484 ± 0.8302\n",
      "  mae: 2.9619 ± 0.0231\n",
      "  huber: 2.5426 ± 0.0243\n",
      "  swd: 9.6846 ± 0.1813\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 507.11 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_0444\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.5, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875a8f0",
   "metadata": {},
   "source": [
    "##### huber + 1.5 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e7a7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.6418, mae: 3.0377, huber: 2.6204, swd: 10.3998, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 27.8412, mae: 3.2507, huber: 2.8267, swd: 10.4608, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 19.5606, mae: 2.7483, huber: 2.3216, swd: 7.3805, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 18.220085\n",
      "        Val objective improved inf → 18.5179, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.8011, mae: 2.8007, huber: 2.3878, swd: 8.3629, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 27.1822, mae: 3.2332, huber: 2.8077, swd: 11.5349, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 18.0126, mae: 2.6576, huber: 2.2319, swd: 7.3073, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 14.932122\n",
      "        No improvement (20.1100), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 25.5666, mae: 2.6957, huber: 2.2831, swd: 7.0876, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 27.9330, mae: 3.2843, huber: 2.8571, swd: 11.5849, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 18.5928, mae: 2.7098, huber: 2.2829, swd: 8.0029, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 12.914505\n",
      "        No improvement (20.2345), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 24.1140, mae: 2.6267, huber: 2.2143, swd: 5.8334, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 27.3721, mae: 3.2883, huber: 2.8612, swd: 12.1584, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 19.0815, mae: 2.7358, huber: 2.3087, swd: 9.0658, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 10.964300\n",
      "        No improvement (21.0988), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 22.1697, mae: 2.5174, huber: 2.1064, swd: 4.7427, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 26.5937, mae: 3.2579, huber: 2.8306, swd: 12.1047, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 19.2108, mae: 2.7400, huber: 2.3124, swd: 9.4070, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 9.220396\n",
      "        No improvement (20.9877), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 20.4240, mae: 2.4066, huber: 1.9972, swd: 4.0620, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 24.6892, mae: 3.1536, huber: 2.7279, swd: 10.9542, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.5390, mae: 2.6898, huber: 2.2636, swd: 9.2682, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 8.090172\n",
      "Epoch [6/50], Test Losses: mse: 19.5606, mae: 2.7483, huber: 2.3216, swd: 7.3805, target_std: 18.3439\n",
      "Best round's Test MSE: 19.5606, MAE: 2.7483, SWD: 7.3805\n",
      "Best round's Validation MSE: 27.8412, MAE: 3.2507, SWD: 10.4608\n",
      "Best round's Test verification MSE : 19.5606, MAE: 2.7483, SWD: 7.3805\n",
      "Time taken: 145.15 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 28.3003, mae: 2.9434, huber: 2.5261, swd: 10.8648, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 27.0961, mae: 3.2520, huber: 2.8267, swd: 11.0185, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 19.6622, mae: 2.7606, huber: 2.3337, swd: 8.2281, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 18.823378\n",
      "        Val objective improved inf → 19.3545, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 26.5420, mae: 2.7484, huber: 2.3358, swd: 8.7529, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 26.5044, mae: 3.1890, huber: 2.7653, swd: 10.9380, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 18.6232, mae: 2.6779, huber: 2.2527, swd: 7.9925, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 15.465221\n",
      "        Val objective improved 19.3545 → 19.1723, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 24.2444, mae: 2.6369, huber: 2.2249, swd: 7.1167, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 24.5333, mae: 3.1358, huber: 2.7102, swd: 10.6937, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.9537, mae: 2.6705, huber: 2.2446, swd: 8.6279, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 12.899999\n",
      "        Val objective improved 19.1723 → 18.7508, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.8353, mae: 2.5242, huber: 2.1132, swd: 5.7890, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 24.6847, mae: 3.1424, huber: 2.7167, swd: 10.8782, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 18.2842, mae: 2.6945, huber: 2.2685, swd: 9.1688, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 10.796727\n",
      "        No improvement (19.0340), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 19.6191, mae: 2.4029, huber: 1.9934, swd: 4.7093, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 25.2720, mae: 3.1758, huber: 2.7497, swd: 11.8912, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 18.2539, mae: 2.6896, huber: 2.2636, swd: 9.6280, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 9.057329\n",
      "        No improvement (20.5865), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.8335, mae: 2.2978, huber: 1.8898, swd: 4.0061, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 25.0260, mae: 3.1736, huber: 2.7478, swd: 12.0160, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.6004, mae: 2.7019, huber: 2.2763, swd: 10.1689, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 7.899017\n",
      "        No improvement (20.7718), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.2506, mae: 2.1975, huber: 1.7913, swd: 3.4525, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 24.4321, mae: 3.1441, huber: 2.7189, swd: 11.6981, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 18.6381, mae: 2.6834, huber: 2.2586, swd: 10.3880, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 6.969970\n",
      "        No improvement (20.2661), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 15.0552, mae: 2.1175, huber: 1.7128, swd: 3.1463, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 24.1134, mae: 3.1358, huber: 2.7102, swd: 11.5784, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 18.8813, mae: 2.7127, huber: 2.2879, swd: 10.6589, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 6.432319\n",
      "Epoch [8/50], Test Losses: mse: 17.9537, mae: 2.6705, huber: 2.2446, swd: 8.6279, target_std: 18.3439\n",
      "Best round's Test MSE: 17.9537, MAE: 2.6705, SWD: 8.6279\n",
      "Best round's Validation MSE: 24.5333, MAE: 3.1358, SWD: 10.6937\n",
      "Best round's Test verification MSE : 17.9537, MAE: 2.6705, SWD: 8.6279\n",
      "Time taken: 192.17 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 28.4178, mae: 2.9428, huber: 2.5260, swd: 10.0978, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 26.3510, mae: 3.1777, huber: 2.7536, swd: 9.5385, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 18.4184, mae: 2.6683, huber: 2.2433, swd: 7.0585, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 17.672617\n",
      "        Val objective improved inf → 17.0613, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 25.8066, mae: 2.7350, huber: 2.3224, swd: 8.0411, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 25.0281, mae: 3.1358, huber: 2.7114, swd: 9.6951, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 17.0512, mae: 2.5876, huber: 2.1634, swd: 7.0316, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 14.384014\n",
      "        No improvement (17.2541), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 23.8830, mae: 2.6404, huber: 2.2284, swd: 6.7813, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 26.1706, mae: 3.2269, huber: 2.7994, swd: 9.6045, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 18.8396, mae: 2.7110, huber: 2.2852, swd: 7.7955, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 12.400330\n",
      "        No improvement (17.2060), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 22.2047, mae: 2.5556, huber: 2.1441, swd: 5.5241, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 24.5328, mae: 3.1307, huber: 2.7050, swd: 9.5764, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.9060, mae: 2.6444, huber: 2.2198, swd: 8.1853, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 10.430225\n",
      "        No improvement (17.0696), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 20.1167, mae: 2.4406, huber: 2.0308, swd: 4.6292, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 25.7109, mae: 3.2090, huber: 2.7825, swd: 10.8262, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 18.5672, mae: 2.6921, huber: 2.2672, swd: 8.6440, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 8.974616\n",
      "        No improvement (19.0218), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 18.0156, mae: 2.3224, huber: 1.9142, swd: 3.9452, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 24.7820, mae: 3.1627, huber: 2.7366, swd: 10.8059, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.5443, mae: 2.6754, huber: 2.2512, swd: 9.3165, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 7.831933\n",
      "Epoch [6/50], Test Losses: mse: 18.4184, mae: 2.6683, huber: 2.2433, swd: 7.0585, target_std: 18.3439\n",
      "Best round's Test MSE: 18.4184, MAE: 2.6683, SWD: 7.0585\n",
      "Best round's Validation MSE: 26.3510, MAE: 3.1777, SWD: 9.5385\n",
      "Best round's Test verification MSE : 18.4184, MAE: 2.6683, SWD: 7.0585\n",
      "Time taken: 142.90 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_1727)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 18.6442 ± 0.6752\n",
      "  mae: 2.6957 ± 0.0372\n",
      "  huber: 2.2698 ± 0.0366\n",
      "  swd: 7.6890 ± 0.6768\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 26.2418 ± 1.3526\n",
      "  mae: 3.1881 ± 0.0475\n",
      "  huber: 2.7635 ± 0.0481\n",
      "  swd: 10.2310 ± 0.4988\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 480.32 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_1727\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 1.5, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 1.5, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2475a9",
   "metadata": {},
   "source": [
    "##### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.0, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de14ff5",
   "metadata": {},
   "source": [
    "##### MSE + 0.1 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d6a67ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.1148, mae: 2.5399, huber: 2.1319, swd: 11.1521, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 21.1792, mae: 2.8622, huber: 2.4471, swd: 10.2308, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8612, mae: 2.3997, huber: 1.9817, swd: 7.4173, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.229981\n",
      "        Val objective improved inf → 22.2023, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.8631, mae: 2.3858, huber: 1.9804, swd: 9.0211, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.1655, mae: 2.9172, huber: 2.5002, swd: 11.0297, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0000, mae: 2.4150, huber: 1.9963, swd: 7.4583, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 18.765193\n",
      "        No improvement (23.2684), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.9281, mae: 2.2963, huber: 1.8911, swd: 7.6179, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.8268, mae: 2.9988, huber: 2.5786, swd: 11.0151, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.5303, mae: 2.5397, huber: 2.1174, swd: 8.5335, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 16.689858\n",
      "        No improvement (23.9284), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.1585, mae: 2.2009, huber: 1.7958, swd: 6.3269, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 23.0025, mae: 3.0338, huber: 2.6119, swd: 11.1141, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.8038, mae: 2.5822, huber: 2.1596, swd: 8.6860, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 14.791200\n",
      "        No improvement (24.1139), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.6142, mae: 2.1015, huber: 1.6970, swd: 5.2884, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 22.8721, mae: 3.0128, huber: 2.5919, swd: 10.9940, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.8596, mae: 2.5685, huber: 2.1463, swd: 8.5911, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 13.143053\n",
      "        No improvement (23.9715), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.4185, mae: 2.0110, huber: 1.6073, swd: 4.5564, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 24.0272, mae: 3.1003, huber: 2.6766, swd: 11.6394, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.3451, mae: 2.6775, huber: 2.2537, swd: 9.7626, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 11.874145\n",
      "Epoch [6/50], Test Losses: mse: 14.8612, mae: 2.3997, huber: 1.9817, swd: 7.4173, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8612, MAE: 2.3997, SWD: 7.4173\n",
      "Best round's Validation MSE: 21.1792, MAE: 2.8622, SWD: 10.2308\n",
      "Best round's Test verification MSE : 14.8612, MAE: 2.3997, SWD: 7.4173\n",
      "Time taken: 147.72 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.2171, mae: 2.5516, huber: 2.1426, swd: 11.5940, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 20.9641, mae: 2.8739, huber: 2.4574, swd: 10.3933, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.1685, mae: 2.4326, huber: 2.0126, swd: 7.9911, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.376529\n",
      "        Val objective improved inf → 22.0035, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.8903, mae: 2.3882, huber: 1.9819, swd: 9.4451, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 21.9413, mae: 2.9058, huber: 2.4889, swd: 10.9432, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3817, mae: 2.4468, huber: 2.0271, swd: 8.0814, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 18.834816\n",
      "        No improvement (23.0356), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.8208, mae: 2.2910, huber: 1.8854, swd: 7.8328, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.8134, mae: 2.8460, huber: 2.4260, swd: 9.0538, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.9813, mae: 2.5048, huber: 2.0844, swd: 8.3694, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 16.604123\n",
      "        Val objective improved 22.0035 → 20.7188, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 13.9650, mae: 2.1915, huber: 1.7864, swd: 6.4461, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 21.0734, mae: 2.9164, huber: 2.4949, swd: 9.9571, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9360, mae: 2.5858, huber: 2.1626, swd: 9.0514, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 14.609585\n",
      "        No improvement (22.0691), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 12.3095, mae: 2.0771, huber: 1.6730, swd: 5.2716, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 23.2051, mae: 3.0510, huber: 2.6283, swd: 11.4959, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 18.1035, mae: 2.6482, huber: 2.2245, swd: 9.7190, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 12.836637\n",
      "        No improvement (24.3547), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 11.0744, mae: 1.9799, huber: 1.5769, swd: 4.5360, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 22.8963, mae: 3.0551, huber: 2.6314, swd: 10.9816, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 19.2456, mae: 2.7135, huber: 2.2892, swd: 10.5809, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 11.527991\n",
      "        No improvement (23.9945), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 10.0309, mae: 1.8905, huber: 1.4887, swd: 3.9485, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 23.3700, mae: 3.0777, huber: 2.6538, swd: 10.9273, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 19.8168, mae: 2.7606, huber: 2.3350, swd: 10.7379, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 10.425763\n",
      "        No improvement (24.4627), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.2667, mae: 1.8223, huber: 1.4214, swd: 3.5716, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 23.7001, mae: 3.1131, huber: 2.6885, swd: 10.9950, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 20.1240, mae: 2.7791, huber: 2.3531, swd: 10.8337, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 9.623820\n",
      "Epoch [8/50], Test Losses: mse: 15.9813, mae: 2.5048, huber: 2.0844, swd: 8.3694, target_std: 18.3439\n",
      "Best round's Test MSE: 15.9813, MAE: 2.5048, SWD: 8.3694\n",
      "Best round's Validation MSE: 19.8134, MAE: 2.8460, SWD: 9.0538\n",
      "Best round's Test verification MSE : 15.9813, MAE: 2.5048, SWD: 8.3694\n",
      "Time taken: 196.20 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 20.9806, mae: 2.5242, huber: 2.1170, swd: 10.7776, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.4901, mae: 2.8398, huber: 2.4253, swd: 9.3646, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.6089, mae: 2.3776, huber: 1.9600, swd: 6.9946, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.058363\n",
      "        Val objective improved inf → 21.4266, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.7908, mae: 2.3775, huber: 1.9720, swd: 8.7516, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 21.6978, mae: 2.9095, huber: 2.4918, swd: 10.1468, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9826, mae: 2.4272, huber: 2.0076, swd: 7.0631, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 18.665975\n",
      "        No improvement (22.7125), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.4600, mae: 2.2678, huber: 1.8624, swd: 7.0686, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 22.7059, mae: 2.9974, huber: 2.5772, swd: 10.8000, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.4298, mae: 2.5231, huber: 2.1015, swd: 8.0846, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 16.166903\n",
      "        No improvement (23.7859), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 13.5398, mae: 2.1598, huber: 1.7545, swd: 5.7312, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 22.1913, mae: 2.9731, huber: 2.5526, swd: 10.1845, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9129, mae: 2.5536, huber: 2.1313, swd: 8.4047, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 14.112907\n",
      "        No improvement (23.2098), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 11.9990, mae: 2.0554, huber: 1.6508, swd: 4.7416, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 23.3515, mae: 3.0761, huber: 2.6529, swd: 10.8919, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.3943, mae: 2.6107, huber: 2.1868, swd: 8.6821, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 12.473200\n",
      "        No improvement (24.4407), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 10.7737, mae: 1.9598, huber: 1.5561, swd: 4.0209, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 24.4117, mae: 3.1215, huber: 2.6979, swd: 11.3734, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.4149, mae: 2.6883, huber: 2.2629, swd: 9.3434, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 11.175798\n",
      "Epoch [6/50], Test Losses: mse: 14.6089, mae: 2.3776, huber: 1.9600, swd: 6.9946, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6089, MAE: 2.3776, SWD: 6.9946\n",
      "Best round's Validation MSE: 20.4901, MAE: 2.8398, SWD: 9.3646\n",
      "Best round's Test verification MSE : 14.6089, MAE: 2.3776, SWD: 6.9946\n",
      "Time taken: 147.75 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_1444)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.1505 ± 0.5964\n",
      "  mae: 2.4274 ± 0.0555\n",
      "  huber: 2.0087 ± 0.0543\n",
      "  swd: 7.5938 ± 0.5749\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.4943 ± 0.5576\n",
      "  mae: 2.8493 ± 0.0094\n",
      "  huber: 2.4328 ± 0.0101\n",
      "  swd: 9.5497 ± 0.4980\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 491.74 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_1444\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.1, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b666b7",
   "metadata": {},
   "source": [
    "##### MSE + 0.5 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7671797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.2849, mae: 2.5525, huber: 2.1440, swd: 11.1402, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 21.1260, mae: 2.8614, huber: 2.4458, swd: 10.1756, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8905, mae: 2.4026, huber: 1.9843, swd: 7.3950, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 26.855027\n",
      "        Val objective improved inf → 26.2138, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.0233, mae: 2.3981, huber: 1.9920, swd: 9.0136, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.4716, mae: 2.9291, huber: 2.5117, swd: 11.2936, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0057, mae: 2.4175, huber: 1.9982, swd: 7.4265, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.530065\n",
      "        No improvement (28.1184), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.1141, mae: 2.3097, huber: 1.9039, swd: 7.6064, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.2240, mae: 2.9613, huber: 2.5409, swd: 10.5821, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.0393, mae: 2.5189, huber: 2.0971, swd: 8.1310, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 19.917321\n",
      "        No improvement (27.5150), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.2868, mae: 2.2119, huber: 1.8064, swd: 6.2624, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 24.1364, mae: 3.0628, huber: 2.6408, swd: 12.0560, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.0973, mae: 2.5952, huber: 2.1720, swd: 8.9029, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 17.417943\n",
      "        No improvement (30.1644), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.8640, mae: 2.1173, huber: 1.7125, swd: 5.2838, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 22.7756, mae: 2.9970, huber: 2.5757, swd: 10.8187, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.5531, mae: 2.5613, huber: 2.1384, swd: 8.4263, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 15.505917\n",
      "        No improvement (28.1850), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.6163, mae: 2.0244, huber: 1.6204, swd: 4.5136, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 23.3896, mae: 3.0579, huber: 2.6331, swd: 11.0864, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.7303, mae: 2.6429, huber: 2.2188, swd: 9.2339, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 13.873128\n",
      "Epoch [6/50], Test Losses: mse: 14.8905, mae: 2.4026, huber: 1.9843, swd: 7.3950, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8905, MAE: 2.4026, SWD: 7.3950\n",
      "Best round's Validation MSE: 21.1260, MAE: 2.8614, SWD: 10.1756\n",
      "Best round's Test verification MSE : 14.8905, MAE: 2.4026, SWD: 7.3950\n",
      "Time taken: 156.92 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.3106, mae: 2.5605, huber: 2.1511, swd: 11.5271, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 20.9596, mae: 2.8756, huber: 2.4585, swd: 10.3118, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2311, mae: 2.4361, huber: 2.0159, swd: 8.0150, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 27.074183\n",
      "        Val objective improved inf → 26.1156, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.9823, mae: 2.3966, huber: 1.9899, swd: 9.3897, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 21.8679, mae: 2.9052, huber: 2.4876, swd: 10.8249, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3984, mae: 2.4493, huber: 2.0296, swd: 8.0486, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.677211\n",
      "        No improvement (27.2803), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.8761, mae: 2.2971, huber: 1.8912, swd: 7.7325, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.0556, mae: 2.8638, huber: 2.4439, swd: 9.2501, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.8850, mae: 2.5016, huber: 2.0808, swd: 8.2538, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 19.742370\n",
      "        Val objective improved 26.1156 → 24.6807, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 13.9942, mae: 2.1937, huber: 1.7884, swd: 6.3027, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 21.0422, mae: 2.9241, huber: 2.5021, swd: 10.0116, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9513, mae: 2.5896, huber: 2.1659, swd: 9.0287, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 17.145531\n",
      "        No improvement (26.0480), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 12.3667, mae: 2.0804, huber: 1.6760, swd: 5.1536, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.3687, mae: 3.0106, huber: 2.5882, swd: 10.8780, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.7595, mae: 2.6371, huber: 2.2130, swd: 9.4448, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 14.943522\n",
      "        No improvement (27.8077), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 11.1937, mae: 1.9880, huber: 1.5846, swd: 4.4317, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 23.4245, mae: 3.0947, huber: 2.6711, swd: 11.5938, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.8190, mae: 2.7128, huber: 2.2880, swd: 10.2508, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 13.409570\n",
      "        No improvement (29.2214), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 10.2250, mae: 1.9055, huber: 1.5033, swd: 3.8919, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 23.7706, mae: 3.0967, huber: 2.6732, swd: 11.4316, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 19.1632, mae: 2.7002, huber: 2.2760, swd: 10.1956, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 12.170897\n",
      "        No improvement (29.4863), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.4363, mae: 1.8348, huber: 1.4336, swd: 3.4816, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 24.0583, mae: 3.1157, huber: 2.6920, swd: 11.5763, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 19.2176, mae: 2.7083, huber: 2.2834, swd: 10.2038, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 11.177152\n",
      "Epoch [8/50], Test Losses: mse: 15.8850, mae: 2.5016, huber: 2.0808, swd: 8.2538, target_std: 18.3439\n",
      "Best round's Test MSE: 15.8850, MAE: 2.5016, SWD: 8.2538\n",
      "Best round's Validation MSE: 20.0556, MAE: 2.8638, SWD: 9.2501\n",
      "Best round's Test verification MSE : 15.8850, MAE: 2.5016, SWD: 8.2538\n",
      "Time taken: 207.39 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.0795, mae: 2.5333, huber: 2.1257, swd: 10.7251, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.5666, mae: 2.8416, huber: 2.4270, swd: 9.3210, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.6658, mae: 2.3816, huber: 1.9636, swd: 6.9966, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 26.442024\n",
      "        Val objective improved inf → 25.2271, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 17.8440, mae: 2.3842, huber: 1.9784, swd: 8.6506, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 21.4808, mae: 2.9063, huber: 2.4880, swd: 9.7740, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.1026, mae: 2.4301, huber: 2.0103, swd: 7.0380, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.169335\n",
      "        No improvement (26.3678), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.4766, mae: 2.2744, huber: 1.8684, swd: 6.9220, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 22.2669, mae: 2.9979, huber: 2.5760, swd: 10.5514, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.5728, mae: 2.5489, huber: 2.1263, swd: 8.1730, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 18.937616\n",
      "        No improvement (27.5426), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 13.6325, mae: 2.1693, huber: 1.7634, swd: 5.6387, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 21.9909, mae: 2.9740, huber: 2.5518, swd: 9.8950, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9738, mae: 2.5618, huber: 2.1393, swd: 8.4347, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 16.451898\n",
      "        No improvement (26.9385), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.2332, mae: 2.0717, huber: 1.6665, swd: 4.7507, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 23.8009, mae: 3.1008, huber: 2.6769, swd: 11.2496, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.5404, mae: 2.6163, huber: 2.1921, swd: 8.6894, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 14.608551\n",
      "        No improvement (29.4257), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.0843, mae: 1.9827, huber: 1.5785, swd: 4.0699, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 23.5790, mae: 3.0947, huber: 2.6699, swd: 10.9313, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.0235, mae: 2.6576, huber: 2.2327, swd: 9.1252, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 13.119245\n",
      "Epoch [6/50], Test Losses: mse: 14.6658, mae: 2.3816, huber: 1.9636, swd: 6.9966, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6658, MAE: 2.3816, SWD: 6.9966\n",
      "Best round's Validation MSE: 20.5666, MAE: 2.8416, SWD: 9.3210\n",
      "Best round's Test verification MSE : 14.6658, MAE: 2.3816, SWD: 6.9966\n",
      "Time taken: 157.10 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_0453)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.1471 ± 0.5298\n",
      "  mae: 2.4286 ± 0.0523\n",
      "  huber: 2.0096 ± 0.0511\n",
      "  swd: 7.5485 ± 0.5246\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.5827 ± 0.4371\n",
      "  mae: 2.8556 ± 0.0099\n",
      "  huber: 2.4389 ± 0.0084\n",
      "  swd: 9.5822 ± 0.4206\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 521.48 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_0453\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.5, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82013e06",
   "metadata": {},
   "source": [
    "##### MSE + 1.5 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "557978db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.6208, mae: 2.5792, huber: 2.1698, swd: 11.1055, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 21.1509, mae: 2.8728, huber: 2.4557, swd: 10.0698, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.0415, mae: 2.4173, huber: 1.9980, swd: 7.4314, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 38.279035\n",
      "        Val objective improved inf → 36.2557, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.3420, mae: 2.4250, huber: 2.0175, swd: 9.0018, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.2403, mae: 2.9253, huber: 2.5065, swd: 11.0240, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.1285, mae: 2.4286, huber: 2.0085, swd: 7.4331, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 31.844686\n",
      "        No improvement (38.7763), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.4050, mae: 2.3357, huber: 1.9288, swd: 7.5557, target_std: 20.3627\n",
      "Epoch [3/50], Val Losses: mse: 22.4398, mae: 2.9787, huber: 2.5579, swd: 10.6452, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.4774, mae: 2.5476, huber: 2.1247, swd: 8.3974, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 27.738548\n",
      "        No improvement (38.4076), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 14.6485, mae: 2.2417, huber: 1.8353, swd: 6.2393, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 22.9285, mae: 3.0164, huber: 2.5940, swd: 10.9235, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.3427, mae: 2.6176, huber: 2.1934, swd: 9.0101, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 24.007419\n",
      "        No improvement (39.3138), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 13.3644, mae: 2.1554, huber: 1.7498, swd: 5.3591, target_std: 20.3629\n",
      "Epoch [5/50], Val Losses: mse: 23.0955, mae: 3.0197, huber: 2.5979, swd: 11.1341, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.1935, mae: 2.5912, huber: 2.1681, swd: 8.9014, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 21.403085\n",
      "        No improvement (39.7967), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 12.2026, mae: 2.0680, huber: 1.6633, swd: 4.6295, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 23.3854, mae: 3.0564, huber: 2.6326, swd: 11.2568, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.6395, mae: 2.6181, huber: 2.1947, swd: 9.1858, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 19.146758\n",
      "Epoch [6/50], Test Losses: mse: 15.0415, mae: 2.4173, huber: 1.9980, swd: 7.4314, target_std: 18.3439\n",
      "Best round's Test MSE: 15.0415, MAE: 2.4173, SWD: 7.4314\n",
      "Best round's Validation MSE: 21.1509, MAE: 2.8728, SWD: 10.0698\n",
      "Best round's Test verification MSE : 15.0415, MAE: 2.4173, SWD: 7.4314\n",
      "Time taken: 140.53 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.5868, mae: 2.5841, huber: 2.1738, swd: 11.4448, target_std: 20.3629\n",
      "Epoch [1/50], Val Losses: mse: 21.2126, mae: 2.8997, huber: 2.4809, swd: 10.3961, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.4937, mae: 2.4552, huber: 2.0344, swd: 8.1173, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 38.754007\n",
      "        Val objective improved inf → 36.8068, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.2410, mae: 2.4187, huber: 2.0111, swd: 9.3267, target_std: 20.3627\n",
      "Epoch [2/50], Val Losses: mse: 21.9583, mae: 2.9203, huber: 2.5016, swd: 10.8208, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3130, mae: 2.4516, huber: 2.0308, swd: 7.8613, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 32.231064\n",
      "        No improvement (38.1894), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 16.0383, mae: 2.3147, huber: 1.9077, swd: 7.5812, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.5383, mae: 2.8944, huber: 2.4729, swd: 9.5413, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 16.0500, mae: 2.5189, huber: 2.0970, swd: 8.3866, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 27.410129\n",
      "        Val objective improved 36.8068 → 34.8502, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.1355, mae: 2.2087, huber: 1.8021, swd: 6.0887, target_std: 20.3627\n",
      "Epoch [4/50], Val Losses: mse: 21.6165, mae: 2.9643, huber: 2.5412, swd: 10.4809, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9529, mae: 2.5881, huber: 2.1645, swd: 9.0855, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 23.268492\n",
      "        No improvement (37.3379), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 12.5886, mae: 2.0980, huber: 1.6926, swd: 5.0043, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.4366, mae: 3.0222, huber: 2.5982, swd: 10.9142, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.4923, mae: 2.6145, huber: 2.1908, swd: 9.5342, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 20.095031\n",
      "        No improvement (38.8079), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 11.5803, mae: 2.0170, huber: 1.6127, swd: 4.3994, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 23.0601, mae: 3.0846, huber: 2.6590, swd: 11.4078, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.3794, mae: 2.6795, huber: 2.2554, swd: 10.0288, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 18.179383\n",
      "        No improvement (40.1718), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 10.6733, mae: 1.9397, huber: 1.5365, swd: 3.8599, target_std: 20.3631\n",
      "Epoch [7/50], Val Losses: mse: 23.0409, mae: 3.0619, huber: 2.6373, swd: 10.9926, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 18.5461, mae: 2.6811, huber: 2.2569, swd: 10.1218, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 16.463120\n",
      "        No improvement (39.5298), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.9295, mae: 1.8753, huber: 1.4731, swd: 3.4740, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 23.7394, mae: 3.1143, huber: 2.6887, swd: 11.2654, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 19.1030, mae: 2.7154, huber: 2.2904, swd: 10.3518, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 15.140586\n",
      "Epoch [8/50], Test Losses: mse: 16.0500, mae: 2.5189, huber: 2.0970, swd: 8.3866, target_std: 18.3439\n",
      "Best round's Test MSE: 16.0500, MAE: 2.5189, SWD: 8.3866\n",
      "Best round's Validation MSE: 20.5383, MAE: 2.8944, SWD: 9.5413\n",
      "Best round's Test verification MSE : 16.0500, MAE: 2.5189, SWD: 8.3866\n",
      "Time taken: 195.37 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 21.3626, mae: 2.5567, huber: 2.1481, swd: 10.6660, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.4759, mae: 2.8432, huber: 2.4277, swd: 9.1020, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8085, mae: 2.3983, huber: 1.9793, swd: 7.0156, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 37.361545\n",
      "        Val objective improved inf → 34.1289, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 18.1134, mae: 2.4086, huber: 2.0016, swd: 8.5752, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 21.1536, mae: 2.9009, huber: 2.4816, swd: 9.4313, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.1066, mae: 2.4352, huber: 2.0148, swd: 6.9932, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 30.976205\n",
      "        No improvement (35.3005), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.8036, mae: 2.3022, huber: 1.8952, swd: 6.9007, target_std: 20.3632\n",
      "Epoch [3/50], Val Losses: mse: 22.4495, mae: 3.0247, huber: 2.6012, swd: 10.5016, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.1189, mae: 2.5883, huber: 2.1643, swd: 8.5240, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 26.154634\n",
      "        No improvement (38.2019), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 13.9488, mae: 2.1971, huber: 1.7905, swd: 5.5957, target_std: 20.3625\n",
      "Epoch [4/50], Val Losses: mse: 22.8404, mae: 3.0193, huber: 2.5958, swd: 10.6553, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.9542, mae: 2.5642, huber: 2.1411, swd: 8.4445, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.342425\n",
      "        No improvement (38.8233), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 12.5471, mae: 2.0994, huber: 1.6935, swd: 4.6902, target_std: 20.3633\n",
      "Epoch [5/50], Val Losses: mse: 23.5440, mae: 3.0965, huber: 2.6717, swd: 11.0317, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.8920, mae: 2.6421, huber: 2.2172, swd: 9.0174, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 19.582423\n",
      "        No improvement (40.0917), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 11.4689, mae: 2.0125, huber: 1.6078, swd: 4.0635, target_std: 20.3627\n",
      "Epoch [6/50], Val Losses: mse: 23.5136, mae: 3.0961, huber: 2.6710, swd: 10.9026, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.9611, mae: 2.6510, huber: 2.2255, swd: 9.0443, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 17.564041\n",
      "Epoch [6/50], Test Losses: mse: 14.8085, mae: 2.3983, huber: 1.9793, swd: 7.0156, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8085, MAE: 2.3983, SWD: 7.0156\n",
      "Best round's Validation MSE: 20.4759, MAE: 2.8432, SWD: 9.1020\n",
      "Best round's Test verification MSE : 14.8085, MAE: 2.3983, SWD: 7.0156\n",
      "Time taken: 147.48 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred336_20250508_1719)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.3000 ± 0.5388\n",
      "  mae: 2.4448 ± 0.0529\n",
      "  huber: 2.0248 ± 0.0517\n",
      "  swd: 7.6112 ± 0.5740\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.7217 ± 0.3046\n",
      "  mae: 2.8701 ± 0.0210\n",
      "  huber: 2.4521 ± 0.0186\n",
      "  swd: 9.5710 ± 0.3957\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 483.50 seconds\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred336_20250508_1719\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 1.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 1.5, 0.0]\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58749050",
   "metadata": {},
   "source": [
    "#### pred=720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "258e30b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 373\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 373\n",
      "Validation Batches: 47\n",
      "Test Batches: 101\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.1677, mae: 2.8764, huber: 2.4645, swd: 14.7016, target_std: 20.3717\n",
      "Epoch [1/50], Val Losses: mse: 24.4334, mae: 3.1730, huber: 2.7519, swd: 9.8117, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 16.9963, mae: 2.6043, huber: 2.1846, swd: 8.0375, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.464471\n",
      "        Val objective improved inf → 2.7519, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 26.9135, mae: 2.7359, huber: 2.3266, swd: 13.3101, target_std: 20.3711\n",
      "Epoch [2/50], Val Losses: mse: 24.1353, mae: 3.1678, huber: 2.7446, swd: 9.1954, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.1743, mae: 2.6213, huber: 2.2005, swd: 8.0122, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.326609\n",
      "        Val objective improved 2.7519 → 2.7446, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 24.6198, mae: 2.6202, huber: 2.2122, swd: 11.5427, target_std: 20.3719\n",
      "Epoch [3/50], Val Losses: mse: 26.4326, mae: 3.2868, huber: 2.8619, swd: 10.7403, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 18.3570, mae: 2.6830, huber: 2.2615, swd: 8.7487, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.212177\n",
      "        No improvement (2.8619), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.8505, mae: 2.4698, huber: 2.0634, swd: 9.4835, target_std: 20.3714\n",
      "Epoch [4/50], Val Losses: mse: 27.8485, mae: 3.3789, huber: 2.9519, swd: 11.6282, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 21.8704, mae: 2.8423, huber: 2.4182, swd: 11.4602, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.063381\n",
      "        No improvement (2.9519), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 19.5339, mae: 2.3306, huber: 1.9258, swd: 7.8544, target_std: 20.3711\n",
      "Epoch [5/50], Val Losses: mse: 28.5732, mae: 3.4371, huber: 3.0085, swd: 12.0188, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 20.7074, mae: 2.8641, huber: 2.4399, swd: 10.4887, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 1.925751\n",
      "        No improvement (3.0085), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.7016, mae: 2.2094, huber: 1.8060, swd: 6.7163, target_std: 20.3720\n",
      "Epoch [6/50], Val Losses: mse: 28.0926, mae: 3.4226, huber: 2.9940, swd: 11.4080, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 21.3255, mae: 2.9022, huber: 2.4772, swd: 10.7240, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 1.806024\n",
      "        No improvement (2.9940), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 16.3144, mae: 2.1094, huber: 1.7074, swd: 5.9981, target_std: 20.3714\n",
      "Epoch [7/50], Val Losses: mse: 28.7421, mae: 3.4854, huber: 3.0554, swd: 11.4633, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 23.5167, mae: 3.0129, huber: 2.5867, swd: 12.3047, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 1.707379\n",
      "Epoch [7/50], Test Losses: mse: 17.1743, mae: 2.6213, huber: 2.2005, swd: 8.0122, target_std: 18.3446\n",
      "Best round's Test MSE: 17.1743, MAE: 2.6213, SWD: 8.0122\n",
      "Best round's Validation MSE: 24.1353, MAE: 3.1678\n",
      "Best round's Test verification MSE : 17.1743, MAE: 2.6213, SWD: 8.0122\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.0193, mae: 2.8628, huber: 2.4509, swd: 13.5114, target_std: 20.3712\n",
      "Epoch [1/50], Val Losses: mse: 24.3871, mae: 3.1722, huber: 2.7502, swd: 8.8069, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.2105, mae: 2.6178, huber: 2.1979, swd: 7.5355, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.450904\n",
      "        Val objective improved inf → 2.7502, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 26.2772, mae: 2.7046, huber: 2.2958, swd: 11.8017, target_std: 20.3711\n",
      "Epoch [2/50], Val Losses: mse: 25.0428, mae: 3.2132, huber: 2.7890, swd: 9.1953, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.5835, mae: 2.6512, huber: 2.2302, swd: 7.6654, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.295758\n",
      "        No improvement (2.7890), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 23.2030, mae: 2.5445, huber: 2.1368, swd: 9.6495, target_std: 20.3714\n",
      "Epoch [3/50], Val Losses: mse: 26.3370, mae: 3.2885, huber: 2.8619, swd: 9.9603, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 18.2609, mae: 2.7224, huber: 2.2994, swd: 8.0189, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.136798\n",
      "        No improvement (2.8619), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 20.5658, mae: 2.3765, huber: 1.9708, swd: 7.9891, target_std: 20.3712\n",
      "Epoch [4/50], Val Losses: mse: 29.8814, mae: 3.4994, huber: 3.0700, swd: 12.2479, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 20.2080, mae: 2.8461, huber: 2.4211, swd: 9.2232, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 1.970842\n",
      "        No improvement (3.0700), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 18.3967, mae: 2.2315, huber: 1.8276, swd: 6.7465, target_std: 20.3716\n",
      "Epoch [5/50], Val Losses: mse: 29.5940, mae: 3.5180, huber: 3.0874, swd: 11.7010, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 21.3461, mae: 2.8873, huber: 2.4617, swd: 9.8964, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 1.827576\n",
      "        No improvement (3.0874), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 16.4429, mae: 2.1045, huber: 1.7022, swd: 5.6785, target_std: 20.3717\n",
      "Epoch [6/50], Val Losses: mse: 30.8232, mae: 3.5817, huber: 3.1504, swd: 12.3979, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 22.1023, mae: 2.9581, huber: 2.5314, swd: 10.1736, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 1.702245\n",
      "Epoch [6/50], Test Losses: mse: 17.2105, mae: 2.6178, huber: 2.1979, swd: 7.5355, target_std: 18.3446\n",
      "Best round's Test MSE: 17.2105, MAE: 2.6178, SWD: 7.5355\n",
      "Best round's Validation MSE: 24.3871, MAE: 3.1722\n",
      "Best round's Test verification MSE : 17.2105, MAE: 2.6178, SWD: 7.5355\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 28.7763, mae: 2.8515, huber: 2.4402, swd: 15.1775, target_std: 20.3714\n",
      "Epoch [1/50], Val Losses: mse: 25.6870, mae: 3.2342, huber: 2.8114, swd: 11.3408, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.2381, mae: 2.6224, huber: 2.2016, swd: 8.6023, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.440161\n",
      "        Val objective improved inf → 2.8114, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 25.9630, mae: 2.6811, huber: 2.2722, swd: 13.2382, target_std: 20.3716\n",
      "Epoch [2/50], Val Losses: mse: 25.0433, mae: 3.2333, huber: 2.8078, swd: 10.2789, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.7277, mae: 2.6652, huber: 2.2423, swd: 8.8629, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.272207\n",
      "        Val objective improved 2.8114 → 2.8078, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 23.4775, mae: 2.5434, huber: 2.1358, swd: 11.3895, target_std: 20.3717\n",
      "Epoch [3/50], Val Losses: mse: 26.1967, mae: 3.3073, huber: 2.8798, swd: 10.9456, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 18.7623, mae: 2.7332, huber: 2.3096, swd: 9.5106, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.135782\n",
      "        No improvement (2.8798), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.2262, mae: 2.4027, huber: 1.9966, swd: 9.7976, target_std: 20.3711\n",
      "Epoch [4/50], Val Losses: mse: 27.2971, mae: 3.3963, huber: 2.9668, swd: 11.5209, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 19.9463, mae: 2.8273, huber: 2.4024, swd: 10.3885, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 1.996573\n",
      "        No improvement (2.9668), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 19.2393, mae: 2.2795, huber: 1.8749, swd: 8.4299, target_std: 20.3717\n",
      "Epoch [5/50], Val Losses: mse: 28.7986, mae: 3.4856, huber: 3.0546, swd: 12.5878, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 21.1205, mae: 2.9149, huber: 2.4888, swd: 11.0958, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 1.874865\n",
      "        No improvement (3.0546), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.5184, mae: 2.1662, huber: 1.7630, swd: 7.3308, target_std: 20.3714\n",
      "Epoch [6/50], Val Losses: mse: 29.1357, mae: 3.5104, huber: 3.0789, swd: 12.5148, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 22.2267, mae: 2.9646, huber: 2.5381, swd: 11.7609, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 1.763033\n",
      "        No improvement (3.0789), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 16.2453, mae: 2.0788, huber: 1.6771, swd: 6.5786, target_std: 20.3718\n",
      "Epoch [7/50], Val Losses: mse: 30.4663, mae: 3.5944, huber: 3.1623, swd: 13.2582, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 22.8864, mae: 3.0019, huber: 2.5749, swd: 12.0706, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 1.677126\n",
      "Epoch [7/50], Test Losses: mse: 17.7277, mae: 2.6652, huber: 2.2423, swd: 8.8629, target_std: 18.3446\n",
      "Best round's Test MSE: 17.7277, MAE: 2.6652, SWD: 8.8629\n",
      "Best round's Validation MSE: 25.0433, MAE: 3.2333\n",
      "Best round's Test verification MSE : 17.7277, MAE: 2.6652, SWD: 8.8629\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (TimeMixer_ettm2_seq336_pred720_20250430_2222)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 17.3708 ± 0.2528\n",
      "  mae: 2.6347 ± 0.0216\n",
      "  huber: 2.2136 ± 0.0203\n",
      "  swd: 8.1369 ± 0.5490\n",
      "  target_std: 18.3446 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 24.5219 ± 0.3828\n",
      "  mae: 3.1911 ± 0.0299\n",
      "  huber: 2.7675 ± 0.0286\n",
      "  swd: 9.4271 ± 0.6229\n",
      "  target_std: 20.5636 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: TimeMixer_ettm2_seq336_pred720_20250430_2222\n",
      "Model: TimeMixer\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatTimeMixerConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=720,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a609043",
   "metadata": {},
   "source": [
    "### PatchTST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60212f",
   "metadata": {},
   "source": [
    "#### pred=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2cc43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 12.8992, mae: 1.9811, huber: 1.5850, swd: 6.4544, target_std: 20.3533\n",
      "Epoch [1/50], Val Losses: mse: 12.0627, mae: 2.1191, huber: 1.7197, swd: 6.3282, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.0431, mae: 1.8453, huber: 1.4435, swd: 4.6360, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.584994\n",
      "        Val objective improved inf → 1.7197, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.6598, mae: 1.8611, huber: 1.4698, swd: 5.8257, target_std: 20.3529\n",
      "Epoch [2/50], Val Losses: mse: 11.7199, mae: 2.0984, huber: 1.6995, swd: 6.1971, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 8.9163, mae: 1.8554, huber: 1.4510, swd: 4.6325, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.469797\n",
      "        Val objective improved 1.7197 → 1.6995, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.2283, mae: 1.8261, huber: 1.4365, swd: 5.5184, target_std: 20.3533\n",
      "Epoch [3/50], Val Losses: mse: 11.9520, mae: 2.1069, huber: 1.7085, swd: 6.3792, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.0936, mae: 1.8539, huber: 1.4507, swd: 4.7599, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.436485\n",
      "        No improvement (1.7085), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 10.9354, mae: 1.8017, huber: 1.4130, swd: 5.2988, target_std: 20.3542\n",
      "Epoch [4/50], Val Losses: mse: 12.1415, mae: 2.0960, huber: 1.7001, swd: 6.5289, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.0111, mae: 1.8382, huber: 1.4368, swd: 4.6641, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.413010\n",
      "        No improvement (1.7001), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 10.5419, mae: 1.7765, huber: 1.3886, swd: 4.9892, target_std: 20.3538\n",
      "Epoch [5/50], Val Losses: mse: 11.9210, mae: 2.0898, huber: 1.6922, swd: 6.3113, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.1643, mae: 1.8556, huber: 1.4524, swd: 4.8149, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.388583\n",
      "        Val objective improved 1.6995 → 1.6922, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 10.1885, mae: 1.7535, huber: 1.3659, swd: 4.7046, target_std: 20.3540\n",
      "Epoch [6/50], Val Losses: mse: 11.7135, mae: 2.0781, huber: 1.6814, swd: 6.2067, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.3205, mae: 1.8797, huber: 1.4755, swd: 4.9454, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.365918\n",
      "        Val objective improved 1.6922 → 1.6814, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 9.8781, mae: 1.7309, huber: 1.3440, swd: 4.4578, target_std: 20.3533\n",
      "Epoch [7/50], Val Losses: mse: 12.1034, mae: 2.1319, huber: 1.7309, swd: 6.2872, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.5108, mae: 1.9139, huber: 1.5074, swd: 4.9418, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.343982\n",
      "        No improvement (1.7309), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 9.6724, mae: 1.7127, huber: 1.3262, swd: 4.2975, target_std: 20.3528\n",
      "Epoch [8/50], Val Losses: mse: 12.0922, mae: 2.1311, huber: 1.7303, swd: 6.3664, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.6268, mae: 1.9100, huber: 1.5038, swd: 5.0529, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.326225\n",
      "        No improvement (1.7303), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 9.4865, mae: 1.6966, huber: 1.3106, swd: 4.1691, target_std: 20.3537\n",
      "Epoch [9/50], Val Losses: mse: 12.6572, mae: 2.1812, huber: 1.7779, swd: 6.5992, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.7663, mae: 1.9233, huber: 1.5170, swd: 5.0379, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.310643\n",
      "        No improvement (1.7779), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 9.3194, mae: 1.6810, huber: 1.2954, swd: 4.0354, target_std: 20.3533\n",
      "Epoch [10/50], Val Losses: mse: 12.9261, mae: 2.2055, huber: 1.8021, swd: 6.7911, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 10.1945, mae: 1.9458, huber: 1.5391, swd: 5.3548, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.295430\n",
      "        No improvement (1.8021), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 9.1203, mae: 1.6648, huber: 1.2798, swd: 3.8912, target_std: 20.3529\n",
      "Epoch [11/50], Val Losses: mse: 12.7937, mae: 2.1851, huber: 1.7823, swd: 6.6870, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 9.7811, mae: 1.9467, huber: 1.5384, swd: 5.1082, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.279785\n",
      "Epoch [11/50], Test Losses: mse: 9.3205, mae: 1.8797, huber: 1.4755, swd: 4.9454, target_std: 18.3806\n",
      "Best round's Test MSE: 9.3205, MAE: 1.8797, SWD: 4.9454\n",
      "Best round's Validation MSE: 11.7135, MAE: 2.0781\n",
      "Best round's Test verification MSE : 9.3205, MAE: 1.8797, SWD: 4.9454\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 12.9285, mae: 1.9838, huber: 1.5877, swd: 6.2185, target_std: 20.3535\n",
      "Epoch [1/50], Val Losses: mse: 12.1149, mae: 2.1376, huber: 1.7353, swd: 6.1271, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.0893, mae: 1.8644, huber: 1.4604, swd: 4.4478, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.587657\n",
      "        Val objective improved inf → 1.7353, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.7168, mae: 1.8631, huber: 1.4722, swd: 5.6800, target_std: 20.3527\n",
      "Epoch [2/50], Val Losses: mse: 11.7827, mae: 2.0994, huber: 1.6988, swd: 5.9541, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.1675, mae: 1.8537, huber: 1.4510, swd: 4.5762, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.472169\n",
      "        Val objective improved 1.7353 → 1.6988, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.3664, mae: 1.8287, huber: 1.4392, swd: 5.4418, target_std: 20.3529\n",
      "Epoch [3/50], Val Losses: mse: 11.7145, mae: 2.0795, huber: 1.6813, swd: 5.8970, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.1416, mae: 1.8492, huber: 1.4470, swd: 4.5772, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.439239\n",
      "        Val objective improved 1.6988 → 1.6813, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.0080, mae: 1.8007, huber: 1.4120, swd: 5.1852, target_std: 20.3530\n",
      "Epoch [4/50], Val Losses: mse: 11.6856, mae: 2.1033, huber: 1.7028, swd: 5.9537, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.1966, mae: 1.8685, huber: 1.4637, swd: 4.5900, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.411968\n",
      "        No improvement (1.7028), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.6532, mae: 1.7754, huber: 1.3874, swd: 4.9168, target_std: 20.3540\n",
      "Epoch [5/50], Val Losses: mse: 12.1348, mae: 2.1103, huber: 1.7104, swd: 6.1894, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.1180, mae: 1.8553, huber: 1.4511, swd: 4.4684, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.387386\n",
      "        No improvement (1.7104), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 10.2853, mae: 1.7537, huber: 1.3663, swd: 4.6325, target_std: 20.3537\n",
      "Epoch [6/50], Val Losses: mse: 12.2680, mae: 2.1228, huber: 1.7223, swd: 6.3082, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.7247, mae: 1.8884, huber: 1.4850, swd: 4.9692, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.366267\n",
      "        No improvement (1.7223), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 9.9607, mae: 1.7334, huber: 1.3466, swd: 4.3774, target_std: 20.3523\n",
      "Epoch [7/50], Val Losses: mse: 12.5763, mae: 2.1718, huber: 1.7686, swd: 6.2565, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.7630, mae: 1.9045, huber: 1.4987, swd: 4.8016, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.346560\n",
      "        No improvement (1.7686), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 9.6916, mae: 1.7114, huber: 1.3249, swd: 4.1665, target_std: 20.3535\n",
      "Epoch [8/50], Val Losses: mse: 12.7414, mae: 2.1922, huber: 1.7867, swd: 6.3432, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 10.0521, mae: 1.9663, huber: 1.5575, swd: 5.0315, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.324899\n",
      "Epoch [8/50], Test Losses: mse: 9.1416, mae: 1.8492, huber: 1.4470, swd: 4.5772, target_std: 18.3806\n",
      "Best round's Test MSE: 9.1416, MAE: 1.8492, SWD: 4.5772\n",
      "Best round's Validation MSE: 11.7145, MAE: 2.0795\n",
      "Best round's Test verification MSE : 9.1416, MAE: 1.8492, SWD: 4.5772\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 12.8499, mae: 1.9749, huber: 1.5789, swd: 5.8061, target_std: 20.3527\n",
      "Epoch [1/50], Val Losses: mse: 12.1598, mae: 2.1297, huber: 1.7313, swd: 5.8780, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.1650, mae: 1.8688, huber: 1.4650, swd: 4.2818, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.578852\n",
      "        Val objective improved inf → 1.7313, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.6983, mae: 1.8628, huber: 1.4723, swd: 5.3004, target_std: 20.3535\n",
      "Epoch [2/50], Val Losses: mse: 11.9595, mae: 2.1035, huber: 1.7055, swd: 5.8655, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.2735, mae: 1.8859, huber: 1.4810, swd: 4.4687, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.472264\n",
      "        Val objective improved 1.7313 → 1.7055, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.3374, mae: 1.8304, huber: 1.4411, swd: 5.0726, target_std: 20.3531\n",
      "Epoch [3/50], Val Losses: mse: 12.1500, mae: 2.0936, huber: 1.6970, swd: 5.9079, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.1450, mae: 1.8484, huber: 1.4454, swd: 4.2762, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.441122\n",
      "        Val objective improved 1.7055 → 1.6970, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.0265, mae: 1.8039, huber: 1.4155, swd: 4.8578, target_std: 20.3542\n",
      "Epoch [4/50], Val Losses: mse: 12.3646, mae: 2.1265, huber: 1.7274, swd: 5.9410, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.5107, mae: 1.8793, huber: 1.4748, swd: 4.5084, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.415533\n",
      "        No improvement (1.7274), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 10.7141, mae: 1.7804, huber: 1.3928, swd: 4.6552, target_std: 20.3530\n",
      "Epoch [5/50], Val Losses: mse: 11.6335, mae: 2.0706, huber: 1.6733, swd: 5.4891, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.2888, mae: 1.8617, huber: 1.4576, swd: 4.4216, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.392759\n",
      "        Val objective improved 1.6970 → 1.6733, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 10.3502, mae: 1.7576, huber: 1.3704, swd: 4.3888, target_std: 20.3539\n",
      "Epoch [6/50], Val Losses: mse: 11.7645, mae: 2.0816, huber: 1.6835, swd: 5.6123, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.2496, mae: 1.8759, huber: 1.4706, swd: 4.3737, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.370389\n",
      "        No improvement (1.6835), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 10.0373, mae: 1.7369, huber: 1.3503, swd: 4.1352, target_std: 20.3534\n",
      "Epoch [7/50], Val Losses: mse: 11.8217, mae: 2.0976, huber: 1.6982, swd: 5.6242, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.4890, mae: 1.8904, huber: 1.4845, swd: 4.5194, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.350261\n",
      "        No improvement (1.6982), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 9.7944, mae: 1.7170, huber: 1.3308, swd: 3.9731, target_std: 20.3526\n",
      "Epoch [8/50], Val Losses: mse: 12.2891, mae: 2.1339, huber: 1.7342, swd: 5.8431, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.8043, mae: 1.9002, huber: 1.4956, swd: 4.7038, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.330752\n",
      "        No improvement (1.7342), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 9.5956, mae: 1.7002, huber: 1.3143, swd: 3.8184, target_std: 20.3540\n",
      "Epoch [9/50], Val Losses: mse: 12.3558, mae: 2.1516, huber: 1.7495, swd: 5.7598, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.7386, mae: 1.9046, huber: 1.4980, swd: 4.5554, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.314297\n",
      "        No improvement (1.7495), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 9.4087, mae: 1.6844, huber: 1.2988, swd: 3.6920, target_std: 20.3540\n",
      "Epoch [10/50], Val Losses: mse: 12.2503, mae: 2.1568, huber: 1.7539, swd: 5.7034, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 9.5440, mae: 1.9144, huber: 1.5071, swd: 4.4763, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.298803\n",
      "Epoch [10/50], Test Losses: mse: 9.2888, mae: 1.8617, huber: 1.4576, swd: 4.4216, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2888, MAE: 1.8617, SWD: 4.4216\n",
      "Best round's Validation MSE: 11.6335, MAE: 2.0706\n",
      "Best round's Test verification MSE : 9.2888, MAE: 1.8617, SWD: 4.4216\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred96_20250430_2026)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.2503 ± 0.0779\n",
      "  mae: 1.8635 ± 0.0125\n",
      "  huber: 1.4600 ± 0.0118\n",
      "  swd: 4.6481 ± 0.2197\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 11.6872 ± 0.0380\n",
      "  mae: 2.0761 ± 0.0039\n",
      "  huber: 1.6787 ± 0.0038\n",
      "  swd: 5.8643 ± 0.2939\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred96_20250430_2026\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439fe8f",
   "metadata": {},
   "source": [
    "#### pred=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9d5b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 377\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 377\n",
      "Validation Batches: 51\n",
      "Test Batches: 105\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 17.6480, mae: 2.2844, huber: 1.8813, swd: 9.1927, target_std: 20.3579\n",
      "Epoch [1/50], Val Losses: mse: 16.4263, mae: 2.4967, huber: 2.0876, swd: 8.3535, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 11.8831, mae: 2.1227, huber: 1.7119, swd: 6.0238, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.881267\n",
      "        Val objective improved inf → 2.0876, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.0316, mae: 2.1625, huber: 1.7638, swd: 8.2410, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 16.1312, mae: 2.4648, huber: 2.0575, swd: 8.1882, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.6497, mae: 2.1489, huber: 1.7389, swd: 6.5203, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.763841\n",
      "        Val objective improved 2.0876 → 2.0575, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.3033, mae: 2.1187, huber: 1.7213, swd: 7.7150, target_std: 20.3578\n",
      "Epoch [3/50], Val Losses: mse: 16.1358, mae: 2.4753, huber: 2.0675, swd: 8.2421, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 12.7909, mae: 2.1680, huber: 1.7570, swd: 6.7024, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.721328\n",
      "        No improvement (2.0675), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 14.5968, mae: 2.0810, huber: 1.6843, swd: 7.1268, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 16.5094, mae: 2.5006, huber: 2.0897, swd: 8.4753, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 12.8478, mae: 2.1723, huber: 1.7607, swd: 6.7346, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.684311\n",
      "        No improvement (2.0897), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 13.9979, mae: 2.0441, huber: 1.6478, swd: 6.6152, target_std: 20.3578\n",
      "Epoch [5/50], Val Losses: mse: 16.0970, mae: 2.4908, huber: 2.0794, swd: 8.1896, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.7123, mae: 2.1873, huber: 1.7745, swd: 6.7455, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.647812\n",
      "        No improvement (2.0794), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 13.4592, mae: 2.0086, huber: 1.6131, swd: 6.1949, target_std: 20.3580\n",
      "Epoch [6/50], Val Losses: mse: 17.6079, mae: 2.5669, huber: 2.1563, swd: 9.3352, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 13.2589, mae: 2.2285, huber: 1.8148, swd: 7.1142, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.613062\n",
      "        No improvement (2.1563), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 13.0651, mae: 1.9828, huber: 1.5876, swd: 5.8873, target_std: 20.3577\n",
      "Epoch [7/50], Val Losses: mse: 18.3227, mae: 2.6246, huber: 2.2107, swd: 9.7633, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 13.3388, mae: 2.2220, huber: 1.8083, swd: 6.9669, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.587644\n",
      "Epoch [7/50], Test Losses: mse: 12.6497, mae: 2.1489, huber: 1.7389, swd: 6.5203, target_std: 18.3527\n",
      "Best round's Test MSE: 12.6497, MAE: 2.1489, SWD: 6.5203\n",
      "Best round's Validation MSE: 16.1312, MAE: 2.4648\n",
      "Best round's Test verification MSE : 12.6497, MAE: 2.1489, SWD: 6.5203\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 17.7072, mae: 2.2805, huber: 1.8780, swd: 9.5887, target_std: 20.3580\n",
      "Epoch [1/50], Val Losses: mse: 16.6526, mae: 2.4955, huber: 2.0862, swd: 8.9750, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 11.7421, mae: 2.1146, huber: 1.7038, swd: 6.1142, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.877973\n",
      "        Val objective improved inf → 2.0862, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.1974, mae: 2.1612, huber: 1.7629, swd: 8.7136, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 15.8241, mae: 2.4884, huber: 2.0772, swd: 8.3535, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.1582, mae: 2.1632, huber: 1.7508, swd: 6.5358, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.762914\n",
      "        Val objective improved 2.0862 → 2.0772, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 15.4067, mae: 2.1214, huber: 1.7241, swd: 8.1230, target_std: 20.3577\n",
      "Epoch [3/50], Val Losses: mse: 16.0075, mae: 2.4739, huber: 2.0641, swd: 8.4006, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 12.0101, mae: 2.1241, huber: 1.7126, swd: 6.3727, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.724064\n",
      "        Val objective improved 2.0772 → 2.0641, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.6577, mae: 2.0835, huber: 1.6870, swd: 7.4721, target_std: 20.3577\n",
      "Epoch [4/50], Val Losses: mse: 16.7923, mae: 2.5368, huber: 2.1239, swd: 8.9555, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 12.2674, mae: 2.1825, huber: 1.7688, swd: 6.4782, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.686959\n",
      "        No improvement (2.1239), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 13.8915, mae: 2.0416, huber: 1.6457, swd: 6.8134, target_std: 20.3578\n",
      "Epoch [5/50], Val Losses: mse: 17.2848, mae: 2.5449, huber: 2.1339, swd: 9.2394, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.3217, mae: 2.1463, huber: 1.7347, swd: 6.5421, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.645696\n",
      "        No improvement (2.1339), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 13.4961, mae: 2.0131, huber: 1.6175, swd: 6.4604, target_std: 20.3578\n",
      "Epoch [6/50], Val Losses: mse: 16.9838, mae: 2.5427, huber: 2.1302, swd: 8.8892, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 12.5400, mae: 2.1915, huber: 1.7781, swd: 6.6486, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.617503\n",
      "        No improvement (2.1302), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 13.1289, mae: 1.9847, huber: 1.5896, swd: 6.1428, target_std: 20.3577\n",
      "Epoch [7/50], Val Losses: mse: 17.8428, mae: 2.6015, huber: 2.1872, swd: 9.5201, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 12.9582, mae: 2.2248, huber: 1.8103, swd: 6.9622, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.589587\n",
      "        No improvement (2.1872), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 12.8004, mae: 1.9609, huber: 1.5662, swd: 5.8804, target_std: 20.3578\n",
      "Epoch [8/50], Val Losses: mse: 17.6748, mae: 2.6110, huber: 2.1981, swd: 9.5818, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 12.9396, mae: 2.2593, huber: 1.8428, swd: 6.9950, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.566228\n",
      "Epoch [8/50], Test Losses: mse: 12.0101, mae: 2.1241, huber: 1.7126, swd: 6.3727, target_std: 18.3527\n",
      "Best round's Test MSE: 12.0101, MAE: 2.1241, SWD: 6.3727\n",
      "Best round's Validation MSE: 16.0075, MAE: 2.4739\n",
      "Best round's Test verification MSE : 12.0101, MAE: 2.1241, SWD: 6.3727\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 17.5678, mae: 2.2766, huber: 1.8741, swd: 8.0741, target_std: 20.3577\n",
      "Epoch [1/50], Val Losses: mse: 16.1012, mae: 2.4657, huber: 2.0576, swd: 7.2046, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 11.7931, mae: 2.1221, huber: 1.7108, swd: 5.1984, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 1.874127\n",
      "        Val objective improved inf → 2.0576, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.1055, mae: 2.1608, huber: 1.7627, swd: 7.3041, target_std: 20.3578\n",
      "Epoch [2/50], Val Losses: mse: 16.7316, mae: 2.5119, huber: 2.1020, swd: 7.5941, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.1537, mae: 2.1195, huber: 1.7096, swd: 5.4090, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.762651\n",
      "        No improvement (2.1020), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 15.4883, mae: 2.1254, huber: 1.7280, swd: 6.9261, target_std: 20.3579\n",
      "Epoch [3/50], Val Losses: mse: 15.9347, mae: 2.4567, huber: 2.0468, swd: 7.1926, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 11.8944, mae: 2.1416, huber: 1.7291, swd: 5.3170, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.728012\n",
      "        Val objective improved 2.0576 → 2.0468, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 14.7968, mae: 2.0905, huber: 1.6934, swd: 6.4287, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 16.1682, mae: 2.4777, huber: 2.0686, swd: 7.2684, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 12.2773, mae: 2.1416, huber: 1.7301, swd: 5.5399, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.693396\n",
      "        No improvement (2.0686), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 14.2165, mae: 2.0573, huber: 1.6608, swd: 6.0101, target_std: 20.3580\n",
      "Epoch [5/50], Val Losses: mse: 16.5000, mae: 2.4824, huber: 2.0743, swd: 7.4607, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.3833, mae: 2.1447, huber: 1.7332, swd: 5.5597, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.660822\n",
      "        No improvement (2.0743), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 13.7080, mae: 2.0270, huber: 1.6311, swd: 5.6444, target_std: 20.3576\n",
      "Epoch [6/50], Val Losses: mse: 16.6197, mae: 2.5143, huber: 2.1019, swd: 7.4779, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 12.4047, mae: 2.1863, huber: 1.7727, swd: 5.6152, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.631092\n",
      "        No improvement (2.1019), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 13.4495, mae: 2.0052, huber: 1.6097, swd: 5.4487, target_std: 20.3580\n",
      "Epoch [7/50], Val Losses: mse: 17.1756, mae: 2.5667, huber: 2.1534, swd: 7.3963, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 12.8734, mae: 2.2398, huber: 1.8233, swd: 5.5569, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.609658\n",
      "        No improvement (2.1534), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 13.0815, mae: 1.9796, huber: 1.5845, swd: 5.1903, target_std: 20.3580\n",
      "Epoch [8/50], Val Losses: mse: 18.3844, mae: 2.6590, huber: 2.2445, swd: 8.3229, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 13.5366, mae: 2.2971, huber: 1.8801, swd: 6.0791, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.584515\n",
      "Epoch [8/50], Test Losses: mse: 11.8944, mae: 2.1416, huber: 1.7291, swd: 5.3170, target_std: 18.3527\n",
      "Best round's Test MSE: 11.8944, MAE: 2.1416, SWD: 5.3170\n",
      "Best round's Validation MSE: 15.9347, MAE: 2.4567\n",
      "Best round's Test verification MSE : 11.8944, MAE: 2.1416, SWD: 5.3170\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred196_20250430_2033)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 12.1847 ± 0.3321\n",
      "  mae: 2.1382 ± 0.0104\n",
      "  huber: 1.7269 ± 0.0108\n",
      "  swd: 6.0700 ± 0.5358\n",
      "  target_std: 18.3527 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 16.0245 ± 0.0811\n",
      "  mae: 2.4651 ± 0.0070\n",
      "  huber: 2.0561 ± 0.0072\n",
      "  swd: 7.9271 ± 0.5266\n",
      "  target_std: 20.5630 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred196_20250430_2033\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=196,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3740",
   "metadata": {},
   "source": [
    "#### 336-336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a22760",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93ffcba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.4797, mae: 2.5568, huber: 2.1489, swd: 11.4615, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 19.6520, mae: 2.7810, huber: 2.3636, swd: 8.6812, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.2172, mae: 2.3256, huber: 1.9102, swd: 6.9224, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.148851\n",
      "        Val objective improved inf → 2.3636, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.5533, mae: 2.4364, huber: 2.0319, swd: 10.3863, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 20.3114, mae: 2.8038, huber: 2.3863, swd: 9.0073, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7798, mae: 2.3560, huber: 1.9402, swd: 7.3379, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.031865\n",
      "        No improvement (2.3863), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.7961, mae: 2.3969, huber: 1.9928, swd: 9.8049, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.4066, mae: 2.7803, huber: 2.3614, swd: 8.4914, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.6795, mae: 2.3708, huber: 1.9540, swd: 7.3836, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.992812\n",
      "        Val objective improved 2.3636 → 2.3614, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.6889, mae: 2.3457, huber: 1.9426, swd: 8.8765, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 19.8943, mae: 2.8009, huber: 2.3828, swd: 8.6350, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7481, mae: 2.3840, huber: 1.9656, swd: 7.4509, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.942643\n",
      "        No improvement (2.3828), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 17.9261, mae: 2.3061, huber: 1.9037, swd: 8.2569, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 20.8561, mae: 2.8667, huber: 2.4488, swd: 9.6156, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.8341, mae: 2.4005, huber: 1.9824, swd: 7.4841, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.903750\n",
      "        No improvement (2.4488), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.3296, mae: 2.2694, huber: 1.8675, swd: 7.7553, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.7031, mae: 2.8672, huber: 2.4480, swd: 9.3720, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.8824, mae: 2.4198, huber: 2.0005, swd: 7.4338, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.867470\n",
      "        No improvement (2.4480), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.8053, mae: 2.2385, huber: 1.8368, swd: 7.3551, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.6294, mae: 2.9353, huber: 2.5150, swd: 10.0982, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.6047, mae: 2.4801, huber: 2.0596, swd: 7.8857, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.836827\n",
      "        No improvement (2.5150), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.3826, mae: 2.2097, huber: 1.8084, swd: 6.9987, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 22.9710, mae: 3.0017, huber: 2.5807, swd: 10.6704, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 16.1397, mae: 2.4955, huber: 2.0745, swd: 8.0315, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.808444\n",
      "Epoch [8/50], Test Losses: mse: 14.6795, mae: 2.3708, huber: 1.9540, swd: 7.3836, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6795, MAE: 2.3708, SWD: 7.3836\n",
      "Best round's Validation MSE: 19.4066, MAE: 2.7803\n",
      "Best round's Test verification MSE : 14.6795, MAE: 2.3708, SWD: 7.3836\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.6350, mae: 2.5637, huber: 2.1559, swd: 12.1484, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 19.8237, mae: 2.7871, huber: 2.3724, swd: 9.1637, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.1331, mae: 2.3151, huber: 1.9001, swd: 7.1673, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.155935\n",
      "        Val objective improved inf → 2.3724, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.5451, mae: 2.4309, huber: 2.0270, swd: 10.8511, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 19.5556, mae: 2.7817, huber: 2.3650, swd: 9.3745, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.2876, mae: 2.3719, huber: 1.9542, swd: 7.4850, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.026958\n",
      "        Val objective improved 2.3724 → 2.3650, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.2998, mae: 2.3730, huber: 1.9701, swd: 9.8419, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 19.6417, mae: 2.7817, huber: 2.3642, swd: 8.9530, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.4734, mae: 2.3532, huber: 1.9367, swd: 7.5405, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.970088\n",
      "        Val objective improved 2.3650 → 2.3642, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.2727, mae: 2.3230, huber: 1.9208, swd: 8.9408, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.0158, mae: 2.8584, huber: 2.4412, swd: 10.1116, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.9440, mae: 2.3844, huber: 1.9668, swd: 7.8339, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.920771\n",
      "        No improvement (2.4412), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 17.5144, mae: 2.2819, huber: 1.8800, swd: 8.2687, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 20.8698, mae: 2.8707, huber: 2.4524, swd: 9.8900, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.0684, mae: 2.4018, huber: 1.9840, swd: 7.9353, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.880001\n",
      "        No improvement (2.4524), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.0087, mae: 2.2485, huber: 1.8468, swd: 7.8334, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 21.5260, mae: 2.9145, huber: 2.4947, swd: 10.2478, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.6275, mae: 2.4548, huber: 2.0352, swd: 8.3098, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.846840\n",
      "        No improvement (2.4947), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.5002, mae: 2.2147, huber: 1.8133, swd: 7.3988, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 21.0274, mae: 2.8702, huber: 2.4527, swd: 9.9224, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.6632, mae: 2.4278, huber: 2.0094, swd: 8.4374, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.813313\n",
      "        No improvement (2.4527), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.1408, mae: 2.1883, huber: 1.7873, swd: 7.1187, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 21.5328, mae: 2.9309, huber: 2.5110, swd: 10.3537, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.8098, mae: 2.4659, huber: 2.0464, swd: 8.4675, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.787306\n",
      "Epoch [8/50], Test Losses: mse: 14.4734, mae: 2.3532, huber: 1.9367, swd: 7.5405, target_std: 18.3439\n",
      "Best round's Test MSE: 14.4734, MAE: 2.3532, SWD: 7.5405\n",
      "Best round's Validation MSE: 19.6417, MAE: 2.7817\n",
      "Best round's Test verification MSE : 14.4734, MAE: 2.3532, SWD: 7.5405\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.5317, mae: 2.5563, huber: 2.1486, swd: 11.2039, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.2625, mae: 2.8398, huber: 2.4199, swd: 8.9206, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.0253, mae: 2.3523, huber: 1.9350, swd: 6.6296, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.148555\n",
      "        Val objective improved inf → 2.4199, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.6474, mae: 2.4349, huber: 2.0306, swd: 10.1491, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 20.0255, mae: 2.7863, huber: 2.3690, swd: 8.2886, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.8259, mae: 2.3559, huber: 1.9396, swd: 7.0754, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.030605\n",
      "        Val objective improved 2.4199 → 2.3690, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.7579, mae: 2.3891, huber: 1.9853, swd: 9.5489, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.6786, mae: 2.7743, huber: 2.3553, swd: 8.3428, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.4035, mae: 2.3664, huber: 1.9483, swd: 6.9139, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 1.985300\n",
      "        Val objective improved 2.3690 → 2.3553, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.8117, mae: 2.3414, huber: 1.9386, swd: 8.8213, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.8639, mae: 2.7910, huber: 2.3736, swd: 8.3844, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.1371, mae: 2.3926, huber: 1.9752, swd: 7.2636, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 1.938622\n",
      "        No improvement (2.3736), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.0877, mae: 2.3006, huber: 1.8984, swd: 8.2168, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 19.3936, mae: 2.7719, huber: 2.3543, swd: 8.0056, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.7083, mae: 2.3725, huber: 1.9548, swd: 7.0078, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 1.898351\n",
      "        Val objective improved 2.3553 → 2.3543, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 17.3622, mae: 2.2615, huber: 1.8597, swd: 7.6394, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 20.8146, mae: 2.8622, huber: 2.4425, swd: 9.0194, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.6095, mae: 2.4514, huber: 2.0319, swd: 7.6044, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 1.859731\n",
      "        No improvement (2.4425), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 16.8933, mae: 2.2317, huber: 1.8301, swd: 7.2572, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.8331, mae: 2.9515, huber: 2.5277, swd: 9.5584, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.0563, mae: 2.4914, huber: 2.0704, swd: 7.6091, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 1.830110\n",
      "        No improvement (2.5277), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4985, mae: 2.2068, huber: 1.8055, swd: 6.9577, target_std: 20.3626\n",
      "Epoch [8/50], Val Losses: mse: 21.7035, mae: 2.9341, huber: 2.5129, swd: 9.7101, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.7523, mae: 2.4820, huber: 2.0614, swd: 7.7136, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 1.805512\n",
      "        No improvement (2.5129), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 16.1065, mae: 2.1796, huber: 1.7786, swd: 6.6673, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.4348, mae: 2.9269, huber: 2.5060, swd: 9.8120, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.6612, mae: 2.4844, huber: 2.0639, swd: 7.7543, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 1.778634\n",
      "        No improvement (2.5060), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 15.8475, mae: 2.1628, huber: 1.7620, swd: 6.4658, target_std: 20.3630\n",
      "Epoch [10/50], Val Losses: mse: 23.3650, mae: 3.0896, huber: 2.6621, swd: 9.3323, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 17.6293, mae: 2.6377, huber: 2.2128, swd: 7.8811, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 1.762018\n",
      "Epoch [10/50], Test Losses: mse: 14.7083, mae: 2.3725, huber: 1.9548, swd: 7.0078, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7083, MAE: 2.3725, SWD: 7.0078\n",
      "Best round's Validation MSE: 19.3936, MAE: 2.7719\n",
      "Best round's Test verification MSE : 14.7083, MAE: 2.3725, SWD: 7.0078\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250430_2039)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.6204 ± 0.1046\n",
      "  mae: 2.3655 ± 0.0087\n",
      "  huber: 1.9485 ± 0.0084\n",
      "  swd: 7.3107 ± 0.2235\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.4806 ± 0.1140\n",
      "  mae: 2.7780 ± 0.0043\n",
      "  huber: 2.3600 ± 0.0042\n",
      "  swd: 8.4833 ± 0.3868\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250430_2039\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b253d",
   "metadata": {},
   "source": [
    "##### huber + 0.1 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e72b8b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.8867, mae: 2.6977, huber: 2.2851, swd: 11.7808, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 20.1794, mae: 2.8652, huber: 2.4436, swd: 9.1213, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.3422, mae: 2.3837, huber: 1.9646, swd: 7.1002, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.463138\n",
      "        Val objective improved inf → 3.3558, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.0734, mae: 2.5221, huber: 2.1126, swd: 9.8495, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 19.5609, mae: 2.8204, huber: 2.3969, swd: 8.3651, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.1063, mae: 2.3462, huber: 1.9283, swd: 6.8985, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.097564\n",
      "        Val objective improved 3.3558 → 3.2334, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.6525, mae: 2.4557, huber: 2.0471, swd: 8.9112, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.5718, mae: 2.8142, huber: 2.3910, swd: 8.5454, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.3087, mae: 2.3616, huber: 1.9437, swd: 7.1347, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.938199\n",
      "        No improvement (3.2455), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 18.7148, mae: 2.4105, huber: 2.0024, swd: 8.3309, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 19.5008, mae: 2.8131, huber: 2.3898, swd: 8.3306, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7532, mae: 2.4057, huber: 1.9862, swd: 7.4171, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.835481\n",
      "        Val objective improved 3.2334 → 3.2229, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.0360, mae: 2.3729, huber: 1.9654, swd: 7.8754, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 19.8811, mae: 2.8340, huber: 2.4090, swd: 8.9052, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.6938, mae: 2.4197, huber: 2.0002, swd: 7.4628, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.752955\n",
      "        No improvement (3.2995), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.4920, mae: 2.3410, huber: 1.9340, swd: 7.4765, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 21.4857, mae: 2.9526, huber: 2.5249, swd: 10.3208, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.2224, mae: 2.4562, huber: 2.0353, swd: 7.9281, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.681696\n",
      "        No improvement (3.5570), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.0543, mae: 2.3181, huber: 1.9113, swd: 7.1292, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.4398, mae: 2.9343, huber: 2.5080, swd: 10.2598, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.3946, mae: 2.4567, huber: 2.0369, swd: 8.0473, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.624216\n",
      "        No improvement (3.5340), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.6997, mae: 2.2990, huber: 1.8926, swd: 6.8311, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 21.7572, mae: 2.9460, huber: 2.5215, swd: 9.5825, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.9846, mae: 2.4641, huber: 2.0436, swd: 8.3223, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.575688\n",
      "        No improvement (3.4797), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.2773, mae: 2.2764, huber: 1.8705, swd: 6.4888, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 22.0884, mae: 2.9792, huber: 2.5541, swd: 10.7226, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 16.0933, mae: 2.5014, huber: 2.0806, swd: 8.6216, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 2.519390\n",
      "Epoch [9/50], Test Losses: mse: 14.7532, mae: 2.4057, huber: 1.9862, swd: 7.4171, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7532, MAE: 2.4057, SWD: 7.4171\n",
      "Best round's Validation MSE: 19.5008, MAE: 2.8131, SWD: 8.3306\n",
      "Best round's Test verification MSE : 14.7532, MAE: 2.4057, SWD: 7.4171\n",
      "Time taken: 147.57 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.6995, mae: 2.6791, huber: 2.2666, swd: 11.9916, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 19.9316, mae: 2.8421, huber: 2.4198, swd: 8.9977, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.2720, mae: 2.3586, huber: 1.9410, swd: 7.2521, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.465775\n",
      "        Val objective improved inf → 3.3196, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.0183, mae: 2.5178, huber: 2.1082, swd: 10.1024, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 19.5683, mae: 2.8198, huber: 2.3948, swd: 8.6167, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.1568, mae: 2.3565, huber: 1.9388, swd: 7.2413, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.118486\n",
      "        Val objective improved 3.3196 → 3.2565, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.7385, mae: 2.4547, huber: 2.0465, swd: 9.3453, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 18.9978, mae: 2.7790, huber: 2.3574, swd: 8.2299, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.3183, mae: 2.3599, huber: 1.9424, swd: 7.4119, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.981036\n",
      "        Val objective improved 3.2565 → 3.1804, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.6805, mae: 2.4024, huber: 1.9953, swd: 8.6891, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.7944, mae: 2.8886, huber: 2.4644, swd: 9.7335, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.6380, mae: 2.3812, huber: 1.9630, swd: 7.7092, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.864172\n",
      "        No improvement (3.4377), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.0515, mae: 2.3694, huber: 1.9627, swd: 8.2330, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.4947, mae: 2.9269, huber: 2.5036, swd: 10.5591, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.7289, mae: 2.3955, huber: 1.9767, swd: 7.7935, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.786007\n",
      "        No improvement (3.5595), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.5052, mae: 2.3379, huber: 1.9316, swd: 7.7807, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 20.1706, mae: 2.8632, huber: 2.4399, swd: 9.5303, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.2083, mae: 2.4576, huber: 2.0370, swd: 8.4023, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.709653\n",
      "        No improvement (3.3930), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.9523, mae: 2.3050, huber: 1.8994, swd: 7.2975, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 22.5079, mae: 2.9851, huber: 2.5605, swd: 11.3829, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.8312, mae: 2.4859, huber: 2.0646, swd: 8.6620, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.629097\n",
      "        No improvement (3.6988), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.5842, mae: 2.2833, huber: 1.8779, swd: 6.9622, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 21.6282, mae: 2.9481, huber: 2.5238, swd: 10.4198, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.5185, mae: 2.4615, huber: 2.0410, swd: 8.3913, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.574091\n",
      "Epoch [8/50], Test Losses: mse: 14.3183, mae: 2.3599, huber: 1.9424, swd: 7.4119, target_std: 18.3439\n",
      "Best round's Test MSE: 14.3183, MAE: 2.3599, SWD: 7.4119\n",
      "Best round's Validation MSE: 18.9978, MAE: 2.7790, SWD: 8.2299\n",
      "Best round's Test verification MSE : 14.3183, MAE: 2.3599, SWD: 7.4119\n",
      "Time taken: 134.63 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.6186, mae: 2.6787, huber: 2.2660, swd: 11.2699, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 19.8216, mae: 2.8537, huber: 2.4298, swd: 7.7444, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8088, mae: 2.3986, huber: 1.9799, swd: 7.2378, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 3.392958\n",
      "        Val objective improved inf → 3.2043, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.7206, mae: 2.5132, huber: 2.1035, swd: 9.3988, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 20.9692, mae: 2.8990, huber: 2.4744, swd: 8.9150, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.2003, mae: 2.3923, huber: 1.9741, swd: 7.4022, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.043404\n",
      "        No improvement (3.3658), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.6609, mae: 2.4561, huber: 2.0477, swd: 8.7515, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.6250, mae: 2.8167, huber: 2.3931, swd: 8.2197, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.5897, mae: 2.4032, huber: 1.9833, swd: 7.0771, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.922821\n",
      "        No improvement (3.2150), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 18.7434, mae: 2.4102, huber: 2.0027, swd: 8.1375, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.5073, mae: 2.8067, huber: 2.3836, swd: 8.1391, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0758, mae: 2.3962, huber: 1.9776, swd: 7.4236, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.816422\n",
      "        Val objective improved 3.2043 → 3.1975, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.1535, mae: 2.3784, huber: 1.9713, swd: 7.7458, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 20.0774, mae: 2.8467, huber: 2.4229, swd: 8.4991, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.8877, mae: 2.4093, huber: 1.9889, swd: 7.4057, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.745892\n",
      "        No improvement (3.2728), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.6560, mae: 2.3505, huber: 1.9438, swd: 7.3516, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 20.9652, mae: 2.8927, huber: 2.4674, swd: 9.1631, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.1357, mae: 2.4278, huber: 2.0070, swd: 7.4694, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.678992\n",
      "        No improvement (3.3838), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.1706, mae: 2.3224, huber: 1.9161, swd: 6.9910, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 20.3374, mae: 2.8620, huber: 2.4382, swd: 8.8128, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.0503, mae: 2.4506, huber: 2.0296, swd: 7.4180, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.615230\n",
      "        No improvement (3.3195), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.7604, mae: 2.2998, huber: 1.8937, swd: 6.6619, target_std: 20.3626\n",
      "Epoch [8/50], Val Losses: mse: 20.1226, mae: 2.8517, huber: 2.4287, swd: 8.5634, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.0854, mae: 2.4498, huber: 2.0290, swd: 7.3890, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.559883\n",
      "        No improvement (3.2850), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.3373, mae: 2.2769, huber: 1.8713, swd: 6.2910, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.3031, mae: 2.9208, huber: 2.4961, swd: 9.5005, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.6205, mae: 2.4703, huber: 2.0493, swd: 7.8003, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 2.500434\n",
      "Epoch [9/50], Test Losses: mse: 15.0758, mae: 2.3962, huber: 1.9776, swd: 7.4236, target_std: 18.3439\n",
      "Best round's Test MSE: 15.0758, MAE: 2.3962, SWD: 7.4236\n",
      "Best round's Validation MSE: 19.5073, MAE: 2.8067, SWD: 8.1391\n",
      "Best round's Test verification MSE : 15.0758, MAE: 2.3962, SWD: 7.4236\n",
      "Time taken: 151.01 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_1429)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.7158 ± 0.3104\n",
      "  mae: 2.3872 ± 0.0197\n",
      "  huber: 1.9687 ± 0.0189\n",
      "  swd: 7.4175 ± 0.0048\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.3353 ± 0.2387\n",
      "  mae: 2.7996 ± 0.0148\n",
      "  huber: 2.3769 ± 0.0141\n",
      "  swd: 8.2332 ± 0.0782\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 433.42 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_1429\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.1, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e21be",
   "metadata": {},
   "source": [
    "##### huber + 0.5 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10efcc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.8690, mae: 3.0650, huber: 2.6441, swd: 12.2708, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 22.0883, mae: 2.9850, huber: 2.5612, swd: 8.4549, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.4682, mae: 2.5247, huber: 2.1031, swd: 7.4011, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 8.779467\n",
      "        Val objective improved inf → 6.7887, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 25.2380, mae: 2.7378, huber: 2.3220, swd: 10.0139, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 20.8582, mae: 2.9064, huber: 2.4814, swd: 8.3359, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.7615, mae: 2.4715, huber: 2.0507, swd: 7.4829, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 7.328975\n",
      "        Val objective improved 6.7887 → 6.6493, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 23.6097, mae: 2.6426, huber: 2.2288, swd: 9.2490, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.7822, mae: 2.9230, huber: 2.4985, swd: 8.7442, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.4456, mae: 2.4643, huber: 2.0438, swd: 7.4967, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 6.853336\n",
      "        No improvement (6.8706), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 22.4549, mae: 2.5788, huber: 2.1668, swd: 8.7520, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.9140, mae: 2.8982, huber: 2.4748, swd: 8.2973, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2779, mae: 2.4583, huber: 2.0370, swd: 7.2837, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 6.542750\n",
      "        Val objective improved 6.6493 → 6.6234, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.3919, mae: 2.5380, huber: 2.1269, swd: 8.4327, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 21.2082, mae: 2.8999, huber: 2.4759, swd: 8.8803, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.1684, mae: 2.4341, huber: 2.0136, swd: 7.3349, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 6.343292\n",
      "        No improvement (6.9160), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 20.5193, mae: 2.4963, huber: 2.0859, swd: 7.9741, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.9482, mae: 2.9039, huber: 2.4781, swd: 8.6404, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5570, mae: 2.4926, huber: 2.0700, swd: 7.7973, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 6.072983\n",
      "        No improvement (6.7983), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 19.8013, mae: 2.4655, huber: 2.0555, swd: 7.4626, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.7308, mae: 2.9286, huber: 2.5042, swd: 9.2548, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.4781, mae: 2.4631, huber: 2.0415, swd: 7.6645, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 5.786843\n",
      "        No improvement (7.1316), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 19.3077, mae: 2.4507, huber: 2.0407, swd: 7.2437, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 20.1422, mae: 2.8476, huber: 2.4222, swd: 8.2122, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.3079, mae: 2.4554, huber: 2.0345, swd: 7.6075, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 5.662509\n",
      "        Val objective improved 6.6234 → 6.5283, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 18.5267, mae: 2.4134, huber: 2.0040, swd: 6.6987, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 21.6533, mae: 2.9347, huber: 2.5106, swd: 9.5048, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.4513, mae: 2.4796, huber: 2.0581, swd: 7.9001, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 5.353367\n",
      "        No improvement (7.2630), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 18.0747, mae: 2.3871, huber: 1.9782, swd: 6.5377, target_std: 20.3630\n",
      "Epoch [10/50], Val Losses: mse: 21.4557, mae: 2.9447, huber: 2.5202, swd: 9.3442, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.7739, mae: 2.4921, huber: 2.0703, swd: 7.9644, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 5.247095\n",
      "        No improvement (7.1923), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 17.5647, mae: 2.3607, huber: 1.9519, swd: 6.2110, target_std: 20.3631\n",
      "Epoch [11/50], Val Losses: mse: 21.2164, mae: 2.9170, huber: 2.4924, swd: 9.4412, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 15.5532, mae: 2.4819, huber: 2.0603, swd: 8.1039, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 5.057434\n",
      "        No improvement (7.2130), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 16.9588, mae: 2.3261, huber: 1.9180, swd: 5.8489, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 23.3603, mae: 3.0434, huber: 2.6168, swd: 11.1179, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 16.3662, mae: 2.5139, huber: 2.0919, swd: 8.6884, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 4.842508\n",
      "        No improvement (8.1757), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 16.6416, mae: 2.3094, huber: 1.9014, swd: 5.7235, target_std: 20.3628\n",
      "Epoch [13/50], Val Losses: mse: 22.7694, mae: 3.0268, huber: 2.6002, swd: 10.7268, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 16.1833, mae: 2.5302, huber: 2.1073, swd: 8.4120, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 4.763084\n",
      "Epoch [13/50], Test Losses: mse: 15.3079, mae: 2.4554, huber: 2.0345, swd: 7.6075, target_std: 18.3439\n",
      "Best round's Test MSE: 15.3079, MAE: 2.4554, SWD: 7.6075\n",
      "Best round's Validation MSE: 20.1422, MAE: 2.8476, SWD: 8.2122\n",
      "Best round's Test verification MSE : 15.3079, MAE: 2.4554, SWD: 7.6075\n",
      "Time taken: 201.97 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.7859, mae: 3.0412, huber: 2.6204, swd: 12.2783, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 22.0646, mae: 2.9902, huber: 2.5630, swd: 9.6273, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.9746, mae: 2.5013, huber: 2.0791, swd: 7.5409, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 8.759528\n",
      "        Val objective improved inf → 7.3767, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 24.3375, mae: 2.7117, huber: 2.2963, swd: 10.2746, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 21.3593, mae: 2.9462, huber: 2.5178, swd: 9.0267, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.5108, mae: 2.4558, huber: 2.0343, swd: 7.4044, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 7.433574\n",
      "        Val objective improved 7.3767 → 7.0311, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 22.5749, mae: 2.6247, huber: 2.2112, swd: 9.5589, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 19.8878, mae: 2.8398, huber: 2.4168, swd: 8.1699, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.4045, mae: 2.4334, huber: 2.0135, swd: 7.6276, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 6.990618\n",
      "        Val objective improved 7.0311 → 6.5018, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.4005, mae: 2.5557, huber: 2.1437, swd: 9.0232, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 19.9353, mae: 2.8515, huber: 2.4274, swd: 8.4079, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.1552, mae: 2.4273, huber: 2.0072, swd: 7.5948, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 6.655267\n",
      "        No improvement (6.6314), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 20.4725, mae: 2.5118, huber: 2.1005, swd: 8.6035, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 20.6470, mae: 2.8876, huber: 2.4619, swd: 9.2703, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2507, mae: 2.4250, huber: 2.0051, swd: 7.7552, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 6.402257\n",
      "        No improvement (7.0970), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 19.8618, mae: 2.4765, huber: 2.0661, swd: 8.3102, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 19.9025, mae: 2.8490, huber: 2.4234, swd: 8.7125, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.7636, mae: 2.4816, huber: 2.0601, swd: 8.3505, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 6.221244\n",
      "        No improvement (6.7796), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 19.5040, mae: 2.4601, huber: 2.0500, swd: 8.0746, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 21.8214, mae: 2.9406, huber: 2.5152, swd: 10.4643, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.8215, mae: 2.4520, huber: 2.0316, swd: 8.4871, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 6.087334\n",
      "        No improvement (7.7473), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 19.1307, mae: 2.4451, huber: 2.0351, swd: 7.8228, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 21.2087, mae: 2.9086, huber: 2.4841, swd: 10.1057, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.1354, mae: 2.4506, huber: 2.0300, swd: 8.0184, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 5.946550\n",
      "Epoch [8/50], Test Losses: mse: 15.4045, mae: 2.4334, huber: 2.0135, swd: 7.6276, target_std: 18.3439\n",
      "Best round's Test MSE: 15.4045, MAE: 2.4334, SWD: 7.6276\n",
      "Best round's Validation MSE: 19.8878, MAE: 2.8398, SWD: 8.1699\n",
      "Best round's Test verification MSE : 15.4045, MAE: 2.4334, SWD: 7.6276\n",
      "Time taken: 125.38 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 29.5017, mae: 3.0470, huber: 2.6260, swd: 11.6926, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 21.9150, mae: 3.0330, huber: 2.6026, swd: 7.9241, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.3784, mae: 2.5779, huber: 2.1516, swd: 7.1599, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 8.472257\n",
      "        Val objective improved inf → 6.5647, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 24.3512, mae: 2.7292, huber: 2.3131, swd: 9.8913, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 21.5100, mae: 2.9502, huber: 2.5220, swd: 8.7083, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.5402, mae: 2.4773, huber: 2.0546, swd: 7.1097, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 7.258700\n",
      "        No improvement (6.8761), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 22.2499, mae: 2.6047, huber: 2.1913, swd: 8.8558, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.5182, mae: 2.8916, huber: 2.4650, swd: 8.3216, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1213, mae: 2.4480, huber: 2.0263, swd: 7.1906, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 6.619198\n",
      "        No improvement (6.6258), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 21.1419, mae: 2.5448, huber: 2.1327, swd: 8.4074, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 20.0070, mae: 2.8694, huber: 2.4423, swd: 7.8789, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.4799, mae: 2.4714, huber: 2.0495, swd: 7.5467, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 6.336425\n",
      "        Val objective improved 6.5647 → 6.3818, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 20.2278, mae: 2.5016, huber: 2.0902, swd: 7.8300, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 20.3856, mae: 2.8683, huber: 2.4426, swd: 8.5224, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.6865, mae: 2.4980, huber: 2.0761, swd: 7.7698, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 6.005255\n",
      "        No improvement (6.7038), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 19.1713, mae: 2.4588, huber: 2.0482, swd: 7.2287, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 21.5401, mae: 2.9212, huber: 2.4953, swd: 9.5399, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.2340, mae: 2.4579, huber: 2.0362, swd: 7.2959, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 5.662541\n",
      "        No improvement (7.2653), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 18.7962, mae: 2.4424, huber: 2.0316, swd: 6.9715, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.7843, mae: 2.9706, huber: 2.5405, swd: 8.6725, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.5370, mae: 2.5511, huber: 2.1261, swd: 7.8492, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 5.517372\n",
      "        No improvement (6.8767), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 17.9622, mae: 2.3981, huber: 1.9881, swd: 6.4780, target_std: 20.3626\n",
      "Epoch [8/50], Val Losses: mse: 21.2062, mae: 2.9101, huber: 2.4840, swd: 9.1062, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.5046, mae: 2.4774, huber: 2.0556, swd: 7.5433, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 5.227113\n",
      "        No improvement (7.0371), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 17.2408, mae: 2.3582, huber: 1.9491, swd: 6.1193, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.0641, mae: 2.9048, huber: 2.4791, swd: 9.0715, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.7489, mae: 2.4860, huber: 2.0644, swd: 7.8144, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 5.008812\n",
      "Epoch [9/50], Test Losses: mse: 15.4799, mae: 2.4714, huber: 2.0495, swd: 7.5467, target_std: 18.3439\n",
      "Best round's Test MSE: 15.4799, MAE: 2.4714, SWD: 7.5467\n",
      "Best round's Validation MSE: 20.0070, MAE: 2.8694, SWD: 7.8789\n",
      "Best round's Test verification MSE : 15.4799, MAE: 2.4714, SWD: 7.5467\n",
      "Time taken: 142.73 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_0041)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.3974 ± 0.0704\n",
      "  mae: 2.4534 ± 0.0156\n",
      "  huber: 2.0325 ± 0.0147\n",
      "  swd: 7.5939 ± 0.0344\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 20.0123 ± 0.1039\n",
      "  mae: 2.8523 ± 0.0125\n",
      "  huber: 2.4271 ± 0.0110\n",
      "  swd: 8.0870 ± 0.1482\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 471.62 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_0041\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbb972",
   "metadata": {},
   "source": [
    "##### huber + 1.5 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c02572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of data_manager failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\qilin\\miniconda3\\envs\\ww\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 283, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\qilin\\miniconda3\\envs\\ww\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 483, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\qilin\\miniconda3\\envs\\ww\\Lib\\importlib\\__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1133, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1063, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"c:\\proj\\DL_notebook\\study\\data_manager.py\", line 196\n",
      "    def load_csv(self, name, path, date_column='date', replace_value=-9999.0, drop_na=True, random):\n",
      "                                                                                            ^^^^^^\n",
      "SyntaxError: parameter without a default follows parameter with a default\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Losses: mse: 35.5547, mae: 3.3709, huber: 2.9451, swd: 12.3772, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 32.1230, mae: 3.5945, huber: 3.1584, swd: 8.8195, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 23.0310, mae: 3.0056, huber: 2.5723, swd: 7.2388, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 21.510884\n",
      "        Val objective improved inf → 16.3876, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.9709, mae: 3.0407, huber: 2.6181, swd: 10.2398, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 23.5775, mae: 3.0936, huber: 2.6649, swd: 8.5048, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 18.0588, mae: 2.6431, huber: 2.2182, swd: 7.7251, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 17.977802\n",
      "        Val objective improved 16.3876 → 15.4221, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.9337, mae: 2.8324, huber: 2.4140, swd: 9.2852, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 24.0871, mae: 3.1493, huber: 2.7180, swd: 11.0877, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.2359, mae: 2.6172, huber: 2.1907, swd: 8.0155, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 16.341751\n",
      "        No improvement (19.3496), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 25.3802, mae: 2.7566, huber: 2.3396, swd: 8.8407, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.9433, mae: 3.0040, huber: 2.5749, swd: 7.9030, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.5452, mae: 2.5723, huber: 2.1474, swd: 7.4199, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 15.600652\n",
      "        Val objective improved 15.4221 → 14.4294, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 24.4676, mae: 2.7042, huber: 2.2887, swd: 8.2898, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 22.4587, mae: 3.0214, huber: 2.5921, swd: 8.3910, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.8641, mae: 2.5448, huber: 2.1212, swd: 7.4691, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 14.723417\n",
      "        No improvement (15.1786), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 23.5971, mae: 2.6582, huber: 2.2434, swd: 7.8830, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 22.4775, mae: 3.0247, huber: 2.5951, swd: 9.0441, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.8898, mae: 2.5939, huber: 2.1690, swd: 7.9642, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 14.067927\n",
      "        No improvement (16.1612), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 22.8338, mae: 2.6194, huber: 2.2057, swd: 7.5252, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 23.6728, mae: 3.0850, huber: 2.6557, swd: 9.7642, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.6000, mae: 2.6065, huber: 2.1825, swd: 8.2699, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 13.493583\n",
      "        No improvement (17.3020), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 22.1959, mae: 2.5887, huber: 2.1756, swd: 7.1982, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 22.2767, mae: 3.0128, huber: 2.5853, swd: 8.9611, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 16.3685, mae: 2.5252, huber: 2.1025, swd: 7.6460, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 12.972889\n",
      "        No improvement (16.0269), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 21.8639, mae: 2.5731, huber: 2.1602, swd: 7.0119, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 22.3361, mae: 3.0163, huber: 2.5873, swd: 9.0857, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 16.9482, mae: 2.5652, huber: 2.1415, swd: 8.1503, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 12.678060\n",
      "Epoch [9/50], Test Losses: mse: 16.5452, mae: 2.5723, huber: 2.1474, swd: 7.4199, target_std: 18.3439\n",
      "Best round's Test MSE: 16.5452, MAE: 2.5723, SWD: 7.4199\n",
      "Best round's Validation MSE: 21.9433, MAE: 3.0040, SWD: 7.9030\n",
      "Best round's Test verification MSE : 16.5452, MAE: 2.5723, SWD: 7.4199\n",
      "Time taken: 147.79 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.5352, mae: 3.2947, huber: 2.8701, swd: 12.3955, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 26.2574, mae: 3.2826, huber: 2.8494, swd: 9.6409, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 19.0760, mae: 2.7487, huber: 2.3198, swd: 7.5644, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 21.463388\n",
      "        Val objective improved inf → 17.3107, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 28.5184, mae: 2.9480, huber: 2.5278, swd: 10.3817, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 24.4639, mae: 3.1512, huber: 2.7193, swd: 10.1414, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 17.6442, mae: 2.6488, huber: 2.2221, swd: 7.5950, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 18.100378\n",
      "        No improvement (17.9314), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 26.5661, mae: 2.8312, huber: 2.4128, swd: 9.5795, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 22.2669, mae: 3.0241, huber: 2.5946, swd: 8.5093, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.1770, mae: 2.6021, huber: 2.1772, swd: 7.7224, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 16.782021\n",
      "        Val objective improved 17.3107 → 15.3585, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 25.3114, mae: 2.7587, huber: 2.3422, swd: 9.1081, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 22.9513, mae: 3.0552, huber: 2.6263, swd: 9.0110, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.3929, mae: 2.6148, huber: 2.1893, swd: 7.7654, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 16.004320\n",
      "        No improvement (16.1428), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 24.5542, mae: 2.7204, huber: 2.3045, swd: 8.7574, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.7759, mae: 3.0497, huber: 2.6197, swd: 9.3986, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.3151, mae: 2.6166, huber: 2.1914, swd: 7.9307, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 15.440568\n",
      "        No improvement (16.7176), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 24.3059, mae: 2.6881, huber: 2.2734, swd: 8.5673, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.9230, mae: 3.0531, huber: 2.6251, swd: 10.3164, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 16.9790, mae: 2.6090, huber: 2.1839, swd: 8.4153, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 15.124390\n",
      "        No improvement (18.0996), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 24.2263, mae: 2.6831, huber: 2.2687, swd: 8.4168, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 23.3379, mae: 3.0754, huber: 2.6455, swd: 9.8990, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.6587, mae: 2.6225, huber: 2.1978, swd: 8.4403, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 14.893858\n",
      "        No improvement (17.4939), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 23.4235, mae: 2.6388, huber: 2.2255, swd: 7.9351, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 22.6797, mae: 3.0180, huber: 2.5925, swd: 9.6797, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 17.3032, mae: 2.5860, huber: 2.1622, swd: 8.2129, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 14.128186\n",
      "Epoch [8/50], Test Losses: mse: 17.1770, mae: 2.6021, huber: 2.1772, swd: 7.7224, target_std: 18.3439\n",
      "Best round's Test MSE: 17.1770, MAE: 2.6021, SWD: 7.7224\n",
      "Best round's Validation MSE: 22.2669, MAE: 3.0241, SWD: 8.5093\n",
      "Best round's Test verification MSE : 17.1770, MAE: 2.6021, SWD: 7.7224\n",
      "Time taken: 131.96 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 33.6937, mae: 3.2754, huber: 2.8504, swd: 11.6291, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 24.5934, mae: 3.2098, huber: 2.7757, swd: 8.4700, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 17.9024, mae: 2.7051, huber: 2.2766, swd: 6.7909, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 20.293992\n",
      "        Val objective improved inf → 15.4807, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.8284, mae: 2.9100, huber: 2.4898, swd: 9.6828, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 23.0118, mae: 3.0904, huber: 2.6590, swd: 8.6944, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 16.5914, mae: 2.5553, huber: 2.1304, swd: 6.8342, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 17.014026\n",
      "        No improvement (15.7005), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 24.9182, mae: 2.7620, huber: 2.3443, swd: 8.7489, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 23.0907, mae: 3.0942, huber: 2.6630, swd: 8.7162, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.0521, mae: 2.6103, huber: 2.1842, swd: 7.1305, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 15.467732\n",
      "        No improvement (15.7374), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 23.4329, mae: 2.6923, huber: 2.2762, swd: 8.2893, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 22.9281, mae: 3.0760, huber: 2.6466, swd: 9.0628, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 16.7802, mae: 2.5622, huber: 2.1383, swd: 7.3002, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 14.710064\n",
      "        No improvement (16.2409), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 22.6765, mae: 2.6515, huber: 2.2364, swd: 7.9713, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 22.4148, mae: 3.0481, huber: 2.6177, swd: 8.9818, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 16.6366, mae: 2.5896, huber: 2.1634, swd: 7.2491, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 14.193428\n",
      "        No improvement (16.0904), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 21.9881, mae: 2.6190, huber: 2.2046, swd: 7.6660, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 23.0109, mae: 3.0507, huber: 2.6218, swd: 9.7554, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.8307, mae: 2.5032, huber: 2.0798, swd: 7.0189, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 13.703614\n",
      "Epoch [6/50], Test Losses: mse: 17.9024, mae: 2.7051, huber: 2.2766, swd: 6.7909, target_std: 18.3439\n",
      "Best round's Test MSE: 17.9024, MAE: 2.7051, SWD: 6.7909\n",
      "Best round's Validation MSE: 24.5934, MAE: 3.2098, SWD: 8.4700\n",
      "Best round's Test verification MSE : 17.9024, MAE: 2.7051, SWD: 6.7909\n",
      "Time taken: 99.80 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_1735)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 17.2082 ± 0.5545\n",
      "  mae: 2.6265 ± 0.0569\n",
      "  huber: 2.2004 ± 0.0552\n",
      "  swd: 7.3111 ± 0.3880\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 22.9345 ± 1.1804\n",
      "  mae: 3.0793 ± 0.0926\n",
      "  huber: 2.6484 ± 0.0904\n",
      "  swd: 8.2941 ± 0.2770\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 379.69 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_1735\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 1.5, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 1.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3421a3",
   "metadata": {},
   "source": [
    "##### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460d3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.9891, mae: 2.6711, huber: 2.2567, swd: 11.6396, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 20.1748, mae: 2.8810, huber: 2.4577, swd: 9.1576, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.6739, mae: 2.3973, huber: 1.9790, swd: 7.3357, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.989137\n",
      "        Val objective improved inf → 20.1748, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.4049, mae: 2.5396, huber: 2.1275, swd: 10.1492, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 19.5357, mae: 2.8606, huber: 2.4339, swd: 8.5728, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.1748, mae: 2.4891, huber: 2.0658, swd: 7.9287, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 20.404895\n",
      "        Val objective improved 20.1748 → 19.5357, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.1696, mae: 2.4795, huber: 2.0682, swd: 9.2400, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.8832, mae: 2.8834, huber: 2.4580, swd: 8.9571, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.5878, mae: 2.4793, huber: 2.0587, swd: 8.1601, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 19.169562\n",
      "        No improvement (19.8832), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 18.5886, mae: 2.4505, huber: 2.0396, swd: 8.7898, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 19.5028, mae: 2.8382, huber: 2.4139, swd: 8.4058, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2907, mae: 2.4820, huber: 2.0602, swd: 7.8485, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 18.588561\n",
      "        Val objective improved 19.5357 → 19.5028, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 17.8443, mae: 2.4141, huber: 2.0033, swd: 8.2038, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 20.4600, mae: 2.8893, huber: 2.4638, swd: 9.1592, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.3280, mae: 2.4832, huber: 2.0613, swd: 7.9679, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 17.844318\n",
      "        No improvement (20.4600), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.2301, mae: 2.3857, huber: 1.9752, swd: 7.7331, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.9298, mae: 2.9073, huber: 2.4812, swd: 9.6111, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.3456, mae: 2.4934, huber: 2.0710, swd: 7.9246, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 17.230139\n",
      "        No improvement (20.9298), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 16.8316, mae: 2.3718, huber: 1.9611, swd: 7.4018, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.0964, mae: 2.9191, huber: 2.4917, swd: 9.2780, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.7284, mae: 2.4978, huber: 2.0753, swd: 7.9200, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 16.831635\n",
      "        No improvement (21.0964), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.3079, mae: 2.3456, huber: 1.9350, swd: 6.9901, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 20.7307, mae: 2.8963, huber: 2.4694, swd: 8.9911, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.9743, mae: 2.4825, huber: 2.0613, swd: 8.2601, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 16.307950\n",
      "        No improvement (20.7307), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 15.7083, mae: 2.3093, huber: 1.8992, swd: 6.5521, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 21.5935, mae: 2.9593, huber: 2.5326, swd: 10.0281, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.8498, mae: 2.5154, huber: 2.0930, swd: 8.2704, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 15.708276\n",
      "Epoch [9/50], Test Losses: mse: 15.2907, mae: 2.4820, huber: 2.0602, swd: 7.8485, target_std: 18.3439\n",
      "Best round's Test MSE: 15.2907, MAE: 2.4820, SWD: 7.8485\n",
      "Best round's Validation MSE: 19.5028, MAE: 2.8382, SWD: 8.4058\n",
      "Best round's Test verification MSE : 15.2907, MAE: 2.4820, SWD: 7.8485\n",
      "Time taken: 143.59 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.9263, mae: 2.6647, huber: 2.2505, swd: 12.1777, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 20.2582, mae: 2.8731, huber: 2.4491, swd: 9.1859, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.6545, mae: 2.3932, huber: 1.9739, swd: 7.5136, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.926329\n",
      "        Val objective improved inf → 20.2582, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.6587, mae: 2.5468, huber: 2.1343, swd: 10.8238, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 20.0992, mae: 2.8619, huber: 2.4370, swd: 8.7483, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9962, mae: 2.3980, huber: 1.9791, swd: 7.7897, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 20.658651\n",
      "        Val objective improved 20.2582 → 20.0992, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.5840, mae: 2.5009, huber: 2.0890, swd: 10.0093, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 19.0302, mae: 2.7987, huber: 2.3739, swd: 8.0195, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.2533, mae: 2.4546, huber: 2.0332, swd: 8.0391, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 19.584027\n",
      "        Val objective improved 20.0992 → 19.0302, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.4418, mae: 2.4450, huber: 2.0338, swd: 9.0856, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.2123, mae: 2.8768, huber: 2.4515, swd: 8.8566, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0017, mae: 2.4156, huber: 1.9954, swd: 7.8833, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 18.441787\n",
      "        No improvement (20.2123), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 17.9936, mae: 2.4263, huber: 2.0155, swd: 8.6981, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.1708, mae: 2.9574, huber: 2.5314, swd: 9.2415, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.6584, mae: 2.4599, huber: 2.0389, swd: 8.3267, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 17.993602\n",
      "        No improvement (21.1708), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.3463, mae: 2.3954, huber: 1.9848, swd: 8.1310, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 20.6333, mae: 2.9019, huber: 2.4759, swd: 9.2617, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5006, mae: 2.4836, huber: 2.0612, swd: 8.2872, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 17.346263\n",
      "        No improvement (20.6333), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.5026, mae: 2.3516, huber: 1.9413, swd: 7.4599, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 20.5984, mae: 2.9086, huber: 2.4827, swd: 9.5182, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.5778, mae: 2.5047, huber: 2.0823, swd: 8.3033, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 16.502598\n",
      "        No improvement (20.5984), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.0887, mae: 2.3295, huber: 1.9193, swd: 7.1499, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 21.9428, mae: 2.9982, huber: 2.5709, swd: 10.4244, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.5082, mae: 2.5009, huber: 2.0784, swd: 8.1253, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 16.088671\n",
      "Epoch [8/50], Test Losses: mse: 15.2533, mae: 2.4546, huber: 2.0332, swd: 8.0391, target_std: 18.3439\n",
      "Best round's Test MSE: 15.2533, MAE: 2.4546, SWD: 8.0391\n",
      "Best round's Validation MSE: 19.0302, MAE: 2.7987, SWD: 8.0195\n",
      "Best round's Test verification MSE : 15.2533, MAE: 2.4546, SWD: 8.0391\n",
      "Time taken: 131.09 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.9402, mae: 2.6709, huber: 2.2567, swd: 11.2953, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 19.8348, mae: 2.8711, huber: 2.4491, swd: 8.0573, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.5903, mae: 2.3899, huber: 1.9714, swd: 6.8165, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 22.940156\n",
      "        Val objective improved inf → 19.8348, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.3772, mae: 2.5360, huber: 2.1240, swd: 9.8126, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 21.8699, mae: 2.9900, huber: 2.5626, swd: 9.5777, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7585, mae: 2.3941, huber: 1.9744, swd: 6.8605, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 20.377244\n",
      "        No improvement (21.8699), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.3106, mae: 2.4858, huber: 2.0743, swd: 9.0715, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.9876, mae: 2.8477, huber: 2.4222, swd: 8.3066, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1450, mae: 2.4359, huber: 2.0157, swd: 7.3767, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 19.310578\n",
      "        No improvement (19.9876), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 18.1101, mae: 2.4284, huber: 2.0176, swd: 8.1736, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 20.0040, mae: 2.8664, huber: 2.4381, swd: 8.5458, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.3293, mae: 2.4807, huber: 2.0583, swd: 7.5291, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 18.110135\n",
      "        No improvement (20.0040), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 17.5585, mae: 2.4012, huber: 1.9905, swd: 7.7643, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 20.5733, mae: 2.9066, huber: 2.4791, swd: 8.9389, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2960, mae: 2.4828, huber: 2.0606, swd: 7.6860, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 17.558529\n",
      "        No improvement (20.5733), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 16.9957, mae: 2.3720, huber: 1.9615, swd: 7.3383, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 22.5196, mae: 3.0411, huber: 2.6114, swd: 10.2636, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.9649, mae: 2.5517, huber: 2.1262, swd: 7.9899, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 16.995712\n",
      "Epoch [6/50], Test Losses: mse: 14.5903, mae: 2.3899, huber: 1.9714, swd: 6.8165, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5903, MAE: 2.3899, SWD: 6.8165\n",
      "Best round's Validation MSE: 19.8348, MAE: 2.8711, SWD: 8.0573\n",
      "Best round's Test verification MSE : 14.5903, MAE: 2.3899, SWD: 6.8165\n",
      "Time taken: 98.58 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_0050)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.0448 ± 0.3217\n",
      "  mae: 2.4422 ± 0.0386\n",
      "  huber: 2.0216 ± 0.0372\n",
      "  swd: 7.5680 ± 0.5371\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.4559 ± 0.3301\n",
      "  mae: 2.8360 ± 0.0296\n",
      "  huber: 2.4123 ± 0.0307\n",
      "  swd: 8.1608 ± 0.1739\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 373.35 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_0050\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db74d99",
   "metadata": {},
   "source": [
    "##### MSE + 0.1SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4281f892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.0066, mae: 2.6772, huber: 2.2627, swd: 11.6080, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 20.7187, mae: 2.9297, huber: 2.5041, swd: 9.7583, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.7651, mae: 2.4325, huber: 2.0119, swd: 7.3440, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 24.167368\n",
      "        Val objective improved inf → 21.6946, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.5385, mae: 2.5502, huber: 2.1380, swd: 10.2132, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 19.4757, mae: 2.8361, huber: 2.4111, swd: 8.2270, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.2083, mae: 2.4349, huber: 2.0144, swd: 7.7243, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.559794\n",
      "        Val objective improved 21.6946 → 20.2984, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.2181, mae: 2.4827, huber: 2.0720, swd: 9.2291, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.6970, mae: 2.8275, huber: 2.4076, swd: 9.0404, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1461, mae: 2.4723, huber: 2.0512, swd: 7.8406, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 20.140963\n",
      "        No improvement (20.6010), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 18.5379, mae: 2.4475, huber: 2.0373, swd: 8.7263, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.4024, mae: 2.9164, huber: 2.4925, swd: 9.4751, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.7738, mae: 2.5643, huber: 2.1405, swd: 8.3883, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 19.410527\n",
      "        No improvement (21.3500), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 17.9086, mae: 2.4145, huber: 2.0045, swd: 8.2481, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 20.1450, mae: 2.8483, huber: 2.4265, swd: 9.0183, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.3125, mae: 2.4748, huber: 2.0543, swd: 7.8270, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 18.733442\n",
      "        No improvement (21.0469), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.3255, mae: 2.3841, huber: 1.9743, swd: 7.7712, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.7259, mae: 2.8980, huber: 2.4743, swd: 9.5300, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5440, mae: 2.4841, huber: 2.0632, swd: 7.9223, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 18.102640\n",
      "        No improvement (21.6789), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 16.8889, mae: 2.3662, huber: 1.9562, swd: 7.4175, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 22.0014, mae: 2.9808, huber: 2.5549, swd: 10.4012, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.0485, mae: 2.5628, huber: 2.1409, swd: 8.9844, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 17.630612\n",
      "Epoch [7/50], Test Losses: mse: 15.2083, mae: 2.4349, huber: 2.0144, swd: 7.7243, target_std: 18.3439\n",
      "Best round's Test MSE: 15.2083, MAE: 2.4349, SWD: 7.7243\n",
      "Best round's Validation MSE: 19.4757, MAE: 2.8361, SWD: 8.2270\n",
      "Best round's Test verification MSE : 15.2083, MAE: 2.4349, SWD: 7.7243\n",
      "Time taken: 122.22 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.8863, mae: 2.6696, huber: 2.2550, swd: 12.0846, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 20.6291, mae: 2.9041, huber: 2.4805, swd: 9.6292, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.7972, mae: 2.4072, huber: 1.9877, swd: 7.6607, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 24.094759\n",
      "        Val objective improved inf → 21.5921, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.4020, mae: 2.5453, huber: 2.1324, swd: 10.5268, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 20.0326, mae: 2.8485, huber: 2.4256, swd: 9.0106, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.4713, mae: 2.3801, huber: 1.9615, swd: 7.4572, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.454709\n",
      "        Val objective improved 21.5921 → 20.9337, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.3845, mae: 2.4961, huber: 2.0851, swd: 9.7566, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 18.9540, mae: 2.7958, huber: 2.3727, swd: 8.1354, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0787, mae: 2.4285, huber: 2.0081, swd: 7.9401, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 20.360163\n",
      "        Val objective improved 20.9337 → 19.7675, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.3056, mae: 2.4374, huber: 2.0276, swd: 8.8997, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.3644, mae: 2.8728, huber: 2.4502, swd: 9.5669, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7447, mae: 2.4186, huber: 1.9985, swd: 7.8080, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 19.195617\n",
      "        No improvement (21.3211), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 17.6272, mae: 2.4021, huber: 1.9927, swd: 8.3398, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 20.8360, mae: 2.9278, huber: 2.5032, swd: 10.0281, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.5136, mae: 2.4910, huber: 2.0697, swd: 8.2785, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 18.461229\n",
      "        No improvement (21.8388), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 16.9786, mae: 2.3719, huber: 1.9628, swd: 7.8143, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 20.5295, mae: 2.8865, huber: 2.4613, swd: 9.7325, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.6812, mae: 2.4981, huber: 2.0769, swd: 8.3081, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 17.760051\n",
      "        No improvement (21.5028), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.4304, mae: 2.3448, huber: 1.9360, swd: 7.3523, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 21.5723, mae: 2.9520, huber: 2.5251, swd: 10.2154, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.7257, mae: 2.5636, huber: 2.1411, swd: 8.9130, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 17.165578\n",
      "        No improvement (22.5939), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.0308, mae: 2.3244, huber: 1.9154, swd: 7.0531, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 21.4102, mae: 2.9424, huber: 2.5192, swd: 10.1194, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.9693, mae: 2.4975, huber: 2.0761, swd: 8.4466, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 16.736093\n",
      "Epoch [8/50], Test Losses: mse: 15.0787, mae: 2.4285, huber: 2.0081, swd: 7.9401, target_std: 18.3439\n",
      "Best round's Test MSE: 15.0787, MAE: 2.4285, SWD: 7.9401\n",
      "Best round's Validation MSE: 18.9540, MAE: 2.7958, SWD: 8.1354\n",
      "Best round's Test verification MSE : 15.0787, MAE: 2.4285, SWD: 7.9401\n",
      "Time taken: 135.97 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.9654, mae: 2.6760, huber: 2.2615, swd: 11.2858, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 19.2200, mae: 2.8364, huber: 2.4157, swd: 7.8404, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8550, mae: 2.4477, huber: 2.0269, swd: 7.2326, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 24.093969\n",
      "        Val objective improved inf → 20.0041, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.4238, mae: 2.5405, huber: 2.1282, swd: 9.8305, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 19.6338, mae: 2.8454, huber: 2.4212, swd: 7.9845, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9020, mae: 2.4230, huber: 2.0027, swd: 7.0988, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.406868\n",
      "        No improvement (20.4322), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.3228, mae: 2.4880, huber: 2.0762, swd: 9.0336, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.6306, mae: 2.9041, huber: 2.4787, swd: 9.0758, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.6861, mae: 2.4183, huber: 1.9980, swd: 7.1010, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 20.226197\n",
      "        No improvement (21.5382), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 18.3457, mae: 2.4398, huber: 2.0286, swd: 8.3071, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.3204, mae: 2.8290, huber: 2.4021, swd: 7.7750, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7553, mae: 2.4196, huber: 1.9991, swd: 7.0395, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 19.176362\n",
      "        No improvement (20.0979), counter 3/5\n",
      "Epoch [5/50], Train Losses: mse: 17.7590, mae: 2.4101, huber: 1.9992, swd: 7.8770, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 20.4731, mae: 2.8853, huber: 2.4589, swd: 8.6189, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.4739, mae: 2.4680, huber: 2.0460, swd: 7.5425, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 18.546731\n",
      "        No improvement (21.3349), counter 4/5\n",
      "Epoch [6/50], Train Losses: mse: 17.1522, mae: 2.3832, huber: 1.9721, swd: 7.3878, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 21.3789, mae: 2.9292, huber: 2.5045, swd: 9.3263, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.5401, mae: 2.4149, huber: 1.9938, swd: 6.8213, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 17.890962\n",
      "Epoch [6/50], Test Losses: mse: 14.8550, mae: 2.4477, huber: 2.0269, swd: 7.2326, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8550, MAE: 2.4477, SWD: 7.2326\n",
      "Best round's Validation MSE: 19.2200, MAE: 2.8364, SWD: 7.8404\n",
      "Best round's Test verification MSE : 14.8550, MAE: 2.4477, SWD: 7.2326\n",
      "Time taken: 101.55 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_1741)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.0473 ± 0.1459\n",
      "  mae: 2.4370 ± 0.0080\n",
      "  huber: 2.0165 ± 0.0078\n",
      "  swd: 7.6323 ± 0.2961\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.2165 ± 0.2130\n",
      "  mae: 2.8228 ± 0.0191\n",
      "  huber: 2.3998 ± 0.0193\n",
      "  swd: 8.0676 ± 0.1650\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 359.85 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_1741\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.1, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f5990",
   "metadata": {},
   "source": [
    "##### MSE + 0.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee564373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.3654, mae: 2.7020, huber: 2.2871, swd: 11.8234, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 21.7175, mae: 2.9895, huber: 2.5629, swd: 10.2925, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.9757, mae: 2.4552, huber: 2.0337, swd: 7.4853, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 29.277082\n",
      "        Val objective improved inf → 26.8638, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.9324, mae: 2.5669, huber: 2.1541, swd: 10.3892, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 19.9927, mae: 2.8768, huber: 2.4492, swd: 8.8276, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7741, mae: 2.4371, huber: 2.0145, swd: 7.4882, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 26.126958\n",
      "        Val objective improved 26.8638 → 24.4065, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.6415, mae: 2.5068, huber: 2.0948, swd: 9.4372, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 21.7525, mae: 3.0121, huber: 2.5842, swd: 10.6489, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.2645, mae: 2.4983, huber: 2.0749, swd: 7.9742, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 24.360083\n",
      "        No improvement (27.0770), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 18.9382, mae: 2.4691, huber: 2.0580, swd: 8.9284, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 19.8441, mae: 2.8421, huber: 2.4179, swd: 8.6485, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.8801, mae: 2.4118, huber: 1.9915, swd: 7.4710, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 23.402422\n",
      "        Val objective improved 24.4065 → 24.1684, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.0883, mae: 2.4273, huber: 2.0165, swd: 8.2618, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 21.0244, mae: 2.9116, huber: 2.4855, swd: 9.5048, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.0044, mae: 2.4297, huber: 2.0079, swd: 7.6450, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 22.219250\n",
      "        No improvement (25.7769), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.6451, mae: 2.4064, huber: 1.9954, swd: 7.8979, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 21.1151, mae: 2.9191, huber: 2.4918, swd: 9.6283, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.8306, mae: 2.4881, huber: 2.0651, swd: 8.1729, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.594019\n",
      "        No improvement (25.9293), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.1965, mae: 2.3846, huber: 1.9738, swd: 7.5379, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 22.8584, mae: 3.0161, huber: 2.5886, swd: 10.9263, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.7951, mae: 2.5160, huber: 2.0935, swd: 8.9706, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 20.965420\n",
      "        No improvement (28.3215), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.6706, mae: 2.3641, huber: 1.9532, swd: 7.0725, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 22.0411, mae: 2.9723, huber: 2.5442, swd: 10.3730, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 16.5195, mae: 2.5078, huber: 2.0854, swd: 8.8057, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 20.206809\n",
      "        No improvement (27.2276), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.1951, mae: 2.3382, huber: 1.9275, swd: 6.6870, target_std: 20.3630\n",
      "Epoch [9/50], Val Losses: mse: 22.1789, mae: 3.0213, huber: 2.5910, swd: 10.4874, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 16.3934, mae: 2.5465, huber: 2.1229, swd: 8.7933, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 19.538663\n",
      "Epoch [9/50], Test Losses: mse: 14.8801, mae: 2.4118, huber: 1.9915, swd: 7.4710, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8801, MAE: 2.4118, SWD: 7.4710\n",
      "Best round's Validation MSE: 19.8441, MAE: 2.8421, SWD: 8.6485\n",
      "Best round's Test verification MSE : 14.8801, MAE: 2.4118, SWD: 7.4710\n",
      "Time taken: 144.99 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.1290, mae: 2.6912, huber: 2.2761, swd: 12.1888, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 19.9009, mae: 2.8580, huber: 2.4328, swd: 8.8839, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8317, mae: 2.3990, huber: 1.9802, swd: 7.5464, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 29.223342\n",
      "        Val objective improved inf → 24.3428, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.5051, mae: 2.5586, huber: 2.1456, swd: 10.4671, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 19.8873, mae: 2.8637, huber: 2.4379, swd: 8.7581, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.6731, mae: 2.3819, huber: 1.9634, swd: 7.5337, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 25.738641\n",
      "        Val objective improved 24.3428 → 24.2663, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.0684, mae: 2.4880, huber: 2.0759, swd: 9.3800, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 19.5471, mae: 2.8521, huber: 2.4255, swd: 8.7736, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.8163, mae: 2.4247, huber: 2.0046, swd: 7.6950, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 23.758410\n",
      "        Val objective improved 24.2663 → 23.9338, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 18.1839, mae: 2.4398, huber: 2.0284, swd: 8.6970, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.0395, mae: 2.9087, huber: 2.4831, swd: 9.9515, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.9790, mae: 2.4082, huber: 1.9891, swd: 7.9276, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.532442\n",
      "        No improvement (26.0152), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 17.7366, mae: 2.4170, huber: 2.0060, swd: 8.3338, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 20.6317, mae: 2.9054, huber: 2.4771, swd: 9.6112, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.1604, mae: 2.4673, huber: 2.0453, swd: 7.9848, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 21.903473\n",
      "        No improvement (25.4373), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.2505, mae: 2.3978, huber: 1.9865, swd: 7.8707, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 21.0295, mae: 2.9319, huber: 2.5046, swd: 10.0118, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.6892, mae: 2.5038, huber: 2.0816, swd: 8.4955, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.185876\n",
      "        No improvement (26.0353), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 16.5494, mae: 2.3602, huber: 1.9494, swd: 7.2503, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 23.0340, mae: 3.0320, huber: 2.6026, swd: 11.2603, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.6020, mae: 2.5709, huber: 2.1481, swd: 9.8713, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 20.174507\n",
      "        No improvement (28.6641), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4922, mae: 2.3516, huber: 1.9411, swd: 7.2466, target_std: 20.3634\n",
      "Epoch [8/50], Val Losses: mse: 22.1792, mae: 2.9777, huber: 2.5505, swd: 10.7983, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.8248, mae: 2.5118, huber: 2.0895, swd: 8.4929, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 20.115498\n",
      "Epoch [8/50], Test Losses: mse: 14.8163, mae: 2.4247, huber: 2.0046, swd: 7.6950, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8163, MAE: 2.4247, SWD: 7.6950\n",
      "Best round's Validation MSE: 19.5471, MAE: 2.8521, SWD: 8.7736\n",
      "Best round's Test verification MSE : 14.8163, MAE: 2.4247, SWD: 7.6950\n",
      "Time taken: 129.00 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.3198, mae: 2.7012, huber: 2.2860, swd: 11.4858, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 19.7881, mae: 2.8882, huber: 2.4624, swd: 8.1680, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8479, mae: 2.4152, huber: 1.9957, swd: 7.1353, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 29.062647\n",
      "        Val objective improved inf → 23.8721, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.6868, mae: 2.5621, huber: 2.1488, swd: 9.8984, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 20.4910, mae: 2.9114, huber: 2.4813, swd: 8.5529, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9894, mae: 2.4308, huber: 2.0084, swd: 7.1494, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 25.636074\n",
      "        No improvement (24.7674), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 19.6230, mae: 2.5103, huber: 2.0977, swd: 9.1657, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.1069, mae: 2.8764, huber: 2.4480, swd: 8.3682, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.8749, mae: 2.4337, huber: 2.0129, swd: 7.2287, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 24.205867\n",
      "        No improvement (24.2910), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 18.5486, mae: 2.4562, huber: 2.0446, swd: 8.3541, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.7125, mae: 2.8641, huber: 2.4347, swd: 8.0849, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.1399, mae: 2.4395, huber: 2.0191, swd: 7.2354, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.725617\n",
      "        Val objective improved 23.8721 → 23.7550, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.0505, mae: 2.4276, huber: 2.0164, swd: 8.0162, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 19.9362, mae: 2.8725, huber: 2.4426, swd: 8.3552, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.0656, mae: 2.4711, huber: 2.0483, swd: 7.3458, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 22.058585\n",
      "        No improvement (24.1137), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.6108, mae: 2.4055, huber: 1.9943, swd: 7.6612, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 22.2179, mae: 2.9925, huber: 2.5636, swd: 10.1669, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.1570, mae: 2.4507, huber: 2.0286, swd: 7.3364, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.441446\n",
      "        No improvement (27.3014), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.0474, mae: 2.3812, huber: 1.9703, swd: 7.1974, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.0776, mae: 2.9428, huber: 2.5122, swd: 8.7884, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.3909, mae: 2.5276, huber: 2.1036, swd: 8.2955, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 20.646124\n",
      "        No improvement (25.4718), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.3492, mae: 2.3473, huber: 1.9366, swd: 6.6399, target_std: 20.3626\n",
      "Epoch [8/50], Val Losses: mse: 20.9222, mae: 2.9039, huber: 2.4766, swd: 8.8661, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.2608, mae: 2.4537, huber: 2.0321, swd: 7.2848, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 19.669138\n",
      "        No improvement (25.3552), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 15.9029, mae: 2.3175, huber: 1.9075, swd: 6.3096, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 20.0606, mae: 2.8798, huber: 2.4513, swd: 8.4211, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.8868, mae: 2.5199, huber: 2.0978, swd: 7.8973, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 19.057754\n",
      "Epoch [9/50], Test Losses: mse: 15.1399, mae: 2.4395, huber: 2.0191, swd: 7.2354, target_std: 18.3439\n",
      "Best round's Test MSE: 15.1399, MAE: 2.4395, SWD: 7.2354\n",
      "Best round's Validation MSE: 19.7125, MAE: 2.8641, SWD: 8.0849\n",
      "Best round's Test verification MSE : 15.1399, MAE: 2.4395, SWD: 7.2354\n",
      "Time taken: 147.22 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_0056)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.9454 ± 0.1399\n",
      "  mae: 2.4253 ± 0.0113\n",
      "  huber: 2.0051 ± 0.0113\n",
      "  swd: 7.4671 ± 0.1877\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.7012 ± 0.1215\n",
      "  mae: 2.8528 ± 0.0090\n",
      "  huber: 2.4260 ± 0.0069\n",
      "  swd: 8.5023 ± 0.2995\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 421.27 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_0056\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38343cf0",
   "metadata": {},
   "source": [
    "##### MSE + 1.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2daee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 24.2731, mae: 2.7659, huber: 2.3497, swd: 12.1862, target_std: 20.3630\n",
      "Epoch [1/50], Val Losses: mse: 21.4858, mae: 2.9763, huber: 2.5499, swd: 9.9333, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.0342, mae: 2.4532, huber: 2.0315, swd: 7.4216, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 42.552412\n",
      "        Val objective improved inf → 36.3858, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.3381, mae: 2.5978, huber: 2.1842, swd: 10.4205, target_std: 20.3628\n",
      "Epoch [2/50], Val Losses: mse: 20.2309, mae: 2.8735, huber: 2.4483, swd: 9.2300, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.8820, mae: 2.4234, huber: 2.0033, swd: 7.5104, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 36.968815\n",
      "        Val objective improved 36.3858 → 34.0759, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 20.0540, mae: 2.5313, huber: 2.1190, swd: 9.5253, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 20.1179, mae: 2.9000, huber: 2.4730, swd: 8.9119, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.3053, mae: 2.4834, huber: 2.0616, swd: 7.9462, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 34.341882\n",
      "        Val objective improved 34.0759 → 33.4858, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.2815, mae: 2.4924, huber: 2.0806, swd: 8.9584, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.3902, mae: 2.8984, huber: 2.4730, swd: 9.1810, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.1076, mae: 2.4918, huber: 2.0687, swd: 7.8393, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 32.719090\n",
      "        No improvement (34.1617), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 18.7289, mae: 2.4620, huber: 2.0510, swd: 8.5440, target_std: 20.3631\n",
      "Epoch [5/50], Val Losses: mse: 21.2178, mae: 2.9071, huber: 2.4820, swd: 9.7430, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.3119, mae: 2.4668, huber: 2.0456, swd: 7.7892, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 31.544977\n",
      "        No improvement (35.8324), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 17.9552, mae: 2.4231, huber: 2.0124, swd: 7.9399, target_std: 20.3633\n",
      "Epoch [6/50], Val Losses: mse: 20.7771, mae: 2.9080, huber: 2.4813, swd: 9.5104, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.7053, mae: 2.5133, huber: 2.0905, swd: 8.0975, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 29.864935\n",
      "        No improvement (35.0426), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 17.8170, mae: 2.4198, huber: 2.0087, swd: 7.8030, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 22.0757, mae: 2.9666, huber: 2.5397, swd: 10.4861, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.7960, mae: 2.5018, huber: 2.0797, swd: 8.2262, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 29.521562\n",
      "        No improvement (37.8048), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 17.3549, mae: 2.4035, huber: 1.9923, swd: 7.4230, target_std: 20.3630\n",
      "Epoch [8/50], Val Losses: mse: 20.5190, mae: 2.8672, huber: 2.4421, swd: 8.9748, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.4924, mae: 2.4874, huber: 2.0651, swd: 7.8828, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 28.489413\n",
      "Epoch [8/50], Test Losses: mse: 15.3053, mae: 2.4834, huber: 2.0616, swd: 7.9462, target_std: 18.3439\n",
      "Best round's Test MSE: 15.3053, MAE: 2.4834, SWD: 7.9462\n",
      "Best round's Validation MSE: 20.1179, MAE: 2.9000, SWD: 8.9119\n",
      "Best round's Test verification MSE : 15.3053, MAE: 2.4834, SWD: 7.9462\n",
      "Time taken: 126.19 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.6864, mae: 2.7452, huber: 2.3289, swd: 12.2354, target_std: 20.3628\n",
      "Epoch [1/50], Val Losses: mse: 19.8851, mae: 2.8890, huber: 2.4615, swd: 8.7883, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.0799, mae: 2.4469, huber: 2.0255, swd: 7.7470, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 42.039492\n",
      "        Val objective improved inf → 33.0676, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 20.6871, mae: 2.5856, huber: 2.1712, swd: 10.2426, target_std: 20.3635\n",
      "Epoch [2/50], Val Losses: mse: 19.3722, mae: 2.8497, huber: 2.4221, swd: 8.4221, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7791, mae: 2.4187, huber: 1.9982, swd: 7.6286, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 36.050997\n",
      "        Val objective improved 33.0676 → 32.0054, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 19.4455, mae: 2.5196, huber: 2.1065, swd: 9.4076, target_std: 20.3628\n",
      "Epoch [3/50], Val Losses: mse: 19.3883, mae: 2.8376, huber: 2.4104, swd: 8.4660, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.9848, mae: 2.4355, huber: 2.0143, swd: 7.7675, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 33.556970\n",
      "        No improvement (32.0873), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 18.6570, mae: 2.4715, huber: 2.0595, swd: 8.8245, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 20.0365, mae: 2.8699, huber: 2.4445, swd: 8.8180, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.8951, mae: 2.4085, huber: 1.9888, swd: 7.7002, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 31.893691\n",
      "        No improvement (33.2635), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 18.0380, mae: 2.4385, huber: 2.0269, swd: 8.3348, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.3835, mae: 2.9573, huber: 2.5331, swd: 10.3103, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.1787, mae: 2.4502, huber: 2.0292, swd: 7.9746, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 30.540231\n",
      "        No improvement (36.8489), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 17.5040, mae: 2.4102, huber: 1.9989, swd: 7.8706, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 20.9135, mae: 2.9315, huber: 2.5043, swd: 9.7122, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5149, mae: 2.4780, huber: 2.0558, swd: 8.1826, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 29.309938\n",
      "        No improvement (35.4818), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 16.9900, mae: 2.3853, huber: 1.9742, swd: 7.4225, target_std: 20.3636\n",
      "Epoch [7/50], Val Losses: mse: 22.6664, mae: 3.0155, huber: 2.5892, swd: 11.5618, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 17.3953, mae: 2.5816, huber: 2.1573, swd: 9.8318, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 28.123668\n",
      "Epoch [7/50], Test Losses: mse: 14.7791, mae: 2.4187, huber: 1.9982, swd: 7.6286, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7791, MAE: 2.4187, SWD: 7.6286\n",
      "Best round's Validation MSE: 19.3722, MAE: 2.8497, SWD: 8.4221\n",
      "Best round's Test verification MSE : 14.7791, MAE: 2.4187, SWD: 7.6286\n",
      "Time taken: 110.95 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 23.9354, mae: 2.7442, huber: 2.3280, swd: 11.6443, target_std: 20.3627\n",
      "Epoch [1/50], Val Losses: mse: 20.0683, mae: 2.8783, huber: 2.4552, swd: 8.0472, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.6449, mae: 2.4426, huber: 2.0235, swd: 7.5591, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 41.401785\n",
      "        Val objective improved inf → 32.1391, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.4901, mae: 2.6039, huber: 2.1897, swd: 10.2539, target_std: 20.3629\n",
      "Epoch [2/50], Val Losses: mse: 22.0012, mae: 3.0141, huber: 2.5824, swd: 9.8285, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 16.0198, mae: 2.4943, huber: 2.0714, swd: 7.9064, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 36.871017\n",
      "        No improvement (36.7439), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 20.0459, mae: 2.5337, huber: 2.1210, swd: 9.2178, target_std: 20.3630\n",
      "Epoch [3/50], Val Losses: mse: 19.5983, mae: 2.8312, huber: 2.4066, swd: 8.0857, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0809, mae: 2.4358, huber: 2.0155, swd: 7.3535, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 33.872667\n",
      "        Val objective improved 32.1391 → 31.7268, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 19.1823, mae: 2.4920, huber: 2.0798, swd: 8.6321, target_std: 20.3631\n",
      "Epoch [4/50], Val Losses: mse: 19.5337, mae: 2.8265, huber: 2.4013, swd: 8.0116, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.3537, mae: 2.4403, huber: 2.0195, swd: 7.4611, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 32.130507\n",
      "        Val objective improved 31.7268 → 31.5510, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 18.4529, mae: 2.4548, huber: 2.0430, swd: 8.0981, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 19.7493, mae: 2.8468, huber: 2.4211, swd: 8.1840, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.5746, mae: 2.4965, huber: 2.0743, swd: 7.7906, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 30.599994\n",
      "        No improvement (32.0253), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 17.9448, mae: 2.4303, huber: 2.0187, swd: 7.7029, target_std: 20.3631\n",
      "Epoch [6/50], Val Losses: mse: 20.9677, mae: 2.9187, huber: 2.4924, swd: 9.0605, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.5648, mae: 2.4778, huber: 2.0562, swd: 7.6462, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 29.499109\n",
      "        No improvement (34.5584), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 17.5019, mae: 2.4105, huber: 1.9992, swd: 7.3519, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 20.9504, mae: 2.9118, huber: 2.4855, swd: 9.1286, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 16.0770, mae: 2.5081, huber: 2.0854, swd: 8.0523, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 28.529820\n",
      "        No improvement (34.6433), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.9425, mae: 2.3853, huber: 1.9741, swd: 6.8674, target_std: 20.3626\n",
      "Epoch [8/50], Val Losses: mse: 20.3540, mae: 2.8960, huber: 2.4694, swd: 8.5865, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.7142, mae: 2.5052, huber: 2.0828, swd: 7.7224, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 27.243638\n",
      "        No improvement (33.2337), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.5708, mae: 2.3634, huber: 1.9524, swd: 6.6153, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.1623, mae: 2.9314, huber: 2.5049, swd: 9.1523, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.8072, mae: 2.4937, huber: 2.0713, swd: 7.6861, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 26.493783\n",
      "Epoch [9/50], Test Losses: mse: 15.3537, mae: 2.4403, huber: 2.0195, swd: 7.4611, target_std: 18.3439\n",
      "Best round's Test MSE: 15.3537, MAE: 2.4403, SWD: 7.4611\n",
      "Best round's Validation MSE: 19.5337, MAE: 2.8265, SWD: 8.0116\n",
      "Best round's Test verification MSE : 15.3537, MAE: 2.4403, SWD: 7.4611\n",
      "Time taken: 143.56 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred336_20250508_0145)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.1460 ± 0.2602\n",
      "  mae: 2.4475 ± 0.0269\n",
      "  huber: 2.0264 ± 0.0263\n",
      "  swd: 7.6786 ± 0.2012\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 19.6746 ± 0.3203\n",
      "  mae: 2.8588 ± 0.0307\n",
      "  huber: 2.4321 ± 0.0301\n",
      "  swd: 8.4485 ± 0.3680\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 380.81 seconds\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred336_20250508_0145\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 1.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 1.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d08ae2",
   "metadata": {},
   "source": [
    "#### pred=720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ac29dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 373\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 373\n",
      "Validation Batches: 47\n",
      "Test Batches: 101\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.1986, mae: 2.9684, huber: 2.5525, swd: 14.7643, target_std: 20.3719\n",
      "Epoch [1/50], Val Losses: mse: 24.6203, mae: 3.2236, huber: 2.7947, swd: 9.4972, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.0757, mae: 2.6125, huber: 2.1907, swd: 7.9845, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.552492\n",
      "        Val objective improved inf → 2.7947, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 28.0065, mae: 2.8405, huber: 2.4276, swd: 13.4317, target_std: 20.3719\n",
      "Epoch [2/50], Val Losses: mse: 23.8469, mae: 3.1642, huber: 2.7376, swd: 8.6309, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.5069, mae: 2.6419, huber: 2.2201, swd: 8.4683, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.427572\n",
      "        Val objective improved 2.7947 → 2.7376, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.9434, mae: 2.7808, huber: 2.3688, swd: 12.6009, target_std: 20.3712\n",
      "Epoch [3/50], Val Losses: mse: 23.3260, mae: 3.1279, huber: 2.7033, swd: 8.5711, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.5594, mae: 2.6718, huber: 2.2497, swd: 8.4682, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.368788\n",
      "        Val objective improved 2.7376 → 2.7033, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 26.1750, mae: 2.7402, huber: 2.3287, swd: 12.0172, target_std: 20.3714\n",
      "Epoch [4/50], Val Losses: mse: 24.3600, mae: 3.2051, huber: 2.7762, swd: 8.8992, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.6799, mae: 2.6816, huber: 2.2577, swd: 8.4222, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.328671\n",
      "        No improvement (2.7762), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 25.3054, mae: 2.6920, huber: 2.2809, swd: 11.3344, target_std: 20.3717\n",
      "Epoch [5/50], Val Losses: mse: 25.6328, mae: 3.2960, huber: 2.8657, swd: 9.7349, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.8305, mae: 2.7101, huber: 2.2856, swd: 8.4937, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.280916\n",
      "        No improvement (2.8657), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 24.7201, mae: 2.6545, huber: 2.2439, swd: 10.8693, target_std: 20.3714\n",
      "Epoch [6/50], Val Losses: mse: 26.0188, mae: 3.3173, huber: 2.8871, swd: 10.3936, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 18.2899, mae: 2.6999, huber: 2.2761, swd: 8.8401, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.243854\n",
      "        No improvement (2.8871), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 24.0087, mae: 2.6152, huber: 2.2049, swd: 10.2841, target_std: 20.3713\n",
      "Epoch [7/50], Val Losses: mse: 26.1289, mae: 3.3113, huber: 2.8816, swd: 10.3814, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 18.3299, mae: 2.7169, huber: 2.2925, swd: 8.8712, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.204925\n",
      "        No improvement (2.8816), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 23.5377, mae: 2.5916, huber: 2.1814, swd: 9.9274, target_std: 20.3713\n",
      "Epoch [8/50], Val Losses: mse: 26.4892, mae: 3.3441, huber: 2.9132, swd: 10.2044, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 18.6818, mae: 2.7484, huber: 2.3232, swd: 9.0084, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.181438\n",
      "Epoch [8/50], Test Losses: mse: 17.5594, mae: 2.6718, huber: 2.2497, swd: 8.4682, target_std: 18.3446\n",
      "Best round's Test MSE: 17.5594, MAE: 2.6718, SWD: 8.4682\n",
      "Best round's Validation MSE: 23.3260, MAE: 3.1279\n",
      "Best round's Test verification MSE : 17.5594, MAE: 2.6718, SWD: 8.4682\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.0985, mae: 2.9638, huber: 2.5480, swd: 13.5474, target_std: 20.3714\n",
      "Epoch [1/50], Val Losses: mse: 23.7117, mae: 3.1606, huber: 2.7320, swd: 7.9566, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 16.7431, mae: 2.5861, huber: 2.1654, swd: 7.1756, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.547980\n",
      "        Val objective improved inf → 2.7320, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.4640, mae: 2.8268, huber: 2.4136, swd: 11.8643, target_std: 20.3715\n",
      "Epoch [2/50], Val Losses: mse: 23.5911, mae: 3.1528, huber: 2.7253, swd: 8.0598, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.0817, mae: 2.6409, huber: 2.2187, swd: 7.6151, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.413599\n",
      "        Val objective improved 2.7320 → 2.7253, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.3774, mae: 2.7637, huber: 2.3514, swd: 11.1487, target_std: 20.3716\n",
      "Epoch [3/50], Val Losses: mse: 24.5787, mae: 3.1840, huber: 2.7550, swd: 8.3301, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.5024, mae: 2.6450, huber: 2.2218, swd: 7.7458, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.351407\n",
      "        No improvement (2.7550), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 25.5173, mae: 2.7156, huber: 2.3039, swd: 10.5462, target_std: 20.3719\n",
      "Epoch [4/50], Val Losses: mse: 24.9871, mae: 3.2294, huber: 2.8004, swd: 8.7047, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.4044, mae: 2.6385, huber: 2.2155, swd: 7.6483, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.303937\n",
      "        No improvement (2.8004), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 24.7431, mae: 2.6697, huber: 2.2587, swd: 10.0025, target_std: 20.3711\n",
      "Epoch [5/50], Val Losses: mse: 26.5375, mae: 3.3358, huber: 2.9055, swd: 9.8891, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.4775, mae: 2.6740, huber: 2.2498, swd: 7.6858, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.258726\n",
      "        No improvement (2.9055), counter 3/5\n",
      "Epoch [6/50], Train Losses: mse: 24.0673, mae: 2.6263, huber: 2.2157, swd: 9.4992, target_std: 20.3719\n",
      "Epoch [6/50], Val Losses: mse: 24.7462, mae: 3.2351, huber: 2.8061, swd: 8.4433, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.9950, mae: 2.7181, huber: 2.2934, swd: 8.1200, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.215668\n",
      "        No improvement (2.8061), counter 4/5\n",
      "Epoch [7/50], Train Losses: mse: 23.3840, mae: 2.5864, huber: 2.1762, swd: 9.0309, target_std: 20.3716\n",
      "Epoch [7/50], Val Losses: mse: 25.2817, mae: 3.2860, huber: 2.8548, swd: 8.5170, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 18.6166, mae: 2.7736, huber: 2.3470, swd: 8.2193, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.176186\n",
      "Epoch [7/50], Test Losses: mse: 17.0817, mae: 2.6409, huber: 2.2187, swd: 7.6151, target_std: 18.3446\n",
      "Best round's Test MSE: 17.0817, MAE: 2.6409, SWD: 7.6151\n",
      "Best round's Validation MSE: 23.5911, MAE: 3.1528\n",
      "Best round's Test verification MSE : 17.0817, MAE: 2.6409, SWD: 7.6151\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 30.1507, mae: 2.9590, huber: 2.5433, swd: 15.4855, target_std: 20.3711\n",
      "Epoch [1/50], Val Losses: mse: 24.5719, mae: 3.2238, huber: 2.7964, swd: 10.5617, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 16.8602, mae: 2.6351, huber: 2.2124, swd: 8.4995, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.543287\n",
      "        Val objective improved inf → 2.7964, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 28.1403, mae: 2.8386, huber: 2.4258, swd: 14.1549, target_std: 20.3714\n",
      "Epoch [2/50], Val Losses: mse: 23.2392, mae: 3.1208, huber: 2.6967, swd: 8.9927, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 16.9082, mae: 2.6269, huber: 2.2049, swd: 8.3591, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.425776\n",
      "        Val objective improved 2.7964 → 2.6967, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 27.0623, mae: 2.7787, huber: 2.3665, swd: 13.3218, target_std: 20.3711\n",
      "Epoch [3/50], Val Losses: mse: 23.4068, mae: 3.1184, huber: 2.6929, swd: 9.0222, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 16.8483, mae: 2.6203, huber: 2.1980, swd: 8.3461, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.366518\n",
      "        Val objective improved 2.6967 → 2.6929, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 26.2797, mae: 2.7353, huber: 2.3236, swd: 12.7157, target_std: 20.3714\n",
      "Epoch [4/50], Val Losses: mse: 23.6306, mae: 3.1674, huber: 2.7393, swd: 9.0972, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 16.8777, mae: 2.6562, huber: 2.2322, swd: 8.3152, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.323571\n",
      "        No improvement (2.7393), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 25.5051, mae: 2.6968, huber: 2.2854, swd: 12.0882, target_std: 20.3714\n",
      "Epoch [5/50], Val Losses: mse: 25.4121, mae: 3.2568, huber: 2.8265, swd: 10.1549, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.0538, mae: 2.6449, huber: 2.2204, swd: 8.1922, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.285395\n",
      "        No improvement (2.8265), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 24.8968, mae: 2.6628, huber: 2.2518, swd: 11.6332, target_std: 20.3717\n",
      "Epoch [6/50], Val Losses: mse: 24.0176, mae: 3.1833, huber: 2.7551, swd: 9.3309, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.2448, mae: 2.6676, huber: 2.2435, swd: 8.5694, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.251751\n",
      "        No improvement (2.7551), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 24.3284, mae: 2.6276, huber: 2.2167, swd: 11.1976, target_std: 20.3716\n",
      "Epoch [7/50], Val Losses: mse: 24.2186, mae: 3.1846, huber: 2.7560, swd: 9.3687, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 17.5635, mae: 2.7130, huber: 2.2873, swd: 8.8759, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.216729\n",
      "        No improvement (2.7560), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 23.7172, mae: 2.5943, huber: 2.1839, swd: 10.7124, target_std: 20.3718\n",
      "Epoch [8/50], Val Losses: mse: 26.6398, mae: 3.3357, huber: 2.9048, swd: 10.9502, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 18.3063, mae: 2.7327, huber: 2.3063, swd: 9.1520, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.183904\n",
      "Epoch [8/50], Test Losses: mse: 16.8483, mae: 2.6203, huber: 2.1980, swd: 8.3461, target_std: 18.3446\n",
      "Best round's Test MSE: 16.8483, MAE: 2.6203, SWD: 8.3461\n",
      "Best round's Validation MSE: 23.4068, MAE: 3.1184\n",
      "Best round's Test verification MSE : 16.8483, MAE: 2.6203, SWD: 8.3461\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (PatchTST_ettm2_seq336_pred720_20250430_2047)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 17.1631 ± 0.2960\n",
      "  mae: 2.6444 ± 0.0212\n",
      "  huber: 2.2221 ± 0.0212\n",
      "  swd: 8.1432 ± 0.3767\n",
      "  target_std: 18.3446 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 23.4413 ± 0.1109\n",
      "  mae: 3.1331 ± 0.0145\n",
      "  huber: 2.7072 ± 0.0135\n",
      "  swd: 8.5510 ± 0.3932\n",
      "  target_std: 20.5636 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: PatchTST_ettm2_seq336_pred720_20250430_2047\n",
      "Model: PatchTST\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatPatchTSTConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=720,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    enc_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    dec_in=data_mgr.datasets['ettm2']['channels'],\n",
    "    c_out=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50,\n",
    "    task_name='long_term_forecast',\n",
    "    factor=3,\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f020271",
   "metadata": {},
   "source": [
    "### DLinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854195a",
   "metadata": {},
   "source": [
    "#### pred=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7674cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([96, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 378\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 96, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 378\n",
      "Validation Batches: 52\n",
      "Test Batches: 106\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.9063, mae: 2.3735, huber: 1.9679, swd: 10.2081, target_std: 20.3538\n",
      "Epoch [1/50], Val Losses: mse: 13.4917, mae: 2.1931, huber: 1.7944, swd: 7.6491, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.6488, mae: 1.9214, huber: 1.5143, swd: 4.9296, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.967917\n",
      "        Val objective improved inf → 1.7944, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8238, mae: 1.8767, huber: 1.4809, swd: 6.7335, target_std: 20.3537\n",
      "Epoch [2/50], Val Losses: mse: 12.7837, mae: 2.1426, huber: 1.7466, swd: 7.0600, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.3700, mae: 1.8987, huber: 1.4935, swd: 4.7728, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.480898\n",
      "        Val objective improved 1.7944 → 1.7466, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.5449, mae: 1.8577, huber: 1.4629, swd: 6.5094, target_std: 20.3531\n",
      "Epoch [3/50], Val Losses: mse: 12.5678, mae: 2.1205, huber: 1.7252, swd: 6.7959, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.3723, mae: 1.8874, huber: 1.4827, swd: 4.7346, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.462878\n",
      "        Val objective improved 1.7466 → 1.7252, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.4453, mae: 1.8503, huber: 1.4559, swd: 6.4122, target_std: 20.3532\n",
      "Epoch [4/50], Val Losses: mse: 12.4972, mae: 2.1145, huber: 1.7193, swd: 6.7463, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.3274, mae: 1.8866, huber: 1.4817, swd: 4.6970, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.455915\n",
      "        Val objective improved 1.7252 → 1.7193, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 11.3728, mae: 1.8438, huber: 1.4496, swd: 6.3614, target_std: 20.3536\n",
      "Epoch [5/50], Val Losses: mse: 12.5296, mae: 2.1213, huber: 1.7262, swd: 6.7461, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.3545, mae: 1.8793, huber: 1.4759, swd: 4.7544, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.449551\n",
      "        No improvement (1.7262), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 11.4173, mae: 1.8509, huber: 1.4564, swd: 6.3725, target_std: 20.3533\n",
      "Epoch [6/50], Val Losses: mse: 12.4825, mae: 2.1118, huber: 1.7168, swd: 6.7526, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.3742, mae: 1.8995, huber: 1.4947, swd: 4.8171, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.456422\n",
      "        Val objective improved 1.7193 → 1.7168, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 11.3559, mae: 1.8458, huber: 1.4515, swd: 6.3437, target_std: 20.3523\n",
      "Epoch [7/50], Val Losses: mse: 12.4995, mae: 2.1195, huber: 1.7240, swd: 6.7570, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.3744, mae: 1.9069, huber: 1.5003, swd: 4.7326, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.451542\n",
      "        No improvement (1.7240), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 11.3678, mae: 1.8470, huber: 1.4525, swd: 6.3434, target_std: 20.3530\n",
      "Epoch [8/50], Val Losses: mse: 12.3831, mae: 2.1078, huber: 1.7122, swd: 6.6317, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.3094, mae: 1.8882, huber: 1.4833, swd: 4.6779, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.452511\n",
      "        Val objective improved 1.7168 → 1.7122, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 11.3564, mae: 1.8438, huber: 1.4497, swd: 6.3349, target_std: 20.3533\n",
      "Epoch [9/50], Val Losses: mse: 12.4183, mae: 2.1108, huber: 1.7158, swd: 6.6790, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.2912, mae: 1.8853, huber: 1.4805, swd: 4.7045, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.449713\n",
      "        No improvement (1.7158), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 11.3331, mae: 1.8426, huber: 1.4485, swd: 6.3238, target_std: 20.3535\n",
      "Epoch [10/50], Val Losses: mse: 12.3931, mae: 2.1094, huber: 1.7147, swd: 6.6407, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 9.2583, mae: 1.8863, huber: 1.4814, swd: 4.6751, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.448520\n",
      "        No improvement (1.7147), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 11.3394, mae: 1.8432, huber: 1.4490, swd: 6.3250, target_std: 20.3530\n",
      "Epoch [11/50], Val Losses: mse: 12.3776, mae: 2.1073, huber: 1.7124, swd: 6.6757, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 9.2455, mae: 1.8790, huber: 1.4747, swd: 4.6602, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.448996\n",
      "        No improvement (1.7124), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 11.3369, mae: 1.8421, huber: 1.4481, swd: 6.3275, target_std: 20.3531\n",
      "Epoch [12/50], Val Losses: mse: 12.3674, mae: 2.1115, huber: 1.7163, swd: 6.6147, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 9.2804, mae: 1.9032, huber: 1.4967, swd: 4.6887, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.448148\n",
      "        No improvement (1.7163), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 11.3242, mae: 1.8428, huber: 1.4486, swd: 6.3113, target_std: 20.3536\n",
      "Epoch [13/50], Val Losses: mse: 12.2744, mae: 2.0991, huber: 1.7042, swd: 6.6003, target_std: 20.5735\n",
      "Epoch [13/50], Test Losses: mse: 9.2454, mae: 1.8873, huber: 1.4820, swd: 4.6941, target_std: 18.3806\n",
      "  Epoch 13 composite train-obj: 1.448565\n",
      "        Val objective improved 1.7122 → 1.7042, saving checkpoint.\n",
      "Epoch [14/50], Train Losses: mse: 11.3305, mae: 1.8455, huber: 1.4511, swd: 6.3115, target_std: 20.3532\n",
      "Epoch [14/50], Val Losses: mse: 12.4403, mae: 2.1131, huber: 1.7178, swd: 6.6809, target_std: 20.5735\n",
      "Epoch [14/50], Test Losses: mse: 9.2649, mae: 1.8819, huber: 1.4773, swd: 4.6867, target_std: 18.3806\n",
      "  Epoch 14 composite train-obj: 1.451134\n",
      "        No improvement (1.7178), counter 1/5\n",
      "Epoch [15/50], Train Losses: mse: 11.3574, mae: 1.8470, huber: 1.4526, swd: 6.3280, target_std: 20.3530\n",
      "Epoch [15/50], Val Losses: mse: 12.4010, mae: 2.1114, huber: 1.7159, swd: 6.6412, target_std: 20.5735\n",
      "Epoch [15/50], Test Losses: mse: 9.3632, mae: 1.8951, huber: 1.4905, swd: 4.7431, target_std: 18.3806\n",
      "  Epoch 15 composite train-obj: 1.452556\n",
      "        No improvement (1.7159), counter 2/5\n",
      "Epoch [16/50], Train Losses: mse: 11.3349, mae: 1.8437, huber: 1.4495, swd: 6.3223, target_std: 20.3531\n",
      "Epoch [16/50], Val Losses: mse: 12.4745, mae: 2.1126, huber: 1.7180, swd: 6.7069, target_std: 20.5735\n",
      "Epoch [16/50], Test Losses: mse: 9.2985, mae: 1.8842, huber: 1.4793, swd: 4.7156, target_std: 18.3806\n",
      "  Epoch 16 composite train-obj: 1.449522\n",
      "        No improvement (1.7180), counter 3/5\n",
      "Epoch [17/50], Train Losses: mse: 11.3693, mae: 1.8492, huber: 1.4547, swd: 6.3217, target_std: 20.3536\n",
      "Epoch [17/50], Val Losses: mse: 12.6522, mae: 2.1271, huber: 1.7320, swd: 6.8300, target_std: 20.5735\n",
      "Epoch [17/50], Test Losses: mse: 9.5223, mae: 1.8965, huber: 1.4931, swd: 4.8475, target_std: 18.3806\n",
      "  Epoch 17 composite train-obj: 1.454728\n",
      "        No improvement (1.7320), counter 4/5\n",
      "Epoch [18/50], Train Losses: mse: 11.3415, mae: 1.8439, huber: 1.4498, swd: 6.3130, target_std: 20.3530\n",
      "Epoch [18/50], Val Losses: mse: 12.4434, mae: 2.1171, huber: 1.7212, swd: 6.6401, target_std: 20.5735\n",
      "Epoch [18/50], Test Losses: mse: 9.4003, mae: 1.9005, huber: 1.4942, swd: 4.7315, target_std: 18.3806\n",
      "  Epoch 18 composite train-obj: 1.449776\n",
      "Epoch [18/50], Test Losses: mse: 9.2454, mae: 1.8873, huber: 1.4820, swd: 4.6941, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2454, MAE: 1.8873, SWD: 4.6941\n",
      "Best round's Validation MSE: 12.2744, MAE: 2.0991\n",
      "Best round's Test verification MSE : 9.2454, MAE: 1.8873, SWD: 4.6941\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.0783, mae: 2.3560, huber: 1.9503, swd: 9.7041, target_std: 20.3544\n",
      "Epoch [1/50], Val Losses: mse: 13.5216, mae: 2.1948, huber: 1.7961, swd: 7.3912, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.6890, mae: 1.9378, huber: 1.5294, swd: 4.7351, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.950329\n",
      "        Val objective improved inf → 1.7961, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8342, mae: 1.8763, huber: 1.4806, swd: 6.5281, target_std: 20.3534\n",
      "Epoch [2/50], Val Losses: mse: 12.6529, mae: 2.1250, huber: 1.7296, swd: 6.7234, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.3661, mae: 1.9008, huber: 1.4950, swd: 4.5669, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.480561\n",
      "        Val objective improved 1.7961 → 1.7296, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.5510, mae: 1.8568, huber: 1.4621, swd: 6.2846, target_std: 20.3534\n",
      "Epoch [3/50], Val Losses: mse: 12.4414, mae: 2.1119, huber: 1.7167, swd: 6.5873, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.2339, mae: 1.8890, huber: 1.4829, swd: 4.5341, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.462062\n",
      "        Val objective improved 1.7296 → 1.7167, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.4378, mae: 1.8476, huber: 1.4534, swd: 6.2008, target_std: 20.3538\n",
      "Epoch [4/50], Val Losses: mse: 12.4761, mae: 2.1179, huber: 1.7229, swd: 6.5312, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.3221, mae: 1.8847, huber: 1.4804, swd: 4.5529, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.453381\n",
      "        No improvement (1.7229), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 11.4048, mae: 1.8486, huber: 1.4544, swd: 6.1647, target_std: 20.3536\n",
      "Epoch [5/50], Val Losses: mse: 12.4878, mae: 2.1143, huber: 1.7189, swd: 6.5048, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.3455, mae: 1.8974, huber: 1.4909, swd: 4.5397, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.454367\n",
      "        No improvement (1.7189), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 11.3938, mae: 1.8481, huber: 1.4537, swd: 6.1603, target_std: 20.3539\n",
      "Epoch [6/50], Val Losses: mse: 12.6298, mae: 2.1284, huber: 1.7331, swd: 6.5478, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.4169, mae: 1.8885, huber: 1.4849, swd: 4.5738, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.453749\n",
      "        No improvement (1.7331), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 11.3896, mae: 1.8486, huber: 1.4543, swd: 6.1442, target_std: 20.3527\n",
      "Epoch [7/50], Val Losses: mse: 12.3523, mae: 2.1069, huber: 1.7115, swd: 6.4302, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.2675, mae: 1.8910, huber: 1.4856, swd: 4.5244, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.454344\n",
      "        Val objective improved 1.7167 → 1.7115, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 11.3573, mae: 1.8455, huber: 1.4512, swd: 6.1291, target_std: 20.3536\n",
      "Epoch [8/50], Val Losses: mse: 12.4703, mae: 2.1184, huber: 1.7230, swd: 6.4853, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.4948, mae: 1.8984, huber: 1.4923, swd: 4.6228, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.451220\n",
      "        No improvement (1.7230), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 11.3587, mae: 1.8449, huber: 1.4506, swd: 6.1265, target_std: 20.3527\n",
      "Epoch [9/50], Val Losses: mse: 12.3893, mae: 2.1102, huber: 1.7146, swd: 6.4178, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.3020, mae: 1.8896, huber: 1.4840, swd: 4.4957, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.450635\n",
      "        No improvement (1.7146), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 11.3499, mae: 1.8453, huber: 1.4509, swd: 6.1151, target_std: 20.3530\n",
      "Epoch [10/50], Val Losses: mse: 12.6610, mae: 2.1364, huber: 1.7390, swd: 6.6124, target_std: 20.5735\n",
      "Epoch [10/50], Test Losses: mse: 9.6179, mae: 1.9058, huber: 1.4975, swd: 4.7232, target_std: 18.3806\n",
      "  Epoch 10 composite train-obj: 1.450905\n",
      "        No improvement (1.7390), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 11.3435, mae: 1.8458, huber: 1.4514, swd: 6.1152, target_std: 20.3534\n",
      "Epoch [11/50], Val Losses: mse: 12.3348, mae: 2.1066, huber: 1.7117, swd: 6.4393, target_std: 20.5735\n",
      "Epoch [11/50], Test Losses: mse: 9.2229, mae: 1.8910, huber: 1.4858, swd: 4.4925, target_std: 18.3806\n",
      "  Epoch 11 composite train-obj: 1.451376\n",
      "        No improvement (1.7117), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 11.3334, mae: 1.8433, huber: 1.4492, swd: 6.1088, target_std: 20.3536\n",
      "Epoch [12/50], Val Losses: mse: 12.4306, mae: 2.1151, huber: 1.7196, swd: 6.4836, target_std: 20.5735\n",
      "Epoch [12/50], Test Losses: mse: 9.2626, mae: 1.8953, huber: 1.4889, swd: 4.5106, target_std: 18.3806\n",
      "  Epoch 12 composite train-obj: 1.449193\n",
      "Epoch [12/50], Test Losses: mse: 9.2675, mae: 1.8910, huber: 1.4856, swd: 4.5244, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2675, MAE: 1.8910, SWD: 4.5244\n",
      "Best round's Validation MSE: 12.3523, MAE: 2.1069\n",
      "Best round's Test verification MSE : 9.2675, MAE: 1.8910, SWD: 4.5244\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 22.7583, mae: 2.3633, huber: 1.9578, swd: 8.9941, target_std: 20.3540\n",
      "Epoch [1/50], Val Losses: mse: 13.2830, mae: 2.1834, huber: 1.7845, swd: 6.8168, target_std: 20.5735\n",
      "Epoch [1/50], Test Losses: mse: 9.5370, mae: 1.9235, huber: 1.5158, swd: 4.3762, target_std: 18.3806\n",
      "  Epoch 1 composite train-obj: 1.957824\n",
      "        Val objective improved inf → 1.7845, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 11.8054, mae: 1.8757, huber: 1.4798, swd: 6.0637, target_std: 20.3536\n",
      "Epoch [2/50], Val Losses: mse: 12.7673, mae: 2.1314, huber: 1.7358, swd: 6.3479, target_std: 20.5735\n",
      "Epoch [2/50], Test Losses: mse: 9.3851, mae: 1.8975, huber: 1.4911, swd: 4.2840, target_std: 18.3806\n",
      "  Epoch 2 composite train-obj: 1.479819\n",
      "        Val objective improved 1.7845 → 1.7358, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 11.5226, mae: 1.8537, huber: 1.4592, swd: 5.8638, target_std: 20.3541\n",
      "Epoch [3/50], Val Losses: mse: 12.5481, mae: 2.1199, huber: 1.7245, swd: 6.2016, target_std: 20.5735\n",
      "Epoch [3/50], Test Losses: mse: 9.3204, mae: 1.8823, huber: 1.4774, swd: 4.2764, target_std: 18.3806\n",
      "  Epoch 3 composite train-obj: 1.459170\n",
      "        Val objective improved 1.7358 → 1.7245, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 11.4522, mae: 1.8515, huber: 1.4571, swd: 5.7973, target_std: 20.3528\n",
      "Epoch [4/50], Val Losses: mse: 12.4093, mae: 2.1084, huber: 1.7135, swd: 6.0814, target_std: 20.5735\n",
      "Epoch [4/50], Test Losses: mse: 9.2865, mae: 1.8837, huber: 1.4789, swd: 4.2316, target_std: 18.3806\n",
      "  Epoch 4 composite train-obj: 1.457138\n",
      "        Val objective improved 1.7245 → 1.7135, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 11.3982, mae: 1.8474, huber: 1.4531, swd: 5.7517, target_std: 20.3538\n",
      "Epoch [5/50], Val Losses: mse: 12.5535, mae: 2.1206, huber: 1.7255, swd: 6.1583, target_std: 20.5735\n",
      "Epoch [5/50], Test Losses: mse: 9.4329, mae: 1.8874, huber: 1.4831, swd: 4.3175, target_std: 18.3806\n",
      "  Epoch 5 composite train-obj: 1.453088\n",
      "        No improvement (1.7255), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 11.3906, mae: 1.8477, huber: 1.4536, swd: 5.7451, target_std: 20.3535\n",
      "Epoch [6/50], Val Losses: mse: 12.4324, mae: 2.1097, huber: 1.7151, swd: 6.1038, target_std: 20.5735\n",
      "Epoch [6/50], Test Losses: mse: 9.2836, mae: 1.8925, huber: 1.4875, swd: 4.2601, target_std: 18.3806\n",
      "  Epoch 6 composite train-obj: 1.453606\n",
      "        No improvement (1.7151), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 11.4090, mae: 1.8513, huber: 1.4569, swd: 5.7563, target_std: 20.3532\n",
      "Epoch [7/50], Val Losses: mse: 12.3870, mae: 2.1117, huber: 1.7167, swd: 6.0999, target_std: 20.5735\n",
      "Epoch [7/50], Test Losses: mse: 9.2079, mae: 1.8889, huber: 1.4833, swd: 4.2252, target_std: 18.3806\n",
      "  Epoch 7 composite train-obj: 1.456861\n",
      "        No improvement (1.7167), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 11.3622, mae: 1.8462, huber: 1.4518, swd: 5.7325, target_std: 20.3534\n",
      "Epoch [8/50], Val Losses: mse: 12.3608, mae: 2.1149, huber: 1.7193, swd: 6.0759, target_std: 20.5735\n",
      "Epoch [8/50], Test Losses: mse: 9.2756, mae: 1.9090, huber: 1.5014, swd: 4.2501, target_std: 18.3806\n",
      "  Epoch 8 composite train-obj: 1.451766\n",
      "        No improvement (1.7193), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 11.3451, mae: 1.8439, huber: 1.4496, swd: 5.7192, target_std: 20.3532\n",
      "Epoch [9/50], Val Losses: mse: 12.4085, mae: 2.1138, huber: 1.7182, swd: 6.1225, target_std: 20.5735\n",
      "Epoch [9/50], Test Losses: mse: 9.2384, mae: 1.8837, huber: 1.4782, swd: 4.2210, target_std: 18.3806\n",
      "  Epoch 9 composite train-obj: 1.449608\n",
      "Epoch [9/50], Test Losses: mse: 9.2865, mae: 1.8837, huber: 1.4789, swd: 4.2316, target_std: 18.3806\n",
      "Best round's Test MSE: 9.2865, MAE: 1.8837, SWD: 4.2316\n",
      "Best round's Validation MSE: 12.4093, MAE: 2.1084\n",
      "Best round's Test verification MSE : 9.2865, MAE: 1.8837, SWD: 4.2316\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred96_20250430_2014)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 9.2664 ± 0.0168\n",
      "  mae: 1.8873 ± 0.0030\n",
      "  huber: 1.4822 ± 0.0027\n",
      "  swd: 4.4834 ± 0.1910\n",
      "  target_std: 18.3806 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 12.3453 ± 0.0553\n",
      "  mae: 2.1048 ± 0.0041\n",
      "  huber: 1.7098 ± 0.0040\n",
      "  swd: 6.3707 ± 0.2160\n",
      "  target_std: 20.5735 ± 0.0000\n",
      "  count: 52.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred96_20250430_2014\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 96\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=96,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d39c4",
   "metadata": {},
   "source": [
    "#### pred=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e376bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([196, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 377\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 196, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 377\n",
      "Validation Batches: 51\n",
      "Test Batches: 105\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 28.4604, mae: 2.6780, huber: 2.2667, swd: 13.3442, target_std: 20.3578\n",
      "Epoch [1/50], Val Losses: mse: 18.7906, mae: 2.6063, huber: 2.1985, swd: 10.4846, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1355, mae: 2.1832, huber: 1.7680, swd: 5.9463, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.266748\n",
      "        Val objective improved inf → 2.1985, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.9107, mae: 2.2126, huber: 1.8090, swd: 9.8036, target_std: 20.3580\n",
      "Epoch [2/50], Val Losses: mse: 18.2690, mae: 2.5621, huber: 2.1547, swd: 10.0167, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 12.1001, mae: 2.1679, huber: 1.7531, swd: 5.9695, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.808990\n",
      "        Val objective improved 2.1985 → 2.1547, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 16.6075, mae: 2.1962, huber: 1.7930, swd: 9.5470, target_std: 20.3580\n",
      "Epoch [3/50], Val Losses: mse: 18.0308, mae: 2.5400, huber: 2.1337, swd: 9.9660, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 11.9681, mae: 2.1572, huber: 1.7438, swd: 5.9563, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.792963\n",
      "        Val objective improved 2.1547 → 2.1337, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 16.5126, mae: 2.1905, huber: 1.7875, swd: 9.4714, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 18.0275, mae: 2.5471, huber: 2.1405, swd: 9.9789, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 11.8918, mae: 2.1462, huber: 1.7325, swd: 5.9204, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.787504\n",
      "        No improvement (2.1405), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 16.4853, mae: 2.1910, huber: 1.7879, swd: 9.4412, target_std: 20.3580\n",
      "Epoch [5/50], Val Losses: mse: 17.9201, mae: 2.5348, huber: 2.1282, swd: 9.7551, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.2007, mae: 2.1727, huber: 1.7592, swd: 6.1255, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.787913\n",
      "        Val objective improved 2.1337 → 2.1282, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 16.4780, mae: 2.1928, huber: 1.7896, swd: 9.4152, target_std: 20.3577\n",
      "Epoch [6/50], Val Losses: mse: 17.9069, mae: 2.5377, huber: 2.1304, swd: 9.7964, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 11.9873, mae: 2.1475, huber: 1.7348, swd: 5.9323, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.789561\n",
      "        No improvement (2.1304), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 16.5100, mae: 2.1978, huber: 1.7944, swd: 9.4188, target_std: 20.3578\n",
      "Epoch [7/50], Val Losses: mse: 17.8638, mae: 2.5364, huber: 2.1291, swd: 9.7992, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 11.9627, mae: 2.1466, huber: 1.7331, swd: 5.9559, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.794408\n",
      "        No improvement (2.1291), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4120, mae: 2.1853, huber: 1.7822, swd: 9.3805, target_std: 20.3578\n",
      "Epoch [8/50], Val Losses: mse: 17.6894, mae: 2.5303, huber: 2.1233, swd: 9.6257, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 11.8432, mae: 2.1355, huber: 1.7230, swd: 5.8727, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.782151\n",
      "        Val objective improved 2.1282 → 2.1233, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 16.3723, mae: 2.1841, huber: 1.7809, swd: 9.3434, target_std: 20.3579\n",
      "Epoch [9/50], Val Losses: mse: 17.8666, mae: 2.5331, huber: 2.1263, swd: 9.7752, target_std: 20.5630\n",
      "Epoch [9/50], Test Losses: mse: 11.9368, mae: 2.1529, huber: 1.7390, swd: 5.9326, target_std: 18.3527\n",
      "  Epoch 9 composite train-obj: 1.780917\n",
      "        No improvement (2.1263), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 16.4072, mae: 2.1880, huber: 1.7848, swd: 9.3626, target_std: 20.3579\n",
      "Epoch [10/50], Val Losses: mse: 17.8225, mae: 2.5298, huber: 2.1231, swd: 9.7174, target_std: 20.5630\n",
      "Epoch [10/50], Test Losses: mse: 11.9254, mae: 2.1471, huber: 1.7344, swd: 5.9128, target_std: 18.3527\n",
      "  Epoch 10 composite train-obj: 1.784780\n",
      "        Val objective improved 2.1233 → 2.1231, saving checkpoint.\n",
      "Epoch [11/50], Train Losses: mse: 16.4203, mae: 2.1902, huber: 1.7868, swd: 9.3561, target_std: 20.3577\n",
      "Epoch [11/50], Val Losses: mse: 17.7989, mae: 2.5366, huber: 2.1286, swd: 9.6875, target_std: 20.5630\n",
      "Epoch [11/50], Test Losses: mse: 11.9482, mae: 2.1516, huber: 1.7371, swd: 5.9156, target_std: 18.3527\n",
      "  Epoch 11 composite train-obj: 1.786821\n",
      "        No improvement (2.1286), counter 1/5\n",
      "Epoch [12/50], Train Losses: mse: 16.3735, mae: 2.1853, huber: 1.7822, swd: 9.3425, target_std: 20.3578\n",
      "Epoch [12/50], Val Losses: mse: 18.1270, mae: 2.5586, huber: 2.1504, swd: 9.8116, target_std: 20.5630\n",
      "Epoch [12/50], Test Losses: mse: 12.0929, mae: 2.1555, huber: 1.7418, swd: 5.9441, target_std: 18.3527\n",
      "  Epoch 12 composite train-obj: 1.782159\n",
      "        No improvement (2.1504), counter 2/5\n",
      "Epoch [13/50], Train Losses: mse: 16.4054, mae: 2.1901, huber: 1.7868, swd: 9.3450, target_std: 20.3578\n",
      "Epoch [13/50], Val Losses: mse: 17.7916, mae: 2.5368, huber: 2.1297, swd: 9.7982, target_std: 20.5630\n",
      "Epoch [13/50], Test Losses: mse: 11.8414, mae: 2.1598, huber: 1.7455, swd: 5.9317, target_std: 18.3527\n",
      "  Epoch 13 composite train-obj: 1.786766\n",
      "        No improvement (2.1297), counter 3/5\n",
      "Epoch [14/50], Train Losses: mse: 16.3773, mae: 2.1862, huber: 1.7831, swd: 9.3313, target_std: 20.3578\n",
      "Epoch [14/50], Val Losses: mse: 17.8316, mae: 2.5378, huber: 2.1305, swd: 9.7873, target_std: 20.5630\n",
      "Epoch [14/50], Test Losses: mse: 11.7719, mae: 2.1387, huber: 1.7252, swd: 5.8321, target_std: 18.3527\n",
      "  Epoch 14 composite train-obj: 1.783110\n",
      "        No improvement (2.1305), counter 4/5\n",
      "Epoch [15/50], Train Losses: mse: 16.3911, mae: 2.1886, huber: 1.7852, swd: 9.3336, target_std: 20.3578\n",
      "Epoch [15/50], Val Losses: mse: 17.9500, mae: 2.5430, huber: 2.1355, swd: 9.8307, target_std: 20.5630\n",
      "Epoch [15/50], Test Losses: mse: 11.8813, mae: 2.1537, huber: 1.7397, swd: 5.8738, target_std: 18.3527\n",
      "  Epoch 15 composite train-obj: 1.785236\n",
      "Epoch [15/50], Test Losses: mse: 11.9254, mae: 2.1471, huber: 1.7344, swd: 5.9128, target_std: 18.3527\n",
      "Best round's Test MSE: 11.9254, MAE: 2.1471, SWD: 5.9128\n",
      "Best round's Validation MSE: 17.8225, MAE: 2.5298\n",
      "Best round's Test verification MSE : 11.9254, MAE: 2.1471, SWD: 5.9128\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 27.3241, mae: 2.6561, huber: 2.2449, swd: 13.3314, target_std: 20.3578\n",
      "Epoch [1/50], Val Losses: mse: 18.6805, mae: 2.5968, huber: 2.1889, swd: 10.7695, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1441, mae: 2.1765, huber: 1.7612, swd: 6.1709, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.244919\n",
      "        Val objective improved inf → 2.1889, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.8857, mae: 2.2088, huber: 1.8053, swd: 10.1366, target_std: 20.3579\n",
      "Epoch [2/50], Val Losses: mse: 18.0723, mae: 2.5528, huber: 2.1465, swd: 10.3589, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 11.9632, mae: 2.1525, huber: 1.7386, swd: 6.1059, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.805302\n",
      "        Val objective improved 2.1889 → 2.1465, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 16.6223, mae: 2.1987, huber: 1.7953, swd: 9.9039, target_std: 20.3579\n",
      "Epoch [3/50], Val Losses: mse: 18.0199, mae: 2.5399, huber: 2.1336, swd: 10.3095, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 11.9606, mae: 2.1557, huber: 1.7423, swd: 6.1513, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.795341\n",
      "        Val objective improved 2.1465 → 2.1336, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 16.5473, mae: 2.1962, huber: 1.7931, swd: 9.8221, target_std: 20.3577\n",
      "Epoch [4/50], Val Losses: mse: 18.1009, mae: 2.5521, huber: 2.1451, swd: 10.2986, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 11.8940, mae: 2.1470, huber: 1.7342, swd: 6.0725, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.793065\n",
      "        No improvement (2.1451), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 16.5031, mae: 2.1933, huber: 1.7901, swd: 9.7780, target_std: 20.3577\n",
      "Epoch [5/50], Val Losses: mse: 18.0075, mae: 2.5436, huber: 2.1361, swd: 10.1819, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.0659, mae: 2.1615, huber: 1.7465, swd: 6.1945, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.790077\n",
      "        No improvement (2.1361), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 16.4295, mae: 2.1865, huber: 1.7834, swd: 9.7444, target_std: 20.3577\n",
      "Epoch [6/50], Val Losses: mse: 17.8903, mae: 2.5350, huber: 2.1284, swd: 10.1056, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 11.9647, mae: 2.1467, huber: 1.7334, swd: 6.1560, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.783375\n",
      "        Val objective improved 2.1336 → 2.1284, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 16.4363, mae: 2.1890, huber: 1.7860, swd: 9.7225, target_std: 20.3580\n",
      "Epoch [7/50], Val Losses: mse: 18.0708, mae: 2.5498, huber: 2.1428, swd: 10.2335, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 11.9145, mae: 2.1508, huber: 1.7377, swd: 6.0781, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.785959\n",
      "        No improvement (2.1428), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4274, mae: 2.1888, huber: 1.7856, swd: 9.7145, target_std: 20.3580\n",
      "Epoch [8/50], Val Losses: mse: 18.0998, mae: 2.5600, huber: 2.1518, swd: 10.1418, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 12.2260, mae: 2.1627, huber: 1.7491, swd: 6.2119, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.785567\n",
      "        No improvement (2.1518), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 16.4423, mae: 2.1916, huber: 1.7883, swd: 9.7065, target_std: 20.3580\n",
      "Epoch [9/50], Val Losses: mse: 17.8352, mae: 2.5423, huber: 2.1352, swd: 10.0339, target_std: 20.5630\n",
      "Epoch [9/50], Test Losses: mse: 11.9294, mae: 2.1486, huber: 1.7356, swd: 6.0665, target_std: 18.3527\n",
      "  Epoch 9 composite train-obj: 1.788260\n",
      "        No improvement (2.1352), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 16.4013, mae: 2.1892, huber: 1.7859, swd: 9.6879, target_std: 20.3579\n",
      "Epoch [10/50], Val Losses: mse: 18.0047, mae: 2.5444, huber: 2.1375, swd: 10.2073, target_std: 20.5630\n",
      "Epoch [10/50], Test Losses: mse: 11.9295, mae: 2.1369, huber: 1.7251, swd: 6.0517, target_std: 18.3527\n",
      "  Epoch 10 composite train-obj: 1.785854\n",
      "        No improvement (2.1375), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 16.3891, mae: 2.1872, huber: 1.7840, swd: 9.6727, target_std: 20.3578\n",
      "Epoch [11/50], Val Losses: mse: 17.9050, mae: 2.5314, huber: 2.1247, swd: 10.1141, target_std: 20.5630\n",
      "Epoch [11/50], Test Losses: mse: 12.0356, mae: 2.1534, huber: 1.7406, swd: 6.1592, target_std: 18.3527\n",
      "  Epoch 11 composite train-obj: 1.783971\n",
      "        Val objective improved 2.1284 → 2.1247, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 16.4065, mae: 2.1881, huber: 1.7849, swd: 9.6860, target_std: 20.3578\n",
      "Epoch [12/50], Val Losses: mse: 17.8776, mae: 2.5384, huber: 2.1314, swd: 10.1077, target_std: 20.5630\n",
      "Epoch [12/50], Test Losses: mse: 11.8813, mae: 2.1478, huber: 1.7338, swd: 6.0732, target_std: 18.3527\n",
      "  Epoch 12 composite train-obj: 1.784918\n",
      "        No improvement (2.1314), counter 1/5\n",
      "Epoch [13/50], Train Losses: mse: 16.3489, mae: 2.1808, huber: 1.7779, swd: 9.6591, target_std: 20.3578\n",
      "Epoch [13/50], Val Losses: mse: 17.7533, mae: 2.5318, huber: 2.1245, swd: 10.0184, target_std: 20.5630\n",
      "Epoch [13/50], Test Losses: mse: 11.8022, mae: 2.1375, huber: 1.7249, swd: 6.0309, target_std: 18.3527\n",
      "  Epoch 13 composite train-obj: 1.777884\n",
      "        Val objective improved 2.1247 → 2.1245, saving checkpoint.\n",
      "Epoch [14/50], Train Losses: mse: 16.3814, mae: 2.1883, huber: 1.7850, swd: 9.6672, target_std: 20.3579\n",
      "Epoch [14/50], Val Losses: mse: 17.8557, mae: 2.5461, huber: 2.1388, swd: 10.0575, target_std: 20.5630\n",
      "Epoch [14/50], Test Losses: mse: 11.9034, mae: 2.1396, huber: 1.7266, swd: 6.0560, target_std: 18.3527\n",
      "  Epoch 14 composite train-obj: 1.784973\n",
      "        No improvement (2.1388), counter 1/5\n",
      "Epoch [15/50], Train Losses: mse: 16.3794, mae: 2.1894, huber: 1.7861, swd: 9.6626, target_std: 20.3579\n",
      "Epoch [15/50], Val Losses: mse: 17.8782, mae: 2.5380, huber: 2.1307, swd: 10.0756, target_std: 20.5630\n",
      "Epoch [15/50], Test Losses: mse: 11.9621, mae: 2.1457, huber: 1.7334, swd: 6.0504, target_std: 18.3527\n",
      "  Epoch 15 composite train-obj: 1.786120\n",
      "        No improvement (2.1307), counter 2/5\n",
      "Epoch [16/50], Train Losses: mse: 16.3419, mae: 2.1822, huber: 1.7791, swd: 9.6441, target_std: 20.3578\n",
      "Epoch [16/50], Val Losses: mse: 17.9721, mae: 2.5543, huber: 2.1459, swd: 10.1971, target_std: 20.5630\n",
      "Epoch [16/50], Test Losses: mse: 11.9676, mae: 2.1627, huber: 1.7470, swd: 6.0954, target_std: 18.3527\n",
      "  Epoch 16 composite train-obj: 1.779074\n",
      "        No improvement (2.1459), counter 3/5\n",
      "Epoch [17/50], Train Losses: mse: 16.3455, mae: 2.1847, huber: 1.7816, swd: 9.6437, target_std: 20.3580\n",
      "Epoch [17/50], Val Losses: mse: 17.9065, mae: 2.5467, huber: 2.1396, swd: 10.1882, target_std: 20.5630\n",
      "Epoch [17/50], Test Losses: mse: 11.8708, mae: 2.1632, huber: 1.7488, swd: 6.0836, target_std: 18.3527\n",
      "  Epoch 17 composite train-obj: 1.781562\n",
      "        No improvement (2.1396), counter 4/5\n",
      "Epoch [18/50], Train Losses: mse: 16.3637, mae: 2.1879, huber: 1.7846, swd: 9.6443, target_std: 20.3580\n",
      "Epoch [18/50], Val Losses: mse: 17.9707, mae: 2.5391, huber: 2.1321, swd: 10.1447, target_std: 20.5630\n",
      "Epoch [18/50], Test Losses: mse: 11.8325, mae: 2.1348, huber: 1.7224, swd: 6.0312, target_std: 18.3527\n",
      "  Epoch 18 composite train-obj: 1.784589\n",
      "Epoch [18/50], Test Losses: mse: 11.8022, mae: 2.1375, huber: 1.7249, swd: 6.0309, target_std: 18.3527\n",
      "Best round's Test MSE: 11.8022, MAE: 2.1375, SWD: 6.0309\n",
      "Best round's Validation MSE: 17.7533, MAE: 2.5318\n",
      "Best round's Test verification MSE : 11.8022, MAE: 2.1375, SWD: 6.0309\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 27.7405, mae: 2.6603, huber: 2.2491, swd: 11.4131, target_std: 20.3577\n",
      "Epoch [1/50], Val Losses: mse: 18.6896, mae: 2.5915, huber: 2.1841, swd: 9.1866, target_std: 20.5630\n",
      "Epoch [1/50], Test Losses: mse: 12.1125, mae: 2.1774, huber: 1.7622, swd: 5.2569, target_std: 18.3527\n",
      "  Epoch 1 composite train-obj: 2.249086\n",
      "        Val objective improved inf → 2.1841, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 16.9560, mae: 2.2187, huber: 1.8148, swd: 8.6266, target_std: 20.3576\n",
      "Epoch [2/50], Val Losses: mse: 18.2880, mae: 2.5554, huber: 2.1487, swd: 8.9665, target_std: 20.5630\n",
      "Epoch [2/50], Test Losses: mse: 11.9470, mae: 2.1600, huber: 1.7463, swd: 5.2146, target_std: 18.3527\n",
      "  Epoch 2 composite train-obj: 1.814832\n",
      "        Val objective improved 2.1841 → 2.1487, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 16.6242, mae: 2.1972, huber: 1.7941, swd: 8.4053, target_std: 20.3578\n",
      "Epoch [3/50], Val Losses: mse: 17.9676, mae: 2.5381, huber: 2.1312, swd: 8.7539, target_std: 20.5630\n",
      "Epoch [3/50], Test Losses: mse: 12.0203, mae: 2.1580, huber: 1.7437, swd: 5.2527, target_std: 18.3527\n",
      "  Epoch 3 composite train-obj: 1.794099\n",
      "        Val objective improved 2.1487 → 2.1312, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 16.5131, mae: 2.1935, huber: 1.7902, swd: 8.3070, target_std: 20.3579\n",
      "Epoch [4/50], Val Losses: mse: 17.9706, mae: 2.5358, huber: 2.1294, swd: 8.7245, target_std: 20.5630\n",
      "Epoch [4/50], Test Losses: mse: 11.8920, mae: 2.1461, huber: 1.7321, swd: 5.2075, target_std: 18.3527\n",
      "  Epoch 4 composite train-obj: 1.790197\n",
      "        Val objective improved 2.1312 → 2.1294, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 16.4761, mae: 2.1906, huber: 1.7875, swd: 8.2828, target_std: 20.3579\n",
      "Epoch [5/50], Val Losses: mse: 18.1107, mae: 2.5535, huber: 2.1466, swd: 8.7753, target_std: 20.5630\n",
      "Epoch [5/50], Test Losses: mse: 12.1176, mae: 2.1510, huber: 1.7381, swd: 5.2916, target_std: 18.3527\n",
      "  Epoch 5 composite train-obj: 1.787470\n",
      "        No improvement (2.1466), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 16.4626, mae: 2.1902, huber: 1.7870, swd: 8.2629, target_std: 20.3577\n",
      "Epoch [6/50], Val Losses: mse: 17.9687, mae: 2.5391, huber: 2.1322, swd: 8.6604, target_std: 20.5630\n",
      "Epoch [6/50], Test Losses: mse: 11.9316, mae: 2.1423, huber: 1.7290, swd: 5.1976, target_std: 18.3527\n",
      "  Epoch 6 composite train-obj: 1.787002\n",
      "        No improvement (2.1322), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 16.4612, mae: 2.1918, huber: 1.7885, swd: 8.2638, target_std: 20.3578\n",
      "Epoch [7/50], Val Losses: mse: 18.0945, mae: 2.5517, huber: 2.1442, swd: 8.7687, target_std: 20.5630\n",
      "Epoch [7/50], Test Losses: mse: 12.0074, mae: 2.1743, huber: 1.7587, swd: 5.2332, target_std: 18.3527\n",
      "  Epoch 7 composite train-obj: 1.788502\n",
      "        No improvement (2.1442), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 16.4339, mae: 2.1905, huber: 1.7873, swd: 8.2307, target_std: 20.3577\n",
      "Epoch [8/50], Val Losses: mse: 18.1588, mae: 2.5569, huber: 2.1495, swd: 8.8428, target_std: 20.5630\n",
      "Epoch [8/50], Test Losses: mse: 12.1202, mae: 2.1501, huber: 1.7372, swd: 5.3302, target_std: 18.3527\n",
      "  Epoch 8 composite train-obj: 1.787280\n",
      "        No improvement (2.1495), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 16.4408, mae: 2.1892, huber: 1.7861, swd: 8.2398, target_std: 20.3580\n",
      "Epoch [9/50], Val Losses: mse: 17.7700, mae: 2.5315, huber: 2.1240, swd: 8.5603, target_std: 20.5630\n",
      "Epoch [9/50], Test Losses: mse: 11.9383, mae: 2.1495, huber: 1.7354, swd: 5.1875, target_std: 18.3527\n",
      "  Epoch 9 composite train-obj: 1.786060\n",
      "        Val objective improved 2.1294 → 2.1240, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 16.3738, mae: 2.1831, huber: 1.7802, swd: 8.1958, target_std: 20.3577\n",
      "Epoch [10/50], Val Losses: mse: 17.8426, mae: 2.5489, huber: 2.1412, swd: 8.5815, target_std: 20.5630\n",
      "Epoch [10/50], Test Losses: mse: 12.0705, mae: 2.1478, huber: 1.7347, swd: 5.2611, target_std: 18.3527\n",
      "  Epoch 10 composite train-obj: 1.780183\n",
      "        No improvement (2.1412), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 16.4089, mae: 2.1897, huber: 1.7863, swd: 8.2136, target_std: 20.3577\n",
      "Epoch [11/50], Val Losses: mse: 17.9395, mae: 2.5469, huber: 2.1393, swd: 8.6187, target_std: 20.5630\n",
      "Epoch [11/50], Test Losses: mse: 11.9214, mae: 2.1537, huber: 1.7390, swd: 5.1644, target_std: 18.3527\n",
      "  Epoch 11 composite train-obj: 1.786255\n",
      "        No improvement (2.1393), counter 2/5\n",
      "Epoch [12/50], Train Losses: mse: 16.3774, mae: 2.1845, huber: 1.7814, swd: 8.1952, target_std: 20.3577\n",
      "Epoch [12/50], Val Losses: mse: 18.2257, mae: 2.5624, huber: 2.1552, swd: 8.7032, target_std: 20.5630\n",
      "Epoch [12/50], Test Losses: mse: 12.3039, mae: 2.1619, huber: 1.7488, swd: 5.3781, target_std: 18.3527\n",
      "  Epoch 12 composite train-obj: 1.781429\n",
      "        No improvement (2.1552), counter 3/5\n",
      "Epoch [13/50], Train Losses: mse: 16.3426, mae: 2.1812, huber: 1.7784, swd: 8.1781, target_std: 20.3578\n",
      "Epoch [13/50], Val Losses: mse: 17.7829, mae: 2.5361, huber: 2.1289, swd: 8.5579, target_std: 20.5630\n",
      "Epoch [13/50], Test Losses: mse: 11.8368, mae: 2.1426, huber: 1.7289, swd: 5.1421, target_std: 18.3527\n",
      "  Epoch 13 composite train-obj: 1.778376\n",
      "        No improvement (2.1289), counter 4/5\n",
      "Epoch [14/50], Train Losses: mse: 16.3866, mae: 2.1881, huber: 1.7848, swd: 8.1836, target_std: 20.3579\n",
      "Epoch [14/50], Val Losses: mse: 17.8963, mae: 2.5366, huber: 2.1296, swd: 8.6300, target_std: 20.5630\n",
      "Epoch [14/50], Test Losses: mse: 11.8075, mae: 2.1389, huber: 1.7256, swd: 5.1388, target_std: 18.3527\n",
      "  Epoch 14 composite train-obj: 1.784780\n",
      "Epoch [14/50], Test Losses: mse: 11.9383, mae: 2.1495, huber: 1.7354, swd: 5.1875, target_std: 18.3527\n",
      "Best round's Test MSE: 11.9383, MAE: 2.1495, SWD: 5.1875\n",
      "Best round's Validation MSE: 17.7700, MAE: 2.5315\n",
      "Best round's Test verification MSE : 11.9383, MAE: 2.1495, SWD: 5.1875\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred196_20250430_2017)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 11.8886 ± 0.0614\n",
      "  mae: 2.1447 ± 0.0052\n",
      "  huber: 1.7316 ± 0.0047\n",
      "  swd: 5.7104 ± 0.3729\n",
      "  target_std: 18.3527 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 17.7819 ± 0.0295\n",
      "  mae: 2.5310 ± 0.0009\n",
      "  huber: 2.1239 ± 0.0005\n",
      "  swd: 9.4321 ± 0.6285\n",
      "  target_std: 20.5630 ± 0.0000\n",
      "  count: 51.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred196_20250430_2017\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 196\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=196,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9b6a4",
   "metadata": {},
   "source": [
    "#### pred=336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ada285",
   "metadata": {},
   "source": [
    "##### huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f65b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.0404, mae: 2.9122, huber: 2.4961, swd: 14.8301, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.2878, mae: 2.9277, huber: 2.5117, swd: 10.9128, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8433, mae: 2.3955, huber: 1.9769, swd: 7.1739, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.496129\n",
      "        Val objective improved inf → 2.5117, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.9528, mae: 2.5131, huber: 2.1032, swd: 12.1960, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.3077, mae: 2.9102, huber: 2.4951, swd: 11.0030, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.6853, mae: 2.3832, huber: 1.9640, swd: 7.1263, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.103202\n",
      "        Val objective improved 2.5117 → 2.4951, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.7426, mae: 2.5008, huber: 2.0912, swd: 12.0343, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 22.0531, mae: 2.8878, huber: 2.4725, swd: 10.8314, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.7222, mae: 2.3809, huber: 1.9629, swd: 7.0753, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.091224\n",
      "        Val objective improved 2.4951 → 2.4725, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.6080, mae: 2.4925, huber: 2.0827, swd: 11.9293, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 22.1315, mae: 2.9009, huber: 2.4846, swd: 10.8507, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7428, mae: 2.3778, huber: 1.9594, swd: 7.1646, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.082703\n",
      "        No improvement (2.4846), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 21.5534, mae: 2.4913, huber: 2.0816, swd: 11.8695, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 22.0703, mae: 2.9057, huber: 2.4879, swd: 10.9113, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.5324, mae: 2.3810, huber: 1.9611, swd: 7.0463, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.081570\n",
      "        No improvement (2.4879), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 21.5369, mae: 2.4933, huber: 2.0834, swd: 11.8604, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 22.2592, mae: 2.9075, huber: 2.4905, swd: 10.8980, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.7448, mae: 2.3886, huber: 1.9684, swd: 7.2124, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.083423\n",
      "        No improvement (2.4905), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 21.5022, mae: 2.4915, huber: 2.0815, swd: 11.8112, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 21.9490, mae: 2.8872, huber: 2.4704, swd: 10.8121, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.5135, mae: 2.3834, huber: 1.9634, swd: 7.0464, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.081546\n",
      "        Val objective improved 2.4725 → 2.4704, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 21.5310, mae: 2.4942, huber: 2.0844, swd: 11.8212, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 22.1034, mae: 2.8991, huber: 2.4825, swd: 10.8885, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.5144, mae: 2.3661, huber: 1.9479, swd: 7.0485, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.084366\n",
      "        No improvement (2.4825), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 21.5083, mae: 2.4908, huber: 2.0809, swd: 11.8220, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 22.0410, mae: 2.8922, huber: 2.4757, swd: 10.8211, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.4113, mae: 2.3666, huber: 1.9487, swd: 6.9758, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 2.080939\n",
      "        No improvement (2.4757), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 21.4416, mae: 2.4866, huber: 2.0768, swd: 11.7727, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 21.9116, mae: 2.8917, huber: 2.4743, swd: 10.6829, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.4617, mae: 2.3596, huber: 1.9412, swd: 6.9925, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 2.076753\n",
      "        No improvement (2.4743), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.4256, mae: 2.4879, huber: 2.0780, swd: 11.7457, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 22.0575, mae: 2.8965, huber: 2.4797, swd: 10.9681, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.5653, mae: 2.3856, huber: 1.9668, swd: 7.0441, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 2.077954\n",
      "        No improvement (2.4797), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.4563, mae: 2.4891, huber: 2.0791, swd: 11.7706, target_std: 20.3632\n",
      "Epoch [12/50], Val Losses: mse: 21.8958, mae: 2.8834, huber: 2.4657, swd: 10.6128, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 14.8095, mae: 2.3902, huber: 1.9708, swd: 7.1476, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 2.079137\n",
      "        Val objective improved 2.4704 → 2.4657, saving checkpoint.\n",
      "Epoch [13/50], Train Losses: mse: 21.4057, mae: 2.4874, huber: 2.0773, swd: 11.7231, target_std: 20.3632\n",
      "Epoch [13/50], Val Losses: mse: 22.1643, mae: 2.9004, huber: 2.4834, swd: 10.8516, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 14.5199, mae: 2.3664, huber: 1.9483, swd: 7.0335, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 2.077337\n",
      "        No improvement (2.4834), counter 1/5\n",
      "Epoch [14/50], Train Losses: mse: 21.4601, mae: 2.4927, huber: 2.0826, swd: 11.7466, target_std: 20.3628\n",
      "Epoch [14/50], Val Losses: mse: 21.8072, mae: 2.8780, huber: 2.4614, swd: 10.6344, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 14.6390, mae: 2.3925, huber: 1.9727, swd: 7.0727, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 2.082587\n",
      "        Val objective improved 2.4657 → 2.4614, saving checkpoint.\n",
      "Epoch [15/50], Train Losses: mse: 21.4121, mae: 2.4859, huber: 2.0760, swd: 11.7193, target_std: 20.3632\n",
      "Epoch [15/50], Val Losses: mse: 21.7957, mae: 2.8868, huber: 2.4697, swd: 10.5795, target_std: 20.5432\n",
      "Epoch [15/50], Test Losses: mse: 14.4409, mae: 2.3670, huber: 1.9474, swd: 6.9416, target_std: 18.3439\n",
      "  Epoch 15 composite train-obj: 2.075987\n",
      "        No improvement (2.4697), counter 1/5\n",
      "Epoch [16/50], Train Losses: mse: 21.3847, mae: 2.4858, huber: 2.0758, swd: 11.7141, target_std: 20.3633\n",
      "Epoch [16/50], Val Losses: mse: 22.1231, mae: 2.9058, huber: 2.4887, swd: 10.6307, target_std: 20.5432\n",
      "Epoch [16/50], Test Losses: mse: 14.7483, mae: 2.3818, huber: 1.9632, swd: 7.0407, target_std: 18.3439\n",
      "  Epoch 16 composite train-obj: 2.075839\n",
      "        No improvement (2.4887), counter 2/5\n",
      "Epoch [17/50], Train Losses: mse: 21.4301, mae: 2.4904, huber: 2.0804, swd: 11.7356, target_std: 20.3627\n",
      "Epoch [17/50], Val Losses: mse: 22.3900, mae: 2.9181, huber: 2.5005, swd: 10.7902, target_std: 20.5432\n",
      "Epoch [17/50], Test Losses: mse: 14.9029, mae: 2.3911, huber: 1.9724, swd: 7.1898, target_std: 18.3439\n",
      "  Epoch 17 composite train-obj: 2.080419\n",
      "        No improvement (2.5005), counter 3/5\n",
      "Epoch [18/50], Train Losses: mse: 21.3897, mae: 2.4859, huber: 2.0760, swd: 11.7047, target_std: 20.3628\n",
      "Epoch [18/50], Val Losses: mse: 22.1034, mae: 2.9055, huber: 2.4872, swd: 10.7918, target_std: 20.5432\n",
      "Epoch [18/50], Test Losses: mse: 14.6938, mae: 2.3820, huber: 1.9622, swd: 7.1285, target_std: 18.3439\n",
      "  Epoch 18 composite train-obj: 2.076003\n",
      "        No improvement (2.4872), counter 4/5\n",
      "Epoch [19/50], Train Losses: mse: 21.3749, mae: 2.4869, huber: 2.0768, swd: 11.7038, target_std: 20.3632\n",
      "Epoch [19/50], Val Losses: mse: 22.1071, mae: 2.9096, huber: 2.4925, swd: 10.7639, target_std: 20.5432\n",
      "Epoch [19/50], Test Losses: mse: 14.5442, mae: 2.3692, huber: 1.9508, swd: 6.9423, target_std: 18.3439\n",
      "  Epoch 19 composite train-obj: 2.076838\n",
      "Epoch [19/50], Test Losses: mse: 14.6390, mae: 2.3925, huber: 1.9727, swd: 7.0727, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6390, MAE: 2.3925, SWD: 7.0727\n",
      "Best round's Validation MSE: 21.8072, MAE: 2.8780\n",
      "Best round's Test verification MSE : 14.6390, MAE: 2.3925, SWD: 7.0727\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.3752, mae: 2.9111, huber: 2.4953, swd: 15.5783, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.2946, mae: 2.9285, huber: 2.5130, swd: 11.2972, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.8252, mae: 2.3986, huber: 1.9793, swd: 7.5034, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.495266\n",
      "        Val objective improved inf → 2.5130, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.9976, mae: 2.5144, huber: 2.1045, swd: 12.7922, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 22.2408, mae: 2.9100, huber: 2.4941, swd: 11.4868, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.7422, mae: 2.4003, huber: 1.9809, swd: 7.5212, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.104486\n",
      "        Val objective improved 2.5130 → 2.4941, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.6924, mae: 2.5009, huber: 2.0911, swd: 12.5559, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 22.3674, mae: 2.9059, huber: 2.4902, swd: 11.4995, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.7199, mae: 2.3795, huber: 1.9615, swd: 7.4304, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.091061\n",
      "        Val objective improved 2.4941 → 2.4902, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.6215, mae: 2.4923, huber: 2.0826, swd: 12.4975, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 22.0708, mae: 2.8970, huber: 2.4806, swd: 11.2055, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.6913, mae: 2.3851, huber: 1.9653, swd: 7.4742, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.082601\n",
      "        Val objective improved 2.4902 → 2.4806, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.5854, mae: 2.4946, huber: 2.0848, swd: 12.4396, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 22.0006, mae: 2.8791, huber: 2.4629, swd: 11.2303, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.7983, mae: 2.3936, huber: 1.9742, swd: 7.5613, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.084842\n",
      "        Val objective improved 2.4806 → 2.4629, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.5351, mae: 2.4935, huber: 2.0836, swd: 12.3972, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 21.9725, mae: 2.8804, huber: 2.4642, swd: 11.2438, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.5436, mae: 2.3786, huber: 1.9593, swd: 7.4093, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.083602\n",
      "        No improvement (2.4642), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.5178, mae: 2.4910, huber: 2.0810, swd: 12.3954, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 22.1191, mae: 2.9029, huber: 2.4854, swd: 11.2343, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.5919, mae: 2.3799, huber: 1.9600, swd: 7.3510, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.081031\n",
      "        No improvement (2.4854), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 21.5081, mae: 2.4909, huber: 2.0810, swd: 12.3832, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 22.0682, mae: 2.9018, huber: 2.4844, swd: 11.1313, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.6465, mae: 2.3793, huber: 1.9604, swd: 7.3997, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.081008\n",
      "        No improvement (2.4844), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 21.4924, mae: 2.4919, huber: 2.0820, swd: 12.3610, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 22.1755, mae: 2.8975, huber: 2.4804, swd: 11.2241, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.7060, mae: 2.3832, huber: 1.9631, swd: 7.4852, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 2.081966\n",
      "        No improvement (2.4804), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 21.5189, mae: 2.4947, huber: 2.0846, swd: 12.3707, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 21.9750, mae: 2.8945, huber: 2.4777, swd: 11.1527, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.4190, mae: 2.3689, huber: 1.9499, swd: 7.3015, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 2.084620\n",
      "Epoch [10/50], Test Losses: mse: 14.7983, mae: 2.3936, huber: 1.9742, swd: 7.5613, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7983, MAE: 2.3936, SWD: 7.5613\n",
      "Best round's Validation MSE: 22.0006, MAE: 2.8791\n",
      "Best round's Test verification MSE : 14.7983, MAE: 2.3936, SWD: 7.5613\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 32.5026, mae: 2.9228, huber: 2.5068, swd: 14.5706, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.3888, mae: 2.9243, huber: 2.5086, swd: 10.4911, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 14.7891, mae: 2.4120, huber: 1.9907, swd: 6.9661, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 2.506812\n",
      "        Val objective improved inf → 2.5086, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.9752, mae: 2.5133, huber: 2.1034, swd: 11.8463, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 22.0661, mae: 2.8925, huber: 2.4782, swd: 10.4827, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.5334, mae: 2.3884, huber: 1.9687, swd: 6.8612, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 2.103385\n",
      "        Val objective improved 2.5086 → 2.4782, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.6927, mae: 2.4995, huber: 2.0899, swd: 11.6411, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 22.2826, mae: 2.9014, huber: 2.4854, swd: 10.4749, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.7525, mae: 2.3905, huber: 1.9702, swd: 6.9303, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 2.089854\n",
      "        No improvement (2.4854), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.6335, mae: 2.4944, huber: 2.0847, swd: 11.5905, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 22.0303, mae: 2.8971, huber: 2.4806, swd: 10.3546, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.5450, mae: 2.3714, huber: 1.9526, swd: 6.7529, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 2.084746\n",
      "        No improvement (2.4806), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 21.5759, mae: 2.4951, huber: 2.0852, swd: 11.5295, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.9302, mae: 2.8807, huber: 2.4643, swd: 10.3299, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.6653, mae: 2.4065, huber: 1.9856, swd: 6.9528, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 2.085206\n",
      "        Val objective improved 2.4782 → 2.4643, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.4927, mae: 2.4884, huber: 2.0786, swd: 11.4761, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.1685, mae: 2.9005, huber: 2.4843, swd: 10.4018, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.5491, mae: 2.3879, huber: 1.9683, swd: 6.7947, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 2.078635\n",
      "        No improvement (2.4843), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.5145, mae: 2.4902, huber: 2.0803, swd: 11.4721, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.8108, mae: 2.8809, huber: 2.4643, swd: 10.2488, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.5073, mae: 2.3839, huber: 1.9645, swd: 6.8301, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 2.080340\n",
      "        Val objective improved 2.4643 → 2.4643, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 21.4572, mae: 2.4893, huber: 2.0793, swd: 11.4257, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 22.1827, mae: 2.9033, huber: 2.4866, swd: 10.4921, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.4683, mae: 2.3664, huber: 1.9476, swd: 6.7037, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 2.079295\n",
      "        No improvement (2.4866), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 21.4462, mae: 2.4870, huber: 2.0772, swd: 11.4243, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 22.3511, mae: 2.9109, huber: 2.4934, swd: 10.3930, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.9355, mae: 2.3954, huber: 1.9768, swd: 6.9363, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 2.077195\n",
      "        No improvement (2.4934), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 21.4494, mae: 2.4889, huber: 2.0788, swd: 11.4166, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 21.9227, mae: 2.8885, huber: 2.4718, swd: 10.3190, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.4385, mae: 2.3693, huber: 1.9502, swd: 6.6884, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 2.078822\n",
      "        No improvement (2.4718), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.5180, mae: 2.4919, huber: 2.0820, swd: 11.4625, target_std: 20.3633\n",
      "Epoch [11/50], Val Losses: mse: 21.8785, mae: 2.8906, huber: 2.4731, swd: 10.2631, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.4361, mae: 2.3812, huber: 1.9606, swd: 6.7322, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 2.082039\n",
      "        No improvement (2.4731), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.4378, mae: 2.4897, huber: 2.0797, swd: 11.3896, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 22.0326, mae: 2.8912, huber: 2.4744, swd: 10.1925, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 14.6465, mae: 2.3781, huber: 1.9594, swd: 6.7588, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 2.079723\n",
      "Epoch [12/50], Test Losses: mse: 14.5073, mae: 2.3839, huber: 1.9645, swd: 6.8301, target_std: 18.3439\n",
      "Best round's Test MSE: 14.5073, MAE: 2.3839, SWD: 6.8301\n",
      "Best round's Validation MSE: 21.8108, MAE: 2.8809\n",
      "Best round's Test verification MSE : 14.5073, MAE: 2.3839, SWD: 6.8301\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250430_2020)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.6482 ± 0.1190\n",
      "  mae: 2.3900 ± 0.0043\n",
      "  huber: 1.9705 ± 0.0042\n",
      "  swd: 7.1547 ± 0.3041\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 21.8729 ± 0.0903\n",
      "  mae: 2.8793 ± 0.0012\n",
      "  huber: 2.4628 ± 0.0012\n",
      "  swd: 10.7045 ± 0.4037\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250430_2020\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1dc19a",
   "metadata": {},
   "source": [
    "##### huber + 0.1SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6bfae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 54.1800, mae: 3.2874, huber: 2.8678, swd: 13.7802, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 23.0501, mae: 3.0088, huber: 2.5879, swd: 10.9698, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.5653, mae: 2.4796, huber: 2.0570, swd: 7.5425, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 4.245828\n",
      "        Val objective improved inf → 3.6849, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.5627, mae: 2.5667, huber: 2.1531, swd: 11.6109, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.7810, mae: 2.9563, huber: 2.5366, swd: 10.4372, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3143, mae: 2.4449, huber: 2.0228, swd: 7.3878, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.314153\n",
      "        Val objective improved 3.6849 → 3.5804, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 22.3473, mae: 2.5498, huber: 2.1365, swd: 11.3816, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 23.0816, mae: 2.9924, huber: 2.5715, swd: 11.2228, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.3659, mae: 2.4553, huber: 2.0347, swd: 7.5553, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 3.274627\n",
      "        No improvement (3.6938), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 22.3373, mae: 2.5481, huber: 2.1344, swd: 11.2955, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 22.6687, mae: 2.9445, huber: 2.5233, swd: 10.0877, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2390, mae: 2.4178, huber: 1.9981, swd: 7.1385, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 3.263932\n",
      "        Val objective improved 3.5804 → 3.5320, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 22.3356, mae: 2.5456, huber: 2.1316, swd: 11.2044, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 23.0232, mae: 2.9822, huber: 2.5597, swd: 10.6987, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2961, mae: 2.4407, huber: 2.0197, swd: 7.2958, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 3.252088\n",
      "        No improvement (3.6296), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 22.3830, mae: 2.5483, huber: 2.1340, swd: 11.1998, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 23.5719, mae: 2.9912, huber: 2.5686, swd: 11.0020, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.9416, mae: 2.4727, huber: 2.0511, swd: 8.1421, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.253986\n",
      "        No improvement (3.6688), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 22.5684, mae: 2.5542, huber: 2.1397, swd: 11.1591, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 22.7079, mae: 2.9252, huber: 2.5033, swd: 9.8857, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.3848, mae: 2.4312, huber: 2.0107, swd: 7.2646, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 3.255642\n",
      "        Val objective improved 3.5320 → 3.4919, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 22.6453, mae: 2.5481, huber: 2.1341, swd: 11.0903, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 23.2759, mae: 2.9550, huber: 2.5320, swd: 10.3240, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.3866, mae: 2.4134, huber: 1.9925, swd: 7.1367, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 3.243104\n",
      "        No improvement (3.5644), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 22.8130, mae: 2.5433, huber: 2.1293, swd: 11.0177, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 23.4389, mae: 2.9414, huber: 2.5194, swd: 10.0548, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.7096, mae: 2.4419, huber: 2.0217, swd: 7.5204, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 3.231079\n",
      "        No improvement (3.5249), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 22.9752, mae: 2.5398, huber: 2.1256, swd: 10.9497, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 23.5743, mae: 2.9620, huber: 2.5378, swd: 10.0887, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.6256, mae: 2.4333, huber: 2.0104, swd: 7.1580, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 3.220610\n",
      "        No improvement (3.5467), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 23.2401, mae: 2.5448, huber: 2.1305, swd: 10.9244, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 24.2778, mae: 2.9974, huber: 2.5739, swd: 10.9110, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 15.5231, mae: 2.4429, huber: 2.0198, swd: 7.0156, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 3.222973\n",
      "        No improvement (3.6650), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 23.4328, mae: 2.5491, huber: 2.1347, swd: 10.9857, target_std: 20.3632\n",
      "Epoch [12/50], Val Losses: mse: 24.0546, mae: 2.9438, huber: 2.5212, swd: 10.2791, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 16.1457, mae: 2.4433, huber: 2.0232, swd: 7.6664, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 3.233265\n",
      "Epoch [12/50], Test Losses: mse: 15.3848, mae: 2.4312, huber: 2.0107, swd: 7.2646, target_std: 18.3439\n",
      "Best round's Test MSE: 15.3848, MAE: 2.4312, SWD: 7.2646\n",
      "Best round's Validation MSE: 22.7079, MAE: 2.9252, SWD: 9.8857\n",
      "Best round's Test verification MSE : 15.3848, MAE: 2.4312, SWD: 7.2646\n",
      "Time taken: 53.49 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 55.7275, mae: 3.3024, huber: 2.8827, swd: 14.4433, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.8030, mae: 2.9685, huber: 2.5492, swd: 10.5756, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.4462, mae: 2.4498, huber: 2.0283, swd: 7.6625, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 4.327049\n",
      "        Val objective improved inf → 3.6067, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.5923, mae: 2.5664, huber: 2.1529, swd: 12.1932, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 22.8229, mae: 2.9550, huber: 2.5354, swd: 10.9484, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3845, mae: 2.4689, huber: 2.0469, swd: 7.9339, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.372253\n",
      "        No improvement (3.6302), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 22.5405, mae: 2.5701, huber: 2.1559, swd: 12.0342, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 23.0116, mae: 2.9657, huber: 2.5451, swd: 11.1339, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.2496, mae: 2.4248, huber: 2.0055, swd: 7.5939, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 3.359271\n",
      "        No improvement (3.6584), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 22.4859, mae: 2.5537, huber: 2.1397, swd: 11.8774, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 22.8446, mae: 2.9481, huber: 2.5263, swd: 10.5630, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.4180, mae: 2.4407, huber: 2.0183, swd: 7.7246, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 3.327427\n",
      "        Val objective improved 3.6067 → 3.5826, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 22.6366, mae: 2.5547, huber: 2.1404, swd: 11.6985, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 23.0129, mae: 2.9304, huber: 2.5090, swd: 10.4520, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.3678, mae: 2.4238, huber: 2.0031, swd: 7.4802, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 3.310219\n",
      "        Val objective improved 3.5826 → 3.5542, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 22.7115, mae: 2.5473, huber: 2.1331, swd: 11.6294, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 23.3436, mae: 2.9373, huber: 2.5155, swd: 10.3495, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.3983, mae: 2.4218, huber: 2.0005, swd: 7.3404, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.296031\n",
      "        Val objective improved 3.5542 → 3.5504, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 23.0876, mae: 2.5505, huber: 2.1362, swd: 11.6054, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 23.5813, mae: 2.9515, huber: 2.5291, swd: 10.5962, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.4785, mae: 2.4166, huber: 1.9964, swd: 7.4108, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 3.296703\n",
      "        No improvement (3.5887), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 23.2266, mae: 2.5484, huber: 2.1341, swd: 11.5621, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 24.2407, mae: 2.9726, huber: 2.5502, swd: 10.7739, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.7639, mae: 2.4464, huber: 2.0255, swd: 7.4725, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 3.290281\n",
      "        No improvement (3.6276), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 23.6024, mae: 2.5573, huber: 2.1428, swd: 11.6204, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 24.1685, mae: 2.9468, huber: 2.5241, swd: 10.4782, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.7362, mae: 2.4186, huber: 1.9974, swd: 7.3985, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 3.304800\n",
      "        No improvement (3.5719), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 23.8120, mae: 2.5525, huber: 2.1380, swd: 11.5023, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 24.2326, mae: 2.9516, huber: 2.5288, swd: 10.4851, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.6533, mae: 2.4212, huber: 1.9985, swd: 7.2189, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 3.288265\n",
      "        No improvement (3.5773), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 23.8917, mae: 2.5467, huber: 2.1323, swd: 11.4340, target_std: 20.3627\n",
      "Epoch [11/50], Val Losses: mse: 24.2969, mae: 2.9481, huber: 2.5243, swd: 10.2205, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 15.9472, mae: 2.4224, huber: 1.9995, swd: 7.2764, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 3.275721\n",
      "        Val objective improved 3.5504 → 3.5463, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 24.2087, mae: 2.5587, huber: 2.1442, swd: 11.5384, target_std: 20.3630\n",
      "Epoch [12/50], Val Losses: mse: 24.4487, mae: 2.9397, huber: 2.5173, swd: 10.1495, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 16.1297, mae: 2.4102, huber: 1.9913, swd: 7.3754, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 3.298025\n",
      "        Val objective improved 3.5463 → 3.5323, saving checkpoint.\n",
      "Epoch [13/50], Train Losses: mse: 24.1897, mae: 2.5361, huber: 2.1221, swd: 11.2564, target_std: 20.3630\n",
      "Epoch [13/50], Val Losses: mse: 25.0482, mae: 2.9714, huber: 2.5495, swd: 10.8356, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 16.0319, mae: 2.4120, huber: 1.9922, swd: 7.2504, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 3.247785\n",
      "        No improvement (3.6330), counter 1/5\n",
      "Epoch [14/50], Train Losses: mse: 24.4892, mae: 2.5535, huber: 2.1391, swd: 11.4367, target_std: 20.3629\n",
      "Epoch [14/50], Val Losses: mse: 25.8387, mae: 3.0193, huber: 2.5957, swd: 11.7052, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 17.2624, mae: 2.4902, huber: 2.0692, swd: 8.8891, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 3.282798\n",
      "        No improvement (3.7662), counter 2/5\n",
      "Epoch [15/50], Train Losses: mse: 24.4583, mae: 2.5414, huber: 2.1274, swd: 11.2651, target_std: 20.3630\n",
      "Epoch [15/50], Val Losses: mse: 24.6528, mae: 2.9332, huber: 2.5110, swd: 10.1440, target_std: 20.5432\n",
      "Epoch [15/50], Test Losses: mse: 16.2172, mae: 2.4117, huber: 1.9907, swd: 7.2783, target_std: 18.3439\n",
      "  Epoch 15 composite train-obj: 3.253892\n",
      "        Val objective improved 3.5323 → 3.5254, saving checkpoint.\n",
      "Epoch [16/50], Train Losses: mse: 24.4892, mae: 2.5440, huber: 2.1298, swd: 11.3189, target_std: 20.3626\n",
      "Epoch [16/50], Val Losses: mse: 24.8737, mae: 2.9367, huber: 2.5151, swd: 10.2233, target_std: 20.5432\n",
      "Epoch [16/50], Test Losses: mse: 16.1894, mae: 2.4038, huber: 1.9838, swd: 7.2363, target_std: 18.3439\n",
      "  Epoch 16 composite train-obj: 3.261700\n",
      "        No improvement (3.5375), counter 1/5\n",
      "Epoch [17/50], Train Losses: mse: 24.6163, mae: 2.5498, huber: 2.1354, swd: 11.3344, target_std: 20.3628\n",
      "Epoch [17/50], Val Losses: mse: 25.0021, mae: 2.9432, huber: 2.5212, swd: 10.0752, target_std: 20.5432\n",
      "Epoch [17/50], Test Losses: mse: 16.4966, mae: 2.4222, huber: 2.0029, swd: 7.4020, target_std: 18.3439\n",
      "  Epoch 17 composite train-obj: 3.268841\n",
      "        No improvement (3.5287), counter 2/5\n",
      "Epoch [18/50], Train Losses: mse: 24.7242, mae: 2.5453, huber: 2.1310, swd: 11.2551, target_std: 20.3627\n",
      "Epoch [18/50], Val Losses: mse: 25.0547, mae: 2.9345, huber: 2.5125, swd: 10.2666, target_std: 20.5432\n",
      "Epoch [18/50], Test Losses: mse: 16.5465, mae: 2.4276, huber: 2.0072, swd: 7.4484, target_std: 18.3439\n",
      "  Epoch 18 composite train-obj: 3.256531\n",
      "        No improvement (3.5391), counter 3/5\n",
      "Epoch [19/50], Train Losses: mse: 24.6953, mae: 2.5362, huber: 2.1223, swd: 11.1630, target_std: 20.3633\n",
      "Epoch [19/50], Val Losses: mse: 25.3220, mae: 2.9621, huber: 2.5390, swd: 10.5292, target_std: 20.5432\n",
      "Epoch [19/50], Test Losses: mse: 16.5303, mae: 2.4214, huber: 2.0010, swd: 7.2893, target_std: 18.3439\n",
      "  Epoch 19 composite train-obj: 3.238577\n",
      "        No improvement (3.5919), counter 4/5\n",
      "Epoch [20/50], Train Losses: mse: 24.8329, mae: 2.5438, huber: 2.1297, swd: 11.2355, target_std: 20.3630\n",
      "Epoch [20/50], Val Losses: mse: 25.5984, mae: 2.9782, huber: 2.5562, swd: 10.7843, target_std: 20.5432\n",
      "Epoch [20/50], Test Losses: mse: 16.4171, mae: 2.4046, huber: 1.9854, swd: 7.1483, target_std: 18.3439\n",
      "  Epoch 20 composite train-obj: 3.253262\n",
      "Epoch [20/50], Test Losses: mse: 16.2172, mae: 2.4117, huber: 1.9907, swd: 7.2783, target_std: 18.3439\n",
      "Best round's Test MSE: 16.2172, MAE: 2.4117, SWD: 7.2783\n",
      "Best round's Validation MSE: 24.6528, MAE: 2.9332, SWD: 10.1440\n",
      "Best round's Test verification MSE : 16.2172, MAE: 2.4117, SWD: 7.2783\n",
      "Time taken: 105.41 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 52.3913, mae: 3.2617, huber: 2.8423, swd: 13.2424, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.8863, mae: 2.9655, huber: 2.5468, swd: 9.9579, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.3867, mae: 2.4587, huber: 2.0367, swd: 7.0306, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 4.166502\n",
      "        Val objective improved inf → 3.5426, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.5744, mae: 2.5688, huber: 2.1552, swd: 11.2945, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 22.6353, mae: 2.9491, huber: 2.5302, swd: 9.8367, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.2090, mae: 2.4473, huber: 2.0265, swd: 7.0014, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 3.284651\n",
      "        Val objective improved 3.5426 → 3.5139, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 22.3526, mae: 2.5548, huber: 2.1412, swd: 11.0418, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 22.6883, mae: 2.9376, huber: 2.5176, swd: 9.8104, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1517, mae: 2.4278, huber: 2.0074, swd: 6.8772, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 3.245372\n",
      "        Val objective improved 3.5139 → 3.4986, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 22.3513, mae: 2.5556, huber: 2.1416, swd: 10.9979, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 22.4412, mae: 2.9327, huber: 2.5117, swd: 9.5900, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0458, mae: 2.4137, huber: 1.9932, swd: 6.7171, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 3.241428\n",
      "        Val objective improved 3.4986 → 3.4707, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 22.3212, mae: 2.5539, huber: 2.1397, swd: 10.9129, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.5255, mae: 2.9310, huber: 2.5095, swd: 9.8904, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.3624, mae: 2.4730, huber: 2.0495, swd: 7.2511, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 3.231019\n",
      "        No improvement (3.4986), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 22.2287, mae: 2.5439, huber: 2.1298, swd: 10.7821, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.7113, mae: 2.9414, huber: 2.5201, swd: 9.6718, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.2204, mae: 2.4387, huber: 2.0181, swd: 6.9485, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 3.207964\n",
      "        No improvement (3.4873), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 22.3369, mae: 2.5492, huber: 2.1351, swd: 10.8006, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 22.3008, mae: 2.9246, huber: 2.5023, swd: 9.3406, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.4051, mae: 2.4609, huber: 2.0388, swd: 7.2471, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 3.215118\n",
      "        Val objective improved 3.4707 → 3.4364, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 22.3373, mae: 2.5456, huber: 2.1315, swd: 10.7040, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 22.8442, mae: 2.9565, huber: 2.5338, swd: 9.7151, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.2094, mae: 2.4146, huber: 1.9945, swd: 6.8271, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 3.201848\n",
      "        No improvement (3.5053), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 22.3976, mae: 2.5464, huber: 2.1323, swd: 10.6732, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 23.0385, mae: 2.9710, huber: 2.5482, swd: 10.0130, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.5786, mae: 2.4443, huber: 2.0241, swd: 7.1247, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 3.199612\n",
      "        No improvement (3.5495), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 22.4538, mae: 2.5476, huber: 2.1335, swd: 10.6813, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 22.7174, mae: 2.9401, huber: 2.5183, swd: 9.4588, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.1538, mae: 2.4176, huber: 1.9974, swd: 6.6609, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 3.201622\n",
      "        No improvement (3.4642), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 22.6462, mae: 2.5555, huber: 2.1412, swd: 10.6973, target_std: 20.3633\n",
      "Epoch [11/50], Val Losses: mse: 23.1810, mae: 2.9741, huber: 2.5512, swd: 10.1242, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 15.3337, mae: 2.4472, huber: 2.0244, swd: 6.7708, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 3.210939\n",
      "        No improvement (3.5636), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 22.6610, mae: 2.5540, huber: 2.1396, swd: 10.6460, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 23.0660, mae: 2.9563, huber: 2.5340, swd: 9.5202, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 15.4927, mae: 2.4206, huber: 2.0009, swd: 6.7801, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 3.204214\n",
      "Epoch [12/50], Test Losses: mse: 15.4051, mae: 2.4609, huber: 2.0388, swd: 7.2471, target_std: 18.3439\n",
      "Best round's Test MSE: 15.4051, MAE: 2.4609, SWD: 7.2471\n",
      "Best round's Validation MSE: 22.3008, MAE: 2.9246, SWD: 9.3406\n",
      "Best round's Test verification MSE : 15.4051, MAE: 2.4609, SWD: 7.2471\n",
      "Time taken: 57.31 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1418)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.6690 ± 0.3877\n",
      "  mae: 2.4346 ± 0.0203\n",
      "  huber: 2.0134 ± 0.0198\n",
      "  swd: 7.2633 ± 0.0128\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 23.2205 ± 1.0263\n",
      "  mae: 2.9276 ± 0.0039\n",
      "  huber: 2.5055 ± 0.0039\n",
      "  swd: 9.7901 ± 0.3349\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 216.27 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1418\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.1, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd03ca",
   "metadata": {},
   "source": [
    "##### huber + 0.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0e8498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 137.0969, mae: 4.6951, huber: 4.2661, swd: 13.8548, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 27.6261, mae: 3.2870, huber: 2.8584, swd: 10.0051, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 18.2150, mae: 2.7167, huber: 2.2867, swd: 7.3505, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 11.193528\n",
      "        Val objective improved inf → 7.8609, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 27.4023, mae: 2.8733, huber: 2.4490, swd: 11.1870, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 27.0733, mae: 3.2253, huber: 2.7972, swd: 9.9558, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 17.8865, mae: 2.6768, huber: 2.2469, swd: 7.2929, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 8.042501\n",
      "        Val objective improved 7.8609 → 7.7751, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.7896, mae: 2.8235, huber: 2.4001, swd: 10.9807, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 27.3332, mae: 3.2383, huber: 2.8098, swd: 10.5567, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.9682, mae: 2.6607, huber: 2.2337, swd: 7.5359, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 7.890461\n",
      "        No improvement (8.0882), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 26.9840, mae: 2.8236, huber: 2.4001, swd: 10.8168, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 26.9753, mae: 3.1883, huber: 2.7599, swd: 9.6411, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 18.0006, mae: 2.6300, huber: 2.2043, swd: 7.2396, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 7.808517\n",
      "        Val objective improved 7.7751 → 7.5805, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 27.0393, mae: 2.8112, huber: 2.3880, swd: 10.6666, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 28.3239, mae: 3.2804, huber: 2.8507, swd: 10.7538, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 18.9292, mae: 2.7112, huber: 2.2840, swd: 7.9429, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 7.721312\n",
      "        No improvement (8.2276), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 27.0495, mae: 2.8112, huber: 2.3876, swd: 10.6569, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 27.6972, mae: 3.2139, huber: 2.7848, swd: 10.6522, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 18.8630, mae: 2.6730, huber: 2.2464, swd: 8.4546, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 7.716017\n",
      "        No improvement (8.1109), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 27.4934, mae: 2.8343, huber: 2.4103, swd: 10.7128, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 27.2718, mae: 3.1867, huber: 2.7570, swd: 9.5737, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 18.5740, mae: 2.6580, huber: 2.2309, swd: 7.6275, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 7.766748\n",
      "        Val objective improved 7.5805 → 7.5439, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 27.3444, mae: 2.8167, huber: 2.3932, swd: 10.5771, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 27.4407, mae: 3.2014, huber: 2.7709, swd: 9.7926, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 18.3150, mae: 2.6317, huber: 2.2042, swd: 7.1646, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 7.681696\n",
      "        No improvement (7.6672), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 27.3746, mae: 2.8111, huber: 2.3879, swd: 10.5076, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 27.0587, mae: 3.1618, huber: 2.7325, swd: 9.2921, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 18.4065, mae: 2.6470, huber: 2.2203, swd: 7.4360, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 7.641715\n",
      "        Val objective improved 7.5439 → 7.3785, saving checkpoint.\n",
      "Epoch [10/50], Train Losses: mse: 27.2125, mae: 2.7946, huber: 2.3714, swd: 10.4094, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 27.4558, mae: 3.2078, huber: 2.7755, swd: 9.6160, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 18.6196, mae: 2.6601, huber: 2.2295, swd: 7.5145, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 7.576139\n",
      "        No improvement (7.5835), counter 1/5\n",
      "Epoch [11/50], Train Losses: mse: 27.4714, mae: 2.8078, huber: 2.3844, swd: 10.4071, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 27.5661, mae: 3.2040, huber: 2.7737, swd: 10.0526, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 18.2463, mae: 2.6356, huber: 2.2073, swd: 7.0208, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 7.587901\n",
      "        No improvement (7.8001), counter 2/5\n",
      "Epoch [12/50], Train Losses: mse: 27.4351, mae: 2.7996, huber: 2.3762, swd: 10.4170, target_std: 20.3632\n",
      "Epoch [12/50], Val Losses: mse: 27.9023, mae: 3.1949, huber: 2.7660, swd: 9.9057, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 19.1499, mae: 2.6609, huber: 2.2362, swd: 8.0290, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 7.584723\n",
      "        No improvement (7.7189), counter 3/5\n",
      "Epoch [13/50], Train Losses: mse: 27.7004, mae: 2.8069, huber: 2.3838, swd: 10.3499, target_std: 20.3632\n",
      "Epoch [13/50], Val Losses: mse: 27.7835, mae: 3.2017, huber: 2.7715, swd: 10.0131, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 18.8113, mae: 2.6346, huber: 2.2081, swd: 7.6772, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 7.558706\n",
      "        No improvement (7.7780), counter 4/5\n",
      "Epoch [14/50], Train Losses: mse: 27.6461, mae: 2.8071, huber: 2.3838, swd: 10.3999, target_std: 20.3628\n",
      "Epoch [14/50], Val Losses: mse: 27.7159, mae: 3.1872, huber: 2.7579, swd: 9.6166, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 18.5464, mae: 2.6197, huber: 2.1941, swd: 7.0156, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 7.583738\n",
      "Epoch [14/50], Test Losses: mse: 18.4065, mae: 2.6470, huber: 2.2203, swd: 7.4360, target_std: 18.3439\n",
      "Best round's Test MSE: 18.4065, MAE: 2.6470, SWD: 7.4360\n",
      "Best round's Validation MSE: 27.0587, MAE: 3.1618, SWD: 9.2921\n",
      "Best round's Test verification MSE : 18.4065, MAE: 2.6470, SWD: 7.4360\n",
      "Time taken: 62.16 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 162.1122, mae: 5.2655, huber: 4.8345, swd: 14.6027, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 67.2240, mae: 3.9891, huber: 3.5586, swd: 10.3322, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 44.5275, mae: 3.3303, huber: 2.8971, swd: 7.5856, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 12.135841\n",
      "        Val objective improved inf → 8.7248, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 75.4020, mae: 3.7132, huber: 3.2864, swd: 11.9058, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 72.6837, mae: 3.9404, huber: 3.5104, swd: 11.1130, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 48.8597, mae: 3.3348, huber: 2.9021, swd: 8.6899, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 9.239309\n",
      "        No improvement (9.0669), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 78.0490, mae: 3.6734, huber: 3.2468, swd: 11.6635, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 72.0687, mae: 3.8962, huber: 3.4672, swd: 10.6709, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 48.2219, mae: 3.2281, huber: 2.8007, swd: 7.6217, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 9.078524\n",
      "        No improvement (8.8026), counter 2/5\n",
      "Epoch [4/50], Train Losses: mse: 78.9504, mae: 3.6455, huber: 3.2195, swd: 11.4856, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 74.9724, mae: 3.9168, huber: 3.4854, swd: 10.3583, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 51.0075, mae: 3.3162, huber: 2.8835, swd: 8.1035, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 8.962317\n",
      "        Val objective improved 8.7248 → 8.6646, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 64.0953, mae: 3.3762, huber: 2.9505, swd: 11.3372, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 57.2051, mae: 3.6107, huber: 3.1806, swd: 9.8689, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 41.5228, mae: 3.0497, huber: 2.6217, swd: 7.7421, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 8.619163\n",
      "        Val objective improved 8.6646 → 8.1151, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 59.0828, mae: 3.2556, huber: 2.8306, swd: 11.1370, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 55.2213, mae: 3.5563, huber: 3.1254, swd: 10.0989, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 40.1439, mae: 3.0064, huber: 2.5769, swd: 7.5696, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 8.399129\n",
      "        No improvement (8.1749), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 59.3294, mae: 3.2519, huber: 2.8269, swd: 11.1228, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 56.4650, mae: 3.5421, huber: 3.1115, swd: 9.9128, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 41.1871, mae: 2.9804, huber: 2.5528, swd: 7.5130, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 8.388276\n",
      "        Val objective improved 8.1151 → 8.0679, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 60.0391, mae: 3.2517, huber: 2.8266, swd: 11.0426, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 55.6314, mae: 3.6059, huber: 3.1753, swd: 10.8307, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 40.5247, mae: 3.0686, huber: 2.6397, swd: 8.1443, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 8.347907\n",
      "        No improvement (8.5906), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 60.2581, mae: 3.2620, huber: 2.8370, swd: 11.1001, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 56.0362, mae: 3.5427, huber: 3.1117, swd: 9.9655, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 41.0339, mae: 3.0003, huber: 2.5714, swd: 7.6383, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 8.386977\n",
      "        No improvement (8.0945), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 60.8576, mae: 3.2652, huber: 2.8402, swd: 11.0620, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 57.1357, mae: 3.5664, huber: 3.1334, swd: 10.2623, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 41.4849, mae: 3.0215, huber: 2.5879, swd: 7.5931, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 8.371246\n",
      "        No improvement (8.2645), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 61.0637, mae: 3.2504, huber: 2.8257, swd: 11.0000, target_std: 20.3627\n",
      "Epoch [11/50], Val Losses: mse: 56.4626, mae: 3.5306, huber: 3.0994, swd: 9.7168, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 41.2645, mae: 2.9804, huber: 2.5515, swd: 7.5051, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 8.325707\n",
      "        Val objective improved 8.0679 → 7.9578, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 61.5661, mae: 3.2590, huber: 2.8341, swd: 10.9772, target_std: 20.3630\n",
      "Epoch [12/50], Val Losses: mse: 57.0857, mae: 3.5384, huber: 3.1075, swd: 9.7679, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 41.7787, mae: 2.9780, huber: 2.5520, swd: 7.6535, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 8.322676\n",
      "        No improvement (7.9915), counter 1/5\n",
      "Epoch [13/50], Train Losses: mse: 61.0831, mae: 3.2330, huber: 2.8084, swd: 10.7795, target_std: 20.3630\n",
      "Epoch [13/50], Val Losses: mse: 56.5847, mae: 3.5425, huber: 3.1128, swd: 10.3416, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 40.8542, mae: 2.9633, huber: 2.5375, swd: 7.3696, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 8.198130\n",
      "        No improvement (8.2836), counter 2/5\n",
      "Epoch [14/50], Train Losses: mse: 61.4645, mae: 3.2581, huber: 2.8333, swd: 11.0511, target_std: 20.3629\n",
      "Epoch [14/50], Val Losses: mse: 60.4350, mae: 3.6587, huber: 3.2269, swd: 12.3443, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 44.6278, mae: 3.1034, huber: 2.6764, swd: 10.1086, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 8.358802\n",
      "        No improvement (9.3991), counter 3/5\n",
      "Epoch [15/50], Train Losses: mse: 61.7683, mae: 3.2413, huber: 2.8169, swd: 10.8622, target_std: 20.3630\n",
      "Epoch [15/50], Val Losses: mse: 59.6707, mae: 3.5803, huber: 3.1489, swd: 10.4089, target_std: 20.5432\n",
      "Epoch [15/50], Test Losses: mse: 43.6045, mae: 3.0280, huber: 2.5986, swd: 7.8898, target_std: 18.3439\n",
      "  Epoch 15 composite train-obj: 8.248053\n",
      "        No improvement (8.3533), counter 4/5\n",
      "Epoch [16/50], Train Losses: mse: 61.8453, mae: 3.2447, huber: 2.8202, swd: 10.9416, target_std: 20.3626\n",
      "Epoch [16/50], Val Losses: mse: 57.1847, mae: 3.5662, huber: 3.1347, swd: 9.9341, target_std: 20.5432\n",
      "Epoch [16/50], Test Losses: mse: 41.4430, mae: 3.0073, huber: 2.5778, swd: 7.5147, target_std: 18.3439\n",
      "  Epoch 16 composite train-obj: 8.290973\n",
      "Epoch [16/50], Test Losses: mse: 41.2645, mae: 2.9804, huber: 2.5515, swd: 7.5051, target_std: 18.3439\n",
      "Best round's Test MSE: 41.2645, MAE: 2.9804, SWD: 7.5051\n",
      "Best round's Validation MSE: 56.4626, MAE: 3.5306, SWD: 9.7168\n",
      "Best round's Test verification MSE : 41.2645, MAE: 2.9804, SWD: 7.5051\n",
      "Time taken: 68.65 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 119.6928, mae: 4.4679, huber: 4.0397, swd: 13.1712, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 27.3722, mae: 3.2458, huber: 2.8191, swd: 9.6453, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 17.7322, mae: 2.6734, huber: 2.2449, swd: 7.0034, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 10.625334\n",
      "        Val objective improved inf → 7.6418, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 26.5057, mae: 2.8107, huber: 2.3873, swd: 10.9320, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 27.2601, mae: 3.2226, huber: 2.7951, swd: 9.4488, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 17.9762, mae: 2.6754, huber: 2.2471, swd: 7.2651, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 7.853302\n",
      "        Val objective improved 7.6418 → 7.5195, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 26.2001, mae: 2.7871, huber: 2.3637, swd: 10.6717, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 26.1584, mae: 3.1473, huber: 2.7198, swd: 9.3216, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 17.2555, mae: 2.6114, huber: 2.1838, swd: 6.9642, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 7.699584\n",
      "        Val objective improved 7.5195 → 7.3806, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 26.4078, mae: 2.7897, huber: 2.3665, swd: 10.5759, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 26.1478, mae: 3.1504, huber: 2.7226, swd: 9.3117, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 17.1988, mae: 2.5891, huber: 2.1631, swd: 6.7597, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 7.654442\n",
      "        Val objective improved 7.3806 → 7.3785, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 26.4252, mae: 2.7760, huber: 2.3532, swd: 10.3723, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 26.6164, mae: 3.1701, huber: 2.7407, swd: 9.6064, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 17.8933, mae: 2.6791, huber: 2.2476, swd: 7.4134, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 7.539325\n",
      "        No improvement (7.5439), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 26.2188, mae: 2.7576, huber: 2.3346, swd: 10.1913, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 26.7623, mae: 3.1688, huber: 2.7407, swd: 9.4559, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 17.8497, mae: 2.6352, huber: 2.2092, swd: 7.1264, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 7.430305\n",
      "        No improvement (7.4687), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 26.5208, mae: 2.7692, huber: 2.3465, swd: 10.2025, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 26.7448, mae: 3.1593, huber: 2.7305, swd: 8.8097, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 18.4706, mae: 2.6627, huber: 2.2360, swd: 7.4800, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 7.447718\n",
      "        Val objective improved 7.3785 → 7.1354, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 26.6360, mae: 2.7774, huber: 2.3543, swd: 10.1985, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 26.8022, mae: 3.1752, huber: 2.7440, swd: 9.1182, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 17.7457, mae: 2.6009, huber: 2.1733, swd: 6.7785, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 7.453499\n",
      "        No improvement (7.3031), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 26.5984, mae: 2.7664, huber: 2.3434, swd: 10.1217, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 27.0114, mae: 3.1886, huber: 2.7579, swd: 9.6288, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 18.1749, mae: 2.6286, huber: 2.2017, swd: 7.4134, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 7.404276\n",
      "        No improvement (7.5723), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 26.6136, mae: 2.7660, huber: 2.3432, swd: 10.1671, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 26.7319, mae: 3.1600, huber: 2.7304, swd: 9.0817, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 17.8939, mae: 2.6164, huber: 2.1893, swd: 6.7870, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 7.426763\n",
      "        No improvement (7.2712), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 26.8406, mae: 2.7754, huber: 2.3524, swd: 10.1976, target_std: 20.3633\n",
      "Epoch [11/50], Val Losses: mse: 27.3836, mae: 3.1986, huber: 2.7686, swd: 9.9531, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 18.1316, mae: 2.6489, huber: 2.2207, swd: 7.0824, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 7.451190\n",
      "        No improvement (7.7452), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 26.8557, mae: 2.7754, huber: 2.3523, swd: 10.1704, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 27.1840, mae: 3.1726, huber: 2.7427, swd: 9.2228, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 18.2658, mae: 2.6075, huber: 2.1820, swd: 7.0187, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 7.437537\n",
      "Epoch [12/50], Test Losses: mse: 18.4706, mae: 2.6627, huber: 2.2360, swd: 7.4800, target_std: 18.3439\n",
      "Best round's Test MSE: 18.4706, MAE: 2.6627, SWD: 7.4800\n",
      "Best round's Validation MSE: 26.7448, MAE: 3.1593, SWD: 8.8097\n",
      "Best round's Test verification MSE : 18.4706, MAE: 2.6627, SWD: 7.4800\n",
      "Time taken: 52.13 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1410)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 26.0472 ± 10.7603\n",
      "  mae: 2.7634 ± 0.1536\n",
      "  huber: 2.3359 ± 0.1526\n",
      "  swd: 7.4737 ± 0.0286\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 36.7554 ± 13.9357\n",
      "  mae: 3.2839 ± 0.1745\n",
      "  huber: 2.8541 ± 0.1734\n",
      "  swd: 9.2729 ± 0.3706\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 183.01 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1410\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [0.0, 0.0, 1.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [0.0, 0.0, 1.0, 0.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1e939",
   "metadata": {},
   "source": [
    "##### MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1f3afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.1505, mae: 3.0724, huber: 2.6500, swd: 15.5327, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.0402, mae: 2.9422, huber: 2.5213, swd: 10.2520, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.3579, mae: 2.4633, huber: 2.0396, swd: 7.4528, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 34.150534\n",
      "        Val objective improved inf → 22.0402, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7125, mae: 2.5778, huber: 2.1600, swd: 12.0334, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 21.7467, mae: 2.9215, huber: 2.4982, swd: 10.7384, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.8527, mae: 2.4436, huber: 2.0182, swd: 7.3204, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.712515\n",
      "        Val objective improved 22.0402 → 21.7467, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.2799, mae: 2.5547, huber: 2.1368, swd: 11.7840, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 21.8367, mae: 2.9410, huber: 2.5160, swd: 10.7963, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1591, mae: 2.4830, huber: 2.0566, swd: 7.6234, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 21.279868\n",
      "        No improvement (21.8367), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.2722, mae: 2.5620, huber: 2.1429, swd: 11.7605, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.7857, mae: 2.9343, huber: 2.5085, swd: 10.4747, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.9944, mae: 2.4432, huber: 2.0204, swd: 7.2826, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 21.272248\n",
      "        No improvement (21.7857), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 21.1812, mae: 2.5610, huber: 2.1414, swd: 11.7046, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.3736, mae: 2.9112, huber: 2.4834, swd: 10.2306, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.9431, mae: 2.4467, huber: 2.0215, swd: 7.3371, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 21.181226\n",
      "        Val objective improved 21.7467 → 21.3736, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.2364, mae: 2.5695, huber: 2.1492, swd: 11.7511, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 21.3755, mae: 2.9176, huber: 2.4883, swd: 10.3886, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.8961, mae: 2.4669, huber: 2.0387, swd: 7.4479, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.236373\n",
      "        No improvement (21.3755), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.2435, mae: 2.5755, huber: 2.1548, swd: 11.7569, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 21.6961, mae: 2.9416, huber: 2.5115, swd: 10.7402, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.7851, mae: 2.4345, huber: 2.0096, swd: 7.2945, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 21.243531\n",
      "        No improvement (21.6961), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 21.2772, mae: 2.5813, huber: 2.1605, swd: 11.7630, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5501, mae: 2.9238, huber: 2.4951, swd: 10.3387, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.6155, mae: 2.4008, huber: 1.9782, swd: 7.0853, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 21.277215\n",
      "        No improvement (21.5501), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2542, mae: 2.5798, huber: 2.1590, swd: 11.7499, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.4748, mae: 2.9158, huber: 2.4856, swd: 10.0896, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.0364, mae: 2.4467, huber: 2.0223, swd: 7.4341, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 21.254168\n",
      "        No improvement (21.4748), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 21.1484, mae: 2.5729, huber: 2.1518, swd: 11.6669, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 21.7093, mae: 2.9566, huber: 2.5261, swd: 10.4217, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.1196, mae: 2.4558, huber: 2.0319, swd: 7.4733, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 21.148400\n",
      "Epoch [10/50], Test Losses: mse: 14.9431, mae: 2.4467, huber: 2.0215, swd: 7.3371, target_std: 18.3439\n",
      "Best round's Test MSE: 14.9431, MAE: 2.4467, SWD: 7.3371\n",
      "Best round's Validation MSE: 21.3736, MAE: 2.9112, SWD: 10.2306\n",
      "Best round's Test verification MSE : 14.9431, MAE: 2.4467, SWD: 7.3371\n",
      "Time taken: 43.79 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.5905, mae: 3.0778, huber: 2.6553, swd: 16.3287, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.0345, mae: 2.9553, huber: 2.5339, swd: 10.9964, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2411, mae: 2.4814, huber: 2.0557, swd: 7.9154, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 34.590457\n",
      "        Val objective improved inf → 22.0345, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.6893, mae: 2.5726, huber: 2.1549, swd: 12.5821, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 21.6544, mae: 2.9181, huber: 2.4930, swd: 10.9185, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0073, mae: 2.4589, huber: 2.0321, swd: 7.7584, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.689281\n",
      "        Val objective improved 22.0345 → 21.6544, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.4097, mae: 2.5664, huber: 2.1479, swd: 12.3958, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.5218, mae: 2.9024, huber: 2.4772, swd: 10.8757, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.8557, mae: 2.4374, huber: 2.0125, swd: 7.6059, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 21.409667\n",
      "        Val objective improved 21.6544 → 21.5218, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.2368, mae: 2.5560, huber: 2.1371, swd: 12.2939, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 21.5645, mae: 2.9135, huber: 2.4875, swd: 10.6317, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.8720, mae: 2.4189, huber: 1.9966, swd: 7.5582, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 21.236820\n",
      "        No improvement (21.5645), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 21.2375, mae: 2.5673, huber: 2.1474, swd: 12.2710, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.3916, mae: 2.9107, huber: 2.4815, swd: 10.8782, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.0078, mae: 2.4754, huber: 2.0471, swd: 7.7860, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 21.237452\n",
      "        Val objective improved 21.5218 → 21.3916, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.3002, mae: 2.5777, huber: 2.1572, swd: 12.3261, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 21.6840, mae: 2.9321, huber: 2.5034, swd: 11.1226, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.6762, mae: 2.4270, huber: 2.0027, swd: 7.6160, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.300177\n",
      "        No improvement (21.6840), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.1823, mae: 2.5682, huber: 2.1478, swd: 12.2568, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.7153, mae: 2.9443, huber: 2.5136, swd: 10.7967, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.1483, mae: 2.4744, huber: 2.0471, swd: 7.8702, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 21.182300\n",
      "        No improvement (21.7153), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 21.3057, mae: 2.5828, huber: 2.1616, swd: 12.3093, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 22.4735, mae: 3.0313, huber: 2.5975, swd: 11.5194, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.4381, mae: 2.5368, huber: 2.1050, swd: 8.0671, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 21.305747\n",
      "        No improvement (22.4735), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2239, mae: 2.5775, huber: 2.1564, swd: 12.2715, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 21.5566, mae: 2.9293, huber: 2.4994, swd: 10.5903, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.7236, mae: 2.4228, huber: 1.9980, swd: 7.4858, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 21.223922\n",
      "        No improvement (21.5566), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 21.2642, mae: 2.5858, huber: 2.1646, swd: 12.2868, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 21.9082, mae: 2.9573, huber: 2.5278, swd: 10.9301, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.5935, mae: 2.4017, huber: 1.9804, swd: 7.4610, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 21.264192\n",
      "Epoch [10/50], Test Losses: mse: 15.0078, mae: 2.4754, huber: 2.0471, swd: 7.7860, target_std: 18.3439\n",
      "Best round's Test MSE: 15.0078, MAE: 2.4754, SWD: 7.7860\n",
      "Best round's Validation MSE: 21.3916, MAE: 2.9107, SWD: 10.8782\n",
      "Best round's Test verification MSE : 15.0078, MAE: 2.4754, SWD: 7.7860\n",
      "Time taken: 43.82 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.7620, mae: 3.0880, huber: 2.6655, swd: 15.3952, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.0762, mae: 2.9471, huber: 2.5261, swd: 9.9826, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2348, mae: 2.4770, huber: 2.0513, swd: 7.2036, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 34.761984\n",
      "        Val objective improved inf → 22.0762, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.6629, mae: 2.5723, huber: 2.1546, swd: 11.6818, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 21.5749, mae: 2.9136, huber: 2.4909, swd: 10.0178, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9210, mae: 2.4586, huber: 2.0318, swd: 7.0655, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 21.662914\n",
      "        Val objective improved 22.0762 → 21.5749, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.3642, mae: 2.5629, huber: 2.1445, swd: 11.4884, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.5312, mae: 2.8973, huber: 2.4730, swd: 9.9587, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.9150, mae: 2.4531, huber: 2.0259, swd: 7.0891, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 21.364182\n",
      "        Val objective improved 21.5749 → 21.5312, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.1874, mae: 2.5543, huber: 2.1353, swd: 11.3975, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 21.3231, mae: 2.8940, huber: 2.4688, swd: 9.7626, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.7945, mae: 2.4041, huber: 1.9821, swd: 6.9108, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 21.187414\n",
      "        Val objective improved 21.5312 → 21.3231, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.2218, mae: 2.5640, huber: 2.1442, swd: 11.3988, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.0766, mae: 2.9424, huber: 2.5156, swd: 10.7613, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2093, mae: 2.4853, huber: 2.0607, swd: 7.5307, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 21.221765\n",
      "        No improvement (22.0766), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 21.1898, mae: 2.5684, huber: 2.1482, swd: 11.3808, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 21.9062, mae: 2.9615, huber: 2.5316, swd: 10.4688, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.9713, mae: 2.4713, huber: 2.0440, swd: 7.2787, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 21.189820\n",
      "        No improvement (21.9062), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 21.2629, mae: 2.5769, huber: 2.1561, swd: 11.4262, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.4137, mae: 2.9195, huber: 2.4911, swd: 9.9128, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.0363, mae: 2.4616, huber: 2.0373, swd: 7.2452, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 21.262940\n",
      "        No improvement (21.4137), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 21.2757, mae: 2.5789, huber: 2.1582, swd: 11.4229, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5734, mae: 2.9364, huber: 2.5073, swd: 10.0886, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.5926, mae: 2.4047, huber: 1.9834, swd: 6.8827, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 21.275735\n",
      "        No improvement (21.5734), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 21.1979, mae: 2.5754, huber: 2.1545, swd: 11.3778, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 21.6124, mae: 2.9249, huber: 2.4952, swd: 9.8087, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.0542, mae: 2.4154, huber: 1.9939, swd: 7.0976, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 21.197854\n",
      "Epoch [9/50], Test Losses: mse: 14.7945, mae: 2.4041, huber: 1.9821, swd: 6.9108, target_std: 18.3439\n",
      "Best round's Test MSE: 14.7945, MAE: 2.4041, SWD: 6.9108\n",
      "Best round's Validation MSE: 21.3231, MAE: 2.8940, SWD: 9.7626\n",
      "Best round's Test verification MSE : 14.7945, MAE: 2.4041, SWD: 6.9108\n",
      "Time taken: 38.84 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1413)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.9151 ± 0.0893\n",
      "  mae: 2.4421 ± 0.0293\n",
      "  huber: 2.0169 ± 0.0267\n",
      "  swd: 7.3447 ± 0.3573\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 21.3628 ± 0.0290\n",
      "  mae: 2.9053 ± 0.0080\n",
      "  huber: 2.4779 ± 0.0065\n",
      "  swd: 10.2904 ± 0.4574\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 126.51 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1413\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766c445",
   "metadata": {},
   "source": [
    "##### MSE + 0.1 SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d93ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.1893, mae: 3.0795, huber: 2.6568, swd: 15.2033, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.1322, mae: 2.9479, huber: 2.5267, swd: 10.3289, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.3983, mae: 2.4652, huber: 2.0414, swd: 7.4699, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 35.709660\n",
      "        Val objective improved inf → 23.1650, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7192, mae: 2.5791, huber: 2.1611, swd: 12.0122, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 21.7797, mae: 2.9238, huber: 2.5004, swd: 10.7464, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.8713, mae: 2.4443, huber: 2.0189, swd: 7.3155, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.920423\n",
      "        Val objective improved 23.1650 → 22.8543, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.2799, mae: 2.5556, huber: 2.1373, swd: 11.7739, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 21.8440, mae: 2.9448, huber: 2.5191, swd: 10.9119, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1747, mae: 2.4863, huber: 2.0596, swd: 7.7181, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 22.457275\n",
      "        No improvement (22.9352), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.2781, mae: 2.5637, huber: 2.1442, swd: 11.7726, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.8021, mae: 2.9391, huber: 2.5126, swd: 10.4658, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0076, mae: 2.4413, huber: 2.0188, swd: 7.2588, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.455375\n",
      "        Val objective improved 22.8543 → 22.8487, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.1980, mae: 2.5642, huber: 2.1441, swd: 11.7309, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.4027, mae: 2.9152, huber: 2.4866, swd: 10.3024, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.9289, mae: 2.4434, huber: 2.0184, swd: 7.3154, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 22.371046\n",
      "        Val objective improved 22.8487 → 22.4330, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.2605, mae: 2.5737, huber: 2.1528, swd: 11.7933, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 21.3668, mae: 2.9189, huber: 2.4889, swd: 10.3073, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.8757, mae: 2.4564, huber: 2.0288, swd: 7.3851, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 22.439851\n",
      "        Val objective improved 22.4330 → 22.3975, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 21.2504, mae: 2.5783, huber: 2.1570, swd: 11.7915, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 21.6351, mae: 2.9396, huber: 2.5091, swd: 10.5540, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.7774, mae: 2.4324, huber: 2.0080, swd: 7.2808, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 22.429601\n",
      "        No improvement (22.6905), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 21.2838, mae: 2.5838, huber: 2.1625, swd: 11.7889, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5412, mae: 2.9281, huber: 2.4986, swd: 10.4587, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.5938, mae: 2.4007, huber: 1.9780, swd: 7.1175, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 22.462684\n",
      "        No improvement (22.5871), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2552, mae: 2.5826, huber: 2.1612, swd: 11.7716, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.4997, mae: 2.9206, huber: 2.4894, swd: 10.0213, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.0957, mae: 2.4473, huber: 2.0230, swd: 7.4685, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 22.432369\n",
      "        No improvement (22.5018), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 21.1483, mae: 2.5755, huber: 2.1538, swd: 11.6765, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 21.7182, mae: 2.9622, huber: 2.5312, swd: 10.3844, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.0883, mae: 2.4499, huber: 2.0264, swd: 7.3810, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 22.315983\n",
      "        No improvement (22.7566), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 21.2822, mae: 2.5922, huber: 2.1701, swd: 11.7348, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 21.8776, mae: 2.9583, huber: 2.5274, swd: 10.6729, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.7313, mae: 2.4293, huber: 2.0056, swd: 7.1656, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 22.455711\n",
      "Epoch [11/50], Test Losses: mse: 14.8757, mae: 2.4564, huber: 2.0288, swd: 7.3851, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8757, MAE: 2.4564, SWD: 7.3851\n",
      "Best round's Validation MSE: 21.3668, MAE: 2.9189, SWD: 10.3073\n",
      "Best round's Test verification MSE : 14.8757, MAE: 2.4564, SWD: 7.3851\n",
      "Time taken: 53.77 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.6071, mae: 3.0839, huber: 2.6612, swd: 15.9832, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.0999, mae: 2.9598, huber: 2.5381, swd: 11.0377, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2587, mae: 2.4846, huber: 2.0586, swd: 7.9139, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 36.205407\n",
      "        Val objective improved inf → 23.2037, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.6888, mae: 2.5732, huber: 2.1553, swd: 12.5550, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 21.6736, mae: 2.9204, huber: 2.4952, swd: 10.9570, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0251, mae: 2.4609, huber: 2.0343, swd: 7.7994, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.944319\n",
      "        Val objective improved 23.2037 → 22.7693, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.4298, mae: 2.5697, huber: 2.1508, swd: 12.4181, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.5305, mae: 2.9033, huber: 2.4780, swd: 10.9124, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.8212, mae: 2.4312, huber: 2.0071, swd: 7.5617, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 22.671628\n",
      "        Val objective improved 22.7693 → 22.6218, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.2439, mae: 2.5581, huber: 2.1388, swd: 12.3064, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 21.6923, mae: 2.9252, huber: 2.4984, swd: 10.8074, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.9589, mae: 2.4287, huber: 2.0060, swd: 7.6700, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.474575\n",
      "        No improvement (22.7730), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 21.2565, mae: 2.5705, huber: 2.1501, swd: 12.3173, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.4400, mae: 2.9163, huber: 2.4868, swd: 11.0075, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.9458, mae: 2.4675, huber: 2.0399, swd: 7.6889, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 22.488273\n",
      "        Val objective improved 22.6218 → 22.5408, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.3206, mae: 2.5825, huber: 2.1614, swd: 12.3683, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 21.6085, mae: 2.9289, huber: 2.4997, swd: 10.9044, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.6385, mae: 2.4213, huber: 1.9969, swd: 7.5019, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 22.557394\n",
      "        No improvement (22.6989), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.1855, mae: 2.5699, huber: 2.1491, swd: 12.2706, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.7368, mae: 2.9434, huber: 2.5122, swd: 10.7511, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.2044, mae: 2.4701, huber: 2.0434, swd: 7.8958, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 22.412518\n",
      "        No improvement (22.8119), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 21.3288, mae: 2.5880, huber: 2.1662, swd: 12.3693, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 22.7249, mae: 3.0546, huber: 2.6196, swd: 12.0396, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.4965, mae: 2.5498, huber: 2.1170, swd: 8.2288, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 22.565731\n",
      "        No improvement (23.9289), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2186, mae: 2.5791, huber: 2.1575, swd: 12.2766, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 21.5862, mae: 2.9318, huber: 2.5014, swd: 10.5074, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.8001, mae: 2.4185, huber: 1.9950, swd: 7.5446, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 22.446314\n",
      "        No improvement (22.6370), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 21.2861, mae: 2.5909, huber: 2.1691, swd: 12.3534, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 21.8364, mae: 2.9544, huber: 2.5244, swd: 10.9107, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.5307, mae: 2.3957, huber: 1.9746, swd: 7.4021, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 22.521456\n",
      "Epoch [10/50], Test Losses: mse: 14.9458, mae: 2.4675, huber: 2.0399, swd: 7.6889, target_std: 18.3439\n",
      "Best round's Test MSE: 14.9458, MAE: 2.4675, SWD: 7.6889\n",
      "Best round's Validation MSE: 21.4400, MAE: 2.9163, SWD: 11.0075\n",
      "Best round's Test verification MSE : 14.9458, MAE: 2.4675, SWD: 7.6889\n",
      "Time taken: 47.74 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.7774, mae: 3.0939, huber: 2.6713, swd: 15.0362, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.1179, mae: 2.9490, huber: 2.5278, swd: 9.9959, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2373, mae: 2.4751, huber: 2.0495, swd: 7.1654, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 36.281026\n",
      "        Val objective improved inf → 23.1175, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.6620, mae: 2.5728, huber: 2.1550, swd: 11.6479, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 21.6088, mae: 2.9186, huber: 2.4953, swd: 10.0699, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9238, mae: 2.4588, huber: 2.0317, swd: 7.0443, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 22.826798\n",
      "        Val objective improved 23.1175 → 22.6158, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.3700, mae: 2.5646, huber: 2.1458, swd: 11.4781, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.5443, mae: 2.9013, huber: 2.4762, swd: 9.9083, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.9580, mae: 2.4575, huber: 2.0297, swd: 7.1067, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 22.517838\n",
      "        Val objective improved 22.6158 → 22.5352, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.1985, mae: 2.5561, huber: 2.1368, swd: 11.4101, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 21.3249, mae: 2.8972, huber: 2.4713, swd: 9.7317, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.8013, mae: 2.4045, huber: 1.9825, swd: 6.8929, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 22.339526\n",
      "        Val objective improved 22.5352 → 22.2981, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.2360, mae: 2.5670, huber: 2.1467, swd: 11.4161, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 21.9582, mae: 2.9369, huber: 2.5092, swd: 10.5097, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.2427, mae: 2.4948, huber: 2.0689, swd: 7.5703, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 22.377582\n",
      "        No improvement (23.0092), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 21.2035, mae: 2.5719, huber: 2.1510, swd: 11.3870, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.1676, mae: 2.9868, huber: 2.5559, swd: 11.0008, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.0752, mae: 2.4916, huber: 2.0632, swd: 7.4595, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 22.342195\n",
      "        No improvement (23.2677), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 21.2623, mae: 2.5795, huber: 2.1581, swd: 11.4181, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.5447, mae: 2.9332, huber: 2.5041, swd: 10.0268, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.0157, mae: 2.4634, huber: 2.0391, swd: 7.1450, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 22.404119\n",
      "        No improvement (22.5474), counter 3/5\n",
      "Epoch [8/50], Train Losses: mse: 21.3097, mae: 2.5851, huber: 2.1638, swd: 11.4488, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5312, mae: 2.9364, huber: 2.5065, swd: 10.1186, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.5540, mae: 2.4019, huber: 1.9805, swd: 6.8502, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 22.454599\n",
      "        No improvement (22.5431), counter 4/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2088, mae: 2.5794, huber: 2.1579, swd: 11.3792, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 21.7019, mae: 2.9378, huber: 2.5072, swd: 9.9214, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.1042, mae: 2.4194, huber: 1.9977, swd: 7.1391, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 22.346741\n",
      "Epoch [9/50], Test Losses: mse: 14.8013, mae: 2.4045, huber: 1.9825, swd: 6.8929, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8013, MAE: 2.4045, SWD: 6.8929\n",
      "Best round's Validation MSE: 21.3249, MAE: 2.8972, SWD: 9.7317\n",
      "Best round's Test verification MSE : 14.8013, MAE: 2.4045, SWD: 6.8929\n",
      "Time taken: 39.02 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1422)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.8742 ± 0.0590\n",
      "  mae: 2.4428 ± 0.0275\n",
      "  huber: 2.0170 ± 0.0249\n",
      "  swd: 7.3223 ± 0.3280\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 21.3772 ± 0.0476\n",
      "  mae: 2.9108 ± 0.0097\n",
      "  huber: 2.4823 ± 0.0079\n",
      "  swd: 10.3488 ± 0.5217\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 140.57 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1422\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.1, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.1, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de62b9",
   "metadata": {},
   "source": [
    "##### MSE + 0.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa1db4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.5239, mae: 3.1058, huber: 2.6823, swd: 14.7230, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.2841, mae: 2.9601, huber: 2.5380, swd: 10.4920, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.4627, mae: 2.4737, huber: 2.0497, swd: 7.5674, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 41.885445\n",
      "        Val objective improved inf → 27.5301, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7409, mae: 2.5858, huber: 2.1665, swd: 12.0428, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 21.8649, mae: 2.9352, huber: 2.5103, swd: 10.8315, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9557, mae: 2.4516, huber: 2.0250, swd: 7.3482, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 27.762271\n",
      "        Val objective improved 27.5301 → 27.2807, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.2936, mae: 2.5614, huber: 2.1414, swd: 11.7703, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 22.0345, mae: 2.9680, huber: 2.5407, swd: 11.3339, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.2463, mae: 2.4920, huber: 2.0662, swd: 7.9176, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 27.178771\n",
      "        No improvement (27.7015), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.3113, mae: 2.5719, huber: 2.1505, swd: 11.8466, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 21.7179, mae: 2.9401, huber: 2.5111, swd: 10.4464, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0326, mae: 2.4343, huber: 2.0115, swd: 7.3850, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 27.234614\n",
      "        Val objective improved 27.2807 → 26.9411, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.2091, mae: 2.5694, huber: 2.1473, swd: 11.7540, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.6485, mae: 2.9433, huber: 2.5122, swd: 10.5807, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.9803, mae: 2.4418, huber: 2.0169, swd: 7.3090, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 27.086113\n",
      "        Val objective improved 26.9411 → 26.9388, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.3100, mae: 2.5845, huber: 2.1615, swd: 11.9175, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 21.4044, mae: 2.9287, huber: 2.4965, swd: 10.1332, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.8540, mae: 2.4395, huber: 2.0129, swd: 7.3215, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 27.268722\n",
      "        Val objective improved 26.9388 → 26.4710, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 21.2985, mae: 2.5886, huber: 2.1652, swd: 11.9000, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 21.5555, mae: 2.9430, huber: 2.5110, swd: 10.3708, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.8258, mae: 2.4344, huber: 2.0103, swd: 7.2507, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 27.248441\n",
      "        No improvement (26.7409), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 21.2711, mae: 2.5871, huber: 2.1638, swd: 11.8309, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5287, mae: 2.9331, huber: 2.5014, swd: 10.2188, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.6809, mae: 2.3942, huber: 1.9721, swd: 7.1138, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 27.186512\n",
      "        No improvement (26.6381), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2058, mae: 2.5834, huber: 2.1601, swd: 11.7793, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.7024, mae: 2.9481, huber: 2.5140, swd: 10.2939, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.1646, mae: 2.4640, huber: 2.0376, swd: 7.5591, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 27.095439\n",
      "        No improvement (26.8493), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 21.1092, mae: 2.5776, huber: 2.1539, swd: 11.6461, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 21.7041, mae: 2.9721, huber: 2.5386, swd: 10.1464, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.0441, mae: 2.4404, huber: 2.0163, swd: 7.2214, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 26.932215\n",
      "        No improvement (26.7773), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 21.1983, mae: 2.5893, huber: 2.1655, swd: 11.7111, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 22.7397, mae: 3.0333, huber: 2.5993, swd: 11.9179, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.7845, mae: 2.4471, huber: 2.0221, swd: 7.3134, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 27.053901\n",
      "Epoch [11/50], Test Losses: mse: 14.8540, mae: 2.4395, huber: 2.0129, swd: 7.3215, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8540, MAE: 2.4395, SWD: 7.3215\n",
      "Best round's Validation MSE: 21.4044, MAE: 2.9287, SWD: 10.1332\n",
      "Best round's Test verification MSE : 14.8540, MAE: 2.4395, SWD: 7.3215\n",
      "Time taken: 48.96 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 34.8893, mae: 3.1073, huber: 2.6838, swd: 15.4798, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.2692, mae: 2.9762, huber: 2.5525, swd: 11.1839, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.3090, mae: 2.4925, huber: 2.0656, swd: 7.9456, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 42.629172\n",
      "        Val objective improved inf → 27.8611, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.7117, mae: 2.5798, huber: 2.1607, swd: 12.5693, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 21.6349, mae: 2.9223, huber: 2.4961, swd: 10.8913, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.0267, mae: 2.4568, huber: 2.0307, swd: 7.8367, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 27.996320\n",
      "        Val objective improved 27.8611 → 27.0806, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.5124, mae: 2.5840, huber: 2.1632, swd: 12.5711, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.6123, mae: 2.9146, huber: 2.4877, swd: 11.0385, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 14.7104, mae: 2.4166, huber: 1.9928, swd: 7.4346, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 27.797972\n",
      "        No improvement (27.1316), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.2314, mae: 2.5629, huber: 2.1416, swd: 12.3271, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 21.8233, mae: 2.9457, huber: 2.5157, swd: 11.0860, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.2294, mae: 2.4665, huber: 2.0405, swd: 8.1609, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 27.394915\n",
      "        No improvement (27.3663), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 21.2937, mae: 2.5804, huber: 2.1579, swd: 12.3982, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.4306, mae: 2.9198, huber: 2.4886, swd: 10.7983, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 14.8426, mae: 2.4382, huber: 2.0121, swd: 7.5447, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 27.492771\n",
      "        Val objective improved 27.0806 → 26.8297, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.2852, mae: 2.5850, huber: 2.1620, swd: 12.3872, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 21.4000, mae: 2.9122, huber: 2.4812, swd: 10.4012, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 14.8784, mae: 2.4223, huber: 1.9990, swd: 7.7056, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 27.478739\n",
      "        Val objective improved 26.8297 → 26.6006, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 21.1943, mae: 2.5763, huber: 2.1534, swd: 12.2840, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 21.6731, mae: 2.9464, huber: 2.5134, swd: 10.6075, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.0149, mae: 2.4476, huber: 2.0215, swd: 7.7017, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 27.336292\n",
      "        No improvement (26.9768), counter 1/5\n",
      "Epoch [8/50], Train Losses: mse: 21.2526, mae: 2.5878, huber: 2.1640, swd: 12.3244, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 22.2795, mae: 3.0217, huber: 2.5868, swd: 11.7726, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.2417, mae: 2.5065, huber: 2.0771, swd: 8.2333, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 27.414819\n",
      "        No improvement (28.1658), counter 2/5\n",
      "Epoch [9/50], Train Losses: mse: 21.2011, mae: 2.5821, huber: 2.1586, swd: 12.2586, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 21.5145, mae: 2.9377, huber: 2.5046, swd: 10.4107, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 14.8770, mae: 2.4313, huber: 2.0065, swd: 7.7441, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 27.330420\n",
      "        No improvement (26.7199), counter 3/5\n",
      "Epoch [10/50], Train Losses: mse: 21.3232, mae: 2.6006, huber: 2.1767, swd: 12.4516, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 21.6393, mae: 2.9515, huber: 2.5185, swd: 10.5950, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.7272, mae: 2.4190, huber: 1.9946, swd: 7.5006, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 27.548986\n",
      "        No improvement (26.9368), counter 4/5\n",
      "Epoch [11/50], Train Losses: mse: 21.1817, mae: 2.5849, huber: 2.1613, swd: 12.2693, target_std: 20.3627\n",
      "Epoch [11/50], Val Losses: mse: 21.3115, mae: 2.9456, huber: 2.5109, swd: 10.3014, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.6928, mae: 2.4318, huber: 2.0043, swd: 7.4022, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 27.316375\n",
      "        Val objective improved 26.6006 → 26.4622, saving checkpoint.\n",
      "Epoch [12/50], Train Losses: mse: 21.1262, mae: 2.5827, huber: 2.1589, swd: 12.2087, target_std: 20.3630\n",
      "Epoch [12/50], Val Losses: mse: 21.5825, mae: 2.9509, huber: 2.5168, swd: 10.4774, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 15.1627, mae: 2.4360, huber: 2.0118, swd: 7.7424, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 27.230541\n",
      "        No improvement (26.8212), counter 1/5\n",
      "Epoch [13/50], Train Losses: mse: 21.1478, mae: 2.5883, huber: 2.1643, swd: 12.1954, target_std: 20.3630\n",
      "Epoch [13/50], Val Losses: mse: 22.0681, mae: 2.9970, huber: 2.5637, swd: 11.6237, target_std: 20.5432\n",
      "Epoch [13/50], Test Losses: mse: 14.4890, mae: 2.4112, huber: 1.9875, swd: 7.4573, target_std: 18.3439\n",
      "  Epoch 13 composite train-obj: 27.245526\n",
      "        No improvement (27.8799), counter 2/5\n",
      "Epoch [14/50], Train Losses: mse: 21.1885, mae: 2.5915, huber: 2.1674, swd: 12.3068, target_std: 20.3629\n",
      "Epoch [14/50], Val Losses: mse: 22.5710, mae: 3.0224, huber: 2.5886, swd: 11.8151, target_std: 20.5432\n",
      "Epoch [14/50], Test Losses: mse: 15.7652, mae: 2.4895, huber: 2.0661, swd: 8.9351, target_std: 18.3439\n",
      "  Epoch 14 composite train-obj: 27.341919\n",
      "        No improvement (28.4786), counter 3/5\n",
      "Epoch [15/50], Train Losses: mse: 21.0792, mae: 2.5825, huber: 2.1587, swd: 12.2249, target_std: 20.3630\n",
      "Epoch [15/50], Val Losses: mse: 21.5663, mae: 2.9604, huber: 2.5259, swd: 10.8015, target_std: 20.5432\n",
      "Epoch [15/50], Test Losses: mse: 14.5355, mae: 2.4289, huber: 2.0009, swd: 7.3383, target_std: 18.3439\n",
      "  Epoch 15 composite train-obj: 27.191596\n",
      "        No improvement (26.9671), counter 4/5\n",
      "Epoch [16/50], Train Losses: mse: 21.0907, mae: 2.5856, huber: 2.1617, swd: 12.2070, target_std: 20.3626\n",
      "Epoch [16/50], Val Losses: mse: 21.8892, mae: 2.9939, huber: 2.5595, swd: 11.5438, target_std: 20.5432\n",
      "Epoch [16/50], Test Losses: mse: 14.6050, mae: 2.4304, huber: 2.0044, swd: 7.4036, target_std: 18.3439\n",
      "  Epoch 16 composite train-obj: 27.194248\n",
      "Epoch [16/50], Test Losses: mse: 14.6928, mae: 2.4318, huber: 2.0043, swd: 7.4022, target_std: 18.3439\n",
      "Best round's Test MSE: 14.6928, MAE: 2.4318, SWD: 7.4022\n",
      "Best round's Validation MSE: 21.3115, MAE: 2.9456, SWD: 10.3014\n",
      "Best round's Test verification MSE : 14.6928, MAE: 2.4318, SWD: 7.4022\n",
      "Time taken: 80.91 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.0199, mae: 3.1158, huber: 2.6924, swd: 14.4383, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.2901, mae: 2.9597, huber: 2.5378, swd: 10.0727, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.2761, mae: 2.4704, huber: 2.0452, swd: 7.0743, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 42.239038\n",
      "        Val objective improved inf → 27.3265, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 21.6925, mae: 2.5801, huber: 2.1609, swd: 11.6367, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 21.8377, mae: 2.9434, huber: 2.5189, swd: 10.5656, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 14.9850, mae: 2.4657, huber: 2.0396, swd: 7.1730, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 27.510873\n",
      "        Val objective improved 27.3265 → 27.1206, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.4212, mae: 2.5759, huber: 2.1552, swd: 11.5415, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.6324, mae: 2.9206, huber: 2.4927, swd: 9.8762, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.0578, mae: 2.4779, huber: 2.0481, swd: 7.1719, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 27.191939\n",
      "        Val objective improved 27.1206 → 26.5705, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.2650, mae: 2.5673, huber: 2.1460, swd: 11.4810, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 21.4831, mae: 2.9216, huber: 2.4929, swd: 9.8259, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 14.9075, mae: 2.4141, huber: 1.9909, swd: 6.9375, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 27.005533\n",
      "        Val objective improved 26.5705 → 26.3960, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.2813, mae: 2.5767, huber: 2.1543, swd: 11.4726, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.0278, mae: 2.9566, huber: 2.5255, swd: 10.7010, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.5370, mae: 2.5388, huber: 2.1090, swd: 8.0678, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 27.017645\n",
      "        No improvement (27.3783), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 21.2480, mae: 2.5814, huber: 2.1585, swd: 11.4250, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.4995, mae: 3.0127, huber: 2.5800, swd: 11.5745, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.2340, mae: 2.5101, huber: 2.0813, swd: 7.7567, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 26.960550\n",
      "        No improvement (28.2867), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 21.2588, mae: 2.5845, huber: 2.1612, swd: 11.4393, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.4223, mae: 2.9305, huber: 2.4995, swd: 9.6919, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 14.8924, mae: 2.4375, huber: 2.0142, swd: 6.9385, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 26.978483\n",
      "        Val objective improved 26.3960 → 26.2682, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 21.3251, mae: 2.5934, huber: 2.1699, swd: 11.5117, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.5424, mae: 2.9460, huber: 2.5138, swd: 9.9676, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.5718, mae: 2.4023, huber: 1.9795, swd: 6.7576, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 27.080951\n",
      "        No improvement (26.5262), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 21.1756, mae: 2.5812, huber: 2.1578, swd: 11.3559, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 21.9207, mae: 2.9679, huber: 2.5343, swd: 10.0907, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.2744, mae: 2.4369, huber: 2.0137, swd: 7.3111, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 26.853523\n",
      "        No improvement (26.9660), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 21.2370, mae: 2.5918, huber: 2.1681, swd: 11.4423, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 22.0182, mae: 2.9852, huber: 2.5519, swd: 10.1848, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.7283, mae: 2.4311, huber: 2.0072, swd: 6.8394, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 26.958174\n",
      "        No improvement (27.1107), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.2435, mae: 2.5918, huber: 2.1679, swd: 11.4562, target_std: 20.3633\n",
      "Epoch [11/50], Val Losses: mse: 21.6416, mae: 2.9596, huber: 2.5265, swd: 10.0988, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.7448, mae: 2.4374, huber: 2.0122, swd: 6.9948, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 26.971608\n",
      "        No improvement (26.6910), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.1537, mae: 2.5863, huber: 2.1625, swd: 11.3465, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 21.7762, mae: 2.9887, huber: 2.5526, swd: 10.2364, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 14.6882, mae: 2.4420, huber: 2.0134, swd: 6.7644, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 26.826963\n",
      "Epoch [12/50], Test Losses: mse: 14.8924, mae: 2.4375, huber: 2.0142, swd: 6.9385, target_std: 18.3439\n",
      "Best round's Test MSE: 14.8924, MAE: 2.4375, SWD: 6.9385\n",
      "Best round's Validation MSE: 21.4223, MAE: 2.9305, SWD: 9.6919\n",
      "Best round's Test verification MSE : 14.8924, MAE: 2.4375, SWD: 6.9385\n",
      "Time taken: 54.77 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1415)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 14.8131 ± 0.0865\n",
      "  mae: 2.4363 ± 0.0033\n",
      "  huber: 2.0104 ± 0.0044\n",
      "  swd: 7.2208 ± 0.2023\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 21.3794 ± 0.0486\n",
      "  mae: 2.9349 ± 0.0076\n",
      "  huber: 2.5023 ± 0.0062\n",
      "  swd: 10.0422 ± 0.2570\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 184.69 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1415\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 0.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 0.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a53184",
   "metadata": {},
   "source": [
    "##### MSE + 1.5SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d948cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([336, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 376\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 336, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 376\n",
      "Validation Batches: 50\n",
      "Test Batches: 104\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.6532, mae: 3.1501, huber: 2.7247, swd: 14.2689, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.9741, mae: 3.0216, huber: 2.5961, swd: 10.8322, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 16.0005, mae: 2.5247, huber: 2.0988, swd: 7.9215, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 57.056543\n",
      "        Val objective improved inf → 39.2224, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.1587, mae: 2.6332, huber: 2.2097, swd: 11.9229, target_std: 20.3632\n",
      "Epoch [2/50], Val Losses: mse: 22.9277, mae: 3.0449, huber: 2.6151, swd: 12.0936, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.7185, mae: 2.5604, huber: 2.1295, swd: 8.1641, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 40.043098\n",
      "        No improvement (41.0680), counter 1/5\n",
      "Epoch [3/50], Train Losses: mse: 21.7089, mae: 2.6044, huber: 2.1801, swd: 11.5518, target_std: 20.3631\n",
      "Epoch [3/50], Val Losses: mse: 22.2961, mae: 2.9999, huber: 2.5692, swd: 11.0226, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.2332, mae: 2.4881, huber: 2.0613, swd: 7.3679, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 39.036613\n",
      "        Val objective improved 39.2224 → 38.8299, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.7408, mae: 2.6143, huber: 2.1888, swd: 11.6274, target_std: 20.3628\n",
      "Epoch [4/50], Val Losses: mse: 22.3294, mae: 2.9966, huber: 2.5639, swd: 10.7107, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.6382, mae: 2.4969, huber: 2.0705, swd: 7.8635, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 39.181941\n",
      "        Val objective improved 38.8299 → 38.3956, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.5748, mae: 2.6031, huber: 2.1772, swd: 11.4219, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 22.4035, mae: 3.0192, huber: 2.5849, swd: 10.9964, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.5213, mae: 2.5048, huber: 2.0772, swd: 7.6070, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 38.707682\n",
      "        No improvement (38.8982), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 21.6784, mae: 2.6185, huber: 2.1919, swd: 11.5556, target_std: 20.3628\n",
      "Epoch [6/50], Val Losses: mse: 21.9255, mae: 2.9714, huber: 2.5367, swd: 10.0921, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.3575, mae: 2.4768, huber: 2.0491, swd: 7.5281, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 39.011872\n",
      "        Val objective improved 38.3956 → 37.0636, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 21.7309, mae: 2.6276, huber: 2.2005, swd: 11.5831, target_std: 20.3633\n",
      "Epoch [7/50], Val Losses: mse: 21.6270, mae: 2.9536, huber: 2.5191, swd: 9.8997, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.1505, mae: 2.4623, huber: 2.0358, swd: 7.1765, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 39.105497\n",
      "        Val objective improved 37.0636 → 36.4766, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 21.6111, mae: 2.6176, huber: 2.1908, swd: 11.4742, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.9833, mae: 2.9812, huber: 2.5461, swd: 10.2406, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.0908, mae: 2.4379, huber: 2.0128, swd: 7.1132, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 38.822388\n",
      "        No improvement (37.3442), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 21.5419, mae: 2.6121, huber: 2.1855, swd: 11.3847, target_std: 20.3629\n",
      "Epoch [9/50], Val Losses: mse: 21.9680, mae: 2.9766, huber: 2.5404, swd: 10.2202, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.2365, mae: 2.4792, huber: 2.0512, swd: 7.3725, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 38.618944\n",
      "        No improvement (37.2983), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 21.4755, mae: 2.6095, huber: 2.1824, swd: 11.2908, target_std: 20.3628\n",
      "Epoch [10/50], Val Losses: mse: 22.0433, mae: 3.0105, huber: 2.5733, swd: 10.1499, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.2510, mae: 2.4695, huber: 2.0421, swd: 7.1516, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 38.411685\n",
      "        No improvement (37.2681), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.5415, mae: 2.6188, huber: 2.1916, swd: 11.3221, target_std: 20.3630\n",
      "Epoch [11/50], Val Losses: mse: 22.6491, mae: 3.0468, huber: 2.6096, swd: 11.0555, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 14.9137, mae: 2.4709, huber: 2.0420, swd: 7.0003, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 38.524641\n",
      "        No improvement (39.2324), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.5472, mae: 2.6177, huber: 2.1903, swd: 11.3621, target_std: 20.3632\n",
      "Epoch [12/50], Val Losses: mse: 22.1016, mae: 2.9931, huber: 2.5564, swd: 10.2335, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 15.5162, mae: 2.4840, huber: 2.0568, swd: 7.5500, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 38.590359\n",
      "Epoch [12/50], Test Losses: mse: 15.1505, mae: 2.4623, huber: 2.0358, swd: 7.1765, target_std: 18.3439\n",
      "Best round's Test MSE: 15.1505, MAE: 2.4623, SWD: 7.1765\n",
      "Best round's Validation MSE: 21.6270, MAE: 2.9536, SWD: 9.8997\n",
      "Best round's Test verification MSE : 15.1505, MAE: 2.4623, SWD: 7.1765\n",
      "Time taken: 55.26 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 36.0391, mae: 3.1533, huber: 2.7277, swd: 15.0336, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.6374, mae: 3.0063, huber: 2.5795, swd: 10.5657, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.5923, mae: 2.5112, huber: 2.0828, swd: 7.6668, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 58.589483\n",
      "        Val objective improved inf → 38.4860, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.1473, mae: 2.6272, huber: 2.2038, swd: 12.4201, target_std: 20.3624\n",
      "Epoch [2/50], Val Losses: mse: 21.9360, mae: 2.9513, huber: 2.5219, swd: 10.4775, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3966, mae: 2.4855, huber: 2.0576, swd: 7.8273, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 40.777412\n",
      "        Val objective improved 38.4860 → 37.6523, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.8584, mae: 2.6205, huber: 2.1953, swd: 12.2098, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 22.0462, mae: 2.9659, huber: 2.5354, swd: 10.9556, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.1124, mae: 2.4545, huber: 2.0281, swd: 7.5125, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 40.173082\n",
      "        No improvement (38.4797), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 21.6586, mae: 2.6050, huber: 2.1795, swd: 12.0474, target_std: 20.3630\n",
      "Epoch [4/50], Val Losses: mse: 22.1523, mae: 2.9876, huber: 2.5539, swd: 10.7862, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.6296, mae: 2.5226, huber: 2.0926, swd: 8.1871, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 39.729659\n",
      "        No improvement (38.3316), counter 2/5\n",
      "Epoch [5/50], Train Losses: mse: 21.7190, mae: 2.6206, huber: 2.1941, swd: 12.0541, target_std: 20.3626\n",
      "Epoch [5/50], Val Losses: mse: 21.7936, mae: 2.9533, huber: 2.5194, swd: 10.5212, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.1575, mae: 2.4653, huber: 2.0378, swd: 7.5957, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 39.800124\n",
      "        Val objective improved 37.6523 → 37.5753, saving checkpoint.\n",
      "Epoch [6/50], Train Losses: mse: 21.5851, mae: 2.6121, huber: 2.1855, swd: 11.9359, target_std: 20.3630\n",
      "Epoch [6/50], Val Losses: mse: 22.0187, mae: 2.9690, huber: 2.5346, swd: 10.4723, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.3710, mae: 2.4717, huber: 2.0452, swd: 7.7353, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 39.488853\n",
      "        No improvement (37.7271), counter 1/5\n",
      "Epoch [7/50], Train Losses: mse: 21.6391, mae: 2.6160, huber: 2.1892, swd: 11.9413, target_std: 20.3626\n",
      "Epoch [7/50], Val Losses: mse: 22.1485, mae: 2.9976, huber: 2.5617, swd: 10.5170, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.1633, mae: 2.4733, huber: 2.0456, swd: 7.4575, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 39.551107\n",
      "        No improvement (37.9240), counter 2/5\n",
      "Epoch [8/50], Train Losses: mse: 21.5999, mae: 2.6192, huber: 2.1918, swd: 11.9311, target_std: 20.3633\n",
      "Epoch [8/50], Val Losses: mse: 22.4456, mae: 3.0391, huber: 2.6024, swd: 11.3810, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 15.6364, mae: 2.5433, huber: 2.1133, swd: 8.2817, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 39.496543\n",
      "        No improvement (39.5171), counter 3/5\n",
      "Epoch [9/50], Train Losses: mse: 21.5988, mae: 2.6170, huber: 2.1897, swd: 11.9101, target_std: 20.3624\n",
      "Epoch [9/50], Val Losses: mse: 22.0508, mae: 2.9913, huber: 2.5548, swd: 10.4642, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.2551, mae: 2.4757, huber: 2.0481, swd: 7.6738, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 39.464051\n",
      "        No improvement (37.7471), counter 4/5\n",
      "Epoch [10/50], Train Losses: mse: 21.6841, mae: 2.6315, huber: 2.2039, swd: 11.9967, target_std: 20.3632\n",
      "Epoch [10/50], Val Losses: mse: 21.9192, mae: 2.9896, huber: 2.5524, swd: 10.4843, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 15.0557, mae: 2.4710, huber: 2.0414, swd: 7.5128, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 39.679105\n",
      "Epoch [10/50], Test Losses: mse: 15.1575, mae: 2.4653, huber: 2.0378, swd: 7.5957, target_std: 18.3439\n",
      "Best round's Test MSE: 15.1575, MAE: 2.4653, SWD: 7.5957\n",
      "Best round's Validation MSE: 21.7936, MAE: 2.9533, SWD: 10.5212\n",
      "Best round's Test verification MSE : 15.1575, MAE: 2.4653, SWD: 7.5957\n",
      "Time taken: 46.39 seconds\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 35.7490, mae: 3.1521, huber: 2.7266, swd: 14.0160, target_std: 20.3632\n",
      "Epoch [1/50], Val Losses: mse: 22.6705, mae: 2.9995, huber: 2.5736, swd: 10.0509, target_std: 20.5432\n",
      "Epoch [1/50], Test Losses: mse: 15.5544, mae: 2.5236, huber: 2.0940, swd: 7.1096, target_std: 18.3439\n",
      "  Epoch 1 composite train-obj: 56.772985\n",
      "        Val objective improved inf → 37.7469, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 22.0712, mae: 2.6208, huber: 2.1976, swd: 11.4293, target_std: 20.3626\n",
      "Epoch [2/50], Val Losses: mse: 22.0556, mae: 2.9630, huber: 2.5346, swd: 9.9761, target_std: 20.5432\n",
      "Epoch [2/50], Test Losses: mse: 15.3203, mae: 2.5044, huber: 2.0751, swd: 7.0784, target_std: 18.3439\n",
      "  Epoch 2 composite train-obj: 39.215179\n",
      "        Val objective improved 37.7469 → 37.0197, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 21.8485, mae: 2.6193, huber: 2.1944, swd: 11.3273, target_std: 20.3626\n",
      "Epoch [3/50], Val Losses: mse: 21.8508, mae: 2.9457, huber: 2.5151, swd: 9.6620, target_std: 20.5432\n",
      "Epoch [3/50], Test Losses: mse: 15.4133, mae: 2.5094, huber: 2.0790, swd: 7.3674, target_std: 18.3439\n",
      "  Epoch 3 composite train-obj: 38.839432\n",
      "        Val objective improved 37.0197 → 36.3437, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 21.7442, mae: 2.6140, huber: 2.1886, swd: 11.3045, target_std: 20.3629\n",
      "Epoch [4/50], Val Losses: mse: 21.7392, mae: 2.9492, huber: 2.5175, swd: 9.6083, target_std: 20.5432\n",
      "Epoch [4/50], Test Losses: mse: 15.0815, mae: 2.4396, huber: 2.0140, swd: 6.8389, target_std: 18.3439\n",
      "  Epoch 4 composite train-obj: 38.700926\n",
      "        Val objective improved 36.3437 → 36.1516, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 21.6611, mae: 2.6129, huber: 2.1869, swd: 11.1798, target_std: 20.3630\n",
      "Epoch [5/50], Val Losses: mse: 22.1085, mae: 2.9785, huber: 2.5447, swd: 10.2306, target_std: 20.5432\n",
      "Epoch [5/50], Test Losses: mse: 15.5161, mae: 2.5435, huber: 2.1117, swd: 7.6163, target_std: 18.3439\n",
      "  Epoch 5 composite train-obj: 38.430830\n",
      "        No improvement (37.4545), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 21.6033, mae: 2.6148, huber: 2.1883, swd: 11.0868, target_std: 20.3626\n",
      "Epoch [6/50], Val Losses: mse: 22.3414, mae: 3.0045, huber: 2.5707, swd: 10.5254, target_std: 20.5432\n",
      "Epoch [6/50], Test Losses: mse: 15.3517, mae: 2.5099, huber: 2.0823, swd: 7.4497, target_std: 18.3439\n",
      "  Epoch 6 composite train-obj: 38.233545\n",
      "        No improvement (38.1294), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 21.5813, mae: 2.6127, huber: 2.1860, swd: 11.0681, target_std: 20.3629\n",
      "Epoch [7/50], Val Losses: mse: 21.5728, mae: 2.9546, huber: 2.5204, swd: 9.2471, target_std: 20.5432\n",
      "Epoch [7/50], Test Losses: mse: 15.3287, mae: 2.4814, huber: 2.0550, swd: 7.0964, target_std: 18.3439\n",
      "  Epoch 7 composite train-obj: 38.183433\n",
      "        Val objective improved 36.1516 → 35.4434, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 21.6332, mae: 2.6230, huber: 2.1960, swd: 11.1136, target_std: 20.3629\n",
      "Epoch [8/50], Val Losses: mse: 21.8389, mae: 2.9800, huber: 2.5444, swd: 9.7837, target_std: 20.5432\n",
      "Epoch [8/50], Test Losses: mse: 14.8891, mae: 2.4424, huber: 2.0158, swd: 6.6769, target_std: 18.3439\n",
      "  Epoch 8 composite train-obj: 38.303539\n",
      "        No improvement (36.5145), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 21.5415, mae: 2.6146, huber: 2.1875, swd: 11.0342, target_std: 20.3634\n",
      "Epoch [9/50], Val Losses: mse: 22.3035, mae: 3.0114, huber: 2.5749, swd: 10.1074, target_std: 20.5432\n",
      "Epoch [9/50], Test Losses: mse: 15.6162, mae: 2.4911, huber: 2.0640, swd: 7.3237, target_std: 18.3439\n",
      "  Epoch 9 composite train-obj: 38.092757\n",
      "        No improvement (37.4646), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 21.5745, mae: 2.6222, huber: 2.1950, swd: 11.0894, target_std: 20.3631\n",
      "Epoch [10/50], Val Losses: mse: 21.9452, mae: 2.9921, huber: 2.5563, swd: 9.6709, target_std: 20.5432\n",
      "Epoch [10/50], Test Losses: mse: 14.9360, mae: 2.4555, huber: 2.0294, swd: 6.6415, target_std: 18.3439\n",
      "  Epoch 10 composite train-obj: 38.208659\n",
      "        No improvement (36.4515), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 21.5913, mae: 2.6241, huber: 2.1966, swd: 11.1253, target_std: 20.3633\n",
      "Epoch [11/50], Val Losses: mse: 22.5144, mae: 3.0345, huber: 2.5980, swd: 10.7542, target_std: 20.5432\n",
      "Epoch [11/50], Test Losses: mse: 15.2544, mae: 2.5029, huber: 2.0741, swd: 7.0598, target_std: 18.3439\n",
      "  Epoch 11 composite train-obj: 38.279287\n",
      "        No improvement (38.6458), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 21.5144, mae: 2.6195, huber: 2.1921, swd: 11.0422, target_std: 20.3627\n",
      "Epoch [12/50], Val Losses: mse: 22.0370, mae: 3.0143, huber: 2.5757, swd: 9.8106, target_std: 20.5432\n",
      "Epoch [12/50], Test Losses: mse: 15.0773, mae: 2.4766, huber: 2.0460, swd: 6.6650, target_std: 18.3439\n",
      "  Epoch 12 composite train-obj: 38.077652\n",
      "Epoch [12/50], Test Losses: mse: 15.3287, mae: 2.4814, huber: 2.0550, swd: 7.0964, target_std: 18.3439\n",
      "Best round's Test MSE: 15.3287, MAE: 2.4814, SWD: 7.0964\n",
      "Best round's Validation MSE: 21.5728, MAE: 2.9546, SWD: 9.2471\n",
      "Best round's Test verification MSE : 15.3287, MAE: 2.4814, SWD: 7.0964\n",
      "Time taken: 53.13 seconds\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred336_20250508_1424)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 15.2122 ± 0.0824\n",
      "  mae: 2.4696 ± 0.0084\n",
      "  huber: 2.0428 ± 0.0086\n",
      "  swd: 7.2895 ± 0.2190\n",
      "  target_std: 18.3439 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 21.6645 ± 0.0939\n",
      "  mae: 2.9538 ± 0.0006\n",
      "  huber: 2.5196 ± 0.0005\n",
      "  swd: 9.8893 ± 0.5202\n",
      "  target_std: 20.5432 ± 0.0000\n",
      "  count: 50.0000 ± 0.0000\n",
      "==================================================\n",
      "Three seeds Time taken: 154.84 seconds\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred336_20250508_1424\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 336\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=336,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    "    loss_backward_weights = [1.0, 0.0, 0.0, 1.5, 0.0],\n",
    "    loss_validate_weights = [1.0, 0.0, 0.0, 1.5, 0.0],\n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccb410",
   "metadata": {},
   "source": [
    "#### pred=720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "270e5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules...\n",
      "  Reloaded: utils\n",
      "Module reload complete.\n",
      "Shape of training data: torch.Size([48776, 7])\n",
      "Shape of validation data: torch.Size([6968, 7])\n",
      "Shape of testing data: torch.Size([13936, 7])\n",
      "Train set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Validation set sample shapes: torch.Size([336, 7]), torch.Size([720, 7])\n",
      "Test set data shapes: torch.Size([13936, 7]), torch.Size([13936, 7])\n",
      "Number of batches in train_loader: 373\n",
      "Batch 0: Data shape torch.Size([128, 336, 7]), Target shape torch.Size([128, 720, 7])\n",
      "\n",
      "==================================================\n",
      "Data Preparation: ettm2\n",
      "==================================================\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Batch Size: 128\n",
      "Scaling: No\n",
      "Train Split: 0.7\n",
      "Val Split: 0.8\n",
      "Training Batches: 373\n",
      "Validation Batches: 47\n",
      "Test Batches: 101\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 1955 (1/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 39.9552, mae: 3.3089, huber: 2.8861, swd: 17.9193, target_std: 20.3713\n",
      "Epoch [1/50], Val Losses: mse: 26.9272, mae: 3.3462, huber: 2.9194, swd: 11.8173, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.6534, mae: 2.6797, huber: 2.2547, swd: 8.2273, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.886062\n",
      "        Val objective improved inf → 2.9194, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.6730, mae: 2.9381, huber: 2.5198, swd: 15.4299, target_std: 20.3717\n",
      "Epoch [2/50], Val Losses: mse: 26.5898, mae: 3.3199, huber: 2.8926, swd: 11.6730, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.4718, mae: 2.6540, huber: 2.2306, swd: 8.2011, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.519806\n",
      "        Val objective improved 2.9194 → 2.8926, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 29.5348, mae: 2.9327, huber: 2.5143, swd: 15.2960, target_std: 20.3717\n",
      "Epoch [3/50], Val Losses: mse: 26.6051, mae: 3.3187, huber: 2.8900, swd: 11.6143, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.5840, mae: 2.6984, huber: 2.2701, swd: 8.2806, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.514263\n",
      "        Val objective improved 2.8926 → 2.8900, saving checkpoint.\n",
      "Epoch [4/50], Train Losses: mse: 29.4599, mae: 2.9326, huber: 2.5138, swd: 15.2137, target_std: 20.3713\n",
      "Epoch [4/50], Val Losses: mse: 26.7850, mae: 3.3256, huber: 2.8971, swd: 11.7522, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.6260, mae: 2.6657, huber: 2.2416, swd: 8.2458, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.513838\n",
      "        No improvement (2.8971), counter 1/5\n",
      "Epoch [5/50], Train Losses: mse: 29.3868, mae: 2.9283, huber: 2.5096, swd: 15.1497, target_std: 20.3719\n",
      "Epoch [5/50], Val Losses: mse: 26.6998, mae: 3.3351, huber: 2.9050, swd: 11.7424, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.3875, mae: 2.6554, huber: 2.2316, swd: 8.0588, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.509555\n",
      "        No improvement (2.9050), counter 2/5\n",
      "Epoch [6/50], Train Losses: mse: 29.3344, mae: 2.9271, huber: 2.5082, swd: 15.1037, target_std: 20.3721\n",
      "Epoch [6/50], Val Losses: mse: 26.7414, mae: 3.3311, huber: 2.9014, swd: 11.7697, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.2188, mae: 2.6463, huber: 2.2210, swd: 7.9810, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.508188\n",
      "        No improvement (2.9014), counter 3/5\n",
      "Epoch [7/50], Train Losses: mse: 29.3133, mae: 2.9271, huber: 2.5081, swd: 15.0704, target_std: 20.3714\n",
      "Epoch [7/50], Val Losses: mse: 26.7337, mae: 3.3238, huber: 2.8940, swd: 11.6511, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 17.4418, mae: 2.6594, huber: 2.2337, swd: 8.1224, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.508059\n",
      "        No improvement (2.8940), counter 4/5\n",
      "Epoch [8/50], Train Losses: mse: 29.2000, mae: 2.9173, huber: 2.4984, swd: 15.0065, target_std: 20.3715\n",
      "Epoch [8/50], Val Losses: mse: 26.2270, mae: 3.2885, huber: 2.8592, swd: 11.3441, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 17.6693, mae: 2.6692, huber: 2.2445, swd: 8.3385, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.498441\n",
      "        Val objective improved 2.8900 → 2.8592, saving checkpoint.\n",
      "Epoch [9/50], Train Losses: mse: 29.2428, mae: 2.9237, huber: 2.5047, swd: 15.0138, target_std: 20.3712\n",
      "Epoch [9/50], Val Losses: mse: 26.5556, mae: 3.3155, huber: 2.8857, swd: 11.4498, target_std: 20.5636\n",
      "Epoch [9/50], Test Losses: mse: 17.4042, mae: 2.6697, huber: 2.2438, swd: 8.1714, target_std: 18.3446\n",
      "  Epoch 9 composite train-obj: 2.504727\n",
      "        No improvement (2.8857), counter 1/5\n",
      "Epoch [10/50], Train Losses: mse: 29.2169, mae: 2.9240, huber: 2.5049, swd: 15.0005, target_std: 20.3712\n",
      "Epoch [10/50], Val Losses: mse: 27.2624, mae: 3.3703, huber: 2.9397, swd: 12.4531, target_std: 20.5636\n",
      "Epoch [10/50], Test Losses: mse: 17.2164, mae: 2.6760, huber: 2.2483, swd: 8.0201, target_std: 18.3446\n",
      "  Epoch 10 composite train-obj: 2.504854\n",
      "        No improvement (2.9397), counter 2/5\n",
      "Epoch [11/50], Train Losses: mse: 29.1582, mae: 2.9183, huber: 2.4993, swd: 14.9434, target_std: 20.3713\n",
      "Epoch [11/50], Val Losses: mse: 27.0626, mae: 3.3607, huber: 2.9303, swd: 11.9538, target_std: 20.5636\n",
      "Epoch [11/50], Test Losses: mse: 17.0542, mae: 2.6449, huber: 2.2193, swd: 7.8434, target_std: 18.3446\n",
      "  Epoch 11 composite train-obj: 2.499302\n",
      "        No improvement (2.9303), counter 3/5\n",
      "Epoch [12/50], Train Losses: mse: 29.1598, mae: 2.9194, huber: 2.5005, swd: 14.9266, target_std: 20.3720\n",
      "Epoch [12/50], Val Losses: mse: 26.7115, mae: 3.3328, huber: 2.9026, swd: 11.8121, target_std: 20.5636\n",
      "Epoch [12/50], Test Losses: mse: 17.0810, mae: 2.6509, huber: 2.2246, swd: 7.9115, target_std: 18.3446\n",
      "  Epoch 12 composite train-obj: 2.500465\n",
      "        No improvement (2.9026), counter 4/5\n",
      "Epoch [13/50], Train Losses: mse: 29.1527, mae: 2.9211, huber: 2.5020, swd: 14.9143, target_std: 20.3716\n",
      "Epoch [13/50], Val Losses: mse: 26.7752, mae: 3.3451, huber: 2.9149, swd: 11.7625, target_std: 20.5636\n",
      "Epoch [13/50], Test Losses: mse: 17.0322, mae: 2.6372, huber: 2.2119, swd: 7.7758, target_std: 18.3446\n",
      "  Epoch 13 composite train-obj: 2.501980\n",
      "Epoch [13/50], Test Losses: mse: 17.6693, mae: 2.6692, huber: 2.2445, swd: 8.3385, target_std: 18.3446\n",
      "Best round's Test MSE: 17.6693, MAE: 2.6692, SWD: 8.3385\n",
      "Best round's Validation MSE: 26.2270, MAE: 3.2885\n",
      "Best round's Test verification MSE : 17.6693, MAE: 2.6692, SWD: 8.3385\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 7 (2/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 39.4060, mae: 3.3005, huber: 2.8777, swd: 16.4075, target_std: 20.3714\n",
      "Epoch [1/50], Val Losses: mse: 26.9368, mae: 3.3399, huber: 2.9137, swd: 10.7853, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.7907, mae: 2.6873, huber: 2.2621, swd: 7.7698, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.877713\n",
      "        Val objective improved inf → 2.9137, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.7604, mae: 2.9437, huber: 2.5255, swd: 14.2819, target_std: 20.3717\n",
      "Epoch [2/50], Val Losses: mse: 26.7617, mae: 3.3206, huber: 2.8937, swd: 10.7448, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.6017, mae: 2.6703, huber: 2.2449, swd: 7.7118, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.525457\n",
      "        Val objective improved 2.9137 → 2.8937, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 29.5409, mae: 2.9360, huber: 2.5175, swd: 14.1225, target_std: 20.3712\n",
      "Epoch [3/50], Val Losses: mse: 26.9555, mae: 3.3404, huber: 2.9122, swd: 10.7582, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.7748, mae: 2.6789, huber: 2.2531, swd: 7.6412, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.517475\n",
      "        No improvement (2.9122), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 29.4452, mae: 2.9309, huber: 2.5121, swd: 14.0518, target_std: 20.3718\n",
      "Epoch [4/50], Val Losses: mse: 26.3767, mae: 3.2995, huber: 2.8713, swd: 10.6045, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.6348, mae: 2.6809, huber: 2.2564, swd: 7.8327, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.512112\n",
      "        Val objective improved 2.8937 → 2.8713, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 29.3390, mae: 2.9264, huber: 2.5076, swd: 13.9510, target_std: 20.3718\n",
      "Epoch [5/50], Val Losses: mse: 26.4439, mae: 3.3027, huber: 2.8741, swd: 10.5955, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.4367, mae: 2.6576, huber: 2.2329, swd: 7.6066, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.507598\n",
      "        No improvement (2.8741), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 29.3638, mae: 2.9290, huber: 2.5100, swd: 13.9701, target_std: 20.3714\n",
      "Epoch [6/50], Val Losses: mse: 26.7163, mae: 3.3322, huber: 2.9023, swd: 10.6916, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.2304, mae: 2.6486, huber: 2.2231, swd: 7.4307, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.509985\n",
      "        No improvement (2.9023), counter 2/5\n",
      "Epoch [7/50], Train Losses: mse: 29.2693, mae: 2.9218, huber: 2.5029, swd: 13.9000, target_std: 20.3711\n",
      "Epoch [7/50], Val Losses: mse: 26.3563, mae: 3.2973, huber: 2.8684, swd: 10.5994, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 17.5141, mae: 2.6737, huber: 2.2486, swd: 7.8377, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.502948\n",
      "        Val objective improved 2.8713 → 2.8684, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 29.2716, mae: 2.9252, huber: 2.5061, swd: 13.8935, target_std: 20.3714\n",
      "Epoch [8/50], Val Losses: mse: 26.6956, mae: 3.3304, huber: 2.9008, swd: 10.8582, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 17.2657, mae: 2.6646, huber: 2.2396, swd: 7.6075, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.506149\n",
      "        No improvement (2.9008), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 29.2045, mae: 2.9212, huber: 2.5022, swd: 13.8333, target_std: 20.3710\n",
      "Epoch [9/50], Val Losses: mse: 26.7266, mae: 3.3281, huber: 2.8979, swd: 10.6188, target_std: 20.5636\n",
      "Epoch [9/50], Test Losses: mse: 17.5011, mae: 2.6573, huber: 2.2317, swd: 7.5231, target_std: 18.3446\n",
      "  Epoch 9 composite train-obj: 2.502175\n",
      "        No improvement (2.8979), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 29.2239, mae: 2.9244, huber: 2.5053, swd: 13.8247, target_std: 20.3716\n",
      "Epoch [10/50], Val Losses: mse: 26.4871, mae: 3.3112, huber: 2.8816, swd: 10.6399, target_std: 20.5636\n",
      "Epoch [10/50], Test Losses: mse: 17.4306, mae: 2.6635, huber: 2.2391, swd: 7.5814, target_std: 18.3446\n",
      "  Epoch 10 composite train-obj: 2.505342\n",
      "        No improvement (2.8816), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 29.2413, mae: 2.9255, huber: 2.5063, swd: 13.8466, target_std: 20.3711\n",
      "Epoch [11/50], Val Losses: mse: 27.0833, mae: 3.3595, huber: 2.9282, swd: 10.6945, target_std: 20.5636\n",
      "Epoch [11/50], Test Losses: mse: 17.5425, mae: 2.6595, huber: 2.2341, swd: 7.5939, target_std: 18.3446\n",
      "  Epoch 11 composite train-obj: 2.506340\n",
      "        No improvement (2.9282), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 29.1557, mae: 2.9193, huber: 2.5003, swd: 13.7916, target_std: 20.3719\n",
      "Epoch [12/50], Val Losses: mse: 26.7969, mae: 3.3389, huber: 2.9083, swd: 10.4964, target_std: 20.5636\n",
      "Epoch [12/50], Test Losses: mse: 17.4697, mae: 2.6522, huber: 2.2282, swd: 7.4339, target_std: 18.3446\n",
      "  Epoch 12 composite train-obj: 2.500283\n",
      "Epoch [12/50], Test Losses: mse: 17.5141, mae: 2.6737, huber: 2.2486, swd: 7.8377, target_std: 18.3446\n",
      "Best round's Test MSE: 17.5141, MAE: 2.6737, SWD: 7.8377\n",
      "Best round's Validation MSE: 26.3563, MAE: 3.2973\n",
      "Best round's Test verification MSE : 17.5141, MAE: 2.6737, SWD: 7.8377\n",
      "\n",
      "==================================================\n",
      " Running experiment with seed 20 (3/3)==================================================\n",
      "\n",
      "Epoch [1/50], Train Losses: mse: 39.6208, mae: 3.3048, huber: 2.8820, swd: 18.7670, target_std: 20.3715\n",
      "Epoch [1/50], Val Losses: mse: 26.6070, mae: 3.3223, huber: 2.8960, swd: 11.9806, target_std: 20.5636\n",
      "Epoch [1/50], Test Losses: mse: 17.6644, mae: 2.6876, huber: 2.2621, swd: 8.7749, target_std: 18.3446\n",
      "  Epoch 1 composite train-obj: 2.881968\n",
      "        Val objective improved inf → 2.8960, saving checkpoint.\n",
      "Epoch [2/50], Train Losses: mse: 29.7440, mae: 2.9431, huber: 2.5248, swd: 16.1995, target_std: 20.3716\n",
      "Epoch [2/50], Val Losses: mse: 26.5888, mae: 3.3156, huber: 2.8889, swd: 12.1235, target_std: 20.5636\n",
      "Epoch [2/50], Test Losses: mse: 17.5146, mae: 2.6768, huber: 2.2516, swd: 8.6399, target_std: 18.3446\n",
      "  Epoch 2 composite train-obj: 2.524759\n",
      "        Val objective improved 2.8960 → 2.8889, saving checkpoint.\n",
      "Epoch [3/50], Train Losses: mse: 29.4869, mae: 2.9305, huber: 2.5121, swd: 15.9920, target_std: 20.3713\n",
      "Epoch [3/50], Val Losses: mse: 26.8780, mae: 3.3376, huber: 2.9093, swd: 12.1396, target_std: 20.5636\n",
      "Epoch [3/50], Test Losses: mse: 17.4328, mae: 2.6483, huber: 2.2244, swd: 8.4640, target_std: 18.3446\n",
      "  Epoch 3 composite train-obj: 2.512134\n",
      "        No improvement (2.9093), counter 1/5\n",
      "Epoch [4/50], Train Losses: mse: 29.4468, mae: 2.9318, huber: 2.5131, swd: 15.9430, target_std: 20.3715\n",
      "Epoch [4/50], Val Losses: mse: 26.5417, mae: 3.3091, huber: 2.8803, swd: 12.0585, target_std: 20.5636\n",
      "Epoch [4/50], Test Losses: mse: 17.5044, mae: 2.6713, huber: 2.2449, swd: 8.5754, target_std: 18.3446\n",
      "  Epoch 4 composite train-obj: 2.513096\n",
      "        Val objective improved 2.8889 → 2.8803, saving checkpoint.\n",
      "Epoch [5/50], Train Losses: mse: 29.3983, mae: 2.9284, huber: 2.5097, swd: 15.8980, target_std: 20.3714\n",
      "Epoch [5/50], Val Losses: mse: 26.6165, mae: 3.3170, huber: 2.8863, swd: 11.9775, target_std: 20.5636\n",
      "Epoch [5/50], Test Losses: mse: 17.6490, mae: 2.6706, huber: 2.2453, swd: 8.6894, target_std: 18.3446\n",
      "  Epoch 5 composite train-obj: 2.509652\n",
      "        No improvement (2.8863), counter 1/5\n",
      "Epoch [6/50], Train Losses: mse: 29.2769, mae: 2.9230, huber: 2.5041, swd: 15.7917, target_std: 20.3715\n",
      "Epoch [6/50], Val Losses: mse: 26.4862, mae: 3.3085, huber: 2.8787, swd: 11.9285, target_std: 20.5636\n",
      "Epoch [6/50], Test Losses: mse: 17.4301, mae: 2.6720, huber: 2.2445, swd: 8.5661, target_std: 18.3446\n",
      "  Epoch 6 composite train-obj: 2.504082\n",
      "        Val objective improved 2.8803 → 2.8787, saving checkpoint.\n",
      "Epoch [7/50], Train Losses: mse: 29.2249, mae: 2.9183, huber: 2.4995, swd: 15.7644, target_std: 20.3718\n",
      "Epoch [7/50], Val Losses: mse: 26.1421, mae: 3.2764, huber: 2.8479, swd: 11.6142, target_std: 20.5636\n",
      "Epoch [7/50], Test Losses: mse: 17.9922, mae: 2.7056, huber: 2.2794, swd: 9.1068, target_std: 18.3446\n",
      "  Epoch 7 composite train-obj: 2.499509\n",
      "        Val objective improved 2.8787 → 2.8479, saving checkpoint.\n",
      "Epoch [8/50], Train Losses: mse: 29.2758, mae: 2.9243, huber: 2.5053, swd: 15.7569, target_std: 20.3714\n",
      "Epoch [8/50], Val Losses: mse: 26.6361, mae: 3.3331, huber: 2.9030, swd: 12.0793, target_std: 20.5636\n",
      "Epoch [8/50], Test Losses: mse: 17.1603, mae: 2.6442, huber: 2.2200, swd: 8.3704, target_std: 18.3446\n",
      "  Epoch 8 composite train-obj: 2.505325\n",
      "        No improvement (2.9030), counter 1/5\n",
      "Epoch [9/50], Train Losses: mse: 29.2824, mae: 2.9266, huber: 2.5075, swd: 15.7631, target_std: 20.3712\n",
      "Epoch [9/50], Val Losses: mse: 26.5460, mae: 3.3225, huber: 2.8927, swd: 11.9462, target_std: 20.5636\n",
      "Epoch [9/50], Test Losses: mse: 17.2533, mae: 2.6454, huber: 2.2217, swd: 8.5019, target_std: 18.3446\n",
      "  Epoch 9 composite train-obj: 2.507501\n",
      "        No improvement (2.8927), counter 2/5\n",
      "Epoch [10/50], Train Losses: mse: 29.2151, mae: 2.9223, huber: 2.5033, swd: 15.7250, target_std: 20.3713\n",
      "Epoch [10/50], Val Losses: mse: 26.6465, mae: 3.3229, huber: 2.8935, swd: 11.9601, target_std: 20.5636\n",
      "Epoch [10/50], Test Losses: mse: 17.3060, mae: 2.6522, huber: 2.2269, swd: 8.3688, target_std: 18.3446\n",
      "  Epoch 10 composite train-obj: 2.503323\n",
      "        No improvement (2.8935), counter 3/5\n",
      "Epoch [11/50], Train Losses: mse: 29.1765, mae: 2.9202, huber: 2.5012, swd: 15.6635, target_std: 20.3709\n",
      "Epoch [11/50], Val Losses: mse: 26.4957, mae: 3.3176, huber: 2.8874, swd: 11.8667, target_std: 20.5636\n",
      "Epoch [11/50], Test Losses: mse: 17.3256, mae: 2.6475, huber: 2.2235, swd: 8.3624, target_std: 18.3446\n",
      "  Epoch 11 composite train-obj: 2.501183\n",
      "        No improvement (2.8874), counter 4/5\n",
      "Epoch [12/50], Train Losses: mse: 29.1771, mae: 2.9222, huber: 2.5030, swd: 15.6567, target_std: 20.3712\n",
      "Epoch [12/50], Val Losses: mse: 26.7011, mae: 3.3246, huber: 2.8942, swd: 11.8450, target_std: 20.5636\n",
      "Epoch [12/50], Test Losses: mse: 17.6302, mae: 2.6538, huber: 2.2307, swd: 8.7350, target_std: 18.3446\n",
      "  Epoch 12 composite train-obj: 2.503040\n",
      "Epoch [12/50], Test Losses: mse: 17.9922, mae: 2.7056, huber: 2.2794, swd: 9.1068, target_std: 18.3446\n",
      "Best round's Test MSE: 17.9922, MAE: 2.7056, SWD: 9.1068\n",
      "Best round's Validation MSE: 26.1421, MAE: 3.2764\n",
      "Best round's Test verification MSE : 17.9922, MAE: 2.7056, SWD: 9.1068\n",
      "\n",
      "==================================================\n",
      "Experiment Summary (DLinear_ettm2_seq336_pred720_20250430_2023)\n",
      "==================================================\n",
      "Number of runs: 3\n",
      "Seeds: [1955, 7, 20]\n",
      "\n",
      "Test Performance at Best Validation (mean ± std):\n",
      "  mse: 17.7252 ± 0.1991\n",
      "  mae: 2.6828 ± 0.0162\n",
      "  huber: 2.2575 ± 0.0156\n",
      "  swd: 8.4277 ± 0.5219\n",
      "  target_std: 18.3446 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "\n",
      "Corresponding Validation Performance (mean ± std):\n",
      "  mse: 26.2418 ± 0.0881\n",
      "  mae: 3.2874 ± 0.0086\n",
      "  huber: 2.8585 ± 0.0084\n",
      "  swd: 11.1859 ± 0.4291\n",
      "  target_std: 20.5636 ± 0.0000\n",
      "  count: 47.0000 ± 0.0000\n",
      "==================================================\n",
      "\n",
      "Experiment complete: DLinear_ettm2_seq336_pred720_20250430_2023\n",
      "Model: DLinear\n",
      "Dataset: ettm2\n",
      "Sequence Length: 336\n",
      "Prediction Length: 720\n",
      "Seeds: [1955, 7, 20]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(monotonic)\n",
    "importlib.reload(train_config)\n",
    "utils.reload_modules([utils])\n",
    "cfg = train_config.FlatDLinearConfig(\n",
    "    seq_len=336,\n",
    "    pred_len=720,\n",
    "    channels=data_mgr.datasets['ettm2']['channels'],\n",
    "    batch_size=128,\n",
    "    learning_rate=9e-4,\n",
    "    seeds=[1955, 7, 20],\n",
    "    epochs=50, \n",
    ")\n",
    "exp = execute_model_evaluation('ettm2', cfg, data_mgr, scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f79ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba906049",
   "metadata": {
    "tags": [
     "split"
    ]
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ww",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
